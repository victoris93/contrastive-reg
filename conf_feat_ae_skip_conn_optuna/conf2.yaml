defaults:
  - override hydra/sweeper: optuna
  - override hydra/job_logging: disabled

project: "optuna on feature autoencoder with logeuclidean loss"
experiment_name: "test optuna"
hypothesis: "first test on optuna"

# Training parameters
multi_gpu: False
num_epochs: 30
batch_size: 32
lr : 0.001
weight_initialization: eigen # if eigen then initialization as in D'Souza, if classic, He initialization
weight_decay: 0
dropout_rate: 0
kfolds: 5
ReEig: False
skip_enc1: True
scheduler_patience: 10

# Model dimensions
input_dim_feat: 100
output_dim_feat: 10

# Loss function and optimizer
loss_function: LogEuclidean # Options: LogEuclidean, Norm

# Paths for data
dataset_path: "/data/parietal/store2/work/mrenaudi/contrastive-reg-3/dataset_100parcels_with_age_2.nc"
targets:
- benton_faces_total

# Directory for saving results
original_dir: original
reconstructed_dir: reconstructed
tensorboard_dir: tensorboard
model_weight_dir: weights
branch_name: feat_ae_skip_conn
output_dir: "/data/parietal/store2/work/mrenaudi/contrastive-reg-3/hydra/${branch_name}"

# Hydra-Optuna sweeper configuration
hydra:
  sweeper:
    sampler:
      _target_: optuna.samplers.TPESampler  # Explicitly specify the sampler (optional)
      seed: 123  # Seed for reproducibility; set to None for randomness
    direction: minimize
    study_name: feature_autoencoder_study
    storage: null
    n_trials: 20
    n_jobs: 1
    params:
      lr: tag(log,interval(1e-7, 1e-1))
      batch_size: choice(10, 20, 32, 40, 50)
      output_dim_feat: choice(10, 20, 30, 40, 50, 60, 70, 80)
      weight_decay: tag(log, interval(1e-6, 1e-1))
      #loss_function : choice("Norm", "LogEuclidean")