{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99de795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "from scipy.stats import pearsonr\n",
    "from cmath import isinf\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "from cmath import isinf\n",
    "from sklearn.model_selection import train_test_split, KFold, LearningCurveDisplay, learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "import multiprocessing\n",
    "from skorch import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d147112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5aa9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim_feat = 499500, input_dim_target = 1, hidden_dim_feat = 1000, output_dim = 2, dropout_rate = 0):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Xavier initialization for feature MLP\n",
    "        self.feat_mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim_feat),\n",
    "            nn.Linear(input_dim_feat, hidden_dim_feat),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(hidden_dim_feat, output_dim)\n",
    "        )\n",
    "        self.init_weights(self.feat_mlp)\n",
    "\n",
    "        # Xavier initialization for target MLP\n",
    "        self.target_mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim_target),\n",
    "            nn.Linear(input_dim_target, output_dim)\n",
    "        )\n",
    "        self.init_weights(self.target_mlp)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        print(x, y)\n",
    "        features = self.feat_mlp(x)\n",
    "        targets = self.target_mlp(y)\n",
    "        features = nn.functional.normalize(features, p=2, dim=1)\n",
    "        targets = nn.functional.normalize(targets, p=2, dim=1)\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5caa4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatData(Dataset):\n",
    "    def __init__(self, path_feat, path_target, target_name, transform = None, train=True, train_size = 0.8, test_size=None, test_site = None, regions = None, threshold_mat = False, threshold_percent = None, random_state=42):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with the capability to handle training and testing splits, \n",
    "        including multiple views for augmented data.\n",
    "        \n",
    "        Args:\n",
    "            path_feat (str): Path to the features file.\n",
    "            path_target (str): Path to the target file.\n",
    "            transform (callable): A transformation function to apply for augmentation.\n",
    "            train (bool): Whether the dataset is used for training. False will load the test set.\n",
    "            test_size (float): Proportion of the dataset to include in the test split.\n",
    "            random_state (int): Random state for reproducible train-test splits.\n",
    "        \"\"\"\n",
    "        # Load the entire dataset\n",
    "        features = np.load(path_feat)      \n",
    "        participant_data = pd.read_csv(path_target)\n",
    "        targets = np.expand_dims(participant_data[target_name].values, axis = 1)\n",
    "        \n",
    "\n",
    "        # Split the dataset into training and test sets\n",
    "        if test_site is None:\n",
    "            train_indices, test_indices = train_test_split(np.arange(len(features)), \n",
    "                                                       train_size = train_size,\n",
    "                                                       test_size=test_size,                \n",
    "                                                       random_state=random_state)\n",
    "        else:\n",
    "            test_indices = participant_data.index[participant_data['dataset'] == test_site].values\n",
    "            train_indices = np.delete(np.arange(len(features)), test_indices)\n",
    "        \n",
    "        if train:\n",
    "            selected_indices = train_indices\n",
    "        else:\n",
    "            selected_indices = test_indices\n",
    "        \n",
    "        # Select the subset of data for the current mode (train/test)\n",
    "        features = features[selected_indices]\n",
    "        if threshold_mat:\n",
    "            thresholded_feat = []\n",
    "            for matrix in features:\n",
    "                threshold = np.percentile(matrix, threshold_percent)\n",
    "                matrix[matrix < threshold] = 0\n",
    "                thresholded_feat.append(matrix)\n",
    "            threshold_feat = np.stack(thresholded_feat)\n",
    "            features = threshold_feat\n",
    "        targets = targets[selected_indices]\n",
    "        \n",
    "\n",
    "        self.n_sub = len(features)\n",
    "        self.n_views = 1\n",
    "        self.transform = transform\n",
    "        self.targets = targets\n",
    "        \n",
    "        vectorized_feat = np.array([sym_matrix_to_vec(mat, discard_diagonal=True) for mat in features])\n",
    "        self.n_features = vectorized_feat.shape[-1]\n",
    "        \n",
    "        if (train and transform is not None):\n",
    "            # augmentation only in training mode\n",
    "            if transform != \"copy\":\n",
    "                augmented_features = np.array([self.transform(sample, regions = regions) for sample in features])\n",
    "\n",
    "                self.n_views = self.n_views + augmented_features.shape[1]\n",
    "                self.features = np.zeros((self.n_sub, self.n_views, self.n_features))\n",
    "                for sub in range(self.n_sub):\n",
    "                    self.features[sub, 0, :] = vectorized_feat[sub]\n",
    "                    self.features[sub, 1:, :] = augmented_features[sub]\n",
    "            else:\n",
    "                self.features = np.repeat(np.expand_dims(vectorized_feat, axis = 1), 2, axis=1)\n",
    "        else:\n",
    "            self.features = np.expand_dims(vectorized_feat, axis = 1)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.n_sub\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features[idx]\n",
    "        targets = self.targets[idx]\n",
    "        features = torch.from_numpy(features).float()\n",
    "        targets = torch.from_numpy(targets).float()\n",
    "        \n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f506c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(NeuralNet):\n",
    "    def __init__(self, module, criterion_pft=None, criterion_ptt=None, n_views = None, **kwargs):\n",
    "        super(CustomNet, self).__init__(module, **kwargs)\n",
    "        self.criterion_pft = criterion_pft\n",
    "        self.criterion_ptt = criterion_ptt\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def initialize(self):\n",
    "        # Properly register custom loss functions as attributes\n",
    "        # This approach avoids directly setting PyTorch components as attributes until the model is initialized\n",
    "        if not hasattr(self, 'criterion_pft_'):\n",
    "            self.criterion_pft_ = self.criterion_pft\n",
    "        if not hasattr(self, 'criterion_ptt_'):\n",
    "            self.criterion_ptt_ = self.criterion_ptt\n",
    "        if not hasattr(self, 'n_views_'):\n",
    "            self.n_views_ = self.n_views\n",
    "        super(CustomNet, self).initialize()\n",
    "        return self\n",
    "    \n",
    "    def train_step_single(self, batch, **fit_params):\n",
    "        self.module_.train()\n",
    "        features, targets = batch\n",
    "        features, targets = features.to(self.device), targets.to(self.device)\n",
    "        self.optimizer_.zero_grad()\n",
    "        mlp_out = self.module_(features, targets)  # Pass both Xi and yi to forward\n",
    "        loss = self.get_loss(mlp_out, targets, training=True)\n",
    "        loss.backward()\n",
    "        self.optimizer_.step()\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def get_loss(self, mlp_out, targets, training=False):\n",
    "        n_views = self.n_views_\n",
    "        out_feat, out_target = mlp_out\n",
    "        bsz = out_feat[0]\n",
    "        out_feat = torch.split(out_feat, [bsz]*n_views, dim=0)\n",
    "        out_feat = torch.cat([f.unsqueeze(1) for f in out_feat], dim=1)\n",
    "        \n",
    "        loss_pft = self.criterion_pft(out_feat, targets)\n",
    "        \n",
    "        out_target = torch.split(out_target, [bsz]*n_views, dim=0)\n",
    "        out_target = torch.cat([f.unsqueeze(1) for f in out_target], dim=1)\n",
    "        \n",
    "        loss_ptt = self.criterion_ptt(out_target, targets)\n",
    "        \n",
    "        mse_loss = self.criterion(out_feat.view(bsz * n_views, 2), out_target.view(bsz * n_views, 2))\n",
    "        \n",
    "        return loss_pft + loss_ptt + mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aeeb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, krnl_sigma):\n",
    "    x = x - x.T\n",
    "    return torch.exp(-(x**2) / (2*(krnl_sigma**2))) / (math.sqrt(2*torch.pi)*krnl_sigma)\n",
    "\n",
    "def cauchy(x, krnl_sigma):\n",
    "        x = x - x.T\n",
    "        return  1. / (krnl_sigma*(x**2) + 1)\n",
    "\n",
    "def rbf(x, krnl_sigma):\n",
    "        x = x - x.T\n",
    "        return torch.exp(-(x**2)/(2*(krnl_sigma**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f739858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss from: https://github.com/EIDOSLAB/contrastive-brain-age-prediction/blob/master/src/losses.py\n",
    "# modified to accept input shape [bsz, n_feats]. In the age paper: [bsz, n_views, n_feats].\n",
    "class KernelizedSupCon(nn.Module):\n",
    "    \"\"\"Supervised contrastive loss: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\n",
    "    Based on: https://github.com/HobbitLong/SupContrast\"\"\"\n",
    "    def __init__(self, method: str, temperature: float=0.03, contrast_mode: str='all',\n",
    "                 base_temperature: float=0.07, krnl_sigma: float = 1., kernel: callable=cauchy, delta_reduction: str='sum'):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "        self.method = method\n",
    "        self.kernel = kernel\n",
    "        self.krnl_sigma = krnl_sigma\n",
    "        self.delta_reduction = delta_reduction\n",
    "\n",
    "        if kernel is not None and method == 'supcon':\n",
    "            raise ValueError('Kernel must be none if method=supcon')\n",
    "        \n",
    "        if kernel is None and method != 'supcon':\n",
    "            raise ValueError('Kernel must not be none if method != supcon')\n",
    "\n",
    "        if delta_reduction not in ['mean', 'sum']:\n",
    "            raise ValueError(f\"Invalid reduction {delta_reduction}\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__} ' \\\n",
    "               f'(t={self.temperature}, ' \\\n",
    "               f'method={self.method}, ' \\\n",
    "               f'kernel={self.kernel is not None}, ' \\\n",
    "               f'delta_reduction={self.delta_reduction})'\n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        \"\"\"Compute loss for model. If `labels` is None, \n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, n_features]. \n",
    "                input has to be rearranged to [bsz, n_views, n_features] and labels [bsz],\n",
    "            labels: ground truth of shape [bsz].\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "\n",
    "        if len(features.shape) != 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, n_feats],'\n",
    "                             '3 dimensions are required')\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        contrast_count = features.shape[1]\n",
    "\n",
    "        if labels is None:\n",
    "            mask = torch.eye(batch_size, device=device)\n",
    "        \n",
    "        else:\n",
    "            labels = labels.view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            \n",
    "            if self.kernel is None:\n",
    "                mask = torch.eq(labels, labels.T)\n",
    "            else:\n",
    "                mask = self.kernel(labels, krnl_sigma = self.krnl_sigma)     \n",
    "        \n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # Tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # Inverse of torch-eye to remove self-contrast (diagonal)\n",
    "        inv_diagonal = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size*anchor_count, device=device).view(-1, 1),\n",
    "            0\n",
    "        )\n",
    "        # compute similarity\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature\n",
    "        )\n",
    "\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        alignment = logits \n",
    "\n",
    "        # base case is:\n",
    "        # - supcon if kernel = none \n",
    "        # - y-aware is kernel != none\n",
    "        uniformity = torch.exp(logits) * inv_diagonal \n",
    "\n",
    "        if self.method == 'threshold':\n",
    "            repeated = mask.unsqueeze(-1).repeat(1, 1, mask.shape[0]) # repeat kernel mask\n",
    "\n",
    "            delta = (mask[:, None].T - repeated.T).transpose(1, 2) # compute the difference w_k - w_j for every k,j\n",
    "            delta = (delta > 0.).float()\n",
    "\n",
    "            # for each z_i, repel only samples j s.t. K(z_i, z_j) < K(z_i, z_k)\n",
    "            uniformity = uniformity.unsqueeze(-1).repeat(1, 1, mask.shape[0])\n",
    "\n",
    "            if self.delta_reduction == 'mean':\n",
    "                uniformity = (uniformity * delta).mean(-1)\n",
    "            else:\n",
    "                uniformity = (uniformity * delta).sum(-1)\n",
    "    \n",
    "        elif self.method == 'expw':\n",
    "            # exp weight e^(s_j(1-w_j))\n",
    "            uniformity = torch.exp(logits * (1 - mask)) * inv_diagonal\n",
    "\n",
    "        uniformity = torch.log(uniformity.sum(1, keepdim=True))\n",
    "\n",
    "\n",
    "        # positive mask contains the anchor-positive pairs\n",
    "        # excluding <self,self> on the diagonal\n",
    "        positive_mask = mask * inv_diagonal\n",
    "\n",
    "        log_prob = alignment - uniformity # log(alignment/uniformity) = log(alignment) - log(uniformity)\n",
    "        log_prob = (positive_mask * log_prob).sum(1) / positive_mask.sum(1) # compute mean of log-likelihood over positive\n",
    " \n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * log_prob\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe60d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim_feat = 499500 # vectorized mat, diagonal discarded\n",
    "# the rest is arbitrary\n",
    "hidden_dim_feat = 1000\n",
    "input_dim_target = 1\n",
    "output_dim = 2\n",
    "num_epochs = 100\n",
    "\n",
    "lr = 0.01 # too low values return nan loss\n",
    "kernel = cauchy\n",
    "batch_size = 30 # too low values return nan loss\n",
    "dropout_rate = 0\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80f251f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomNet(\n",
    "    module=MLP,\n",
    "    optimizer=optim.Adam,\n",
    "    lr = 0.01,\n",
    "    module__input_dim_feat = 499500,\n",
    "    module__hidden_dim_feat = 1000,\n",
    "    module__input_dim_target = 1,\n",
    "    module__output_dim = 2,\n",
    "    n_views = 1,\n",
    "    criterion_pft=KernelizedSupCon,\n",
    "    criterion_ptt=KernelizedSupCon,\n",
    "    criterion=torch.nn.MSELoss,  # Default criterion, actual loss handled in get_loss\n",
    "    batch_size=30,\n",
    "    max_epochs=100,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8578ba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4374, 0.3349, 0.7186,  ..., 0.7013, 0.8503, 0.9213],\n",
      "        [0.6630, 0.1731, 0.2612,  ..., 0.9956, 0.4345, 0.6973],\n",
      "        [0.3197, 0.4278, 0.7204,  ..., 1.1741, 0.8465, 1.0405],\n",
      "        ...,\n",
      "        [0.5074, 0.8293, 0.5729,  ..., 0.9363, 0.5785, 1.1114],\n",
      "        [0.5888, 0.5437, 0.7450,  ..., 1.0310, 0.9717, 0.8969],\n",
      "        [0.6094, 0.6127, 0.6738,  ..., 0.9107, 0.3333, 0.6336]],\n",
      "       device='cuda:0') tensor([[41.],\n",
      "        [48.],\n",
      "        [64.],\n",
      "        [23.],\n",
      "        [41.],\n",
      "        [21.],\n",
      "        [24.],\n",
      "        [60.],\n",
      "        [30.],\n",
      "        [25.],\n",
      "        [23.],\n",
      "        [24.],\n",
      "        [71.],\n",
      "        [38.],\n",
      "        [31.],\n",
      "        [27.],\n",
      "        [24.],\n",
      "        [22.],\n",
      "        [25.],\n",
      "        [35.],\n",
      "        [53.],\n",
      "        [20.],\n",
      "        [25.],\n",
      "        [22.],\n",
      "        [27.],\n",
      "        [22.],\n",
      "        [20.],\n",
      "        [40.],\n",
      "        [29.],\n",
      "        [20.]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "split_with_sizes(): argument 'split_sizes' (position 2) must be tuple of ints, but found element of type Tensor at pos 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1319\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized_:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1278\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_train_begin\u001b[39m\u001b[38;5;124m'\u001b[39m, X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1190\u001b[0m, in \u001b[0;36mNeuralNet.fit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_epoch_begin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mon_epoch_kwargs)\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single_epoch(iterator_valid, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1194\u001b[0m                           step_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mon_epoch_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1226\u001b[0m, in \u001b[0;36mNeuralNet.run_single_epoch\u001b[0;34m(self, iterator, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_batch_begin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch\u001b[38;5;241m=\u001b[39mbatch, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[0;32m-> 1226\u001b[0m     step \u001b[38;5;241m=\u001b[39m \u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mrecord_batch(prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, step[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m   1228\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m (get_len(batch[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m))\n\u001b[1;32m   1229\u001b[0m                   \u001b[38;5;28;01melse\u001b[39;00m get_len(batch))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1105\u001b[0m, in \u001b[0;36mNeuralNet.train_step\u001b[0;34m(self, batch, **fit_params)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_grad_computed\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1099\u001b[0m         named_parameters\u001b[38;5;241m=\u001b[39mTeeGenerator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_learnable_params()),\n\u001b[1;32m   1100\u001b[0m         batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[1;32m   1101\u001b[0m         training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_accumulator\u001b[38;5;241m.\u001b[39mget_step()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1060\u001b[0m, in \u001b[0;36mNeuralNet._step_optimizer\u001b[0;34m(self, step_fn)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/adam.py:143\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 143\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    146\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1094\u001b[0m, in \u001b[0;36mNeuralNet.train_step.<locals>.step_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_fn\u001b[39m():\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zero_grad_optimizer()\n\u001b[0;32m-> 1094\u001b[0m     step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m     step_accumulator\u001b[38;5;241m.\u001b[39mstore_step(step)\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_grad_computed\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1099\u001b[0m         named_parameters\u001b[38;5;241m=\u001b[39mTeeGenerator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_learnable_params()),\n\u001b[1;32m   1100\u001b[0m         batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[1;32m   1101\u001b[0m         training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1102\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[39], line 26\u001b[0m, in \u001b[0;36mCustomNet.train_step_single\u001b[0;34m(self, batch, **fit_params)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     25\u001b[0m mlp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_(features, targets)  \u001b[38;5;66;03m# Pass both Xi and yi to forward\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[39], line 35\u001b[0m, in \u001b[0;36mCustomNet.get_loss\u001b[0;34m(self, mlp_out, targets, training)\u001b[0m\n\u001b[1;32m     33\u001b[0m out_feat, out_target \u001b[38;5;241m=\u001b[39m mlp_out\n\u001b[1;32m     34\u001b[0m bsz \u001b[38;5;241m=\u001b[39m out_feat[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 35\u001b[0m out_feat \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mbsz\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn_views\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m out_feat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([f\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m out_feat], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m loss_pft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion_pft(out_feat, targets)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/functional.py:187\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    182\u001b[0m         split, (tensor,), tensor, split_size_or_sections, dim\u001b[38;5;241m=\u001b[39mdim)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# Overwriting reason:\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# This dispatches to two ATen functions depending on the type of\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# split_size_or_sections. The branching code is in _tensor.py, which we\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# call here.\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_size_or_sections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_tensor.py:864\u001b[0m, in \u001b[0;36mTensor.split\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_VF\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m, split_size, dim)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_with_sizes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: split_with_sizes(): argument 'split_sizes' (position 2) must be tuple of ints, but found element of type Tensor at pos 0"
     ]
    }
   ],
   "source": [
    "model.fit(X= features.squeeze(1), y =targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a447e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeEstimator(BaseEstimator):\n",
    "    \"\"\" Define the age estimator on latent space network features.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        n_jobs = multiprocessing.cpu_count()\n",
    "        self.age_estimator = GridSearchCV(\n",
    "            Ridge(), param_grid={\"alpha\": 10.**np.arange(-2, 3)}, cv=5,\n",
    "            scoring=\"r2\", n_jobs=n_jobs)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.age_estimator.fit(X, y)\n",
    "        return self.score(X, y), self.r2(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.age_estimator.predict(X)\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.age_estimator.predict(X)\n",
    "        return mean_absolute_percentage_error(y, y_pred)\n",
    "    \n",
    "    def r2(self, X, y):\n",
    "        y_pred = self.age_estimator.predict(X)\n",
    "        return r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44e00622",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionAgeEstimator(BaseEstimator):\n",
    "    def __init__(self, custom_net):\n",
    "        \"\"\"\n",
    "        custom_net: An instance of CustomNet, already initialized but not necessarily trained.\n",
    "        age_estimator: An instance of AgeEstimator, not yet fitted.\n",
    "        \"\"\"\n",
    "        self.custom_net = custom_net\n",
    "        n_jobs = multiprocessing.cpu_count()\n",
    "        self.age_estimator = GridSearchCV(\n",
    "            Ridge(), param_grid={\"alpha\": 10.**np.arange(-2, 3)}, cv=5,\n",
    "            scoring=\"r2\", n_jobs=n_jobs)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.custom_net.fit(X, y)\n",
    "        X_proj = self.custom_net.predict(X)\n",
    "        self.age_estimator.fit(X_proj, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_proj = self.custom_net.predict(X)\n",
    "        return self.age_estimator.predict(X_proj)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return r2_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb4624b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_age_estimator = ProjectionAgeEstimator(custom_net=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f58b6b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "train_dataset = MatData(\"matrices.npy\", \"participants.csv\", \"age\", train=True, test_size = 0.2)\n",
    "test_dataset = MatData(\"matrices.npy\", \"participants.csv\", \"age\", train=False, test_size = 0.2)\n",
    "dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc982073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_to_numpy(loader):\n",
    "    features, targets = [], []\n",
    "    for feat, targ in loader:\n",
    "        features.append(feat.numpy())\n",
    "        targets.append(targ.numpy())\n",
    "    return np.concatenate(features), np.concatenate(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ebe6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, targets = loader_to_numpy(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4b6bdb4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprojection_age_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[70], line 14\u001b[0m, in \u001b[0;36mProjectionAgeEstimator.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     X_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_net\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mage_estimator\u001b[38;5;241m.\u001b[39mfit(X_proj, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/regressor.py:82\u001b[0m, in \u001b[0;36mNeuralNetRegressor.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# this is actually a pylint bug:\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNeuralNetRegressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1319\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized_:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1278\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_train_begin\u001b[39m\u001b[38;5;124m'\u001b[39m, X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1190\u001b[0m, in \u001b[0;36mNeuralNet.fit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_epoch_begin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mon_epoch_kwargs)\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single_epoch(iterator_valid, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1194\u001b[0m                           step_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mon_epoch_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1226\u001b[0m, in \u001b[0;36mNeuralNet.run_single_epoch\u001b[0;34m(self, iterator, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_batch_begin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch\u001b[38;5;241m=\u001b[39mbatch, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[0;32m-> 1226\u001b[0m     step \u001b[38;5;241m=\u001b[39m \u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mrecord_batch(prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, step[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m   1228\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m (get_len(batch[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m))\n\u001b[1;32m   1229\u001b[0m                   \u001b[38;5;28;01melse\u001b[39;00m get_len(batch))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1105\u001b[0m, in \u001b[0;36mNeuralNet.train_step\u001b[0;34m(self, batch, **fit_params)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_grad_computed\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1099\u001b[0m         named_parameters\u001b[38;5;241m=\u001b[39mTeeGenerator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_learnable_params()),\n\u001b[1;32m   1100\u001b[0m         batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[1;32m   1101\u001b[0m         training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_accumulator\u001b[38;5;241m.\u001b[39mget_step()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1060\u001b[0m, in \u001b[0;36mNeuralNet._step_optimizer\u001b[0;34m(self, step_fn)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/adam.py:143\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 143\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    146\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1094\u001b[0m, in \u001b[0;36mNeuralNet.train_step.<locals>.step_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_fn\u001b[39m():\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zero_grad_optimizer()\n\u001b[0;32m-> 1094\u001b[0m     step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m     step_accumulator\u001b[38;5;241m.\u001b[39mstore_step(step)\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_grad_computed\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1099\u001b[0m         named_parameters\u001b[38;5;241m=\u001b[39mTeeGenerator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_learnable_params()),\n\u001b[1;32m   1100\u001b[0m         batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[1;32m   1101\u001b[0m         training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1102\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:993\u001b[0m, in \u001b[0;36mNeuralNet.train_step_single\u001b[0;34m(self, batch, **fit_params)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_training(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    992\u001b[0m Xi, yi \u001b[38;5;241m=\u001b[39m unpack_data(batch)\n\u001b[0;32m--> 993\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loss(y_pred, yi, X\u001b[38;5;241m=\u001b[39mXi, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    995\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1521\u001b[0m, in \u001b[0;36mNeuralNet.infer\u001b[0;34m(self, x, **fit_params)\u001b[0m\n\u001b[1;32m   1519\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_x_and_fit_params(x, fit_params)\n\u001b[1;32m   1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx_dict)\n\u001b[0;32m-> 1521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "projection_age_estimator.fit(features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5dd65f55",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CustomNet' object has no attribute 'callbacks_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/regressor.py:82\u001b[0m, in \u001b[0;36mNeuralNetRegressor.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# this is actually a pylint bug:\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNeuralNetRegressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1319\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized_:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1276\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized_:\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[0;32m-> 1276\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotify\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mon_train_begin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:385\u001b[0m, in \u001b[0;36mNeuralNet.notify\u001b[0;34m(self, method_name, **cb_kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call the callback method specified in ``method_name`` with\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03mparameters specified in ``cb_kwargs``.\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m \n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_name)(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcb_kwargs)\n\u001b[0;32m--> 385\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks_\u001b[49m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(cb, method_name)(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcb_kwargs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CustomNet' object has no attribute 'callbacks_'"
     ]
    }
   ],
   "source": [
    "model.fit(features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27e4f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator=projection_age_estimator,  # Your skorch wrapped model\n",
    "    X=features,  # Combined features\n",
    "    y=targets.ravel(),  # Ensure targets are in the correct shape\n",
    "    scoring='r2'  # Example scoring metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c14312f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display = LearningCurveDisplay(train_sizes=train_sizes, train_scores=train_scores, test_scores=test_scores, score_name=\"R2\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90ba46e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5d96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
