{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99de795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "from scipy.stats import pearsonr\n",
    "from cmath import isinf\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "from cmath import isinf\n",
    "from sklearn.model_selection import train_test_split, KFold, LearningCurveDisplay, learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "import multiprocessing\n",
    "from skorch import NeuralNet\n",
    "from skorch.callbacks import Callback\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d147112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7d8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_to_numpy(loader):\n",
    "    features, targets = [], []\n",
    "    for feat, targ in loader:\n",
    "        features.append(feat.numpy())\n",
    "        targets.append(targ.numpy())\n",
    "    return np.concatenate(features), np.concatenate(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5aa9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim_feat = 499500, input_dim_target = 1, hidden_dim_feat = 1000, output_dim = 2, dropout_rate = 0):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Xavier initialization for feature MLP\n",
    "        self.feat_mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim_feat),\n",
    "            nn.Linear(input_dim_feat, hidden_dim_feat),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(hidden_dim_feat, output_dim)\n",
    "        )\n",
    "        self.init_weights(self.feat_mlp)\n",
    "\n",
    "        # Xavier initialization for target MLP\n",
    "        self.target_mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim_target),\n",
    "            nn.Linear(input_dim_target, output_dim)\n",
    "        )\n",
    "        self.init_weights(self.target_mlp)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        features = self.feat_mlp(x)\n",
    "        targets = self.target_mlp(y)\n",
    "        features = nn.functional.normalize(features, p=2, dim=1)\n",
    "        targets = nn.functional.normalize(targets, p=2, dim=1)\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93673abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeEstimator(BaseEstimator):\n",
    "    \"\"\" Define the age estimator on latent space network features.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        n_jobs = multiprocessing.cpu_count()\n",
    "        self.age_estimator = GridSearchCV(\n",
    "            Ridge(), param_grid={\"alpha\": 10.**np.arange(-2, 3)}, cv=5,\n",
    "            scoring=\"r2\", n_jobs=n_jobs)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.age_estimator.fit(X, y)\n",
    "        return self.score(X, y), self.r2(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.age_estimator.predict(X)\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.age_estimator.predict(X)\n",
    "        return mean_absolute_percentage_error(y, y_pred)\n",
    "    \n",
    "    def r2(self, X, y):\n",
    "        y_pred = self.age_estimator.predict(X)\n",
    "        return r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5caa4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatData(Dataset):\n",
    "    def __init__(self, path_feat, path_target, target_name, transform = None, train=True, train_size = 0.8, test_size=None, test_site = None, regions = None, threshold_mat = False, threshold_percent = None, random_state=42):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with the capability to handle training and testing splits, \n",
    "        including multiple views for augmented data.\n",
    "        \n",
    "        Args:\n",
    "            path_feat (str): Path to the features file.\n",
    "            path_target (str): Path to the target file.\n",
    "            transform (callable): A transformation function to apply for augmentation.\n",
    "            train (bool): Whether the dataset is used for training. False will load the test set.\n",
    "            test_size (float): Proportion of the dataset to include in the test split.\n",
    "            random_state (int): Random state for reproducible train-test splits.\n",
    "        \"\"\"\n",
    "        # Load the entire dataset\n",
    "        features = np.load(path_feat)      \n",
    "        participant_data = pd.read_csv(path_target)\n",
    "        targets = np.expand_dims(participant_data[target_name].values, axis = 1)\n",
    "        \n",
    "\n",
    "        # Split the dataset into training and test sets\n",
    "        if test_site is None:\n",
    "            train_indices, test_indices = train_test_split(np.arange(len(features)), \n",
    "                                                       train_size = train_size,\n",
    "                                                       test_size=test_size,                \n",
    "                                                       random_state=random_state)\n",
    "        else:\n",
    "            test_indices = participant_data.index[participant_data['dataset'] == test_site].values\n",
    "            train_indices = np.delete(np.arange(len(features)), test_indices)\n",
    "        \n",
    "        if train:\n",
    "            selected_indices = train_indices\n",
    "        else:\n",
    "            selected_indices = test_indices\n",
    "        \n",
    "        # Select the subset of data for the current mode (train/test)\n",
    "        features = features[selected_indices]\n",
    "        if threshold_mat:\n",
    "            thresholded_feat = []\n",
    "            for matrix in features:\n",
    "                threshold = np.percentile(matrix, threshold_percent)\n",
    "                matrix[matrix < threshold] = 0\n",
    "                thresholded_feat.append(matrix)\n",
    "            threshold_feat = np.stack(thresholded_feat)\n",
    "            features = threshold_feat\n",
    "        targets = targets[selected_indices]\n",
    "        \n",
    "\n",
    "        self.n_sub = len(features)\n",
    "        self.n_views = 1\n",
    "        self.transform = transform\n",
    "        self.targets = targets\n",
    "        \n",
    "        vectorized_feat = np.array([sym_matrix_to_vec(mat, discard_diagonal=True) for mat in features])\n",
    "        self.n_features = vectorized_feat.shape[-1]\n",
    "        \n",
    "        if (train and transform is not None):\n",
    "            # augmentation only in training mode\n",
    "            if transform != \"copy\":\n",
    "                augmented_features = np.array([self.transform(sample, regions = regions) for sample in features])\n",
    "\n",
    "                self.n_views = self.n_views + augmented_features.shape[1]\n",
    "                self.features = np.zeros((self.n_sub, self.n_views, self.n_features))\n",
    "                for sub in range(self.n_sub):\n",
    "                    self.features[sub, 0, :] = vectorized_feat[sub]\n",
    "                    self.features[sub, 1:, :] = augmented_features[sub]\n",
    "            else:\n",
    "                self.features = np.repeat(np.expand_dims(vectorized_feat, axis = 1), 2, axis=1)\n",
    "        else:\n",
    "            self.features = np.expand_dims(vectorized_feat, axis = 1)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.n_sub\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features[idx]\n",
    "        targets = self.targets[idx]\n",
    "        features = torch.from_numpy(features).float()\n",
    "        targets = torch.from_numpy(targets).float()\n",
    "        \n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f506c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(NeuralNet):\n",
    "    def __init__(self, module, estimator = None, criterion_pft=None, criterion_ptt=None, n_views = None, **kwargs):\n",
    "        super(CustomNet, self).__init__(module, **kwargs)\n",
    "        self.criterion_pft_cls = criterion_pft\n",
    "        self.criterion_ptt_cls = criterion_ptt\n",
    "        self.n_views = n_views\n",
    "        self.estimator = estimator\n",
    "        \n",
    "    def fit(self, X_train, y_train, **fit_params):\n",
    "        self.X_train_ = X_train\n",
    "        self.y_train_ = y_train\n",
    "        super().fit(X, y, **fit_params)\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        params = super(CustomNet, self).get_params(deep=deep)\n",
    "        params.update({\n",
    "            'criterion_pft_cls': self.criterion_pft_cls,\n",
    "            'criterion_ptt_cls': self.criterion_ptt_cls,\n",
    "            'n_views': self.n_views,\n",
    "            'estimator': self.estimator,\n",
    "        })\n",
    "        return params\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        super(CustomNet, self).set_params(**{k: v for k, v in parameters.items() if k not in ['criterion_pft', 'criterion_ptt', 'n_views', 'estimator']})\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def initialize_criterion(self):\n",
    "        super().initialize_criterion()  # Initialize default criterion first\n",
    "        # Setup custom criterion with parameters from get_params_for\n",
    "        if self.criterion_pft_cls is not None:\n",
    "            self.criterion_pft_ = self.criterion_pft_cls(**self.get_params_for('criterion_pft'))\n",
    "        if self.criterion_ptt_cls is not None:\n",
    "            self.criterion_ptt_ = self.criterion_ptt_cls(**self.get_params_for('criterion_ptt'))\n",
    "        return self\n",
    "    \n",
    "    def train_step_single(self, batch, **fit_params):\n",
    "        self.module_.train()\n",
    "        features, targets = batch\n",
    "        features, targets = features.to(self.device), targets.to(self.device)\n",
    "        self.optimizer_.zero_grad()\n",
    "        mlp_out = self.module_(features, targets)  # Pass both Xi and yi to forward\n",
    "        loss = self.get_loss(mlp_out, targets, training=True)\n",
    "        loss.backward()\n",
    "        self.optimizer_.step()\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, **fit_params):\n",
    "        self.module_.eval()  # Set the module in evaluation mode\n",
    "        features = self.X_test_\n",
    "        targets = self.y_test_\n",
    "        with torch.no_grad():\n",
    "            features, targets = features.to(self.device), targets.to(self.device)\n",
    "            out_feat, out_target = self.module_(features, targets)\n",
    "        \n",
    "        loss = self.get_loss((out_feat, out_target), targets, training=False)\n",
    "        \n",
    "        if hasattr(self, 'train_proj_'):\n",
    "            self.estimator = self.estimator.fit(self.train_proj_.cpu().numpy())\n",
    "            y_pred = self.estimator.predict(out_feat.cpu().numpy())\n",
    "            r2 = self.estimator.r2(out_feat.cpu().numpy())\n",
    "        else:\n",
    "            y_pred = None\n",
    "            r2 = None\n",
    "        return {'loss': loss, 'y_pred': y_pred, 'r2':r2}\n",
    "\n",
    "    def get_loss(self, mlp_out, targets, training=False):\n",
    "        n_views = self.n_views\n",
    "        out_feat, out_target = mlp_out\n",
    "        bsz = out_feat.shape[0]\n",
    "        out_feat = torch.split(out_feat, [bsz]*n_views, dim=0)\n",
    "        out_feat = torch.cat([f.unsqueeze(1) for f in out_feat], dim=1)\n",
    "        \n",
    "        loss = self.criterion_pft_(out_feat, targets)\n",
    "        out_target = torch.split(out_target, [bsz]*n_views, dim=0)\n",
    "        out_target = torch.cat([f.unsqueeze(1) for f in out_target], dim=1)\n",
    "        \n",
    "        loss += self.criterion_ptt_(out_target, targets)\n",
    "        loss += torch.nn.functional.mse_loss(out_feat.view(bsz * n_views, 2), out_target.view(bsz * n_views, 2))\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ec4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjCallback(Callback):\n",
    "    def on_train_end(self, net, **kwargs):\n",
    "        X_train = getattr(net, 'X_train_', None)\n",
    "        y_train = getattr(net, 'y_train_', None)\n",
    "        net.module_.eval()\n",
    "        with torch.no_grad():\n",
    "            X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "            y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "            features, _ = net.module_(X_train_tensor, y_train_tensor)\n",
    "            net.train_proj_ = features\n",
    "\n",
    "class InitializeCallback(Callback):\n",
    "    def on_train_begin(self, net, X=None, y=None, **kwargs):\n",
    "        if not hasattr(net, 'estimator'):\n",
    "            net.estimator = AgeEstimator()\n",
    "        if not hasattr(net, 'criterion_pft_'):\n",
    "            net.criterion_pft_ = net.criterion_pft(**net.get_params_for('criterion_pft'))\n",
    "        if not hasattr(net, 'criterion_ptt_'):\n",
    "            net.criterion_ptt_ = net.criterion_ptt(**net.get_params_for('criterion_ptt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aeeb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, krnl_sigma):\n",
    "    x = x - x.T\n",
    "    return torch.exp(-(x**2) / (2*(krnl_sigma**2))) / (math.sqrt(2*torch.pi)*krnl_sigma)\n",
    "\n",
    "def cauchy(x, krnl_sigma):\n",
    "        x = x - x.T\n",
    "        return  1. / (krnl_sigma*(x**2) + 1)\n",
    "\n",
    "def rbf(x, krnl_sigma):\n",
    "        x = x - x.T\n",
    "        return torch.exp(-(x**2)/(2*(krnl_sigma**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f739858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss from: https://github.com/EIDOSLAB/contrastive-brain-age-prediction/blob/master/src/losses.py\n",
    "# modified to accept input shape [bsz, n_feats]. In the age paper: [bsz, n_views, n_feats].\n",
    "class KernelizedSupCon(nn.Module):\n",
    "    \"\"\"Supervised contrastive loss: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\n",
    "    Based on: https://github.com/HobbitLong/SupContrast\"\"\"\n",
    "    def __init__(self, method: str='expw', temperature: float=0.03, contrast_mode: str='all',\n",
    "                 base_temperature: float=0.07, krnl_sigma: float = 1., kernel: callable=cauchy, delta_reduction: str='sum'):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "        self.method = method\n",
    "        self.kernel = kernel\n",
    "        self.krnl_sigma = krnl_sigma\n",
    "        self.delta_reduction = delta_reduction\n",
    "\n",
    "        if kernel is not None and method == 'supcon':\n",
    "            raise ValueError('Kernel must be none if method=supcon')\n",
    "        \n",
    "        if kernel is None and method != 'supcon':\n",
    "            raise ValueError('Kernel must not be none if method != supcon')\n",
    "\n",
    "        if delta_reduction not in ['mean', 'sum']:\n",
    "            raise ValueError(f\"Invalid reduction {delta_reduction}\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__} ' \\\n",
    "               f'(t={self.temperature}, ' \\\n",
    "               f'method={self.method}, ' \\\n",
    "               f'kernel={self.kernel is not None}, ' \\\n",
    "               f'delta_reduction={self.delta_reduction})'\n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        \"\"\"Compute loss for model. If `labels` is None, \n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, n_features]. \n",
    "                input has to be rearranged to [bsz, n_views, n_features] and labels [bsz],\n",
    "            labels: ground truth of shape [bsz].\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "\n",
    "        if len(features.shape) != 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, n_feats],'\n",
    "                             '3 dimensions are required')\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        contrast_count = features.shape[1]\n",
    "\n",
    "        if labels is None:\n",
    "            mask = torch.eye(batch_size, device=device)\n",
    "        \n",
    "        else:\n",
    "            labels = labels.view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            \n",
    "            if self.kernel is None:\n",
    "                mask = torch.eq(labels, labels.T)\n",
    "            else:\n",
    "                mask = self.kernel(labels, krnl_sigma = self.krnl_sigma)     \n",
    "        \n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # Tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # Inverse of torch-eye to remove self-contrast (diagonal)\n",
    "        inv_diagonal = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size*anchor_count, device=device).view(-1, 1),\n",
    "            0\n",
    "        )\n",
    "        # compute similarity\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature\n",
    "        )\n",
    "\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        alignment = logits \n",
    "\n",
    "        # base case is:\n",
    "        # - supcon if kernel = none \n",
    "        # - y-aware is kernel != none\n",
    "        uniformity = torch.exp(logits) * inv_diagonal \n",
    "\n",
    "        if self.method == 'threshold':\n",
    "            repeated = mask.unsqueeze(-1).repeat(1, 1, mask.shape[0]) # repeat kernel mask\n",
    "\n",
    "            delta = (mask[:, None].T - repeated.T).transpose(1, 2) # compute the difference w_k - w_j for every k,j\n",
    "            delta = (delta > 0.).float()\n",
    "\n",
    "            # for each z_i, repel only samples j s.t. K(z_i, z_j) < K(z_i, z_k)\n",
    "            uniformity = uniformity.unsqueeze(-1).repeat(1, 1, mask.shape[0])\n",
    "\n",
    "            if self.delta_reduction == 'mean':\n",
    "                uniformity = (uniformity * delta).mean(-1)\n",
    "            else:\n",
    "                uniformity = (uniformity * delta).sum(-1)\n",
    "    \n",
    "        elif self.method == 'expw':\n",
    "            # exp weight e^(s_j(1-w_j))\n",
    "            uniformity = torch.exp(logits * (1 - mask)) * inv_diagonal\n",
    "\n",
    "        uniformity = torch.log(uniformity.sum(1, keepdim=True))\n",
    "\n",
    "\n",
    "        # positive mask contains the anchor-positive pairs\n",
    "        # excluding <self,self> on the diagonal\n",
    "        positive_mask = mask * inv_diagonal\n",
    "\n",
    "        log_prob = alignment - uniformity # log(alignment/uniformity) = log(alignment) - log(uniformity)\n",
    "        log_prob = (positive_mask * log_prob).sum(1) / positive_mask.sum(1) # compute mean of log-likelihood over positive\n",
    " \n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * log_prob\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c0a66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "train_dataset = MatData(\"matrices.npy\", \"participants.csv\", \"age\", train=True, train_size = 100, test_size = 50)\n",
    "test_dataset = MatData(\"matrices.npy\", \"participants.csv\", \"age\", train=False, train_size = 100, test_size = 50)\n",
    "dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle = False)\n",
    "X, y = loader_to_numpy(dataloader)\n",
    "X = X.squeeze(1)\n",
    "\n",
    "X_train, y_train = X[:100], y[:100]\n",
    "X_test, y_test = X[100:], y[100:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0786aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b31c6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomNet(\n",
    "    module=MLP,\n",
    "    optimizer=optim.Adam,\n",
    "    lr = 0.01,\n",
    "    estimator = AgeEstimator(),\n",
    "    module__input_dim_feat = 499500,\n",
    "    module__hidden_dim_feat = 1000,\n",
    "    module__input_dim_target = 1,\n",
    "    module__output_dim = 2,\n",
    "    train_split=predefined_split(test_dataset),\n",
    "    n_views = 1,\n",
    "    callbacks=[ProjCallback()],\n",
    "    criterion_pft=KernelizedSupCon,\n",
    "    criterion_ptt=KernelizedSupCon,\n",
    "    criterion=torch.nn.MSELoss(),  # Default criterion, actual loss handled in get_loss\n",
    "    batch_size=20,\n",
    "    max_epochs=10,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fafb8ee8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "validation_step() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mCustomNet.fit\u001b[0;34m(self, X_train, y_train, X_test, y_test, **fit_params)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test_ \u001b[38;5;241m=\u001b[39m X_test\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test_ \u001b[38;5;241m=\u001b[39m y_test\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1319\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized_:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1278\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_train_begin\u001b[39m\u001b[38;5;124m'\u001b[39m, X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1193\u001b[0m, in \u001b[0;36mNeuralNet.fit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_epoch_begin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mon_epoch_kwargs)\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single_epoch(iterator_train, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1191\u001b[0m                           step_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m-> 1193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mon_epoch_kwargs)\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/skorch/net.py:1226\u001b[0m, in \u001b[0;36mNeuralNet.run_single_epoch\u001b[0;34m(self, iterator, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_batch_begin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch\u001b[38;5;241m=\u001b[39mbatch, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[0;32m-> 1226\u001b[0m     step \u001b[38;5;241m=\u001b[39m \u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mrecord_batch(prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, step[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m   1228\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m (get_len(batch[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m))\n\u001b[1;32m   1229\u001b[0m                   \u001b[38;5;28;01melse\u001b[39;00m get_len(batch))\n",
      "\u001b[0;31mTypeError\u001b[0m: validation_step() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27e4f2ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <class '__main__.CustomNet'>[initialized](\n  module_=MLP(\n    (feat_mlp): Sequential(\n      (0): BatchNorm1d(499500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=499500, out_features=1000, bias=True)\n      (2): ReLU()\n      (3): Dropout(p=0, inplace=False)\n      (4): Linear(in_features=1000, out_features=2, bias=True)\n    )\n    (target_mlp): Sequential(\n      (0): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=1, out_features=2, bias=True)\n    )\n  ),\n), as the constructor either does not set or modifies parameter criterion_pft_cls",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ready_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[0;32m/apps/eb/2020b/skylake/software/Python/3.9.6-GCCcore-11.2.0/lib/python3.9/queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_sizes, train_scores, test_scores \u001b[38;5;241m=\u001b[39m \u001b[43mlearning_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_sizes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Combined features\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1683\u001b[0m, in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n_train_samples \u001b[38;5;129;01min\u001b[39;00m train_sizes_abs:\n\u001b[1;32m   1681\u001b[0m         train_test_proportions\u001b[38;5;241m.\u001b[39mappend((train[:n_train_samples], test))\n\u001b[0;32m-> 1683\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_test_proportions\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m results \u001b[38;5;241m=\u001b[39m _aggregate_score_dicts(results)\n\u001b[1;32m   1701\u001b[0m train_scores \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_unique_ticks)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    870\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_effective_n_jobs\n\u001b[1;32m    871\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[0;32m--> 873\u001b[0m islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(islice) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/parallel.py:61\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m---> 61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1685\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n_train_samples \u001b[38;5;129;01min\u001b[39;00m train_sizes_abs:\n\u001b[1;32m   1681\u001b[0m         train_test_proportions\u001b[38;5;241m.\u001b[39mappend((train[:n_train_samples], test))\n\u001b[1;32m   1683\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m   1684\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m-> 1685\u001b[0m         \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1686\u001b[0m         X,\n\u001b[1;32m   1687\u001b[0m         y,\n\u001b[1;32m   1688\u001b[0m         scorer,\n\u001b[1;32m   1689\u001b[0m         train,\n\u001b[1;32m   1690\u001b[0m         test,\n\u001b[1;32m   1691\u001b[0m         verbose,\n\u001b[1;32m   1692\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1693\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m   1694\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1695\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m   1696\u001b[0m         return_times\u001b[38;5;241m=\u001b[39mreturn_times,\n\u001b[1;32m   1697\u001b[0m     )\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m train_test_proportions\n\u001b[1;32m   1699\u001b[0m )\n\u001b[1;32m   1700\u001b[0m results \u001b[38;5;241m=\u001b[39m _aggregate_score_dicts(results)\n\u001b[1;32m   1701\u001b[0m train_scores \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_unique_ticks)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py:76\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_clone__()\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py:123\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m    121\u001b[0m     param2 \u001b[38;5;241m=\u001b[39m params_set[name]\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m param2:\n\u001b[0;32m--> 123\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, as the constructor \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither does not set or modifies parameter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator, name)\n\u001b[1;32m    126\u001b[0m         )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# _sklearn_output_config is used by `set_output` to configure the output\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# container of an estimator.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sklearn_output_config\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <class '__main__.CustomNet'>[initialized](\n  module_=MLP(\n    (feat_mlp): Sequential(\n      (0): BatchNorm1d(499500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=499500, out_features=1000, bias=True)\n      (2): ReLU()\n      (3): Dropout(p=0, inplace=False)\n      (4): Linear(in_features=1000, out_features=2, bias=True)\n    )\n    (target_mlp): Sequential(\n      (0): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=1, out_features=2, bias=True)\n    )\n  ),\n), as the constructor either does not set or modifies parameter criterion_pft_cls"
     ]
    }
   ],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator=model,\n",
    "    train_sizes = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    X=X,  # Combined features\n",
    "    y=y,\n",
    "    cv = 5,\n",
    "    scoring='r2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c14312f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAGwCAYAAAC5ACFFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2gElEQVR4nO3de1yUZf7/8feACJ4GQoERBQ/JKilpSiLWfm2TxI5aurqsmZir265mpVlSJh4qK8tDZdm2ZWtlurqumZmtYadV8oBmnmDL9ZgCmQIeEhGu3x/9nG0SLkFBGHs9H4/7IXPNdd3357oGnbf33DPjMMYYAQAAoFQ+1V0AAABATUZYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACARa3qLuBSUFJSogMHDqhBgwZyOBzVXQ4AACgHY4yOHj2q8PBw+fiUff6IsFQJDhw4oIiIiOouAwAAnId9+/apadOmZd5PWKoEDRo0kPTjYjudzmquBgAAlEdBQYEiIiLcz+NlISxVgjMvvTmdTsISAABe5lyX0HCBNwAAgAVhCQAAwIKwBAAAYME1SwAA1FDFxcUqKiqq7jK8lp+fn3x9fS94P4QlAABqGGOMsrOzlZeXV92leL2goCC5XK4L+hxEwhIAADXMmaAUGhqqunXr8oHH58EYoxMnTig3N1eS1Lhx4/PeF2EJAIAapLi42B2UGjZsWN3leLU6depIknJzcxUaGnreL8lxgTcAADXImWuU6tatW82VXBrOrOOFXPtFWAIAoAbipbfKURnrSFgCAACwICwBAABYEJYAAECN1bx5c82YMaNaayAsAQCAC+ZwOKzbhAkTzmu/69ev17Bhwyq32AriowMAAMAFO3jwoPvnBQsWaPz48crKynK31a9f3/2zMUbFxcWqVevcMSQkJKRyCz0PnFkCAKCGM8boxKnTF30zxpS7RpfL5d4CAwPlcDjctzMzM9WgQQN98MEH6tSpk/z9/fXvf/9bO3fuVK9evRQWFqb69evr6quv1kcffeSx35+/DOdwOPTXv/5Vt99+u+rWrauoqCgtXbq0spa6VJxZAgCghvuhqFhXjP/woh93+6RE1a1deVFh7NixevbZZ9WyZUtddtll2rdvn2666SY98cQT8vf319y5c3XrrbcqKytLkZGRZe5n4sSJeuaZZzR16lS98MILGjBggPbs2aPg4OBKq/WnOLMEAAAuikmTJumGG27Q5ZdfruDgYLVv315//OMf1a5dO0VFRWny5Mm6/PLLz3mmKDk5WUlJSWrVqpWefPJJHTt2TOvWrauyujmzBABADVfHz1fbJyVWy3ErU2xsrMftY8eOacKECXr//fd18OBBnT59Wj/88IP27t1r3c+VV17p/rlevXpyOp3u74CrCoQlAABqOIfDUakvh1WXevXqedx+8MEHtXLlSj377LNq1aqV6tSpo759++rUqVPW/fj5+XncdjgcKikpqfR6z/D+lQcAAF5p9erVSk5O1u233y7pxzNNu3fvrt6iSsE1SwAAoFpERUVp8eLF+vLLL7V582b9/ve/r9IzROeLsAQAAKrFtGnTdNlll6lr16669dZblZiYqI4dO1Z3WWdxmIp8iAJKVVBQoMDAQOXn58vpdFZ3OQAAL3by5Ent2rVLLVq0UEBAQHWX4/Vs61ne52/OLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAADABXM4HNZtwoQJF7TvJUuWVFqtFVWr2o4MAAAuGQcPHnT/vGDBAo0fP15ZWVnutvr161dHWZWCM0sAAOCCuVwu9xYYGCiHw+HRNn/+fEVHRysgIEBt2rTRSy+95B576tQpjRgxQo0bN1ZAQICaNWumKVOmSJKaN28uSbr99tvlcDjcty8mziwBAFDTGSMVnbj4x/WrKzkcF7ybt99+W+PHj9eLL76oq666Sps2bdLQoUNVr149DRo0SM8//7yWLl2qv//974qMjNS+ffu0b98+SdL69esVGhqqOXPmqGfPnvL19b3geiqKsAQAQE1XdEJ6MvziH/eRA1Ltehe8m9TUVD333HO64447JEktWrTQ9u3b9corr2jQoEHau3evoqKidO2118rhcKhZs2busSEhIZKkoKAguVyuC67lfBCWAABAlTl+/Lh27typIUOGaOjQoe7206dPKzAwUJKUnJysG264Qa1bt1bPnj11yy23qEePHtVV8lkISwAA1HR+dX88y1Mdx71Ax44dkyS9+uqriouL87jvzEtqHTt21K5du/TBBx/oo48+Ur9+/ZSQkKBFixZd8PErA2EJAICazuGolJfDqkNYWJjCw8P13//+VwMGDCizn9PpVP/+/dW/f3/17dtXPXv21OHDhxUcHCw/Pz8VFxdfxKo9EZYAAECVmjhxokaOHKnAwED17NlThYWF2rBhg44cOaJRo0Zp2rRpaty4sa666ir5+Pho4cKFcrlcCgoKkvTjO+LS0tJ0zTXXyN/fX5dddtlFrZ+PDgAAAFXqD3/4g/76179qzpw5iomJUbdu3fTGG2+oRYsWkqQGDRromWeeUWxsrK6++mrt3r1by5cvl4/PjzHlueee08qVKxUREaGrrrrqotfvMMaYi37US0xBQYECAwOVn58vp9NZ3eUAALzYyZMntWvXLrVo0UIBAQHVXY7Xs61neZ+/ObMEAABg4XVhadasWWrevLkCAgIUFxendevWWfsvXLhQbdq0UUBAgGJiYrR8+fIy+95zzz1yOByaMWNGJVcNAAC8lVeFpQULFmjUqFFKTU3Vxo0b1b59eyUmJio3N7fU/mvWrFFSUpKGDBmiTZs2qXfv3urdu7e2bt16Vt9//vOf+uKLLxQeXg0f+gUAAGosrwpL06ZN09ChQzV48GBdccUVmj17turWravXX3+91P4zZ85Uz549NWbMGEVHR2vy5Mnq2LGjXnzxRY9+3377re699169/fbb8vPzuxhTAQAAXsJrwtKpU6eUkZGhhIQEd5uPj48SEhKUnp5e6pj09HSP/pKUmJjo0b+kpEQDBw7UmDFj1LZt23LVUlhYqIKCAo8NAIDKxPuvKkdlrKPXhKVDhw6puLhYYWFhHu1hYWHKzs4udUx2dvY5+z/99NOqVauWRo4cWe5apkyZosDAQPcWERFRgZkAAFC2M69wnDhRDV+cewk6s44X8srRL/pDKTMyMjRz5kxt3LhRjgp8q3JKSopGjRrlvl1QUEBgAgBUCl9fXwUFBbmvx61bt26FnqPwI2OMTpw4odzcXAUFBbm/WuV8eE1YatSokXx9fZWTk+PRnpOTU+a3ELtcLmv/zz//XLm5uYqMjHTfX1xcrNGjR2vGjBnavXt3qfv19/eXv7//BcwGAICynXmeKusNTCi/oKCgMnNCeXlNWKpdu7Y6deqktLQ09e7dW9KP1xulpaVpxIgRpY6Jj49XWlqa7r//fnfbypUrFR8fL0kaOHBgqdc0DRw4UIMHD66SeQAAcC4Oh0ONGzdWaGioioqKqrscr+Xn53dBZ5TO8JqwJEmjRo3SoEGDFBsbq86dO2vGjBk6fvy4O9jcddddatKkiaZMmSJJuu+++9StWzc999xzuvnmmzV//nxt2LBBf/nLXyRJDRs2VMOGDT2O4efnJ5fLpdatW1/cyQEA8DO+vr6V8mSPC+NVYal///767rvvNH78eGVnZ6tDhw5asWKF+yLuvXv3ur9HRpK6du2qefPmady4cXrkkUcUFRWlJUuWqF27dtU1BQAA4GX4brhKwHfDAQDgffhuOAAAgEpAWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwMLrwtKsWbPUvHlzBQQEKC4uTuvWrbP2X7hwodq0aaOAgADFxMRo+fLl7vuKior08MMPKyYmRvXq1VN4eLjuuusuHThwoKqnAQAAvIRXhaUFCxZo1KhRSk1N1caNG9W+fXslJiYqNze31P5r1qxRUlKShgwZok2bNql3797q3bu3tm7dKkk6ceKENm7cqMcee0wbN27U4sWLlZWVpdtuu+1iTgsAANRgDmOMqe4iyisuLk5XX321XnzxRUlSSUmJIiIidO+992rs2LFn9e/fv7+OHz+uZcuWudu6dOmiDh06aPbs2aUeY/369ercubP27NmjyMjIctVVUFCgwMBA5efny+l0nsfMAADAxVbe52+vObN06tQpZWRkKCEhwd3m4+OjhIQEpaenlzomPT3do78kJSYmltlfkvLz8+VwOBQUFFRmn8LCQhUUFHhsAADg0uQ1YenQoUMqLi5WWFiYR3tYWJiys7NLHZOdnV2h/idPntTDDz+spKQka8KcMmWKAgMD3VtEREQFZwMAALyF14SlqlZUVKR+/frJGKOXX37Z2jclJUX5+fnubd++fRepSgAAcLHVqu4CyqtRo0by9fVVTk6OR3tOTo5cLlepY1wuV7n6nwlKe/bs0apVq8553ZG/v7/8/f3PYxYAAMDbeM2Zpdq1a6tTp05KS0tzt5WUlCgtLU3x8fGljomPj/foL0krV6706H8mKH399df66KOP1LBhw6qZAAAA8Epec2ZJkkaNGqVBgwYpNjZWnTt31owZM3T8+HENHjxYknTXXXepSZMmmjJliiTpvvvuU7du3fTcc8/p5ptv1vz587Vhwwb95S9/kfRjUOrbt682btyoZcuWqbi42H09U3BwsGrXrl09EwUAADWGV4Wl/v3767vvvtP48eOVnZ2tDh06aMWKFe6LuPfu3Ssfn/+dLOvatavmzZuncePG6ZFHHlFUVJSWLFmidu3aSZK+/fZbLV26VJLUoUMHj2N9/PHHuu666y7KvAAAQM3lVZ+zVFPxOUsAAHifS+5zlgAAAKoDYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAIsKhaWioiI99NBDatWqlTp37qzXX3/d4/6cnBz5+vpWaoE/N2vWLDVv3lwBAQGKi4vTunXrrP0XLlyoNm3aKCAgQDExMVq+fLnH/cYYjR8/Xo0bN1adOnWUkJCgr7/+uiqnAAAAvEiFwtITTzyhuXPn6p577lGPHj00atQo/fGPf/ToY4yp1AJ/asGCBRo1apRSU1O1ceNGtW/fXomJicrNzS21/5o1a5SUlKQhQ4Zo06ZN6t27t3r37q2tW7e6+zzzzDN6/vnnNXv2bK1du1b16tVTYmKiTp48WWXzAAAA3sNhKpBuoqKiNH36dN1yyy2SpG+++UY33nijrr32Wr3++uvKzc1VeHi4iouLq6TYuLg4XX311XrxxRclSSUlJYqIiNC9996rsWPHntW/f//+On78uJYtW+Zu69Klizp06KDZs2fLGKPw8HCNHj1aDz74oCQpPz9fYWFheuONN/S73/2uXHUVFBQoMDBQ+fn5cjqdlTBTAABQ1cr7/F2hM0vffvut2rVr577dqlUrffLJJ1qzZo0GDhxYZSFJkk6dOqWMjAwlJCS423x8fJSQkKD09PRSx6Snp3v0l6TExER3/127dik7O9ujT2BgoOLi4srcpyQVFhaqoKDAYwMAAJemCoUll8ulnTt3erQ1adJEH3/8sdavX6/k5OTKrM3DoUOHVFxcrLCwMI/2sLAwZWdnlzomOzvb2v/MnxXZpyRNmTJFgYGB7i0iIqLC8wEAAN6hQmHp+uuv17x5885qDw8P16pVq7Rr165KK6wmS0lJUX5+vnvbt29fdZcEAACqSK2KdH7ssceUmZlZ6n1NmjTRp59+qnfffbdSCvu5Ro0aydfXVzk5OR7tOTk5crlcpY5xuVzW/mf+zMnJUePGjT36dOjQocxa/P395e/vfz7TAAAAXqZCZ5aaNWumxMTEUu8rLCzU/PnzNXHixEop7Odq166tTp06KS0tzd1WUlKitLQ0xcfHlzomPj7eo78krVy50t2/RYsWcrlcHn0KCgq0du3aMvcJAAB+WSoUlgoLC5WSkqLY2Fh17dpVS5YskSTNmTNHLVq00PTp0/XAAw9URZ2SpFGjRunVV1/V3/72N+3YsUN/+tOfdPz4cQ0ePFiSdNdddyklJcXd/7777tOKFSv03HPPKTMzUxMmTNCGDRs0YsQISZLD4dD999+vxx9/XEuXLtWWLVt01113KTw8XL17966yeQAAAO9RoZfhxo8fr1deeUUJCQlas2aNfvvb32rw4MH64osvNG3aNP32t7+t0g+l7N+/v7777juNHz9e2dnZ6tChg1asWOG+QHvv3r3y8flf/uvatavmzZuncePG6ZFHHlFUVJSWLFni8Y6+hx56SMePH9ewYcOUl5ena6+9VitWrFBAQECVzQMAAHiPCn3OUsuWLTVjxgzddttt2rp1q6688kolJyfrtddek8PhqMo6azQ+ZwkAAO9TJZ+ztH//fnXq1EmS1K5dO/n7++uBBx74RQclAABwaatQWCouLlbt2rXdt2vVqqX69etXelEAAAA1RYWuWTLGKDk52f22+ZMnT+qee+5RvXr1PPotXry48ioEAACoRhUKS4MGDfK4feedd1ZqMQAAADVNhcLSnDlzqqoOAACAGqlC1ywBAAD80hCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC68JS4cPH9aAAQPkdDoVFBSkIUOG6NixY9YxJ0+e1PDhw9WwYUPVr19fffr0UU5Ojvv+zZs3KykpSREREapTp46io6M1c+bMqp4KAADwIl4TlgYMGKBt27Zp5cqVWrZsmT777DMNGzbMOuaBBx7Qe++9p4ULF+rTTz/VgQMHdMcdd7jvz8jIUGhoqN566y1t27ZNjz76qFJSUvTiiy9W9XQAAICXcBhjTHUXcS47duzQFVdcofXr1ys2NlaStGLFCt10003av3+/wsPDzxqTn5+vkJAQzZs3T3379pUkZWZmKjo6Wunp6erSpUupxxo+fLh27NihVatWlVlPYWGhCgsL3bcLCgoUERGh/Px8OZ3OC5kqAAC4SAoKChQYGHjO52+vOLOUnp6uoKAgd1CSpISEBPn4+Gjt2rWljsnIyFBRUZESEhLcbW3atFFkZKTS09PLPFZ+fr6Cg4Ot9UyZMkWBgYHuLSIiooIzAgAA3sIrwlJ2drZCQ0M92mrVqqXg4GBlZ2eXOaZ27doKCgryaA8LCytzzJo1a7RgwYJzvryXkpKi/Px897Zv377yTwYAAHiVag1LY8eOlcPhsG6ZmZkXpZatW7eqV69eSk1NVY8ePax9/f395XQ6PTYAAHBpqlWdBx89erSSk5OtfVq2bCmXy6Xc3FyP9tOnT+vw4cNyuVyljnO5XDp16pTy8vI8zi7l5OScNWb79u3q3r27hg0bpnHjxp3XXAAAwKWpWsNSSEiIQkJCztkvPj5eeXl5ysjIUKdOnSRJq1atUklJieLi4kod06lTJ/n5+SktLU19+vSRJGVlZWnv3r2Kj49399u2bZuuv/56DRo0SE888UQlzAoAAFxKvOLdcJJ04403KicnR7Nnz1ZRUZEGDx6s2NhYzZs3T5L07bffqnv37po7d646d+4sSfrTn/6k5cuX64033pDT6dS9994r6cdrk6QfX3q7/vrrlZiYqKlTp7qP5evrW64Qd0Z5r6YHAAA1R3mfv6v1zFJFvP322xoxYoS6d+8uHx8f9enTR88//7z7/qKiImVlZenEiRPutunTp7v7FhYWKjExUS+99JL7/kWLFum7777TW2+9pbfeesvd3qxZM+3evfuizAsAANRsXnNmqSbjzBIAAN7nkvqcJQAAgOpCWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwMJrwtLhw4c1YMAAOZ1OBQUFaciQITp27Jh1zMmTJzV8+HA1bNhQ9evXV58+fZSTk1Nq3++//15NmzaVw+FQXl5eFcwAAAB4I68JSwMGDNC2bdu0cuVKLVu2TJ999pmGDRtmHfPAAw/ovffe08KFC/Xpp5/qwIEDuuOOO0rtO2TIEF155ZVVUToAAPBiDmOMqe4izmXHjh264oortH79esXGxkqSVqxYoZtuukn79+9XeHj4WWPy8/MVEhKiefPmqW/fvpKkzMxMRUdHKz09XV26dHH3ffnll7VgwQKNHz9e3bt315EjRxQUFFRmPYWFhSosLHTfLigoUEREhPLz8+V0Oitp1gAAoCoVFBQoMDDwnM/fXnFmKT09XUFBQe6gJEkJCQny8fHR2rVrSx2TkZGhoqIiJSQkuNvatGmjyMhIpaenu9u2b9+uSZMmae7cufLxKd9yTJkyRYGBge4tIiLiPGcGAABqOq8IS9nZ2QoNDfVoq1WrloKDg5WdnV3mmNq1a591higsLMw9prCwUElJSZo6daoiIyPLXU9KSory8/Pd2759+yo2IQAA4DWqNSyNHTtWDofDumVmZlbZ8VNSUhQdHa0777yzQuP8/f3ldDo9NgAAcGmqVZ0HHz16tJKTk619WrZsKZfLpdzcXI/206dP6/Dhw3K5XKWOc7lcOnXqlPLy8jzOLuXk5LjHrFq1Slu2bNGiRYskSWcu32rUqJEeffRRTZw48TxnBgAALhXVGpZCQkIUEhJyzn7x8fHKy8tTRkaGOnXqJOnHoFNSUqK4uLhSx3Tq1El+fn5KS0tTnz59JElZWVnau3ev4uPjJUn/+Mc/9MMPP7jHrF+/Xnfffbc+//xzXX755Rc6PQAAcAmo1rBUXtHR0erZs6eGDh2q2bNnq6ioSCNGjNDvfvc79zvhvv32W3Xv3l1z585V586dFRgYqCFDhmjUqFEKDg6W0+nUvffeq/j4ePc74X4eiA4dOuQ+nu3dcAAA4JfDK8KSJL399tsaMWKEunfvLh8fH/Xp00fPP/+8+/6ioiJlZWXpxIkT7rbp06e7+xYWFioxMVEvvfRSdZQPAAC8lFd8zlJNV97PaQAAADXHJfU5SwAAANWFsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgUau6C7gUGGMkSQUFBdVcCQAAKK8zz9tnnsfLQliqBEePHpUkRUREVHMlAACgoo4eParAwMAy73eYc8UpnFNJSYkOHDigBg0ayOFwVHc51aqgoEARERHat2+fnE5ndZdzyWKdLx7W+uJgnS8O1tmTMUZHjx5VeHi4fHzKvjKJM0uVwMfHR02bNq3uMmoUp9PJX8SLgHW+eFjri4N1vjhY5/+xnVE6gwu8AQAALAhLAAAAFoQlVCp/f3+lpqbK39+/uku5pLHOFw9rfXGwzhcH63x+uMAbAADAgjNLAAAAFoQlAAAAC8ISAACABWEJAADAgrCECjt8+LAGDBggp9OpoKAgDRkyRMeOHbOOOXnypIYPH66GDRuqfv366tOnj3Jyckrt+/3336tp06ZyOBzKy8urghl4h6pY582bNyspKUkRERGqU6eOoqOjNXPmzKqeSo0ya9YsNW/eXAEBAYqLi9O6deus/RcuXKg2bdooICBAMTExWr58ucf9xhiNHz9ejRs3Vp06dZSQkKCvv/66KqfgFSpznYuKivTwww8rJiZG9erVU3h4uO666y4dOHCgqqdR41X27/NP3XPPPXI4HJoxY0YlV+2FDFBBPXv2NO3btzdffPGF+fzzz02rVq1MUlKSdcw999xjIiIiTFpamtmwYYPp0qWL6dq1a6l9e/XqZW688UYjyRw5cqQKZuAdqmKdX3vtNTNy5EjzySefmJ07d5o333zT1KlTx7zwwgtVPZ0aYf78+aZ27drm9ddfN9u2bTNDhw41QUFBJicnp9T+q1evNr6+vuaZZ54x27dvN+PGjTN+fn5my5Yt7j5PPfWUCQwMNEuWLDGbN282t912m2nRooX54YcfLta0apzKXue8vDyTkJBgFixYYDIzM016errp3Lmz6dSp08WcVo1TFb/PZyxevNi0b9/ehIeHm+nTp1fxTGo+whIqZPv27UaSWb9+vbvtgw8+MA6Hw3z77beljsnLyzN+fn5m4cKF7rYdO3YYSSY9Pd2j70svvWS6detm0tLSftFhqarX+af+/Oc/m9/85jeVV3wN1rlzZzN8+HD37eLiYhMeHm6mTJlSav9+/fqZm2++2aMtLi7O/PGPfzTGGFNSUmJcLpeZOnWq+/68vDzj7+9v3nnnnSqYgXeo7HUuzbp164wks2fPnsop2gtV1Trv37/fNGnSxGzdutU0a9aMsGSM4WU4VEh6erqCgoIUGxvrbktISJCPj4/Wrl1b6piMjAwVFRUpISHB3damTRtFRkYqPT3d3bZ9+3ZNmjRJc+fOtX6h4S9BVa7zz+Xn5ys4OLjyiq+hTp06pYyMDI/18fHxUUJCQpnrk56e7tFfkhITE939d+3apezsbI8+gYGBiouLs675pawq1rk0+fn5cjgcCgoKqpS6vU1VrXNJSYkGDhyoMWPGqG3btlVTvBf6ZT8jocKys7MVGhrq0VarVi0FBwcrOzu7zDG1a9c+6x+1sLAw95jCwkIlJSVp6tSpioyMrJLavUlVrfPPrVmzRgsWLNCwYcMqpe6a7NChQyouLlZYWJhHu219srOzrf3P/FmRfV7qqmKdf+7kyZN6+OGHlZSU9Iv9MtiqWuenn35atWrV0siRIyu/aC9GWIIkaezYsXI4HNYtMzOzyo6fkpKi6Oho3XnnnVV2jJqgutf5p7Zu3apevXopNTVVPXr0uCjHBC5UUVGR+vXrJ2OMXn755eou55KSkZGhmTNn6o033pDD4ajucmqUWtVdAGqG0aNHKzk52dqnZcuWcrlcys3N9Wg/ffq0Dh8+LJfLVeo4l8ulU6dOKS8vz+OsR05OjnvMqlWrtGXLFi1atEjSj+8wkqRGjRrp0Ucf1cSJE89zZjVLda/zGdu3b1f37t01bNgwjRs37rzm4m0aNWokX1/fs96FWdr6nOFyuaz9z/yZk5Ojxo0be/Tp0KFDJVbvPapinc84E5T27NmjVatW/WLPKklVs86ff/65cnNzPc7uFxcXa/To0ZoxY4Z2795duZPwJtV90RS8y5kLjzds2OBu+/DDD8t14fGiRYvcbZmZmR4XHn/zzTdmy5Yt7u311183ksyaNWvKfGfHpayq1tkYY7Zu3WpCQ0PNmDFjqm4CNVTnzp3NiBEj3LeLi4tNkyZNrBfE3nLLLR5t8fHxZ13g/eyzz7rvz8/P5wLvSl5nY4w5deqU6d27t2nbtq3Jzc2tmsK9TGWv86FDhzz+Hd6yZYsJDw83Dz/8sMnMzKy6iXgBwhIqrGfPnuaqq64ya9euNf/+979NVFSUx1va9+/fb1q3bm3Wrl3rbrvnnntMZGSkWbVqldmwYYOJj4838fHxZR7j448//kW/G86YqlnnLVu2mJCQEHPnnXeagwcPurdfypPP/Pnzjb+/v3njjTfM9u3bzbBhw0xQUJDJzs42xhgzcOBAM3bsWHf/1atXm1q1aplnn33W7Nixw6Smppb60QFBQUHm3XffNV999ZXp1asXHx1Qyet86tQpc9ttt5mmTZuaL7/80uN3t7CwsFrmWBNUxe/zz/FuuB8RllBh33//vUlKSjL169c3TqfTDB482Bw9etR9/65du4wk8/HHH7vbfvjhB/PnP//ZXHbZZaZu3brm9ttvNwcPHizzGISlqlnn1NRUI+msrVmzZhdxZtXrhRdeMJGRkaZ27dqmc+fO5osvvnDf161bNzNo0CCP/n//+9/Nr371K1O7dm3Ttm1b8/7773vcX1JSYh577DETFhZm/P39Tffu3U1WVtbFmEqNVpnrfOZ3vbTtp7//v0SV/fv8c4SlHzmM+f8XhwAAAOAsvBsOAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQmooXbv3i2Hw6Evv/yyuktxy8zMVJcuXRQQEOB1XxSbnJys3r17V9n+r7vuOt1///2Vvt9PPvlEDodDeXl5lb7vylTR+dfE32+gLIQloAzJyclyOBx66qmnPNqXLFkih8NRTVVVr9TUVNWrV09ZWVlKS0ur7nJqlMWLF2vy5MkXtI+qClylqezwWNH5R0RE6ODBg2rXrl2l1VAVqjpkwzsQlgCLgIAAPf300zpy5Eh1l1JpTp06dd5jd+7cqWuvvVbNmjVTw4YNK7Eq7xccHKwGDRpUdxmVrqioqFz9Kjp/X19fuVwu1apV63xLAy4awhJgkZCQIJfLpSlTppTZZ8KECWe9JDVjxgw1b97cffvM/06ffPJJhYWFKSgoSJMmTdLp06c1ZswYBQcHq2nTppozZ85Z+8/MzFTXrl0VEBCgdu3a6dNPP/W4f+vWrbrxxhtVv359hYWFaeDAgTp06JD7/uuuu04jRozQ/fffr0aNGikxMbHUeZSUlGjSpElq2rSp/P391aFDB61YscJ9v8PhUEZGhiZNmiSHw6EJEyaUup9FixYpJiZGderUUcOGDZWQkKDjx49LktavX68bbrhBjRo1UmBgoLp166aNGzd6jHc4HHrllVd0yy23qG7duoqOjlZ6erq++eYbXXfddapXr566du2qnTt3nvUYvPLKK4qIiFDdunXVr18/5efnl1rjmflOmTJFLVq0UJ06ddS+fXstWrTIff+RI0c0YMAAhYSEqE6dOoqKiir18fnpOv/0rFDz5s315JNP6u6771aDBg0UGRmpv/zlL2WOT05O1qeffqqZM2fK4XDI4XBo9+7d7vszMjIUGxurunXrqmvXrsrKyvIY/+6776pjx44KCAhQy5YtNXHiRJ0+fbrUY02YMEF/+9vf9O6777qP9cknn7hfGluwYIG6deumgIAAvf322/r++++VlJSkJk2aqG7duoqJidE777xzQfP/+ctwZ15uTEtLs87z8ccfV2hoqBo0aKA//OEPGjt2rPUl4XM9jvv27VO/fv0UFBSk4OBg9erVy73uZa0TfoGq+5t8gZpq0KBBplevXmbx4sUmICDA7Nu3zxhjzD//+U/z0786qamppn379h5jp0+fbpo1a+axrwYNGpjhw4ebzMxM89prrxlJJjEx0TzxxBPmP//5j5k8ebLx8/NzH+fMN603bdrULFq0yGzfvt384Q9/MA0aNDCHDh0yxhhz5MgRExISYlJSUsyOHTvMxo0bzQ033GB+85vfuI/drVs3U79+fTNmzBiTmZlpMjMzS53vtGnTjNPpNO+8847JzMw0Dz30kPHz8zP/+c9/jDHGHDx40LRt29aMHj3aHDx40Bw9evSsfRw4cMDUqlXLTJs2zezatct89dVXZtasWe6+aWlp5s033zQ7duww27dvN0OGDDFhYWGmoKDAvQ9JpkmTJmbBggUmKyvL9O7d2zRv3txcf/31ZsWKFWb79u2mS5cupmfPnh6PQb169cz1119vNm3aZD799FPTqlUr8/vf//6sx/OMxx9/3LRp08asWLHC7Ny508yZM8f4+/ubTz75xBhjzPDhw02HDh3M+vXrza5du8zKlSvN0qVLS127M+t83333uW83a9bMBAcHm1mzZpmvv/7aTJkyxfj4+JS5/nl5eSY+Pt4MHTrUHDx40Bw8eNCcPn3afPzxx0aSiYuLM5988onZtm2b+fWvf226du3qHvvZZ58Zp9Np3njjDbNz507zr3/9yzRv3txMmDCh1GMdPXrU9OvXz/Ts2dN9rMLCQvfvXPPmzc0//vEP89///tccOHDA7N+/30ydOtVs2rTJ7Ny50zz//PPG19fXrF279rznf+ZYmzZtMsaYcs3zrbfeMgEBAeb11183WVlZZuLEicbpdJ719++nbI/jqVOnTHR0tLn77rvNV199ZbZv325+//vfm9atW5vCwsIy1wm/PIQloAw/fXLt0qWLufvuu40x5x+WmjVrZoqLi91trVu3Nr/+9a/dt0+fPm3q1atn3nnnHWPM/55MnnrqKXefoqIi07RpU/P0008bY4yZPHmy6dGjh8ex9+3bZySZrKwsY8yPT2JXXXXVOecbHh5unnjiCY+2q6++2vz5z392327fvr1JTU0tcx8ZGRlGktm9e/c5j2eMMcXFxaZBgwbmvffec7dJMuPGjXPfTk9PN5LMa6+95m575513TEBAgPt2amqq8fX1Nfv373e3ffDBB8bHx8ccPHjQGOP5eJ48edLUrVvXrFmzxqOeIUOGmKSkJGOMMbfeeqsZPHhwueZhTOlh4c4773TfLikpMaGhoebll18u9z6M+V+I+Oijj9xt77//vpFkfvjhB2OMMd27dzdPPvmkx7g333zTNG7cuMxj/Tw8GvO/37kZM2aUOe6Mm2++2YwePbrM2s81/7LCkm2ecXFxZvjw4R51XHPNNdawZHsc33zzTdO6dWtTUlLibissLDR16tQxH374oTGm9HXCLw8vwwHl8PTTT+tvf/ubduzYcd77aNu2rXx8/vdXLiwsTDExMe7bvr6+atiwoXJzcz3GxcfHu3+uVauWYmNj3XVs3rxZH3/8serXr+/e2rRpI0keL1N16tTJWltBQYEOHDiga665xqP9mmuuqdCc27dvr+7duysmJka//e1v9eqrr3pc75WTk6OhQ4cqKipKgYGBcjqdOnbsmPbu3euxnyuvvNL9c1hYmCR5rFVYWJhOnjypgoICd1tkZKSaNGnivh0fH6+SkpKzXsaRpG+++UYnTpzQDTfc4LF2c+fOda/bn/70J82fP18dOnTQQw89pDVr1pR7HUqbh8PhkMvlOuvxPZ99NW7cWJLc+9q8ebMmTZrkMZehQ4fq4MGDOnHiRIWPFRsb63G7uLhYkydPVkxMjIKDg1W/fn19+OGHZz1utprLO3/bPLOystS5c2eP/j+//XO2x3Hz5s365ptv1KBBA/e6BQcH6+TJkx5/fwCurAPK4f/+7/+UmJiolJQUJScne9zn4+MjY4xHW2kXxfr5+XncdjgcpbaVlJSUu65jx47p1ltv1dNPP33WfWeeaCSpXr165d7nhfD19dXKlSu1Zs0a/etf/9ILL7ygRx99VGvXrlWLFi00aNAgff/995o5c6aaNWsmf39/xcfHn3XR+U/X5cw7D0trq8ha/dSxY8ckSe+//75HwJIkf39/SdKNN96oPXv2aPny5Vq5cqW6d++u4cOH69lnny33cS708S1rXz+f/7FjxzRx4kTdcccdZ40LCAio8LF+/vsydepUzZw5UzNmzFBMTIzq1aun+++//5xvFjif+Vfm4yzZH8djx46pU6dOevvtt88aFxISct7HxKWHM0tAOT311FN67733lJ6e7tEeEhKi7Oxsj8BUmZ8d88UXX7h/Pn36tDIyMhQdHS1J6tixo7Zt26bmzZurVatWHltFApLT6VR4eLhWr17t0b569WpdccUVFarX4XDommuu0cSJE7Vp0ybVrl1b//znP937GzlypG666Sa1bdtW/v7+HhejX4i9e/fqwIED7ttffPGFfHx81Lp167P6XnHFFfL399fevXvPWreIiAh3v5CQEA0aNEhvvfWWZsyYYb1AuzLUrl1bxcXFFR7XsWNHZWVlnTWXVq1aeZzNPN9jrV69Wr169dKdd96p9u3bq2XLlvrPf/5T4TovVOvWrbV+/XqPtp/fLk1Zj2PHjh319ddfKzQ09Kx1CwwMlHT+jwkuLZxZAsopJiZGAwYM0PPPP+/Rft111+m7777TM888o759+2rFihX64IMP5HQ6K+W4s2bNUlRUlKKjozV9+nQdOXJEd999tyRp+PDhevXVV5WUlKSHHnpIwcHB+uabbzR//nz99a9/la+vb7mPM2bMGKWmpuryyy9Xhw4dNGfOHH355Zel/q+7LGvXrlVaWpp69Oih0NBQrV27Vt9995073EVFRenNN99UbGysCgoKNGbMGNWpU6diC1KGgIAADRo0SM8++6wKCgo0cuRI9evXTy6X66y+DRo00IMPPqgHHnhAJSUluvbaa5Wfn6/Vq1fL6XRq0KBBGj9+vDp16qS2bduqsLBQy5Ytc8+jqjRv3lxr167V7t273S8Jlcf48eN1yy23KDIyUn379pWPj482b96srVu36vHHHy/zWB9++KGysrLUsGFDdzgoTVRUlBYtWqQ1a9bosssu07Rp05STk1PhIH2h7r33Xg0dOlSxsbHq2rWrFixYoK+++kotW7Ysc4ztcRwwYICmTp2qXr16ud8JumfPHi1evFgPPfSQmjZtWuo6/fyMGS59nFkCKmDSpElnvSQQHR2tl156SbNmzVL79u21bt06Pfjgg5V2zKeeekpPPfWU2rdvr3//+99aunSpGjVqJEnus0HFxcXq0aOHYmJidP/99ysoKKjMMwplGTlypEaNGqXRo0crJiZGK1as0NKlSxUVFVXufTidTn322We66aab9Ktf/Urjxo3Tc889pxtvvFGS9Nprr+nIkSPq2LGjBg4cqJEjRyo0NLRCdZalVatWuuOOO3TTTTepR48euvLKK/XSSy+V2X/y5Ml67LHHNGXKFEVHR6tnz556//331aJFC0k/nlFISUnRlVdeqf/7v/+Tr6+v5s+fXym1luXBBx+Ur6+vrrjiCoWEhJzzmqAzEhMTtWzZMv3rX//S1VdfrS5dumj69Olq1qxZmWOGDh2q1q1bKzY2ViEhIWedVfypcePGqWPHjkpMTNR1110nl8tVLR/UOGDAAKWkpOjBBx9Ux44dtWvXLiUnJ1tfarQ9jnXr1tVnn32myMhI3XHHHYqOjtaQIUN08uRJ9392KrJOuHQ5zM8vtgAALzNhwgQtWbKEr874Bbrhhhvkcrn05ptvVncpuITxMhwAwCucOHFCs2fPVmJionx9ffXOO+/oo48+0sqVK6u7NFziCEsAAK/gcDi0fPlyPfHEEzp58qRat26tf/zjH0pISKju0nCJ42U4AAAACy7wBgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABg8f8Amn2qC+PgNN0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display = LearningCurveDisplay(train_sizes=train_sizes, train_scores=train_scores, test_scores=test_scores, score_name=\"R2\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90ba46e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5d96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
