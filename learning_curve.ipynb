{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99de795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "from scipy.stats import pearsonr\n",
    "from cmath import isinf\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "from cmath import isinf\n",
    "from sklearn.model_selection import train_test_split, KFold, LearningCurveDisplay, learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from skorch import NeuralNet\n",
    "from skorch.callbacks import Callback\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d147112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7d8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_to_numpy(loader):\n",
    "    features, targets = [], []\n",
    "    for feat, targ in loader:\n",
    "        features.append(feat.numpy())\n",
    "        targets.append(targ.numpy())\n",
    "    return np.concatenate(features), np.concatenate(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5aa9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim_feat = 499500, input_dim_target = 1, hidden_dim_feat = 1000, output_dim = 2, dropout_rate = 0):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Xavier initialization for feature MLP\n",
    "        self.feat_mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim_feat),\n",
    "            nn.Linear(input_dim_feat, hidden_dim_feat),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(hidden_dim_feat, output_dim)\n",
    "        )\n",
    "        self.init_weights(self.feat_mlp)\n",
    "\n",
    "        # Xavier initialization for target MLP\n",
    "        self.target_mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim_target),\n",
    "            nn.Linear(input_dim_target, output_dim)\n",
    "        )\n",
    "        self.init_weights(self.target_mlp)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        features = self.feat_mlp(x)\n",
    "        targets = self.target_mlp(y)\n",
    "        features = nn.functional.normalize(features, p=2, dim=1)\n",
    "        targets = nn.functional.normalize(targets, p=2, dim=1)\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93673abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "import multiprocessing\n",
    "\n",
    "@torch.no_grad()\n",
    "def gather_feats_targets(model, dataloader, device):\n",
    "    features = []\n",
    "    targets = []\n",
    "\n",
    "    model.eval()\n",
    "    for idx, (feat, target) in enumerate(dataloader):\n",
    "        if len(feat.shape) > 2:\n",
    "            feat = feat[:, 0, :]\n",
    "        feat = feat.to(device)\n",
    "        target = target.to(device)\n",
    "        out_feat, out_target= model(feat, target)\n",
    "        features.append(out_feat)\n",
    "        targets.append(target[:, 0])\n",
    "    \n",
    "    return torch.cat(features, 0).cpu().numpy(), torch.cat(targets, 0).cpu().numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_age(model, train_loader, test_loader, device):\n",
    "    age_estimator = AgeEstimator()\n",
    "    X_train, y_train = gather_feats_targets(model, train_loader, device)\n",
    "    age_estimator.fit(X_train, y_train)\n",
    "    y_pred_train = age_estimator.predict(X_train)\n",
    "    X_test, y_test = gather_feats_targets(model, test_loader, device)\n",
    "    y_pred_test = age_estimator.predict(X_test)\n",
    "    return y_train, y_test, y_pred_train, y_pred_test\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_age_mae_r2(model, train_loader, test_loader, device): # test_int, test_ext, opts\n",
    "    age_estimator = AgeEstimator()\n",
    "\n",
    "    print(\"Training age estimator\")\n",
    "    train_X, train_y = gather_feats_targets(model, train_loader, device)\n",
    "    mae_train, r2_train = age_estimator.fit(train_X, train_y)\n",
    "    X_test, y_test = gather_feats_targets(model, test_loader, device)\n",
    "    #ext_X, ext_y = gather_age_feats(model, test_ext, opts)\n",
    "    mae_test = age_estimator.score(X_test, y_test)\n",
    "    r2_test = age_estimator.r2(X_test, y_test)\n",
    "    # mae_ext = age_estimator.score(ext_X, ext_y)\n",
    "\n",
    "    return mae_train, r2_train, mae_test, r2_test # mae, r2 for train and test\n",
    "\n",
    "class AgeEstimator(BaseEstimator):\n",
    "    \"\"\" Define the age estimator on latent space network features.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        n_jobs = multiprocessing.cpu_count()\n",
    "        self.age_estimator = GridSearchCV(\n",
    "            Ridge(), param_grid={\"alpha\": 10.**np.arange(-2, 3)}, cv=5,\n",
    "            scoring=\"r2\", n_jobs=n_jobs)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.age_estimator.fit(X, y)\n",
    "        return self.score(X, y), self.r2(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.age_estimator.predict(X)\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.age_estimator.predict(X)\n",
    "        return mean_absolute_percentage_error(y, y_pred)\n",
    "    \n",
    "    def r2(self, X, y):\n",
    "        y_pred = self.age_estimator.predict(X)\n",
    "        return r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5caa4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatData(Dataset):\n",
    "    def __init__(self, path_feat, path_target, target_name, indices, transform = None, regions = None, threshold_mat = False, threshold_percent = None, random_state=42):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with the capability to handle training and testing splits, \n",
    "        including multiple views for augmented data.\n",
    "        \n",
    "        Args:\n",
    "            path_feat (str): Path to the features file.\n",
    "            path_target (str): Path to the target file.\n",
    "            transform (callable): A transformation function to apply for augmentation.\n",
    "            train (bool): Whether the dataset is used for training. False will load the test set.\n",
    "            test_size (float): Proportion of the dataset to include in the test split.\n",
    "            random_state (int): Random state for reproducible train-test splits.\n",
    "        \"\"\"\n",
    "        \n",
    "        features = np.load(path_feat)[indices]\n",
    "        participant_data = pd.read_csv(path_target)\n",
    "        targets = participant_data[target_name].values[indices]\n",
    "        targets = np.expand_dims(targets, axis = 1)\n",
    "        \n",
    "        if threshold_mat:\n",
    "            thresholded_feat = []\n",
    "            for matrix in features:\n",
    "                threshold = np.percentile(matrix, threshold_percent)\n",
    "                matrix[matrix < threshold] = 0\n",
    "                thresholded_feat.append(matrix)\n",
    "            threshold_feat = np.stack(thresholded_feat)\n",
    "            features = threshold_feat\n",
    "        \n",
    "\n",
    "        self.n_sub = len(features)\n",
    "        self.n_views = 1\n",
    "        self.transform = transform\n",
    "        self.targets = targets\n",
    "        \n",
    "        vectorized_feat = np.array([sym_matrix_to_vec(mat, discard_diagonal=True) for mat in features])\n",
    "        self.n_features = vectorized_feat.shape[-1]\n",
    "        \n",
    "        if transform is not None:\n",
    "            # augmentation only in training mode\n",
    "            if transform != \"copy\":\n",
    "                augmented_features = np.array([self.transform(sample, regions = regions) for sample in features])\n",
    "\n",
    "                self.n_views = self.n_views + augmented_features.shape[1]\n",
    "                self.features = np.zeros((self.n_sub, self.n_views, self.n_features))\n",
    "                for sub in range(self.n_sub):\n",
    "                    self.features[sub, 0, :] = vectorized_feat[sub]\n",
    "                    self.features[sub, 1:, :] = augmented_features[sub]\n",
    "            else:\n",
    "                self.features = np.repeat(np.expand_dims(vectorized_feat, axis = 1), 2, axis=1)\n",
    "        else:\n",
    "            self.features = np.expand_dims(vectorized_feat, axis = 1)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.n_sub\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features[idx]\n",
    "        targets = self.targets[idx]\n",
    "        features = torch.from_numpy(features).float()\n",
    "        targets = torch.from_numpy(targets).float()\n",
    "        \n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aeeb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, krnl_sigma):\n",
    "    x = x - x.T\n",
    "    return torch.exp(-(x**2) / (2*(krnl_sigma**2))) / (math.sqrt(2*torch.pi)*krnl_sigma)\n",
    "\n",
    "def cauchy(x, krnl_sigma):\n",
    "        x = x - x.T\n",
    "        return  1. / (krnl_sigma*(x**2) + 1)\n",
    "\n",
    "def rbf(x, krnl_sigma):\n",
    "        x = x - x.T\n",
    "        return torch.exp(-(x**2)/(2*(krnl_sigma**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f739858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss from: https://github.com/EIDOSLAB/contrastive-brain-age-prediction/blob/master/src/losses.py\n",
    "# modified to accept input shape [bsz, n_feats]. In the age paper: [bsz, n_views, n_feats].\n",
    "class KernelizedSupCon(nn.Module):\n",
    "    \"\"\"Supervised contrastive loss: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\n",
    "    Based on: https://github.com/HobbitLong/SupContrast\"\"\"\n",
    "    def __init__(self, method: str='expw', temperature: float=0.03, contrast_mode: str='all',\n",
    "                 base_temperature: float=0.07, krnl_sigma: float = 1., kernel: callable=cauchy, delta_reduction: str='sum'):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "        self.method = method\n",
    "        self.kernel = kernel\n",
    "        self.krnl_sigma = krnl_sigma\n",
    "        self.delta_reduction = delta_reduction\n",
    "\n",
    "        if kernel is not None and method == 'supcon':\n",
    "            raise ValueError('Kernel must be none if method=supcon')\n",
    "        \n",
    "        if kernel is None and method != 'supcon':\n",
    "            raise ValueError('Kernel must not be none if method != supcon')\n",
    "\n",
    "        if delta_reduction not in ['mean', 'sum']:\n",
    "            raise ValueError(f\"Invalid reduction {delta_reduction}\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__} ' \\\n",
    "               f'(t={self.temperature}, ' \\\n",
    "               f'method={self.method}, ' \\\n",
    "               f'kernel={self.kernel is not None}, ' \\\n",
    "               f'delta_reduction={self.delta_reduction})'\n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        \"\"\"Compute loss for model. If `labels` is None, \n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, n_features]. \n",
    "                input has to be rearranged to [bsz, n_views, n_features] and labels [bsz],\n",
    "            labels: ground truth of shape [bsz].\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "\n",
    "        if len(features.shape) != 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, n_feats],'\n",
    "                             '3 dimensions are required')\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        contrast_count = features.shape[1]\n",
    "\n",
    "        if labels is None:\n",
    "            mask = torch.eye(batch_size, device=device)\n",
    "        \n",
    "        else:\n",
    "            labels = labels.view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            \n",
    "            if self.kernel is None:\n",
    "                mask = torch.eq(labels, labels.T)\n",
    "            else:\n",
    "                mask = self.kernel(labels, krnl_sigma = self.krnl_sigma)     \n",
    "        \n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # Tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # Inverse of torch-eye to remove self-contrast (diagonal)\n",
    "        inv_diagonal = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size*anchor_count, device=device).view(-1, 1),\n",
    "            0\n",
    "        )\n",
    "        # compute similarity\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature\n",
    "        )\n",
    "\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        alignment = logits \n",
    "\n",
    "        # base case is:\n",
    "        # - supcon if kernel = none \n",
    "        # - y-aware is kernel != none\n",
    "        uniformity = torch.exp(logits) * inv_diagonal \n",
    "\n",
    "        if self.method == 'threshold':\n",
    "            repeated = mask.unsqueeze(-1).repeat(1, 1, mask.shape[0]) # repeat kernel mask\n",
    "\n",
    "            delta = (mask[:, None].T - repeated.T).transpose(1, 2) # compute the difference w_k - w_j for every k,j\n",
    "            delta = (delta > 0.).float()\n",
    "\n",
    "            # for each z_i, repel only samples j s.t. K(z_i, z_j) < K(z_i, z_k)\n",
    "            uniformity = uniformity.unsqueeze(-1).repeat(1, 1, mask.shape[0])\n",
    "\n",
    "            if self.delta_reduction == 'mean':\n",
    "                uniformity = (uniformity * delta).mean(-1)\n",
    "            else:\n",
    "                uniformity = (uniformity * delta).sum(-1)\n",
    "    \n",
    "        elif self.method == 'expw':\n",
    "            # exp weight e^(s_j(1-w_j))\n",
    "            uniformity = torch.exp(logits * (1 - mask)) * inv_diagonal\n",
    "\n",
    "        uniformity = torch.log(uniformity.sum(1, keepdim=True))\n",
    "\n",
    "\n",
    "        # positive mask contains the anchor-positive pairs\n",
    "        # excluding <self,self> on the diagonal\n",
    "        positive_mask = mask * inv_diagonal\n",
    "\n",
    "        log_prob = alignment - uniformity # log(alignment/uniformity) = log(alignment) - log(uniformity)\n",
    "        log_prob = (positive_mask * log_prob).sum(1) / positive_mask.sum(1) # compute mean of log-likelihood over positive\n",
    " \n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * log_prob\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c35b8b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = pd.read_csv(\"participants.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7fc00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion_pft, criterion_ptt, optimizer):\n",
    "    \n",
    "    model.train()\n",
    "    batch_losses = []\n",
    "    for batch_num, (features, targets) in enumerate(train_loader):\n",
    "        bsz = targets.shape[0]\n",
    "        n_views = features.shape[1]\n",
    "        n_feat = features.shape[-1]\n",
    "        \n",
    "        features = features.view(bsz * n_views, n_feat) # [bsz*2, 499500]\n",
    "        features, targets = features.to(device), targets.to(device) # [bsz, 2, 499500], [bsz, 1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out_feat, out_target = model(features, torch.cat(n_views*[targets], dim=0)) # ([bsz*5, 1], [bsz*5, 1])\n",
    "        \n",
    "        out_feat = torch.split(out_feat, [bsz]*n_views, dim=0)\n",
    "        out_feat = torch.cat([f.unsqueeze(1) for f in out_feat], dim=1) # [bsz, 5, 2]\n",
    "        \n",
    "        loss = criterion_pft(out_feat, targets) # ([bsz, 5, 2], [bsz, 1])\n",
    "        \n",
    "        out_target = torch.split(out_target, [bsz]*n_views, dim=0)\n",
    "        out_target = torch.cat([f.unsqueeze(1) for f in out_target], dim=1) # [bsz, 2, 2]\n",
    "        loss += criterion_ptt(out_target, targets) # ([bsz, 5, 2], [bsz, 1])\n",
    "        loss += torch.nn.functional.mse_loss(out_feat.view(bsz * n_views, 2), out_target.view(bsz * n_views, 2)) # mse_loss([bsz*2, 2], [bsz*2, 2])\n",
    "    \n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        batch_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "    mean_loss = sum(batch_losses)/len(batch_losses)\n",
    "    print(f'Epoch {epoch} | Mean Loss {mean_loss}')\n",
    "        \n",
    "    return mean_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8492848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, criterion_pft, criterion_ptt, optimizer):\n",
    "    \n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    emb_features = [] # saving the embedded features for each batch\n",
    "    emb_targets = []\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "        for batch_num, (features, targets) in enumerate(v):\n",
    "            bsz = targets.shape[0]\n",
    "            n_views = 1\n",
    "            n_feat = features.shape[-1]\n",
    "\n",
    "            if len(features.shape) > 2:\n",
    "                n_views = features.shape[1]\n",
    "                features = features.view(bsz * n_views, n_feat) # [bsz*2, 499500]\n",
    "            features, targets = features.to(device), targets.to(device) # [bsz, 2, 499500], [bsz, 1]\n",
    "\n",
    "            out_feat, out_target = model(features, torch.cat(n_views*[targets], dim=0))   \n",
    "\n",
    "            out_feat = torch.split(out_feat, [bsz]*n_views, dim=0)\n",
    "            out_feat = torch.cat([f.unsqueeze(1) for f in out_feat], dim=1) # [bsz, 5, 2]\n",
    "\n",
    "            loss = criterion_pft(out_feat, targets) # ([bsz, 5, 2], [bsz, 1])\n",
    "\n",
    "            out_target = torch.split(out_target, [bsz]*n_views, dim=0)\n",
    "            out_target = torch.cat([f.unsqueeze(1) for f in out_target], dim=1) # [bsz, 2, 2]\n",
    "\n",
    "            loss += criterion_ptt(out_target, targets) # ([bsz, 5, 2], [bsz, 1])\n",
    "            loss += torch.nn.functional.mse_loss(out_feat.view(bsz * n_views, 2), out_target.view(bsz * n_views, 2)) # mse_loss([bsz*2, 2], [bsz*2, 2])\n",
    "\n",
    "            emb_features.append(out_feat[:, 0, :])\n",
    "            emb_targets.append(out_target[:, 0, :])\n",
    "\n",
    "            test_losses.append(loss.item())\n",
    "            total_loss += loss.item() * features.size(0)\n",
    "            total_samples += features.size(0)\n",
    "\n",
    "        test_losses =np.array(test_losses)\n",
    "        average_loss = total_loss / total_samples\n",
    "        print('Mean Test Loss: %6.2f' % (average_loss))\n",
    "        \n",
    "        return torch.row_stack(emb_features).cpu(), torch.row_stack(emb_features).cpu()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d977c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f782af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  0.1\n",
      "Epoch 0 | Mean Loss 8.919943650563559\n",
      "Epoch 1 | Mean Loss 3.874942143758138\n",
      "Epoch 2 | Mean Loss 3.2753611405690513\n",
      "Epoch 3 | Mean Loss 3.2424439589182534\n",
      "Epoch 4 | Mean Loss 3.152751843134562\n",
      "Epoch 5 | Mean Loss 3.062312602996826\n",
      "Epoch 6 | Mean Loss 3.0395615100860596\n",
      "Epoch 7 | Mean Loss 2.974789539972941\n",
      "Epoch 8 | Mean Loss 2.9283856550852456\n",
      "Epoch 9 | Mean Loss 2.8457045555114746\n",
      "Epoch 10 | Mean Loss 2.8308163483937583\n",
      "Epoch 11 | Mean Loss 2.774228493372599\n",
      "Epoch 12 | Mean Loss 2.744319121042887\n",
      "Epoch 13 | Mean Loss 2.6850635210673013\n",
      "Epoch 14 | Mean Loss 2.7358898321787515\n",
      "Epoch 15 | Mean Loss 2.683438857396444\n",
      "Epoch 16 | Mean Loss 2.5876128673553467\n",
      "Epoch 17 | Mean Loss 2.565842787424723\n",
      "Epoch 18 | Mean Loss 2.5915112495422363\n",
      "Epoch 19 | Mean Loss 2.5431607564290366\n",
      "Epoch 20 | Mean Loss 2.4905656973520913\n",
      "Epoch 21 | Mean Loss 2.5508903662363687\n",
      "Epoch 22 | Mean Loss 2.4935876528422036\n",
      "Epoch 23 | Mean Loss 2.4604878425598145\n",
      "Epoch 24 | Mean Loss 2.4554930130640664\n",
      "Epoch 25 | Mean Loss 2.4091268380482993\n",
      "Epoch 26 | Mean Loss 2.4360567728678384\n",
      "Epoch 27 | Mean Loss 2.438803513844808\n",
      "Epoch 28 | Mean Loss 2.4134669303894043\n",
      "Epoch 29 | Mean Loss 2.4221213658650718\n",
      "Epoch 30 | Mean Loss 2.3788108030954995\n",
      "Epoch 31 | Mean Loss 2.441323200861613\n",
      "Epoch 32 | Mean Loss 2.4044471979141235\n",
      "Epoch 33 | Mean Loss 2.3856512705485025\n",
      "Epoch 34 | Mean Loss 2.377749800682068\n",
      "Epoch 35 | Mean Loss 2.3760999838511148\n",
      "Epoch 36 | Mean Loss 2.3730823596318564\n",
      "Epoch 37 | Mean Loss 2.458606163660685\n",
      "Epoch 38 | Mean Loss 2.364675680796305\n",
      "Epoch 39 | Mean Loss 2.3902252515157065\n",
      "Epoch 40 | Mean Loss 2.3821005821228027\n",
      "Epoch 41 | Mean Loss 2.3537890911102295\n",
      "Epoch 42 | Mean Loss 2.3705578247706094\n",
      "Epoch 43 | Mean Loss 2.3666892846425376\n",
      "Epoch 44 | Mean Loss 2.365451137224833\n",
      "Epoch 45 | Mean Loss 2.3603800932566323\n",
      "Epoch 46 | Mean Loss 2.356524427731832\n",
      "Epoch 47 | Mean Loss 2.3731382687886557\n",
      "Epoch 48 | Mean Loss 2.370686928431193\n",
      "Epoch 49 | Mean Loss 2.358639200528463\n",
      "Epoch 50 | Mean Loss 2.389228185017904\n",
      "Epoch 51 | Mean Loss 2.373626788457235\n",
      "Epoch 52 | Mean Loss 2.3829497496287027\n",
      "Epoch 53 | Mean Loss 2.3722918033599854\n",
      "Epoch 54 | Mean Loss 2.3881890773773193\n",
      "Epoch 55 | Mean Loss 2.3451364835103354\n",
      "Epoch 56 | Mean Loss 2.395721515019735\n",
      "Epoch 57 | Mean Loss 2.3608036041259766\n",
      "Epoch 58 | Mean Loss 2.3800326188405356\n",
      "Epoch 59 | Mean Loss 2.389491558074951\n",
      "Epoch 60 | Mean Loss 2.3416999181111655\n",
      "Epoch 61 | Mean Loss 2.363361199696859\n",
      "Epoch 62 | Mean Loss 2.373789111773173\n",
      "Epoch 63 | Mean Loss 2.367481509844462\n",
      "Epoch 64 | Mean Loss 2.455543120702108\n",
      "Epoch 65 | Mean Loss 2.387763182322184\n",
      "Epoch 66 | Mean Loss 2.3655441999435425\n",
      "Epoch 67 | Mean Loss 2.3793795108795166\n",
      "Epoch 68 | Mean Loss 2.35852042833964\n",
      "Epoch 69 | Mean Loss 2.3712403774261475\n",
      "Epoch 70 | Mean Loss 2.3691412607828775\n",
      "Epoch 71 | Mean Loss 2.392348845799764\n",
      "Epoch 72 | Mean Loss 2.390614906946818\n",
      "Epoch 73 | Mean Loss 2.360332727432251\n",
      "Epoch 74 | Mean Loss 2.4047203858693442\n",
      "Epoch 75 | Mean Loss 2.3954737981160483\n",
      "Epoch 76 | Mean Loss 2.36308487256368\n",
      "Epoch 77 | Mean Loss 2.3779386281967163\n",
      "Epoch 78 | Mean Loss 2.3805840412775674\n",
      "Epoch 79 | Mean Loss 2.3469813664754233\n",
      "Epoch 80 | Mean Loss 2.3672341108322144\n",
      "Epoch 81 | Mean Loss 2.3743545611699424\n",
      "Epoch 82 | Mean Loss 2.3500913778940835\n",
      "Epoch 83 | Mean Loss 2.3639551798502603\n",
      "Epoch 84 | Mean Loss 2.38865331808726\n",
      "Epoch 85 | Mean Loss 2.3679595788319907\n",
      "Epoch 86 | Mean Loss 2.3728963136672974\n",
      "Epoch 87 | Mean Loss 2.3730369408925376\n",
      "Epoch 88 | Mean Loss 2.3459893067677817\n",
      "Epoch 89 | Mean Loss 2.36708402633667\n",
      "Epoch 90 | Mean Loss 2.372050325075785\n",
      "Epoch 91 | Mean Loss 2.379711151123047\n",
      "Epoch 92 | Mean Loss 2.379981279373169\n",
      "Epoch 93 | Mean Loss 2.3617106278737388\n",
      "Epoch 94 | Mean Loss 2.360064744949341\n",
      "Epoch 95 | Mean Loss 2.356766184171041\n",
      "Epoch 96 | Mean Loss 2.38931671778361\n",
      "Epoch 97 | Mean Loss 2.3669035037358603\n",
      "Epoch 98 | Mean Loss 2.350893417994181\n",
      "Epoch 99 | Mean Loss 2.408095121383667\n",
      "Epoch 0 | Mean Loss 11.36030387878418\n",
      "Epoch 1 | Mean Loss 4.767122586568196\n",
      "Epoch 2 | Mean Loss 4.200616677602132\n",
      "Epoch 3 | Mean Loss 4.1008327802022295\n",
      "Epoch 4 | Mean Loss 3.988403797149658\n",
      "Epoch 5 | Mean Loss 3.961897134780884\n",
      "Epoch 6 | Mean Loss 3.7463765939076743\n",
      "Epoch 7 | Mean Loss 3.6500693957010903\n",
      "Epoch 8 | Mean Loss 3.5068508783976235\n",
      "Epoch 9 | Mean Loss 3.2068554560343423\n",
      "Epoch 10 | Mean Loss 3.2294973532358804\n",
      "Epoch 11 | Mean Loss 3.1623294353485107\n",
      "Epoch 12 | Mean Loss 3.0363341172536216\n",
      "Epoch 13 | Mean Loss 2.935483376185099\n",
      "Epoch 14 | Mean Loss 2.7771782080332437\n",
      "Epoch 15 | Mean Loss 2.8018480141957602\n",
      "Epoch 16 | Mean Loss 2.65086038907369\n",
      "Epoch 17 | Mean Loss 2.682589848836263\n",
      "Epoch 18 | Mean Loss 2.621820052464803\n",
      "Epoch 19 | Mean Loss 2.5781172116597495\n",
      "Epoch 20 | Mean Loss 2.5147233804066977\n",
      "Epoch 21 | Mean Loss 2.473715861638387\n",
      "Epoch 22 | Mean Loss 2.370777408281962\n",
      "Epoch 23 | Mean Loss 2.431581695874532\n",
      "Epoch 24 | Mean Loss 2.4334023793538413\n",
      "Epoch 25 | Mean Loss 2.4328993956247964\n",
      "Epoch 26 | Mean Loss 2.425381620724996\n",
      "Epoch 27 | Mean Loss 2.4186522165934243\n",
      "Epoch 28 | Mean Loss 2.4631501833597818\n",
      "Epoch 29 | Mean Loss 2.3315174182256064\n",
      "Epoch 30 | Mean Loss 2.4304121335347495\n",
      "Epoch 31 | Mean Loss 2.355111837387085\n",
      "Epoch 32 | Mean Loss 2.386513868967692\n",
      "Epoch 33 | Mean Loss 2.415719191233317\n",
      "Epoch 34 | Mean Loss 2.390500624974569\n",
      "Epoch 35 | Mean Loss 2.346464991569519\n",
      "Epoch 36 | Mean Loss 2.4070112705230713\n",
      "Epoch 37 | Mean Loss 2.3934208154678345\n",
      "Epoch 38 | Mean Loss 2.3354146480560303\n",
      "Epoch 39 | Mean Loss 2.396895170211792\n",
      "Epoch 40 | Mean Loss 2.3292725483576455\n",
      "Epoch 41 | Mean Loss 2.390411138534546\n",
      "Epoch 42 | Mean Loss 2.3828558921813965\n",
      "Epoch 43 | Mean Loss 2.317246397336324\n",
      "Epoch 44 | Mean Loss 2.3444828589757285\n",
      "Epoch 45 | Mean Loss 2.382667581240336\n",
      "Epoch 46 | Mean Loss 2.300972024599711\n",
      "Epoch 47 | Mean Loss 2.3632547855377197\n",
      "Epoch 48 | Mean Loss 2.370794653892517\n",
      "Epoch 49 | Mean Loss 2.3863396644592285\n",
      "Epoch 50 | Mean Loss 2.3481364250183105\n",
      "Epoch 51 | Mean Loss 2.37759268283844\n",
      "Epoch 52 | Mean Loss 2.3701281547546387\n",
      "Epoch 53 | Mean Loss 2.2946186860402427\n",
      "Epoch 54 | Mean Loss 2.3471661806106567\n",
      "Epoch 55 | Mean Loss 2.310173273086548\n",
      "Epoch 56 | Mean Loss 2.353410283724467\n",
      "Epoch 57 | Mean Loss 2.3190675576527915\n",
      "Epoch 58 | Mean Loss 2.369634826978048\n",
      "Epoch 59 | Mean Loss 2.294650077819824\n",
      "Epoch 60 | Mean Loss 2.3530492385228476\n",
      "Epoch 61 | Mean Loss 2.3496575355529785\n",
      "Epoch 62 | Mean Loss 2.359887401262919\n",
      "Epoch 63 | Mean Loss 2.2862099011739097\n",
      "Epoch 64 | Mean Loss 2.2700218756993613\n",
      "Epoch 65 | Mean Loss 2.3465253512064614\n",
      "Epoch 66 | Mean Loss 2.2947965463002524\n",
      "Epoch 67 | Mean Loss 2.3270036776860556\n",
      "Epoch 68 | Mean Loss 2.3593398332595825\n",
      "Epoch 69 | Mean Loss 2.344805637995402\n",
      "Epoch 70 | Mean Loss 2.382451335589091\n",
      "Epoch 71 | Mean Loss 2.310791293780009\n",
      "Epoch 72 | Mean Loss 2.362666289011637\n",
      "Epoch 73 | Mean Loss 2.3162004152933755\n",
      "Epoch 74 | Mean Loss 2.414513270060221\n",
      "Epoch 75 | Mean Loss 2.346436937650045\n",
      "Epoch 76 | Mean Loss 2.3372542460759482\n",
      "Epoch 77 | Mean Loss 2.3371901909510293\n",
      "Epoch 78 | Mean Loss 2.31683611869812\n",
      "Epoch 79 | Mean Loss 2.372679670651754\n",
      "Epoch 80 | Mean Loss 2.3291143576304116\n",
      "Epoch 81 | Mean Loss 2.348607619603475\n",
      "Epoch 82 | Mean Loss 2.2598569790522256\n",
      "Epoch 83 | Mean Loss 2.2699414094289145\n",
      "Epoch 84 | Mean Loss 2.2554434140523276\n",
      "Epoch 85 | Mean Loss 2.3492176135381064\n",
      "Epoch 86 | Mean Loss 2.2904442151387534\n",
      "Epoch 87 | Mean Loss 2.3311758041381836\n",
      "Epoch 88 | Mean Loss 2.2627756595611572\n",
      "Epoch 89 | Mean Loss 2.360969066619873\n",
      "Epoch 90 | Mean Loss 2.325575908025106\n",
      "Epoch 91 | Mean Loss 2.316498279571533\n",
      "Epoch 92 | Mean Loss 2.29411244392395\n",
      "Epoch 93 | Mean Loss 2.333381096522013\n",
      "Epoch 94 | Mean Loss 2.3465859095255532\n",
      "Epoch 95 | Mean Loss 2.3691099484761557\n",
      "Epoch 96 | Mean Loss 2.3686345418294272\n",
      "Epoch 97 | Mean Loss 2.2857890129089355\n",
      "Epoch 98 | Mean Loss 2.323756297429403\n",
      "Epoch 99 | Mean Loss 2.289281646410624\n",
      "Epoch 0 | Mean Loss 9.914082527160645\n",
      "Epoch 1 | Mean Loss 4.790324529012044\n",
      "Epoch 2 | Mean Loss 4.41319998105367\n",
      "Epoch 3 | Mean Loss 4.309071699778239\n",
      "Epoch 4 | Mean Loss 4.330487648646037\n",
      "Epoch 5 | Mean Loss 4.248798529307048\n",
      "Epoch 6 | Mean Loss 4.239322503407796\n",
      "Epoch 7 | Mean Loss 4.187214533487956\n",
      "Epoch 8 | Mean Loss 4.143493016560872\n",
      "Epoch 9 | Mean Loss 4.165405035018921\n",
      "Epoch 10 | Mean Loss 4.121104717254639\n",
      "Epoch 11 | Mean Loss 4.112858772277832\n",
      "Epoch 12 | Mean Loss 4.0822517077128095\n",
      "Epoch 13 | Mean Loss 4.0234856605529785\n",
      "Epoch 14 | Mean Loss 4.009288549423218\n",
      "Epoch 15 | Mean Loss 3.9825258255004883\n",
      "Epoch 16 | Mean Loss 3.9027379353841147\n",
      "Epoch 17 | Mean Loss 3.890086015065511\n",
      "Epoch 18 | Mean Loss 3.830117146174113\n",
      "Epoch 19 | Mean Loss 3.7438015143076577\n",
      "Epoch 20 | Mean Loss 3.733301321665446\n",
      "Epoch 21 | Mean Loss 3.6684605280558267\n",
      "Epoch 22 | Mean Loss 3.602557818094889\n",
      "Epoch 23 | Mean Loss 3.5023298263549805\n",
      "Epoch 24 | Mean Loss 3.414245843887329\n",
      "Epoch 25 | Mean Loss 3.3675523598988852\n",
      "Epoch 26 | Mean Loss 3.2390114466349282\n",
      "Epoch 27 | Mean Loss 3.1026131312052407\n",
      "Epoch 28 | Mean Loss 3.0410684744517007\n",
      "Epoch 29 | Mean Loss 2.924575090408325\n",
      "Epoch 30 | Mean Loss 2.873379389444987\n",
      "Epoch 31 | Mean Loss 2.766256093978882\n",
      "Epoch 32 | Mean Loss 2.6861321926116943\n",
      "Epoch 33 | Mean Loss 2.6279430389404297\n",
      "Epoch 34 | Mean Loss 2.6080609957377114\n",
      "Epoch 35 | Mean Loss 2.581807533899943\n",
      "Epoch 36 | Mean Loss 2.523939530054728\n",
      "Epoch 37 | Mean Loss 2.508227268854777\n",
      "Epoch 38 | Mean Loss 2.4960171381632485\n",
      "Epoch 39 | Mean Loss 2.492640813191732\n",
      "Epoch 40 | Mean Loss 2.4512811501820884\n",
      "Epoch 41 | Mean Loss 2.477081775665283\n",
      "Epoch 42 | Mean Loss 2.4275344610214233\n",
      "Epoch 43 | Mean Loss 2.416214426358541\n",
      "Epoch 44 | Mean Loss 2.403781215349833\n",
      "Epoch 45 | Mean Loss 2.420437534650167\n",
      "Epoch 46 | Mean Loss 2.3906951347986856\n",
      "Epoch 47 | Mean Loss 2.4281910260518393\n",
      "Epoch 48 | Mean Loss 2.3941057125727334\n",
      "Epoch 49 | Mean Loss 2.4546762307484946\n",
      "Epoch 50 | Mean Loss 2.3990242083867392\n",
      "Epoch 51 | Mean Loss 2.4019872744878135\n",
      "Epoch 52 | Mean Loss 2.4033976793289185\n",
      "Epoch 53 | Mean Loss 2.392820437749227\n",
      "Epoch 54 | Mean Loss 2.384518623352051\n",
      "Epoch 55 | Mean Loss 2.4160104592641196\n",
      "Epoch 56 | Mean Loss 2.4128258228302\n",
      "Epoch 57 | Mean Loss 2.4486331144968667\n",
      "Epoch 58 | Mean Loss 2.403291344642639\n",
      "Epoch 59 | Mean Loss 2.3877750635147095\n",
      "Epoch 60 | Mean Loss 2.400758902231852\n",
      "Epoch 61 | Mean Loss 2.3920505046844482\n",
      "Epoch 62 | Mean Loss 2.3981239795684814\n",
      "Epoch 63 | Mean Loss 2.48296856880188\n",
      "Epoch 64 | Mean Loss 2.394851565361023\n",
      "Epoch 65 | Mean Loss 2.3747443358103433\n",
      "Epoch 66 | Mean Loss 2.375248114267985\n",
      "Epoch 67 | Mean Loss 2.4064979553222656\n",
      "Epoch 68 | Mean Loss 2.368638555208842\n",
      "Epoch 69 | Mean Loss 2.3686031897862754\n",
      "Epoch 70 | Mean Loss 2.371171991030375\n",
      "Epoch 71 | Mean Loss 2.3816545406977334\n",
      "Epoch 72 | Mean Loss 2.382355014483134\n",
      "Epoch 73 | Mean Loss 2.368495146433512\n",
      "Epoch 74 | Mean Loss 2.3513720432917276\n",
      "Epoch 75 | Mean Loss 2.3836023012797036\n",
      "Epoch 76 | Mean Loss 2.3822258710861206\n",
      "Epoch 77 | Mean Loss 2.37423574924469\n",
      "Epoch 78 | Mean Loss 2.3710520267486572\n",
      "Epoch 79 | Mean Loss 2.399805943171183\n",
      "Epoch 80 | Mean Loss 2.3796154657999673\n",
      "Epoch 81 | Mean Loss 2.3629472653071084\n",
      "Epoch 82 | Mean Loss 2.3353747924168906\n",
      "Epoch 83 | Mean Loss 2.346997777620951\n",
      "Epoch 84 | Mean Loss 2.3749857346216836\n",
      "Epoch 85 | Mean Loss 2.3647428353627524\n",
      "Epoch 86 | Mean Loss 2.362829009691874\n",
      "Epoch 87 | Mean Loss 2.3844887018203735\n",
      "Epoch 88 | Mean Loss 2.362847169240316\n",
      "Epoch 89 | Mean Loss 2.345571279525757\n",
      "Epoch 90 | Mean Loss 2.340707302093506\n",
      "Epoch 91 | Mean Loss 2.364744464556376\n",
      "Epoch 92 | Mean Loss 2.399272918701172\n",
      "Epoch 93 | Mean Loss 2.365061044692993\n",
      "Epoch 94 | Mean Loss 2.4167466163635254\n",
      "Epoch 95 | Mean Loss 2.3723127841949463\n",
      "Epoch 96 | Mean Loss 2.374624570210775\n",
      "Epoch 97 | Mean Loss 2.391852935155233\n",
      "Epoch 98 | Mean Loss 2.359929362932841\n",
      "Epoch 99 | Mean Loss 2.3598580360412598\n",
      "Epoch 0 | Mean Loss 7.578963120778401\n",
      "Epoch 1 | Mean Loss 4.5229560534159345\n",
      "Epoch 2 | Mean Loss 4.191409746805827\n",
      "Epoch 3 | Mean Loss 4.139972448348999\n",
      "Epoch 4 | Mean Loss 3.873047192891439\n",
      "Epoch 5 | Mean Loss 3.9467900594075522\n",
      "Epoch 6 | Mean Loss 3.9012738863627114\n",
      "Epoch 7 | Mean Loss 3.606189171473185\n",
      "Epoch 8 | Mean Loss 3.6887670358022056\n",
      "Epoch 9 | Mean Loss 3.5763185024261475\n",
      "Epoch 10 | Mean Loss 3.4737629095713296\n",
      "Epoch 11 | Mean Loss 3.439710776011149\n",
      "Epoch 12 | Mean Loss 3.407416741053263\n",
      "Epoch 13 | Mean Loss 3.2197632789611816\n",
      "Epoch 14 | Mean Loss 3.2087417443593345\n",
      "Epoch 15 | Mean Loss 3.1050190925598145\n",
      "Epoch 16 | Mean Loss 3.0944101015726724\n",
      "Epoch 17 | Mean Loss 2.996875762939453\n",
      "Epoch 18 | Mean Loss 2.9044241110483804\n",
      "Epoch 19 | Mean Loss 2.8273964722951255\n",
      "Epoch 20 | Mean Loss 2.7598251501719155\n",
      "Epoch 21 | Mean Loss 2.702200412750244\n",
      "Epoch 22 | Mean Loss 2.6386467615763345\n",
      "Epoch 23 | Mean Loss 2.603780508041382\n",
      "Epoch 24 | Mean Loss 2.5573689142862954\n",
      "Epoch 25 | Mean Loss 2.5444708665211997\n",
      "Epoch 26 | Mean Loss 2.530747334162394\n",
      "Epoch 27 | Mean Loss 2.534515062967936\n",
      "Epoch 28 | Mean Loss 2.5024794737497964\n",
      "Epoch 29 | Mean Loss 2.4711607297261557\n",
      "Epoch 30 | Mean Loss 2.4521185557047525\n",
      "Epoch 31 | Mean Loss 2.424973646799723\n",
      "Epoch 32 | Mean Loss 2.4386963844299316\n",
      "Epoch 33 | Mean Loss 2.455945094426473\n",
      "Epoch 34 | Mean Loss 2.446443478266398\n",
      "Epoch 35 | Mean Loss 2.422722021738688\n",
      "Epoch 36 | Mean Loss 2.4197558959325156\n",
      "Epoch 37 | Mean Loss 2.427034298578898\n",
      "Epoch 38 | Mean Loss 2.4522058169047036\n",
      "Epoch 39 | Mean Loss 2.4608651796976724\n",
      "Epoch 40 | Mean Loss 2.4417908986409507\n",
      "Epoch 41 | Mean Loss 2.4047316312789917\n",
      "Epoch 42 | Mean Loss 2.42484978834788\n",
      "Epoch 43 | Mean Loss 2.4397384325663247\n",
      "Epoch 44 | Mean Loss 2.4283660252889\n",
      "Epoch 45 | Mean Loss 2.419405142466227\n",
      "Epoch 46 | Mean Loss 2.423646608988444\n",
      "Epoch 47 | Mean Loss 2.420765479405721\n",
      "Epoch 48 | Mean Loss 2.4164860248565674\n",
      "Epoch 49 | Mean Loss 2.4115868409474692\n",
      "Epoch 50 | Mean Loss 2.375605344772339\n",
      "Epoch 51 | Mean Loss 2.415388305981954\n",
      "Epoch 52 | Mean Loss 2.3899304072062173\n",
      "Epoch 53 | Mean Loss 2.4285200436909995\n",
      "Epoch 54 | Mean Loss 2.4859718481699624\n",
      "Epoch 55 | Mean Loss 2.4126274585723877\n",
      "Epoch 56 | Mean Loss 2.409653902053833\n",
      "Epoch 57 | Mean Loss 2.4245870113372803\n",
      "Epoch 58 | Mean Loss 2.4103145599365234\n",
      "Epoch 59 | Mean Loss 2.376366138458252\n",
      "Epoch 60 | Mean Loss 2.4607444604237876\n",
      "Epoch 61 | Mean Loss 2.4125627676645913\n",
      "Epoch 62 | Mean Loss 2.412747859954834\n",
      "Epoch 63 | Mean Loss 2.3992879390716553\n",
      "Epoch 64 | Mean Loss 2.4071484009424844\n",
      "Epoch 65 | Mean Loss 2.4056673844655356\n",
      "Epoch 66 | Mean Loss 2.4141294161478677\n",
      "Epoch 67 | Mean Loss 2.4245632092158\n",
      "Epoch 68 | Mean Loss 2.418797016143799\n",
      "Epoch 69 | Mean Loss 2.430739959081014\n",
      "Epoch 70 | Mean Loss 2.3823959032694497\n",
      "Epoch 71 | Mean Loss 2.377530097961426\n",
      "Epoch 72 | Mean Loss 2.3884172439575195\n",
      "Epoch 73 | Mean Loss 2.4253761768341064\n",
      "Epoch 74 | Mean Loss 2.359319885571798\n",
      "Epoch 75 | Mean Loss 2.4262569745381675\n",
      "Epoch 76 | Mean Loss 2.376660188039144\n",
      "Epoch 77 | Mean Loss 2.399306376775106\n",
      "Epoch 78 | Mean Loss 2.401238719622294\n",
      "Epoch 79 | Mean Loss 2.414595444997152\n",
      "Epoch 80 | Mean Loss 2.4111667474110923\n",
      "Epoch 81 | Mean Loss 2.3681271076202393\n",
      "Epoch 82 | Mean Loss 2.448824961980184\n",
      "Epoch 83 | Mean Loss 2.401742378870646\n",
      "Epoch 84 | Mean Loss 2.3851402203241983\n",
      "Epoch 85 | Mean Loss 2.375515937805176\n",
      "Epoch 86 | Mean Loss 2.3751206000645957\n",
      "Epoch 87 | Mean Loss 2.4142043590545654\n",
      "Epoch 88 | Mean Loss 2.405903776486715\n",
      "Epoch 89 | Mean Loss 2.3701157172520957\n",
      "Epoch 90 | Mean Loss 2.368778189023336\n",
      "Epoch 91 | Mean Loss 2.4093816677729287\n",
      "Epoch 92 | Mean Loss 2.362092057863871\n",
      "Epoch 93 | Mean Loss 2.41033927599589\n",
      "Epoch 94 | Mean Loss 2.3568722009658813\n",
      "Epoch 95 | Mean Loss 2.3586264848709106\n",
      "Epoch 96 | Mean Loss 2.4174750645955405\n",
      "Epoch 97 | Mean Loss 2.405570467313131\n",
      "Epoch 98 | Mean Loss 2.4010329643885293\n",
      "Epoch 99 | Mean Loss 2.3821260134379068\n",
      "Epoch 0 | Mean Loss 9.692300796508789\n",
      "Epoch 1 | Mean Loss 3.973658800125122\n",
      "Epoch 2 | Mean Loss 3.390082597732544\n",
      "Epoch 3 | Mean Loss 3.3336718877156577\n",
      "Epoch 4 | Mean Loss 3.3222997188568115\n",
      "Epoch 5 | Mean Loss 3.293402671813965\n",
      "Epoch 6 | Mean Loss 3.1787302494049072\n",
      "Epoch 7 | Mean Loss 2.949519952138265\n",
      "Epoch 8 | Mean Loss 2.9633054733276367\n",
      "Epoch 9 | Mean Loss 3.02748171488444\n",
      "Epoch 10 | Mean Loss 2.955114205678304\n",
      "Epoch 11 | Mean Loss 2.833169380823771\n",
      "Epoch 12 | Mean Loss 2.8612824281056723\n",
      "Epoch 13 | Mean Loss 2.73830509185791\n",
      "Epoch 14 | Mean Loss 2.7469025452931723\n",
      "Epoch 15 | Mean Loss 2.6410655975341797\n",
      "Epoch 16 | Mean Loss 2.6471451123555503\n",
      "Epoch 17 | Mean Loss 2.5831836064656577\n",
      "Epoch 18 | Mean Loss 2.5558109283447266\n",
      "Epoch 19 | Mean Loss 2.560002644856771\n",
      "Epoch 20 | Mean Loss 2.517969846725464\n",
      "Epoch 21 | Mean Loss 2.509102741877238\n",
      "Epoch 22 | Mean Loss 2.471643050511678\n",
      "Epoch 23 | Mean Loss 2.41930882136027\n",
      "Epoch 24 | Mean Loss 2.409355640411377\n",
      "Epoch 25 | Mean Loss 2.4135995705922446\n",
      "Epoch 26 | Mean Loss 2.3969662189483643\n",
      "Epoch 27 | Mean Loss 2.474119265874227\n",
      "Epoch 28 | Mean Loss 2.456575552622477\n",
      "Epoch 29 | Mean Loss 2.430983622868856\n",
      "Epoch 30 | Mean Loss 2.3528052965799966\n",
      "Epoch 31 | Mean Loss 2.3917834758758545\n",
      "Epoch 32 | Mean Loss 2.4532078901926675\n",
      "Epoch 33 | Mean Loss 2.4360822439193726\n",
      "Epoch 34 | Mean Loss 2.461477359135946\n",
      "Epoch 35 | Mean Loss 2.345518469810486\n",
      "Epoch 36 | Mean Loss 2.43855619430542\n",
      "Epoch 37 | Mean Loss 2.4483107725779214\n",
      "Epoch 38 | Mean Loss 2.3490585883458457\n",
      "Epoch 39 | Mean Loss 2.4367263317108154\n",
      "Epoch 40 | Mean Loss 2.4224884510040283\n",
      "Epoch 41 | Mean Loss 2.435530424118042\n",
      "Epoch 42 | Mean Loss 2.3455957969029746\n",
      "Epoch 43 | Mean Loss 2.3623375495274863\n",
      "Epoch 44 | Mean Loss 2.4048190911610923\n",
      "Epoch 45 | Mean Loss 2.4238885243733725\n",
      "Epoch 46 | Mean Loss 2.4263439973195395\n",
      "Epoch 47 | Mean Loss 2.4206129709879556\n",
      "Epoch 48 | Mean Loss 2.4278192122777305\n",
      "Epoch 49 | Mean Loss 2.338162104288737\n",
      "Epoch 50 | Mean Loss 2.462681214014689\n",
      "Epoch 51 | Mean Loss 2.473494370778402\n",
      "Epoch 52 | Mean Loss 2.3971640268961587\n",
      "Epoch 53 | Mean Loss 2.4054855505625405\n",
      "Epoch 54 | Mean Loss 2.410117506980896\n",
      "Epoch 55 | Mean Loss 2.414278189341227\n",
      "Epoch 56 | Mean Loss 2.4078734715779624\n",
      "Epoch 57 | Mean Loss 2.3353015979131064\n",
      "Epoch 58 | Mean Loss 2.4336817264556885\n",
      "Epoch 59 | Mean Loss 2.4332372347513833\n",
      "Epoch 60 | Mean Loss 2.462907314300537\n",
      "Epoch 61 | Mean Loss 2.4059200286865234\n",
      "Epoch 62 | Mean Loss 2.3375591039657593\n",
      "Epoch 63 | Mean Loss 2.3508792718251548\n",
      "Epoch 64 | Mean Loss 2.3691267172495523\n",
      "Epoch 65 | Mean Loss 2.342542211214701\n",
      "Epoch 66 | Mean Loss 2.382008711496989\n",
      "Epoch 67 | Mean Loss 2.3053388595581055\n",
      "Epoch 68 | Mean Loss 2.431490659713745\n",
      "Epoch 69 | Mean Loss 2.4191279808680215\n",
      "Epoch 70 | Mean Loss 2.3275930484135947\n",
      "Epoch 71 | Mean Loss 2.4223641554514566\n",
      "Epoch 72 | Mean Loss 2.3580934206644693\n",
      "Epoch 73 | Mean Loss 2.390315572420756\n",
      "Epoch 74 | Mean Loss 2.4714850584665933\n",
      "Epoch 75 | Mean Loss 2.408242146174113\n",
      "Epoch 76 | Mean Loss 2.3687920570373535\n",
      "Epoch 77 | Mean Loss 2.403587579727173\n",
      "Epoch 78 | Mean Loss 2.3738823334376016\n",
      "Epoch 79 | Mean Loss 2.407952626546224\n",
      "Epoch 80 | Mean Loss 2.4096418221791587\n",
      "Epoch 81 | Mean Loss 2.343075712521871\n",
      "Epoch 82 | Mean Loss 2.391069253285726\n",
      "Epoch 83 | Mean Loss 2.412152051925659\n",
      "Epoch 84 | Mean Loss 2.4182651042938232\n",
      "Epoch 85 | Mean Loss 2.3399774630864463\n",
      "Epoch 86 | Mean Loss 2.3684786558151245\n",
      "Epoch 87 | Mean Loss 2.36728843053182\n",
      "Epoch 88 | Mean Loss 2.3645392258961997\n",
      "Epoch 89 | Mean Loss 2.3993070920308432\n",
      "Epoch 90 | Mean Loss 2.400693416595459\n",
      "Epoch 91 | Mean Loss 2.416590690612793\n",
      "Epoch 92 | Mean Loss 2.368786334991455\n",
      "Epoch 93 | Mean Loss 2.3783980210622153\n",
      "Epoch 94 | Mean Loss 2.3863441546758017\n",
      "Epoch 95 | Mean Loss 2.4495206673940024\n",
      "Epoch 96 | Mean Loss 2.3699698448181152\n",
      "Epoch 97 | Mean Loss 2.383971691131592\n",
      "Epoch 98 | Mean Loss 2.3809306621551514\n",
      "Epoch 99 | Mean Loss 2.3708168268203735\n",
      "Train size:  0.2\n",
      "Epoch 0 | Mean Loss 6.546734094619751\n",
      "Epoch 1 | Mean Loss 2.7912776947021483\n",
      "Epoch 2 | Mean Loss 2.7336010456085207\n",
      "Epoch 3 | Mean Loss 2.720960521697998\n",
      "Epoch 4 | Mean Loss 2.7221236705780028\n",
      "Epoch 5 | Mean Loss 2.7166290283203125\n",
      "Epoch 6 | Mean Loss 2.694804573059082\n",
      "Epoch 7 | Mean Loss 2.6744317531585695\n",
      "Epoch 8 | Mean Loss 2.647276210784912\n",
      "Epoch 9 | Mean Loss 2.6670894622802734\n",
      "Epoch 10 | Mean Loss 2.6570476055145265\n",
      "Epoch 11 | Mean Loss 2.6563647747039796\n",
      "Epoch 12 | Mean Loss 2.63340106010437\n",
      "Epoch 13 | Mean Loss 2.622357892990112\n",
      "Epoch 14 | Mean Loss 2.6837383270263673\n",
      "Epoch 15 | Mean Loss 2.6309457302093504\n",
      "Epoch 16 | Mean Loss 2.632567310333252\n",
      "Epoch 17 | Mean Loss 2.6380768775939942\n",
      "Epoch 18 | Mean Loss 2.649848794937134\n",
      "Epoch 19 | Mean Loss 2.6383074283599854\n",
      "Epoch 20 | Mean Loss 2.619884395599365\n",
      "Epoch 21 | Mean Loss 2.6186734199523927\n",
      "Epoch 22 | Mean Loss 2.6099063396453857\n",
      "Epoch 23 | Mean Loss 2.6053397178649904\n",
      "Epoch 24 | Mean Loss 2.6334864139556884\n",
      "Epoch 25 | Mean Loss 2.596706485748291\n",
      "Epoch 26 | Mean Loss 2.6142946243286134\n",
      "Epoch 27 | Mean Loss 2.6079092025756836\n",
      "Epoch 28 | Mean Loss 2.6274248600006103\n",
      "Epoch 29 | Mean Loss 2.6005692958831785\n",
      "Epoch 30 | Mean Loss 2.6394312381744385\n",
      "Epoch 31 | Mean Loss 2.596506357192993\n",
      "Epoch 32 | Mean Loss 2.6100795745849608\n",
      "Epoch 33 | Mean Loss 2.609816312789917\n",
      "Epoch 34 | Mean Loss 2.603719186782837\n",
      "Epoch 35 | Mean Loss 2.604721927642822\n",
      "Epoch 36 | Mean Loss 2.6167158126831054\n",
      "Epoch 37 | Mean Loss 2.6140285968780517\n",
      "Epoch 38 | Mean Loss 2.6060795307159426\n",
      "Epoch 39 | Mean Loss 2.624204730987549\n",
      "Epoch 40 | Mean Loss 2.595702314376831\n",
      "Epoch 41 | Mean Loss 2.588325548171997\n",
      "Epoch 42 | Mean Loss 2.6150228500366213\n",
      "Epoch 43 | Mean Loss 2.5940655708312987\n",
      "Epoch 44 | Mean Loss 2.5927945613861083\n",
      "Epoch 45 | Mean Loss 2.599923086166382\n",
      "Epoch 46 | Mean Loss 2.5933369636535644\n",
      "Epoch 47 | Mean Loss 2.5821319580078126\n",
      "Epoch 48 | Mean Loss 2.6151405811309814\n",
      "Epoch 49 | Mean Loss 2.5972192764282225\n",
      "Epoch 50 | Mean Loss 2.6045711517333983\n",
      "Epoch 51 | Mean Loss 2.589813995361328\n",
      "Epoch 52 | Mean Loss 2.6026527881622314\n",
      "Epoch 53 | Mean Loss 2.5963053703308105\n",
      "Epoch 54 | Mean Loss 2.5924903392791747\n",
      "Epoch 55 | Mean Loss 2.6043449878692626\n",
      "Epoch 56 | Mean Loss 2.597684717178345\n",
      "Epoch 57 | Mean Loss 2.593260478973389\n",
      "Epoch 58 | Mean Loss 2.6034972190856935\n",
      "Epoch 59 | Mean Loss 2.596906900405884\n",
      "Epoch 60 | Mean Loss 2.603059911727905\n",
      "Epoch 61 | Mean Loss 2.6090930461883546\n",
      "Epoch 62 | Mean Loss 2.6083062648773194\n",
      "Epoch 63 | Mean Loss 2.5983161449432375\n",
      "Epoch 64 | Mean Loss 2.6099909782409667\n",
      "Epoch 65 | Mean Loss 2.5996410846710205\n",
      "Epoch 66 | Mean Loss 2.601207208633423\n",
      "Epoch 67 | Mean Loss 2.5711212158203125\n",
      "Epoch 68 | Mean Loss 2.6096811294555664\n",
      "Epoch 69 | Mean Loss 2.5882652759552003\n",
      "Epoch 70 | Mean Loss 2.6118977069854736\n",
      "Epoch 71 | Mean Loss 2.5976517677307127\n",
      "Epoch 72 | Mean Loss 2.593505048751831\n",
      "Epoch 73 | Mean Loss 2.5850183963775635\n",
      "Epoch 74 | Mean Loss 2.606492805480957\n",
      "Epoch 75 | Mean Loss 2.6044896125793455\n",
      "Epoch 76 | Mean Loss 2.5859867095947267\n",
      "Epoch 77 | Mean Loss 2.593698501586914\n",
      "Epoch 78 | Mean Loss 2.6030678272247316\n",
      "Epoch 79 | Mean Loss 2.603538465499878\n",
      "Epoch 80 | Mean Loss 2.5772813320159913\n",
      "Epoch 81 | Mean Loss 2.586694288253784\n",
      "Epoch 82 | Mean Loss 2.623247671127319\n",
      "Epoch 83 | Mean Loss 2.6077984809875487\n",
      "Epoch 84 | Mean Loss 2.591987419128418\n",
      "Epoch 85 | Mean Loss 2.594026708602905\n",
      "Epoch 86 | Mean Loss 2.5762824058532714\n",
      "Epoch 87 | Mean Loss 2.5779215335845946\n",
      "Epoch 88 | Mean Loss 2.5802688121795656\n",
      "Epoch 89 | Mean Loss 2.5815282821655274\n",
      "Epoch 90 | Mean Loss 2.599405813217163\n",
      "Epoch 91 | Mean Loss 2.5967803478240965\n",
      "Epoch 92 | Mean Loss 2.5905839920043947\n",
      "Epoch 93 | Mean Loss 2.5862682819366456\n",
      "Epoch 94 | Mean Loss 2.6198680877685545\n",
      "Epoch 95 | Mean Loss 2.5708009243011474\n",
      "Epoch 96 | Mean Loss 2.5707770347595216\n",
      "Epoch 97 | Mean Loss 2.592859172821045\n",
      "Epoch 98 | Mean Loss 2.5898332595825195\n",
      "Epoch 99 | Mean Loss 2.600355625152588\n",
      "Epoch 0 | Mean Loss 8.789119815826416\n",
      "Epoch 1 | Mean Loss 4.643130493164063\n",
      "Epoch 2 | Mean Loss 4.378231620788574\n",
      "Epoch 3 | Mean Loss 4.2662403106689455\n",
      "Epoch 4 | Mean Loss 4.263674259185791\n",
      "Epoch 5 | Mean Loss 4.234051609039307\n",
      "Epoch 6 | Mean Loss 4.140123176574707\n",
      "Epoch 7 | Mean Loss 4.077534198760986\n",
      "Epoch 8 | Mean Loss 4.005125904083252\n",
      "Epoch 9 | Mean Loss 3.9355475902557373\n",
      "Epoch 10 | Mean Loss 3.899447202682495\n",
      "Epoch 11 | Mean Loss 3.8324889183044433\n",
      "Epoch 12 | Mean Loss 3.73492317199707\n",
      "Epoch 13 | Mean Loss 3.6864559650421143\n",
      "Epoch 14 | Mean Loss 3.6176074028015135\n",
      "Epoch 15 | Mean Loss 3.540713310241699\n",
      "Epoch 16 | Mean Loss 3.473786401748657\n",
      "Epoch 17 | Mean Loss 3.406000280380249\n",
      "Epoch 18 | Mean Loss 3.354106569290161\n",
      "Epoch 19 | Mean Loss 3.2673959255218508\n",
      "Epoch 20 | Mean Loss 3.1916260719299316\n",
      "Epoch 21 | Mean Loss 3.1482684135437013\n",
      "Epoch 22 | Mean Loss 3.1265032291412354\n",
      "Epoch 23 | Mean Loss 3.0673678874969483\n",
      "Epoch 24 | Mean Loss 3.065949010848999\n",
      "Epoch 25 | Mean Loss 3.007978582382202\n",
      "Epoch 26 | Mean Loss 2.9598412990570067\n",
      "Epoch 27 | Mean Loss 2.9189451217651365\n",
      "Epoch 28 | Mean Loss 2.8771133422851562\n",
      "Epoch 29 | Mean Loss 2.852413034439087\n",
      "Epoch 30 | Mean Loss 2.8479434967041017\n",
      "Epoch 31 | Mean Loss 2.819671154022217\n",
      "Epoch 32 | Mean Loss 2.7779126167297363\n",
      "Epoch 33 | Mean Loss 2.808921384811401\n",
      "Epoch 34 | Mean Loss 2.782612180709839\n",
      "Epoch 35 | Mean Loss 2.753611612319946\n",
      "Epoch 36 | Mean Loss 2.776188039779663\n",
      "Epoch 37 | Mean Loss 2.6982704639434814\n",
      "Epoch 38 | Mean Loss 2.7396567821502686\n",
      "Epoch 39 | Mean Loss 2.6986647129058836\n",
      "Epoch 40 | Mean Loss 2.7297191619873047\n",
      "Epoch 41 | Mean Loss 2.695628786087036\n",
      "Epoch 42 | Mean Loss 2.6587767124176027\n",
      "Epoch 43 | Mean Loss 2.663078212738037\n",
      "Epoch 44 | Mean Loss 2.6946250915527346\n",
      "Epoch 45 | Mean Loss 2.629860544204712\n",
      "Epoch 46 | Mean Loss 2.636637496948242\n",
      "Epoch 47 | Mean Loss 2.672782039642334\n",
      "Epoch 48 | Mean Loss 2.6450953483581543\n",
      "Epoch 49 | Mean Loss 2.6480101585388183\n",
      "Epoch 50 | Mean Loss 2.6293819427490233\n",
      "Epoch 51 | Mean Loss 2.635452222824097\n",
      "Epoch 52 | Mean Loss 2.6369348049163817\n",
      "Epoch 53 | Mean Loss 2.638533115386963\n",
      "Epoch 54 | Mean Loss 2.606442022323608\n",
      "Epoch 55 | Mean Loss 2.63605637550354\n",
      "Epoch 56 | Mean Loss 2.6367300510406495\n",
      "Epoch 57 | Mean Loss 2.6109877586364747\n",
      "Epoch 58 | Mean Loss 2.6184283256530763\n",
      "Epoch 59 | Mean Loss 2.619571828842163\n",
      "Epoch 60 | Mean Loss 2.640053367614746\n",
      "Epoch 61 | Mean Loss 2.6277574062347413\n",
      "Epoch 62 | Mean Loss 2.614158296585083\n",
      "Epoch 63 | Mean Loss 2.6135771751403807\n",
      "Epoch 64 | Mean Loss 2.6207035541534425\n",
      "Epoch 65 | Mean Loss 2.594155740737915\n",
      "Epoch 66 | Mean Loss 2.621812105178833\n",
      "Epoch 67 | Mean Loss 2.615842580795288\n",
      "Epoch 68 | Mean Loss 2.593348503112793\n",
      "Epoch 69 | Mean Loss 2.6109477996826174\n",
      "Epoch 70 | Mean Loss 2.610566282272339\n",
      "Epoch 71 | Mean Loss 2.603354072570801\n",
      "Epoch 72 | Mean Loss 2.6125545501708984\n",
      "Epoch 73 | Mean Loss 2.5904069423675535\n",
      "Epoch 74 | Mean Loss 2.5863623142242433\n",
      "Epoch 75 | Mean Loss 2.5919167518615724\n",
      "Epoch 76 | Mean Loss 2.588269758224487\n",
      "Epoch 77 | Mean Loss 2.5757084846496583\n",
      "Epoch 78 | Mean Loss 2.5796673774719237\n",
      "Epoch 79 | Mean Loss 2.59627685546875\n",
      "Epoch 80 | Mean Loss 2.582010269165039\n",
      "Epoch 81 | Mean Loss 2.5648534297943115\n",
      "Epoch 82 | Mean Loss 2.5869075775146486\n",
      "Epoch 83 | Mean Loss 2.6013118743896486\n",
      "Epoch 84 | Mean Loss 2.590846538543701\n",
      "Epoch 85 | Mean Loss 2.583318281173706\n",
      "Epoch 86 | Mean Loss 2.577449321746826\n",
      "Epoch 87 | Mean Loss 2.569369077682495\n",
      "Epoch 88 | Mean Loss 2.5694316387176515\n",
      "Epoch 89 | Mean Loss 2.584525966644287\n",
      "Epoch 90 | Mean Loss 2.5921014308929444\n",
      "Epoch 91 | Mean Loss 2.5811843872070312\n",
      "Epoch 92 | Mean Loss 2.595807123184204\n",
      "Epoch 93 | Mean Loss 2.5801687240600586\n",
      "Epoch 94 | Mean Loss 2.5691240310668944\n",
      "Epoch 95 | Mean Loss 2.5748854637145997\n",
      "Epoch 96 | Mean Loss 2.58829927444458\n",
      "Epoch 97 | Mean Loss 2.572919178009033\n",
      "Epoch 98 | Mean Loss 2.577790117263794\n",
      "Epoch 99 | Mean Loss 2.593153142929077\n",
      "Epoch 0 | Mean Loss 11.338130378723145\n",
      "Epoch 1 | Mean Loss 3.558047962188721\n",
      "Epoch 2 | Mean Loss 3.2170085430145265\n",
      "Epoch 3 | Mean Loss 3.022901439666748\n",
      "Epoch 4 | Mean Loss 2.8895915031433104\n",
      "Epoch 5 | Mean Loss 2.7915626049041746\n",
      "Epoch 6 | Mean Loss 2.721523380279541\n",
      "Epoch 7 | Mean Loss 2.6780669689178467\n",
      "Epoch 8 | Mean Loss 2.6474936485290526\n",
      "Epoch 9 | Mean Loss 2.624045562744141\n",
      "Epoch 10 | Mean Loss 2.602283763885498\n",
      "Epoch 11 | Mean Loss 2.6045856952667235\n",
      "Epoch 12 | Mean Loss 2.609297037124634\n",
      "Epoch 13 | Mean Loss 2.6191710948944094\n",
      "Epoch 14 | Mean Loss 2.607118272781372\n",
      "Epoch 15 | Mean Loss 2.602501106262207\n",
      "Epoch 16 | Mean Loss 2.5837029933929445\n",
      "Epoch 17 | Mean Loss 2.6016984462738035\n",
      "Epoch 18 | Mean Loss 2.607434844970703\n",
      "Epoch 19 | Mean Loss 2.5998430252075195\n",
      "Epoch 20 | Mean Loss 2.60401291847229\n",
      "Epoch 21 | Mean Loss 2.5946822643280028\n",
      "Epoch 22 | Mean Loss 2.5920055389404295\n",
      "Epoch 23 | Mean Loss 2.580242872238159\n",
      "Epoch 24 | Mean Loss 2.597500276565552\n",
      "Epoch 25 | Mean Loss 2.6052132129669188\n",
      "Epoch 26 | Mean Loss 2.6065423011779787\n",
      "Epoch 27 | Mean Loss 2.5812622547149657\n",
      "Epoch 28 | Mean Loss 2.595406246185303\n",
      "Epoch 29 | Mean Loss 2.5927858352661133\n",
      "Epoch 30 | Mean Loss 2.584279680252075\n",
      "Epoch 31 | Mean Loss 2.5907122135162353\n",
      "Epoch 32 | Mean Loss 2.5981815338134764\n",
      "Epoch 33 | Mean Loss 2.583771514892578\n",
      "Epoch 34 | Mean Loss 2.602871036529541\n",
      "Epoch 35 | Mean Loss 2.599006175994873\n",
      "Epoch 36 | Mean Loss 2.591318130493164\n",
      "Epoch 37 | Mean Loss 2.6001350402832033\n",
      "Epoch 38 | Mean Loss 2.578981065750122\n",
      "Epoch 39 | Mean Loss 2.5830408573150634\n",
      "Epoch 40 | Mean Loss 2.5926413536071777\n",
      "Epoch 41 | Mean Loss 2.5873899459838867\n",
      "Epoch 42 | Mean Loss 2.6012502670288087\n",
      "Epoch 43 | Mean Loss 2.5957812309265136\n",
      "Epoch 44 | Mean Loss 2.591321563720703\n",
      "Epoch 45 | Mean Loss 2.584884214401245\n",
      "Epoch 46 | Mean Loss 2.5728991508483885\n",
      "Epoch 47 | Mean Loss 2.5819958686828612\n",
      "Epoch 48 | Mean Loss 2.5698945999145506\n",
      "Epoch 49 | Mean Loss 2.594035005569458\n",
      "Epoch 50 | Mean Loss 2.577797222137451\n",
      "Epoch 51 | Mean Loss 2.581287956237793\n",
      "Epoch 52 | Mean Loss 2.581185293197632\n",
      "Epoch 53 | Mean Loss 2.567473220825195\n",
      "Epoch 54 | Mean Loss 2.558113193511963\n",
      "Epoch 55 | Mean Loss 2.5796070098876953\n",
      "Epoch 56 | Mean Loss 2.578315782546997\n",
      "Epoch 57 | Mean Loss 2.5657535076141356\n",
      "Epoch 58 | Mean Loss 2.5585540294647218\n",
      "Epoch 59 | Mean Loss 2.549200439453125\n",
      "Epoch 60 | Mean Loss 2.5788042068481447\n",
      "Epoch 61 | Mean Loss 2.5616832733154298\n",
      "Epoch 62 | Mean Loss 2.5516533851623535\n",
      "Epoch 63 | Mean Loss 2.55689058303833\n",
      "Epoch 64 | Mean Loss 2.561233711242676\n",
      "Epoch 65 | Mean Loss 2.5688900470733644\n",
      "Epoch 66 | Mean Loss 2.550932693481445\n",
      "Epoch 67 | Mean Loss 2.536650466918945\n",
      "Epoch 68 | Mean Loss 2.5367237091064454\n",
      "Epoch 69 | Mean Loss 2.538913679122925\n",
      "Epoch 70 | Mean Loss 2.5251072883605956\n",
      "Epoch 71 | Mean Loss 2.511595869064331\n",
      "Epoch 72 | Mean Loss 2.4932851791381836\n",
      "Epoch 73 | Mean Loss 2.498034381866455\n",
      "Epoch 74 | Mean Loss 2.5012638092041017\n",
      "Epoch 75 | Mean Loss 2.517633581161499\n",
      "Epoch 76 | Mean Loss 2.5046209335327148\n",
      "Epoch 77 | Mean Loss 2.508229303359985\n",
      "Epoch 78 | Mean Loss 2.511613607406616\n",
      "Epoch 79 | Mean Loss 2.471195363998413\n",
      "Epoch 80 | Mean Loss 2.465278911590576\n",
      "Epoch 81 | Mean Loss 2.4659794330596925\n",
      "Epoch 82 | Mean Loss 2.470390510559082\n",
      "Epoch 83 | Mean Loss 2.502696180343628\n",
      "Epoch 84 | Mean Loss 2.4929216384887694\n",
      "Epoch 85 | Mean Loss 2.455985498428345\n",
      "Epoch 86 | Mean Loss 2.5153687953948975\n",
      "Epoch 87 | Mean Loss 2.467484188079834\n",
      "Epoch 88 | Mean Loss 2.4780937671661376\n",
      "Epoch 89 | Mean Loss 2.466747188568115\n",
      "Epoch 90 | Mean Loss 2.4759469032287598\n",
      "Epoch 91 | Mean Loss 2.4491670608520506\n",
      "Epoch 92 | Mean Loss 2.4624245166778564\n",
      "Epoch 93 | Mean Loss 2.4707443714141846\n",
      "Epoch 94 | Mean Loss 2.418595314025879\n",
      "Epoch 95 | Mean Loss 2.4039960384368895\n",
      "Epoch 96 | Mean Loss 2.4018198966979982\n",
      "Epoch 97 | Mean Loss 2.4076164245605467\n",
      "Epoch 98 | Mean Loss 2.434996318817139\n",
      "Epoch 99 | Mean Loss 2.3960686206817625\n",
      "Epoch 0 | Mean Loss 9.937303638458252\n",
      "Epoch 1 | Mean Loss 4.313426876068116\n",
      "Epoch 2 | Mean Loss 4.381506538391113\n",
      "Epoch 3 | Mean Loss 4.210020446777344\n",
      "Epoch 4 | Mean Loss 4.059166145324707\n",
      "Epoch 5 | Mean Loss 3.9117281436920166\n",
      "Epoch 6 | Mean Loss 3.8022987842559814\n",
      "Epoch 7 | Mean Loss 3.7050374031066893\n",
      "Epoch 8 | Mean Loss 3.576559829711914\n",
      "Epoch 9 | Mean Loss 3.450942945480347\n",
      "Epoch 10 | Mean Loss 3.3214441299438477\n",
      "Epoch 11 | Mean Loss 3.226806879043579\n",
      "Epoch 12 | Mean Loss 3.113847494125366\n",
      "Epoch 13 | Mean Loss 2.924900770187378\n",
      "Epoch 14 | Mean Loss 2.8122154235839845\n",
      "Epoch 15 | Mean Loss 2.7269753932952883\n",
      "Epoch 16 | Mean Loss 2.6628511428833006\n",
      "Epoch 17 | Mean Loss 2.6348162651062013\n",
      "Epoch 18 | Mean Loss 2.6226714611053468\n",
      "Epoch 19 | Mean Loss 2.605470561981201\n",
      "Epoch 20 | Mean Loss 2.6063585758209227\n",
      "Epoch 21 | Mean Loss 2.6248898983001707\n",
      "Epoch 22 | Mean Loss 2.615852975845337\n",
      "Epoch 23 | Mean Loss 2.6136709690093993\n",
      "Epoch 24 | Mean Loss 2.6069491863250733\n",
      "Epoch 25 | Mean Loss 2.617133092880249\n",
      "Epoch 26 | Mean Loss 2.607944679260254\n",
      "Epoch 27 | Mean Loss 2.599924087524414\n",
      "Epoch 28 | Mean Loss 2.6106088638305662\n",
      "Epoch 29 | Mean Loss 2.610246467590332\n",
      "Epoch 30 | Mean Loss 2.629135990142822\n",
      "Epoch 31 | Mean Loss 2.5969848155975344\n",
      "Epoch 32 | Mean Loss 2.6187326431274416\n",
      "Epoch 33 | Mean Loss 2.580415964126587\n",
      "Epoch 34 | Mean Loss 2.6101736068725585\n",
      "Epoch 35 | Mean Loss 2.60490140914917\n",
      "Epoch 36 | Mean Loss 2.601241445541382\n",
      "Epoch 37 | Mean Loss 2.591061305999756\n",
      "Epoch 38 | Mean Loss 2.5951162815093993\n",
      "Epoch 39 | Mean Loss 2.6112153053283693\n",
      "Epoch 40 | Mean Loss 2.597402811050415\n",
      "Epoch 41 | Mean Loss 2.585929298400879\n",
      "Epoch 42 | Mean Loss 2.5978870391845703\n",
      "Epoch 43 | Mean Loss 2.5909552574157715\n",
      "Epoch 44 | Mean Loss 2.6184066772460937\n",
      "Epoch 45 | Mean Loss 2.6181862354278564\n",
      "Epoch 46 | Mean Loss 2.577279043197632\n",
      "Epoch 47 | Mean Loss 2.5768504619598387\n",
      "Epoch 48 | Mean Loss 2.5880330562591554\n",
      "Epoch 49 | Mean Loss 2.592247247695923\n",
      "Epoch 50 | Mean Loss 2.5947049617767335\n",
      "Epoch 51 | Mean Loss 2.594768762588501\n",
      "Epoch 52 | Mean Loss 2.5933361530303953\n",
      "Epoch 53 | Mean Loss 2.5975903034210206\n",
      "Epoch 54 | Mean Loss 2.586992311477661\n",
      "Epoch 55 | Mean Loss 2.5738883018493652\n",
      "Epoch 56 | Mean Loss 2.6006407260894777\n",
      "Epoch 57 | Mean Loss 2.587190341949463\n",
      "Epoch 58 | Mean Loss 2.58992075920105\n",
      "Epoch 59 | Mean Loss 2.5906397819519045\n",
      "Epoch 60 | Mean Loss 2.595227813720703\n",
      "Epoch 61 | Mean Loss 2.585506248474121\n",
      "Epoch 62 | Mean Loss 2.5860408306121827\n",
      "Epoch 63 | Mean Loss 2.5799909591674806\n",
      "Epoch 64 | Mean Loss 2.574686861038208\n",
      "Epoch 65 | Mean Loss 2.5715978145599365\n",
      "Epoch 66 | Mean Loss 2.5847249031066895\n",
      "Epoch 67 | Mean Loss 2.584086561203003\n",
      "Epoch 68 | Mean Loss 2.5724955081939695\n",
      "Epoch 69 | Mean Loss 2.5946550369262695\n",
      "Epoch 70 | Mean Loss 2.580492305755615\n",
      "Epoch 71 | Mean Loss 2.567625379562378\n",
      "Epoch 72 | Mean Loss 2.5850409507751464\n",
      "Epoch 73 | Mean Loss 2.5829351425170897\n",
      "Epoch 74 | Mean Loss 2.574842929840088\n",
      "Epoch 75 | Mean Loss 2.5757065296173094\n",
      "Epoch 76 | Mean Loss 2.5618546485900877\n",
      "Epoch 77 | Mean Loss 2.5808640480041505\n",
      "Epoch 78 | Mean Loss 2.568827676773071\n",
      "Epoch 79 | Mean Loss 2.60957612991333\n",
      "Epoch 80 | Mean Loss 2.578501987457275\n",
      "Epoch 81 | Mean Loss 2.565803337097168\n",
      "Epoch 82 | Mean Loss 2.566316032409668\n",
      "Epoch 83 | Mean Loss 2.5757150650024414\n",
      "Epoch 84 | Mean Loss 2.566995716094971\n",
      "Epoch 85 | Mean Loss 2.5575822830200194\n",
      "Epoch 86 | Mean Loss 2.5676197528839113\n",
      "Epoch 87 | Mean Loss 2.562306213378906\n",
      "Epoch 88 | Mean Loss 2.5730363368988036\n",
      "Epoch 89 | Mean Loss 2.552598762512207\n",
      "Epoch 90 | Mean Loss 2.586459827423096\n",
      "Epoch 91 | Mean Loss 2.562834310531616\n",
      "Epoch 92 | Mean Loss 2.571856069564819\n",
      "Epoch 93 | Mean Loss 2.545746326446533\n",
      "Epoch 94 | Mean Loss 2.55849609375\n",
      "Epoch 95 | Mean Loss 2.568815231323242\n",
      "Epoch 96 | Mean Loss 2.5446463584899903\n",
      "Epoch 97 | Mean Loss 2.554836368560791\n",
      "Epoch 98 | Mean Loss 2.55171422958374\n",
      "Epoch 99 | Mean Loss 2.568437194824219\n",
      "Epoch 0 | Mean Loss 6.60984435081482\n",
      "Epoch 1 | Mean Loss 2.721656322479248\n",
      "Epoch 2 | Mean Loss 2.650639772415161\n",
      "Epoch 3 | Mean Loss 2.654044580459595\n",
      "Epoch 4 | Mean Loss 2.6035804748535156\n",
      "Epoch 5 | Mean Loss 2.6001848220825194\n",
      "Epoch 6 | Mean Loss 2.638926601409912\n",
      "Epoch 7 | Mean Loss 2.612612724304199\n",
      "Epoch 8 | Mean Loss 2.605861759185791\n",
      "Epoch 9 | Mean Loss 2.604900074005127\n",
      "Epoch 10 | Mean Loss 2.6128939628601073\n",
      "Epoch 11 | Mean Loss 2.624244213104248\n",
      "Epoch 12 | Mean Loss 2.623577356338501\n",
      "Epoch 13 | Mean Loss 2.6239817142486572\n",
      "Epoch 14 | Mean Loss 2.6049476146697996\n",
      "Epoch 15 | Mean Loss 2.630182218551636\n",
      "Epoch 16 | Mean Loss 2.6117493152618407\n",
      "Epoch 17 | Mean Loss 2.613745021820068\n",
      "Epoch 18 | Mean Loss 2.6103565216064455\n",
      "Epoch 19 | Mean Loss 2.6257155895233155\n",
      "Epoch 20 | Mean Loss 2.6155204296112062\n",
      "Epoch 21 | Mean Loss 2.624261665344238\n",
      "Epoch 22 | Mean Loss 2.6093963623046874\n",
      "Epoch 23 | Mean Loss 2.6238898754119875\n",
      "Epoch 24 | Mean Loss 2.6235673904418944\n",
      "Epoch 25 | Mean Loss 2.6188471794128416\n",
      "Epoch 26 | Mean Loss 2.6226449966430665\n",
      "Epoch 27 | Mean Loss 2.626748514175415\n",
      "Epoch 28 | Mean Loss 2.6200889110565186\n",
      "Epoch 29 | Mean Loss 2.6058057308197022\n",
      "Epoch 30 | Mean Loss 2.628075885772705\n",
      "Epoch 31 | Mean Loss 2.6227964878082277\n",
      "Epoch 32 | Mean Loss 2.6351694583892824\n",
      "Epoch 33 | Mean Loss 2.6301119804382322\n",
      "Epoch 34 | Mean Loss 2.6213778018951417\n",
      "Epoch 35 | Mean Loss 2.6033580780029295\n",
      "Epoch 36 | Mean Loss 2.6128671169281006\n",
      "Epoch 37 | Mean Loss 2.5816433429718018\n",
      "Epoch 38 | Mean Loss 2.5907759189605715\n",
      "Epoch 39 | Mean Loss 2.6387647151947022\n",
      "Epoch 40 | Mean Loss 2.6013773918151855\n",
      "Epoch 41 | Mean Loss 2.6423270225524904\n",
      "Epoch 42 | Mean Loss 2.6146474838256837\n",
      "Epoch 43 | Mean Loss 2.6141058921813967\n",
      "Epoch 44 | Mean Loss 2.600932168960571\n",
      "Epoch 45 | Mean Loss 2.618905210494995\n",
      "Epoch 46 | Mean Loss 2.624541759490967\n",
      "Epoch 47 | Mean Loss 2.612092208862305\n",
      "Epoch 48 | Mean Loss 2.628467845916748\n",
      "Epoch 49 | Mean Loss 2.608410596847534\n",
      "Epoch 50 | Mean Loss 2.6208478927612306\n",
      "Epoch 51 | Mean Loss 2.6171841621398926\n",
      "Epoch 52 | Mean Loss 2.6205402851104735\n",
      "Epoch 53 | Mean Loss 2.615230369567871\n",
      "Epoch 54 | Mean Loss 2.6042628288269043\n",
      "Epoch 55 | Mean Loss 2.5976330280303954\n",
      "Epoch 56 | Mean Loss 2.6033562660217284\n",
      "Epoch 57 | Mean Loss 2.6046804428100585\n",
      "Epoch 58 | Mean Loss 2.6141889572143553\n",
      "Epoch 59 | Mean Loss 2.595870590209961\n",
      "Epoch 60 | Mean Loss 2.595947027206421\n",
      "Epoch 61 | Mean Loss 2.5968525886535643\n",
      "Epoch 62 | Mean Loss 2.6171208381652833\n",
      "Epoch 63 | Mean Loss 2.6116089820861816\n",
      "Epoch 64 | Mean Loss 2.6188523292541506\n",
      "Epoch 65 | Mean Loss 2.5936761856079102\n",
      "Epoch 66 | Mean Loss 2.6145373821258544\n",
      "Epoch 67 | Mean Loss 2.59851016998291\n",
      "Epoch 68 | Mean Loss 2.6163140296936036\n",
      "Epoch 69 | Mean Loss 2.6034722328186035\n",
      "Epoch 70 | Mean Loss 2.6207741260528565\n",
      "Epoch 71 | Mean Loss 2.603789281845093\n",
      "Epoch 72 | Mean Loss 2.5925201416015624\n",
      "Epoch 73 | Mean Loss 2.576079082489014\n",
      "Epoch 74 | Mean Loss 2.604355573654175\n",
      "Epoch 75 | Mean Loss 2.60486741065979\n",
      "Epoch 76 | Mean Loss 2.6083414554595947\n",
      "Epoch 77 | Mean Loss 2.553453063964844\n",
      "Epoch 78 | Mean Loss 2.610918140411377\n",
      "Epoch 79 | Mean Loss 2.6082438945770265\n",
      "Epoch 80 | Mean Loss 2.578517532348633\n",
      "Epoch 81 | Mean Loss 2.606537961959839\n",
      "Epoch 82 | Mean Loss 2.597817897796631\n",
      "Epoch 83 | Mean Loss 2.610016393661499\n",
      "Epoch 84 | Mean Loss 2.611782455444336\n",
      "Epoch 85 | Mean Loss 2.6104947566986083\n",
      "Epoch 86 | Mean Loss 2.5972307682037354\n",
      "Epoch 87 | Mean Loss 2.5971731185913085\n",
      "Epoch 88 | Mean Loss 2.593199348449707\n",
      "Epoch 89 | Mean Loss 2.590114116668701\n",
      "Epoch 90 | Mean Loss 2.573267412185669\n",
      "Epoch 91 | Mean Loss 2.595078468322754\n",
      "Epoch 92 | Mean Loss 2.582313966751099\n",
      "Epoch 93 | Mean Loss 2.582651710510254\n",
      "Epoch 94 | Mean Loss 2.590412950515747\n",
      "Epoch 95 | Mean Loss 2.590913486480713\n",
      "Epoch 96 | Mean Loss 2.5770505905151366\n",
      "Epoch 97 | Mean Loss 2.607571268081665\n",
      "Epoch 98 | Mean Loss 2.5746128082275392\n",
      "Epoch 99 | Mean Loss 2.5959100246429445\n",
      "Train size:  0.3\n",
      "Epoch 0 | Mean Loss 5.490662395954132\n",
      "Epoch 1 | Mean Loss 3.2471578419208527\n",
      "Epoch 2 | Mean Loss 3.0377528369426727\n",
      "Epoch 3 | Mean Loss 2.8867473006248474\n",
      "Epoch 4 | Mean Loss 2.7730749249458313\n",
      "Epoch 5 | Mean Loss 2.714678108692169\n",
      "Epoch 6 | Mean Loss 2.6442020386457443\n",
      "Epoch 7 | Mean Loss 2.614296704530716\n",
      "Epoch 8 | Mean Loss 2.5982173085212708\n",
      "Epoch 9 | Mean Loss 2.58531653881073\n",
      "Epoch 10 | Mean Loss 2.5822218507528305\n",
      "Epoch 11 | Mean Loss 2.572034239768982\n",
      "Epoch 12 | Mean Loss 2.57786525785923\n",
      "Epoch 13 | Mean Loss 2.5633057355880737\n",
      "Epoch 14 | Mean Loss 2.577752470970154\n",
      "Epoch 15 | Mean Loss 2.558341920375824\n",
      "Epoch 16 | Mean Loss 2.556177645921707\n",
      "Epoch 17 | Mean Loss 2.5616363286972046\n",
      "Epoch 18 | Mean Loss 2.5250679403543472\n",
      "Epoch 19 | Mean Loss 2.52816940844059\n",
      "Epoch 20 | Mean Loss 2.5365499556064606\n",
      "Epoch 21 | Mean Loss 2.542246997356415\n",
      "Epoch 22 | Mean Loss 2.5155064910650253\n",
      "Epoch 23 | Mean Loss 2.515484020113945\n",
      "Epoch 24 | Mean Loss 2.521115019917488\n",
      "Epoch 25 | Mean Loss 2.5286373794078827\n",
      "Epoch 26 | Mean Loss 2.5188980400562286\n",
      "Epoch 27 | Mean Loss 2.5261410623788834\n",
      "Epoch 28 | Mean Loss 2.5166681110858917\n",
      "Epoch 29 | Mean Loss 2.529560625553131\n",
      "Epoch 30 | Mean Loss 2.527379035949707\n",
      "Epoch 31 | Mean Loss 2.5407932698726654\n",
      "Epoch 32 | Mean Loss 2.519723415374756\n",
      "Epoch 33 | Mean Loss 2.5138547271490097\n",
      "Epoch 34 | Mean Loss 2.50805526971817\n",
      "Epoch 35 | Mean Loss 2.5117592215538025\n",
      "Epoch 36 | Mean Loss 2.5165987759828568\n",
      "Epoch 37 | Mean Loss 2.506884053349495\n",
      "Epoch 38 | Mean Loss 2.5171924829483032\n",
      "Epoch 39 | Mean Loss 2.514115020632744\n",
      "Epoch 40 | Mean Loss 2.526872009038925\n",
      "Epoch 41 | Mean Loss 2.5189356803894043\n",
      "Epoch 42 | Mean Loss 2.518378123641014\n",
      "Epoch 43 | Mean Loss 2.514454036951065\n",
      "Epoch 44 | Mean Loss 2.5213308334350586\n",
      "Epoch 45 | Mean Loss 2.5362269580364227\n",
      "Epoch 46 | Mean Loss 2.5029064267873764\n",
      "Epoch 47 | Mean Loss 2.514734297990799\n",
      "Epoch 48 | Mean Loss 2.4967361241579056\n",
      "Epoch 49 | Mean Loss 2.5047918558120728\n",
      "Epoch 50 | Mean Loss 2.5254310220479965\n",
      "Epoch 51 | Mean Loss 2.523616075515747\n",
      "Epoch 52 | Mean Loss 2.5234191715717316\n",
      "Epoch 53 | Mean Loss 2.516485646367073\n",
      "Epoch 54 | Mean Loss 2.5187421441078186\n",
      "Epoch 55 | Mean Loss 2.510854035615921\n",
      "Epoch 56 | Mean Loss 2.529021441936493\n",
      "Epoch 57 | Mean Loss 2.5305333137512207\n",
      "Epoch 58 | Mean Loss 2.5197378545999527\n",
      "Epoch 59 | Mean Loss 2.5088975727558136\n",
      "Epoch 60 | Mean Loss 2.5022255033254623\n",
      "Epoch 61 | Mean Loss 2.510048121213913\n",
      "Epoch 62 | Mean Loss 2.5075410455465317\n",
      "Epoch 63 | Mean Loss 2.51154662668705\n",
      "Epoch 64 | Mean Loss 2.5083393454551697\n",
      "Epoch 65 | Mean Loss 2.518135964870453\n",
      "Epoch 66 | Mean Loss 2.5253018736839294\n",
      "Epoch 67 | Mean Loss 2.5274126678705215\n",
      "Epoch 68 | Mean Loss 2.518054783344269\n",
      "Epoch 69 | Mean Loss 2.5134875178337097\n",
      "Epoch 70 | Mean Loss 2.5121345669031143\n",
      "Epoch 71 | Mean Loss 2.5034865885972977\n",
      "Epoch 72 | Mean Loss 2.5267451852560043\n",
      "Epoch 73 | Mean Loss 2.5119484215974808\n",
      "Epoch 74 | Mean Loss 2.5126819908618927\n",
      "Epoch 75 | Mean Loss 2.529665380716324\n",
      "Epoch 76 | Mean Loss 2.512675315141678\n",
      "Epoch 77 | Mean Loss 2.505257859826088\n",
      "Epoch 78 | Mean Loss 2.5250458121299744\n",
      "Epoch 79 | Mean Loss 2.509587898850441\n",
      "Epoch 80 | Mean Loss 2.5165224224328995\n",
      "Epoch 81 | Mean Loss 2.5213359892368317\n",
      "Epoch 82 | Mean Loss 2.530667006969452\n",
      "Epoch 83 | Mean Loss 2.501961961388588\n",
      "Epoch 84 | Mean Loss 2.512050524353981\n",
      "Epoch 85 | Mean Loss 2.5113412886857986\n",
      "Epoch 86 | Mean Loss 2.525623381137848\n",
      "Epoch 87 | Mean Loss 2.519168898463249\n",
      "Epoch 88 | Mean Loss 2.5099290907382965\n",
      "Epoch 89 | Mean Loss 2.515117257833481\n",
      "Epoch 90 | Mean Loss 2.5259215384721756\n",
      "Epoch 91 | Mean Loss 2.5165543109178543\n",
      "Epoch 92 | Mean Loss 2.5069727152585983\n",
      "Epoch 93 | Mean Loss 2.51994888484478\n",
      "Epoch 94 | Mean Loss 2.501022309064865\n",
      "Epoch 95 | Mean Loss 2.5342219173908234\n",
      "Epoch 96 | Mean Loss 2.505725085735321\n",
      "Epoch 97 | Mean Loss 2.5006916224956512\n",
      "Epoch 98 | Mean Loss 2.5092525482177734\n",
      "Epoch 99 | Mean Loss 2.52674762904644\n",
      "Epoch 0 | Mean Loss 5.170683354139328\n",
      "Epoch 1 | Mean Loss 2.9349991977214813\n",
      "Epoch 2 | Mean Loss 2.8365403413772583\n",
      "Epoch 3 | Mean Loss 2.7134890854358673\n",
      "Epoch 4 | Mean Loss 2.6520555913448334\n",
      "Epoch 5 | Mean Loss 2.6043294817209244\n",
      "Epoch 6 | Mean Loss 2.5484408885240555\n",
      "Epoch 7 | Mean Loss 2.5316715836524963\n",
      "Epoch 8 | Mean Loss 2.5529878437519073\n",
      "Epoch 9 | Mean Loss 2.516677498817444\n",
      "Epoch 10 | Mean Loss 2.5009805560112\n",
      "Epoch 11 | Mean Loss 2.518023192882538\n",
      "Epoch 12 | Mean Loss 2.533679276704788\n",
      "Epoch 13 | Mean Loss 2.513500139117241\n",
      "Epoch 14 | Mean Loss 2.525526136159897\n",
      "Epoch 15 | Mean Loss 2.5035483837127686\n",
      "Epoch 16 | Mean Loss 2.4973021149635315\n",
      "Epoch 17 | Mean Loss 2.5223077833652496\n",
      "Epoch 18 | Mean Loss 2.5277872681617737\n",
      "Epoch 19 | Mean Loss 2.5017888993024826\n",
      "Epoch 20 | Mean Loss 2.523554712533951\n",
      "Epoch 21 | Mean Loss 2.510020613670349\n",
      "Epoch 22 | Mean Loss 2.510854199528694\n",
      "Epoch 23 | Mean Loss 2.509834736585617\n",
      "Epoch 24 | Mean Loss 2.513371154665947\n",
      "Epoch 25 | Mean Loss 2.517379015684128\n",
      "Epoch 26 | Mean Loss 2.5268213152885437\n",
      "Epoch 27 | Mean Loss 2.527299016714096\n",
      "Epoch 28 | Mean Loss 2.4968561977148056\n",
      "Epoch 29 | Mean Loss 2.511458918452263\n",
      "Epoch 30 | Mean Loss 2.506660059094429\n",
      "Epoch 31 | Mean Loss 2.5144810676574707\n",
      "Epoch 32 | Mean Loss 2.525906413793564\n",
      "Epoch 33 | Mean Loss 2.5135132670402527\n",
      "Epoch 34 | Mean Loss 2.5190777480602264\n",
      "Epoch 35 | Mean Loss 2.4980128407478333\n",
      "Epoch 36 | Mean Loss 2.509383261203766\n",
      "Epoch 37 | Mean Loss 2.517492637038231\n",
      "Epoch 38 | Mean Loss 2.506266564130783\n",
      "Epoch 39 | Mean Loss 2.53237584233284\n",
      "Epoch 40 | Mean Loss 2.506210133433342\n",
      "Epoch 41 | Mean Loss 2.5067099779844284\n",
      "Epoch 42 | Mean Loss 2.5009662359952927\n",
      "Epoch 43 | Mean Loss 2.5242641866207123\n",
      "Epoch 44 | Mean Loss 2.5105355829000473\n",
      "Epoch 45 | Mean Loss 2.5038136541843414\n",
      "Epoch 46 | Mean Loss 2.5195968747138977\n",
      "Epoch 47 | Mean Loss 2.511249840259552\n",
      "Epoch 48 | Mean Loss 2.5072013288736343\n",
      "Epoch 49 | Mean Loss 2.5205041617155075\n",
      "Epoch 50 | Mean Loss 2.5176964700222015\n",
      "Epoch 51 | Mean Loss 2.5126725286245346\n",
      "Epoch 52 | Mean Loss 2.5121176093816757\n",
      "Epoch 53 | Mean Loss 2.5021783262491226\n",
      "Epoch 54 | Mean Loss 2.5271470844745636\n",
      "Epoch 55 | Mean Loss 2.5187941789627075\n",
      "Epoch 56 | Mean Loss 2.517789363861084\n",
      "Epoch 57 | Mean Loss 2.5091780573129654\n",
      "Epoch 58 | Mean Loss 2.513366401195526\n",
      "Epoch 59 | Mean Loss 2.514207273721695\n",
      "Epoch 60 | Mean Loss 2.497912585735321\n",
      "Epoch 61 | Mean Loss 2.498427599668503\n",
      "Epoch 62 | Mean Loss 2.5126813501119614\n",
      "Epoch 63 | Mean Loss 2.501071512699127\n",
      "Epoch 64 | Mean Loss 2.489841029047966\n",
      "Epoch 65 | Mean Loss 2.5024216324090958\n",
      "Epoch 66 | Mean Loss 2.5149458944797516\n",
      "Epoch 67 | Mean Loss 2.517249673604965\n",
      "Epoch 68 | Mean Loss 2.5141339898109436\n",
      "Epoch 69 | Mean Loss 2.5326048135757446\n",
      "Epoch 70 | Mean Loss 2.500133663415909\n",
      "Epoch 71 | Mean Loss 2.509337931871414\n",
      "Epoch 72 | Mean Loss 2.5359294414520264\n",
      "Epoch 73 | Mean Loss 2.5012082904577255\n",
      "Epoch 74 | Mean Loss 2.5093099772930145\n",
      "Epoch 75 | Mean Loss 2.5148570388555527\n",
      "Epoch 76 | Mean Loss 2.497701942920685\n",
      "Epoch 77 | Mean Loss 2.5288756787776947\n",
      "Epoch 78 | Mean Loss 2.5226908326148987\n",
      "Epoch 79 | Mean Loss 2.5067813992500305\n",
      "Epoch 80 | Mean Loss 2.520603746175766\n",
      "Epoch 81 | Mean Loss 2.5220752209424973\n",
      "Epoch 82 | Mean Loss 2.531571388244629\n",
      "Epoch 83 | Mean Loss 2.5099858045578003\n",
      "Epoch 84 | Mean Loss 2.510324254631996\n",
      "Epoch 85 | Mean Loss 2.5070278495550156\n",
      "Epoch 86 | Mean Loss 2.4969768673181534\n",
      "Epoch 87 | Mean Loss 2.502081036567688\n",
      "Epoch 88 | Mean Loss 2.5096087753772736\n",
      "Epoch 89 | Mean Loss 2.520955264568329\n",
      "Epoch 90 | Mean Loss 2.5235108584165573\n",
      "Epoch 91 | Mean Loss 2.5090757608413696\n",
      "Epoch 92 | Mean Loss 2.515935316681862\n",
      "Epoch 93 | Mean Loss 2.493166521191597\n",
      "Epoch 94 | Mean Loss 2.4963694363832474\n",
      "Epoch 95 | Mean Loss 2.518602430820465\n",
      "Epoch 96 | Mean Loss 2.509937047958374\n",
      "Epoch 97 | Mean Loss 2.5078907757997513\n",
      "Epoch 98 | Mean Loss 2.513669788837433\n",
      "Epoch 99 | Mean Loss 2.499886631965637\n",
      "Epoch 0 | Mean Loss 5.965449035167694\n",
      "Epoch 1 | Mean Loss 4.187266439199448\n",
      "Epoch 2 | Mean Loss 3.9977536499500275\n",
      "Epoch 3 | Mean Loss 3.8691399693489075\n",
      "Epoch 4 | Mean Loss 3.7147403359413147\n",
      "Epoch 5 | Mean Loss 3.5142562687397003\n",
      "Epoch 6 | Mean Loss 3.2790351510047913\n",
      "Epoch 7 | Mean Loss 3.0703163743019104\n",
      "Epoch 8 | Mean Loss 2.837915778160095\n",
      "Epoch 9 | Mean Loss 2.665325343608856\n",
      "Epoch 10 | Mean Loss 2.6217044442892075\n",
      "Epoch 11 | Mean Loss 2.6133123636245728\n",
      "Epoch 12 | Mean Loss 2.592081695795059\n",
      "Epoch 13 | Mean Loss 2.6073089987039566\n",
      "Epoch 14 | Mean Loss 2.5816069692373276\n",
      "Epoch 15 | Mean Loss 2.576392352581024\n",
      "Epoch 16 | Mean Loss 2.5614954978227615\n",
      "Epoch 17 | Mean Loss 2.5545729845762253\n",
      "Epoch 18 | Mean Loss 2.5738761126995087\n",
      "Epoch 19 | Mean Loss 2.5437443554401398\n",
      "Epoch 20 | Mean Loss 2.5463263392448425\n",
      "Epoch 21 | Mean Loss 2.559300184249878\n",
      "Epoch 22 | Mean Loss 2.5404469966888428\n",
      "Epoch 23 | Mean Loss 2.5373351722955704\n",
      "Epoch 24 | Mean Loss 2.561735600233078\n",
      "Epoch 25 | Mean Loss 2.5199408382177353\n",
      "Epoch 26 | Mean Loss 2.521433264017105\n",
      "Epoch 27 | Mean Loss 2.522096037864685\n",
      "Epoch 28 | Mean Loss 2.51717209815979\n",
      "Epoch 29 | Mean Loss 2.5218164771795273\n",
      "Epoch 30 | Mean Loss 2.512645199894905\n",
      "Epoch 31 | Mean Loss 2.5067880004644394\n",
      "Epoch 32 | Mean Loss 2.5371024906635284\n",
      "Epoch 33 | Mean Loss 2.5257396399974823\n",
      "Epoch 34 | Mean Loss 2.5251105278730392\n",
      "Epoch 35 | Mean Loss 2.53142312169075\n",
      "Epoch 36 | Mean Loss 2.5404384434223175\n",
      "Epoch 37 | Mean Loss 2.5162646919488907\n",
      "Epoch 38 | Mean Loss 2.518305867910385\n",
      "Epoch 39 | Mean Loss 2.5094986259937286\n",
      "Epoch 40 | Mean Loss 2.5311363637447357\n",
      "Epoch 41 | Mean Loss 2.5129651576280594\n",
      "Epoch 42 | Mean Loss 2.508913666009903\n",
      "Epoch 43 | Mean Loss 2.5092125982046127\n",
      "Epoch 44 | Mean Loss 2.496543765068054\n",
      "Epoch 45 | Mean Loss 2.524527281522751\n",
      "Epoch 46 | Mean Loss 2.516654297709465\n",
      "Epoch 47 | Mean Loss 2.51329505443573\n",
      "Epoch 48 | Mean Loss 2.5293940901756287\n",
      "Epoch 49 | Mean Loss 2.5351904928684235\n",
      "Epoch 50 | Mean Loss 2.5246378779411316\n",
      "Epoch 51 | Mean Loss 2.5066720098257065\n",
      "Epoch 52 | Mean Loss 2.5160133242607117\n",
      "Epoch 53 | Mean Loss 2.5274850726127625\n",
      "Epoch 54 | Mean Loss 2.514252185821533\n",
      "Epoch 55 | Mean Loss 2.5193054378032684\n",
      "Epoch 56 | Mean Loss 2.5056543797254562\n",
      "Epoch 57 | Mean Loss 2.52203731238842\n",
      "Epoch 58 | Mean Loss 2.511073112487793\n",
      "Epoch 59 | Mean Loss 2.510286435484886\n",
      "Epoch 60 | Mean Loss 2.514400377869606\n",
      "Epoch 61 | Mean Loss 2.5149190723896027\n",
      "Epoch 62 | Mean Loss 2.5158019214868546\n",
      "Epoch 63 | Mean Loss 2.5197680294513702\n",
      "Epoch 64 | Mean Loss 2.511727422475815\n",
      "Epoch 65 | Mean Loss 2.5116908997297287\n",
      "Epoch 66 | Mean Loss 2.505703866481781\n",
      "Epoch 67 | Mean Loss 2.5178493708372116\n",
      "Epoch 68 | Mean Loss 2.5248900055885315\n",
      "Epoch 69 | Mean Loss 2.4979972541332245\n",
      "Epoch 70 | Mean Loss 2.5177855640649796\n",
      "Epoch 71 | Mean Loss 2.511282503604889\n",
      "Epoch 72 | Mean Loss 2.51804456114769\n",
      "Epoch 73 | Mean Loss 2.5084338635206223\n",
      "Epoch 74 | Mean Loss 2.4833052903413773\n",
      "Epoch 75 | Mean Loss 2.5316262543201447\n",
      "Epoch 76 | Mean Loss 2.509544253349304\n",
      "Epoch 77 | Mean Loss 2.533123940229416\n",
      "Epoch 78 | Mean Loss 2.5044320821762085\n",
      "Epoch 79 | Mean Loss 2.510955899953842\n",
      "Epoch 80 | Mean Loss 2.5016546547412872\n",
      "Epoch 81 | Mean Loss 2.5132355988025665\n",
      "Epoch 82 | Mean Loss 2.5108319222927094\n",
      "Epoch 83 | Mean Loss 2.5229668468236923\n",
      "Epoch 84 | Mean Loss 2.5227566063404083\n",
      "Epoch 85 | Mean Loss 2.531358689069748\n",
      "Epoch 86 | Mean Loss 2.5112720727920532\n",
      "Epoch 87 | Mean Loss 2.530434101819992\n",
      "Epoch 88 | Mean Loss 2.51621013879776\n",
      "Epoch 89 | Mean Loss 2.5088561177253723\n",
      "Epoch 90 | Mean Loss 2.534048318862915\n",
      "Epoch 91 | Mean Loss 2.510517790913582\n",
      "Epoch 92 | Mean Loss 2.5076014548540115\n",
      "Epoch 93 | Mean Loss 2.5139966160058975\n",
      "Epoch 94 | Mean Loss 2.5281070470809937\n",
      "Epoch 95 | Mean Loss 2.5101773738861084\n",
      "Epoch 96 | Mean Loss 2.502535730600357\n",
      "Epoch 97 | Mean Loss 2.5170068740844727\n",
      "Epoch 98 | Mean Loss 2.5224587321281433\n",
      "Epoch 99 | Mean Loss 2.5081307739019394\n",
      "Epoch 0 | Mean Loss 7.0376808643341064\n",
      "Epoch 1 | Mean Loss 4.037315636873245\n",
      "Epoch 2 | Mean Loss 3.614826261997223\n",
      "Epoch 3 | Mean Loss 3.2271526157855988\n",
      "Epoch 4 | Mean Loss 2.9394874274730682\n",
      "Epoch 5 | Mean Loss 2.7797891795635223\n",
      "Epoch 6 | Mean Loss 2.6797790825366974\n",
      "Epoch 7 | Mean Loss 2.6269656121730804\n",
      "Epoch 8 | Mean Loss 2.5763184130191803\n",
      "Epoch 9 | Mean Loss 2.5454560220241547\n",
      "Epoch 10 | Mean Loss 2.5152135640382767\n",
      "Epoch 11 | Mean Loss 2.520059749484062\n",
      "Epoch 12 | Mean Loss 2.517301231622696\n",
      "Epoch 13 | Mean Loss 2.521538123488426\n",
      "Epoch 14 | Mean Loss 2.530100628733635\n",
      "Epoch 15 | Mean Loss 2.5092138946056366\n",
      "Epoch 16 | Mean Loss 2.500033751130104\n",
      "Epoch 17 | Mean Loss 2.518103063106537\n",
      "Epoch 18 | Mean Loss 2.5145009756088257\n",
      "Epoch 19 | Mean Loss 2.5180504322052\n",
      "Epoch 20 | Mean Loss 2.5430100560188293\n",
      "Epoch 21 | Mean Loss 2.522288531064987\n",
      "Epoch 22 | Mean Loss 2.517058566212654\n",
      "Epoch 23 | Mean Loss 2.532785326242447\n",
      "Epoch 24 | Mean Loss 2.5282409489154816\n",
      "Epoch 25 | Mean Loss 2.527579575777054\n",
      "Epoch 26 | Mean Loss 2.5163524001836777\n",
      "Epoch 27 | Mean Loss 2.4955929815769196\n",
      "Epoch 28 | Mean Loss 2.5231232941150665\n",
      "Epoch 29 | Mean Loss 2.5264811515808105\n",
      "Epoch 30 | Mean Loss 2.51505808532238\n",
      "Epoch 31 | Mean Loss 2.510323166847229\n",
      "Epoch 32 | Mean Loss 2.525637000799179\n",
      "Epoch 33 | Mean Loss 2.5270976424217224\n",
      "Epoch 34 | Mean Loss 2.5151131451129913\n",
      "Epoch 35 | Mean Loss 2.5327882766723633\n",
      "Epoch 36 | Mean Loss 2.506103962659836\n",
      "Epoch 37 | Mean Loss 2.51446570456028\n",
      "Epoch 38 | Mean Loss 2.531738355755806\n",
      "Epoch 39 | Mean Loss 2.518045663833618\n",
      "Epoch 40 | Mean Loss 2.5200882256031036\n",
      "Epoch 41 | Mean Loss 2.5120467841625214\n",
      "Epoch 42 | Mean Loss 2.514497622847557\n",
      "Epoch 43 | Mean Loss 2.5110989958047867\n",
      "Epoch 44 | Mean Loss 2.5285785794258118\n",
      "Epoch 45 | Mean Loss 2.502758741378784\n",
      "Epoch 46 | Mean Loss 2.5046981424093246\n",
      "Epoch 47 | Mean Loss 2.523682117462158\n",
      "Epoch 48 | Mean Loss 2.5121052861213684\n",
      "Epoch 49 | Mean Loss 2.522886633872986\n",
      "Epoch 50 | Mean Loss 2.508407399058342\n",
      "Epoch 51 | Mean Loss 2.504586711525917\n",
      "Epoch 52 | Mean Loss 2.5224818140268326\n",
      "Epoch 53 | Mean Loss 2.5206942409276962\n",
      "Epoch 54 | Mean Loss 2.524181753396988\n",
      "Epoch 55 | Mean Loss 2.517799511551857\n",
      "Epoch 56 | Mean Loss 2.529545098543167\n",
      "Epoch 57 | Mean Loss 2.5190466344356537\n",
      "Epoch 58 | Mean Loss 2.510513335466385\n",
      "Epoch 59 | Mean Loss 2.501881778240204\n",
      "Epoch 60 | Mean Loss 2.536442846059799\n",
      "Epoch 61 | Mean Loss 2.4855057448148727\n",
      "Epoch 62 | Mean Loss 2.5184260308742523\n",
      "Epoch 63 | Mean Loss 2.507929742336273\n",
      "Epoch 64 | Mean Loss 2.543253093957901\n",
      "Epoch 65 | Mean Loss 2.5050414204597473\n",
      "Epoch 66 | Mean Loss 2.5140195190906525\n",
      "Epoch 67 | Mean Loss 2.511351376771927\n",
      "Epoch 68 | Mean Loss 2.505662739276886\n",
      "Epoch 69 | Mean Loss 2.510790601372719\n",
      "Epoch 70 | Mean Loss 2.5184668600559235\n",
      "Epoch 71 | Mean Loss 2.5122826993465424\n",
      "Epoch 72 | Mean Loss 2.5202369689941406\n",
      "Epoch 73 | Mean Loss 2.5001551508903503\n",
      "Epoch 74 | Mean Loss 2.51913258433342\n",
      "Epoch 75 | Mean Loss 2.512458384037018\n",
      "Epoch 76 | Mean Loss 2.5116828978061676\n",
      "Epoch 77 | Mean Loss 2.5239380449056625\n",
      "Epoch 78 | Mean Loss 2.511566609144211\n",
      "Epoch 79 | Mean Loss 2.519179552793503\n",
      "Epoch 80 | Mean Loss 2.513350620865822\n",
      "Epoch 81 | Mean Loss 2.5214495062828064\n",
      "Epoch 82 | Mean Loss 2.5180174112319946\n",
      "Epoch 83 | Mean Loss 2.5044027268886566\n",
      "Epoch 84 | Mean Loss 2.5072318017482758\n",
      "Epoch 85 | Mean Loss 2.5383394360542297\n",
      "Epoch 86 | Mean Loss 2.504967078566551\n",
      "Epoch 87 | Mean Loss 2.518605649471283\n",
      "Epoch 88 | Mean Loss 2.5236049592494965\n",
      "Epoch 89 | Mean Loss 2.5031421333551407\n",
      "Epoch 90 | Mean Loss 2.5194166004657745\n",
      "Epoch 91 | Mean Loss 2.500552326440811\n",
      "Epoch 92 | Mean Loss 2.5171433687210083\n",
      "Epoch 93 | Mean Loss 2.5037048906087875\n",
      "Epoch 94 | Mean Loss 2.514949232339859\n",
      "Epoch 95 | Mean Loss 2.518327385187149\n",
      "Epoch 96 | Mean Loss 2.519448399543762\n",
      "Epoch 97 | Mean Loss 2.528202176094055\n",
      "Epoch 98 | Mean Loss 2.527535930275917\n",
      "Epoch 99 | Mean Loss 2.5145193785429\n",
      "Epoch 0 | Mean Loss 8.29450410604477\n",
      "Epoch 1 | Mean Loss 4.77939510345459\n",
      "Epoch 2 | Mean Loss 4.7686450481414795\n",
      "Epoch 3 | Mean Loss 4.582875907421112\n",
      "Epoch 4 | Mean Loss 4.363722890615463\n",
      "Epoch 5 | Mean Loss 4.266993671655655\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_pft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_ptt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Evaluate the model on both training and testing sets\u001b[39;00m\n\u001b[1;32m     55\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m gather_feats_targets(model, train_loader, device)\n",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion_pft, criterion_ptt, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m batch_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_num, (features, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      6\u001b[0m     bsz \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m     n_views \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# val_indices = participants.index[participants['dataset'] == \"COBRE\"].values\n",
    "n_subj = len(participants)\n",
    "batch_size = 30\n",
    "\n",
    "input_dim_feat = 499500 # vectorized mat, diagonal discarded\n",
    "# the rest is arbitrary\n",
    "hidden_dim_feat = 1000\n",
    "input_dim_target = 1\n",
    "output_dim = 2\n",
    "\n",
    "lr = 0.01\n",
    "dropout_rate = 0\n",
    "weight_decay = 0\n",
    "kernel = cauchy\n",
    "epochs = 100\n",
    "\n",
    "criterion_pft = KernelizedSupCon(method='expw', temperature=0.03, base_temperature=0.07, kernel=kernel, krnl_sigma = 1, contrast_mode = 'all')\n",
    "criterion_ptt = KernelizedSupCon(method='expw', temperature=0.03, base_temperature=0.07, kernel=kernel, krnl_sigma = 1, contrast_mode = 'all')\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "results_series = []\n",
    "all_indices = np.arange(n_subj)\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    \n",
    "    print(\"Train size: \", train_size)\n",
    "    num_train = int(n_subj * train_size)\n",
    "    train_indices = np.random.choice(all_indices, num_train, replace=False)\n",
    "    fold_num = 0\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(train_indices):\n",
    "        \n",
    "        training_fold_indices = train_indices[train_idx]\n",
    "        validation_fold_indices = train_indices[test_idx]\n",
    "\n",
    "        train_dataset = MatData(\"matrices.npy\", \"participants.csv\", \"age\", indices=training_fold_indices)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        validation_dataset = MatData(\"matrices.npy\", \"participants.csv\", \"age\", indices=validation_fold_indices)\n",
    "        val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = MLP(input_dim_feat, input_dim_target, hidden_dim_feat, output_dim, dropout_rate).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        for epoch in range(epochs):\n",
    "            train(model, train_loader, criterion_pft, criterion_ptt, optimizer)\n",
    "\n",
    "        # Evaluate the model on both training and testing sets\n",
    "        X_train, y_train = gather_feats_targets(model, train_loader, device)\n",
    "        estimator = AgeEstimator()\n",
    "        estimator.fit(X_train, y_train)\n",
    "        mae_train = estimator.score(X_train, y_train)\n",
    "        r2_train = estimator.r2(X_train, y_train)\n",
    "        \n",
    "        X_test, y_test = gather_feats_targets(model, val_loader, device)\n",
    "        mae_test = estimator.score(X_test, y_test)\n",
    "        r2_test = estimator.r2(X_test, y_test)\n",
    "        \n",
    "        # Record results for this fold\n",
    "        results_series.append(pd.Series({\n",
    "            \"Training Size\": num_train,\n",
    "            \"Fold Number\": int(fold_num),\n",
    "            \"MAE Train\": mae_train,\n",
    "            \"R2 Train\": r2_train,\n",
    "            \"MAE Test\": mae_test,\n",
    "            \"R2 Test\": r2_test}))\n",
    "        fold_num += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8984455",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "462b51d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/cv_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results.to_csv(\"results/cv_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b564e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the training MAE\n",
    "sns.lineplot(data=results, x=\"Train Sizes\", y=\"MAE Train\", label=\"MAE Train\", color=\"#0081a7\")\n",
    "\n",
    "# Plot the testing MAE\n",
    "sns.lineplot(data=results, x=\"Train Sizes\", y=\"MAE Test\", label=\"MAE Test\", color=\"#f07167\")\n",
    "\n",
    "# Adding some plot details\n",
    "plt.title(\"MAE Comparison for Train and Test Sets\")\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
    "plt.xlabel(\"Training Sizes\")\n",
    "plt.legend(title=\"Data Type\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "051e2a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2IAAAIjCAYAAABh3KjvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADudklEQVR4nOzdd3RU1drH8e+Zll4IJIQSktA7oUPoShcQKSoWuh3L9YqI16t4fRVU7F2UYqFIEZVeFKWGGnonIZQUanoyk5nz/hEyEgmQMpOTZJ7PWrOWmZw55zczmOSZvfezFVVVVYQQQgghhBBClBqd1gGEEEIIIYQQwtVIISaEEEIIIYQQpUwKMSGEEEIIIYQoZVKICSGEEEIIIUQpk0JMCCGEEEIIIUqZFGJCCCGEEEIIUcqkEBNCCCGEEEKIUiaFmBBCCCGEEEKUMinEhBBCCCGEEKKUSSEmhBCiVIwePZqwsDCtY9zUjh07iIyMxMvLC0VRiI6O1jpSiUyZMgVFUbSOUSxl/d+KEEI4ghRiQohybfbs2SiKgqIobNq06Ybvq6pKSEgIiqIwYMCAAs9x9epV3N3dURSFw4cPF3jM6NGj7df5583d3b1QWbOysvjggw9o3749fn5+uLu7U79+fSZMmMCxY8cK/6SFw1ksFoYPH87ly5f54IMP+P777wkNDXXKtcLCwm76b+n62+zZs51y/Yrg+v/vb3VzVDG3ZcsWpkyZwtWrVwv9mN9++41u3boRFBSEp6cntWvX5t5772XVqlXFyvDWW2+xdOnSYj1WCFE2GbQOIIQQjuDu7s7cuXPp3Llzvvv//PNPzp49i5ub200fu3DhQhRFITg4mB9//JH/+7//K/A4Nzc3vvnmmxvu1+v1t8138eJF+vbty65duxgwYAAPPPAA3t7eHD16lPnz5/P1119jNptve57ybMaMGdhsNq1jFOjkyZOcPn2aGTNmMH78eKde68MPPyQtLc3+9YoVK5g3bx4ffPABVapUsd8fGRlZouu88sorvPTSSyU6R1nVtWtXvv/++3z3jR8/nnbt2vHoo4/a7/P29nbI9bZs2cLrr7/O6NGj8ff3v+3x06dPZ+LEiXTr1o3Jkyfj6enJiRMnWLduHfPnz6dv375FzvDWW28xbNgwBg8eXPQnIIQok6QQE0JUCP3792fhwoV8/PHHGAx//2ibO3curVu35uLFizd97A8//ED//v0JDQ1l7ty5Ny3EDAYDDz30ULHyjR49mj179rBo0SKGDh2a73tvvPEG//nPf4p13vIgPT0dLy8vjEaj1lFuKikpCaBQf2QXVt7z/qd//iGdkJDAvHnzGDx48C1HcG52vpsxGAz5/l+oSGrXrk3t2rXz3ff4449Tu3btYv8/6ig5OTm88cYb9OrVizVr1tzw/bx/a0IIIVMThRAVwogRI7h06RJr166132c2m1m0aBEPPPDATR8XFxfHxo0buf/++7n//vuJiYlhy5YtDs0WFRXF8uXLGTdu3A1FGOSOtE2fPj3ffb///jtdunTBy8sLf39/7r777humTeatATp27BgPPfQQfn5+BAYG8t///hdVVTlz5gx33303vr6+BAcH89577+V7/IYNG1AUhQULFvDyyy8THByMl5cXgwYN4syZM/mO3bhxI8OHD6dWrVq4ubkREhLCv/71LzIzM/MdN3r0aLy9vTl58iT9+/fHx8eHBx980P69fxYa8+fPp3Xr1vj4+ODr60uzZs346KOP8h1z6tQphg8fTkBAAJ6ennTo0IHly5cX+Fx++ukn3nzzTWrWrIm7uzt33nknJ06cuMk783fmbt26ATB8+HAURaF79+7Fei8OHTrEAw88QKVKlW4YnS2KW72OhX0vClojpigKEyZMYOnSpTRt2hQ3NzeaNGlSqOlyZrOZV199ldatW+Pn54eXlxddunThjz/+yHdcbGwsiqIwffp0vv76a+rUqYObmxtt27Zlx44dN5w3L4u7uztNmzbl559/LurLdVPnzp1j7NixVK1a1f5cZ86cecNxn3zyCU2aNMHT05NKlSrRpk0b5s6dC+S+jhMnTgQgPDzcPu0xNja2wGtevHiRlJQUOnXqVOD3g4KC8n2dnZ3Na6+9Rt26de3v54svvkh2drb9GEVRSE9PZ86cOfbrjx49GoDU1FSee+45wsLCcHNzIygoiF69erF79+6ivlxCiFJWMT8qE0K4nLCwMDp27Mi8efPo168fACtXriQ5OZn777+fjz/+uMDHzZs3Dy8vLwYMGICHhwd16tThxx9/vOm0sIJG1kwmE76+vjfN9uuvvwLw8MMPF+q5rFu3jn79+lG7dm2mTJlCZmYmn3zyCZ06dWL37t03FDP33XcfjRo1Ytq0aSxfvpz/+7//IyAggK+++oo77riDt99+mx9//JEXXniBtm3b0rVr13yPf/PNN1EUhUmTJpGUlMSHH35Iz549iY6OxsPDA8idvpmRkcETTzxB5cqV2b59O5988glnz55l4cKF+c6Xk5NDnz596Ny5M9OnT8fT07PA57l27VpGjBjBnXfeydtvvw3A4cOH2bx5M88++ywAiYmJREZGkpGRwTPPPEPlypWZM2cOgwYNYtGiRdxzzz35zjlt2jR0Oh0vvPACycnJvPPOOzz44INERUXd9PV+7LHHqFGjBm+99RbPPPMMbdu2pWrVqsV6L4YPH069evV46623UFX1ptcsjJu9jkV5LwqyadMmlixZwpNPPomPjw8ff/wxQ4cOJS4ujsqVK9/0cSkpKXzzzTeMGDGCRx55hNTUVL799lv69OnD9u3biYiIyHf83LlzSU1N5bHHHkNRFN555x2GDBnCqVOn7KOja9asYejQoTRu3JipU6dy6dIlxowZQ82aNYv/wl2TmJhIhw4d7MVnYGAgK1euZNy4caSkpPDcc88BuVNmn3nmGYYNG8azzz5LVlYW+/btIyoqigceeIAhQ4Zw7NixG6aPBgYGFnjdoKAgPDw8+O2333j66acJCAi4aUabzcagQYPYtGkTjz76KI0aNWL//v188MEHHDt2zL4m7Pvvv79h6mWdOnWA3JHARYsWMWHCBBo3bsylS5fYtGkThw8fplWrViV+HYUQTqQKIUQ5NmvWLBVQd+zYoX766aeqj4+PmpGRoaqqqg4fPlzt0aOHqqqqGhoaqt511103PL5Zs2bqgw8+aP/65ZdfVqtUqaJaLJZ8x40aNUoFCrz16dPnlhnvueceFVCvXLlSqOcUERGhBgUFqZcuXbLft3fvXlWn06kjR4603/faa6+pgProo4/a78vJyVFr1qypKoqiTps2zX7/lStXVA8PD3XUqFH2+/744w8VUGvUqKGmpKTY7//pp59UQP3oo4/s9+W9ptebOnWqqiiKevr0aft9ea/TSy+9dMPxo0aNUkNDQ+1fP/vss6qvr6+ak5Nz09fiueeeUwF148aN9vtSU1PV8PBwNSwsTLVarfmeS6NGjdTs7Gz7sR999JEKqPv377/pNa5//MKFC/PdX9T3YsSIEbe8TkHeffddFVBjYmLs993qdSzse5GX6XqAajKZ1BMnTuR7PoD6ySef3DJnTk5OvtdWVXP/XVWtWlUdO3as/b6YmBgVUCtXrqxevnzZfv8vv/yiAupvv/1mvy8iIkKtVq2aevXqVft9a9asUYF8/1YKw8vLK9+/73HjxqnVqlVTL168mO+4+++/X/Xz87O/jnfffbfapEmTW567oPfoVl599VUVUL28vNR+/fqpb775prpr164bjvv+++9VnU6X79+3qqrql19+qQLq5s2bb/r88vj5+alPPfVUoXIJIcoWmZoohKgw7r33XjIzM1m2bBmpqaksW7bsltMS9+3bx/79+xkxYoT9vhEjRnDx4kVWr159w/Hu7u6sXbv2htu0adNumSslJQUAHx+f2z6H+Ph4oqOjGT16dL5P0ps3b06vXr1YsWLFDY+5vrmEXq+nTZs2qKrKuHHj7Pf7+/vToEEDTp06dcPjR44cmS/bsGHDqFatWr5r5Y2MQe5apYsXLxIZGYmqquzZs+eGcz7xxBO3fa7+/v6kp6fnm076TytWrKBdu3b5pvl5e3vz6KOPEhsby6FDh/IdP2bMGEwmk/3rLl26ABT4vG+nOO/F448/XuTr3EpBr2NR34t/6tmzp300BXKfj6+v721fI71eb39tbTYbly9fJicnhzZt2hQ4De6+++6jUqVK9q//+V7kvb6jRo3Cz8/PflyvXr1o3LjxbZ/HraiqyuLFixk4cCCqqnLx4kX7rU+fPiQnJ9sz+/v7c/bs2QKnTRbX66+/zty5c2nZsiWrV6/mP//5D61bt6ZVq1b5prUuXLiQRo0a0bBhw3wZ77jjDoAbpn0WxN/fn6ioKM6fP++w/EKI0iGFmBCiwggMDKRnz57MnTuXJUuWYLVaGTZs2E2P/+GHH/Dy8qJ27dqcOHGCEydO4O7uTlhYGD/++OMNx+v1enr27HnD7Z9Tsv4pb9piamrqbZ/D6dOnAWjQoMEN32vUqBEXL14kPT093/21atXK93Vea/zrO/Dl3X/lypUbzluvXr18XyuKQt26dfOtgYmLi7MXJN7e3gQGBtrXVSUnJ+d7vMFgKNTUsieffJL69evTr18/atasydixY29Yq3T69OmbvhZ537/eP1+LvEKgoOd9O8V5L8LDw4t8nZu52etYlPeiIP98jSD3dSrMazRnzhyaN2+Ou7s7lStXJjAwkOXLlxd43du9F3mv7z///UHBr3lRXLhwgatXr/L1118TGBiY7zZmzBjg76YZkyZNwtvbm3bt2lGvXj2eeuopNm/eXKLrQ+6HOhs3buTKlSusWbOGBx54gD179jBw4ECysrIAOH78OAcPHrwhY/369fNlvJV33nmHAwcOEBISQrt27ZgyZUqxPngQQpQ+WSMmhKhQHnjgAR555BESEhLo16/fTbvgqarKvHnzSE9PL/DT96SkJNLS0hzS/rphw4YA7N+/3z4q4EgFtc+/WUt9tRjrlqxWK7169eLy5ctMmjSJhg0b4uXlxblz5xg9evQNLend3NzQ6W7/OV9QUBDR0dGsXr2alStXsnLlSmbNmsXIkSOZM2dOkXOCY593cVw/WlVSBb2ORX0vClLc1+iHH35g9OjRDB48mIkTJxIUFIRer2fq1KmcPHnSYddxhLzX4aGHHmLUqFEFHtO8eXMgt6g+evQoy5YtY9WqVSxevJjPP/+cV199lddff73EWXx9fenVqxe9evXCaDQyZ84coqKi6NatGzabjWbNmvH+++8X+NiQkJDbnv/ee++lS5cu/Pzzz6xZs4Z3332Xt99+myVLltjXywohyiYpxIQQFco999zDY489xrZt21iwYMFNj8vbX+x///uffXQlz5UrV3j00UdZunSpQ1phDxw4kKlTp/LDDz/cthDL20T46NGjN3zvyJEjVKlSpUgtzAvj+PHj+b5WVZUTJ07Y/1Ddv38/x44dY86cOYwcOdJ+3K2mFBaWyWRi4MCBDBw4EJvNxpNPPslXX33Ff//7X+rWrUtoaOhNXwvAaZsuX3/u0nwvbseZ78XtLFq0iNq1a7NkyZJ83Rhfe+21Yp0v7/X9578/KPg1L4rAwEB8fHywWq307Nnztsd7eXlx3333cd9992E2mxkyZAhvvvkmkydPtm/27ght2rRhzpw5xMfHA7kNN/bu3cudd95522vc6vvVqlXjySef5MknnyQpKYlWrVrx5ptvSiEmRBknUxOFEBWKt7c3X3zxBVOmTGHgwIE3PS5vWuLEiRMZNmxYvtsjjzxCvXr1CpyeWBwdO3akb9++fPPNN/YuaNczm8288MILQO4fVBEREcyZM4erV6/ajzlw4ABr1qyhf//+Dsl0ve+++y7ftMlFixYRHx9v/yMub2Tj+pEMVVVvaDNfVJcuXcr3tU6nsxd/ea27+/fvz/bt29m6dav9uPT0dL7++mvCwsJKvJboVrR4L27HWe9Fca8dFRWV770piutf3+unNq5du/aGtX/FyTp06FAWL17MgQMHbvj+hQsX7P/9z3+HJpOJxo0bo6oqFosFwF5wX//v4GYyMjJu+pqsXLkS+Hvq5b333su5c+eYMWPGDcdmZmbmm/rq5eV1w/WtVusN00KDgoKoXr16vvb3QoiySUbEhBAVzs2mIuXJzs5m8eLF9OrVC3d39wKPGTRoEB999BFJSUn2fX9ycnL44YcfCjz+nnvuueXoyHfffUfv3r0ZMmQIAwcO5M4778TLy4vjx48zf/584uPj7XuJvfvuu/Tr14+OHTsybtw4e8t0Pz8/pkyZUohXoGgCAgLo3LkzY8aMITExkQ8//JC6devyyCOPALlTK+vUqcMLL7zAuXPn8PX1ZfHixcVad3W98ePHc/nyZe644w5q1qzJ6dOn+eSTT4iIiLCPUr700kv2LQmeeeYZAgICmDNnDjExMSxevLhQUyBLorTfi9tx1ntRGAMGDGDJkiXcc8893HXXXcTExPDll1/SuHFj0tLSinXOqVOnctddd9G5c2fGjh3L5cuX7Xt6FfeceaZNm8Yff/xB+/bteeSRR2jcuDGXL19m9+7drFu3jsuXLwPQu3dvgoOD6dSpE1WrVuXw4cN8+umn3HXXXfYmNq1btwbgP//5D/fffz9Go5GBAwcW+P98RkYGkZGRdOjQgb59+xISEsLVq1dZunQpGzduZPDgwbRs2RLI3dLip59+4vHHH+ePP/6gU6dOWK1Wjhw5wk8//cTq1atp06aNPcO6det4//33qV69OuHh4TRo0ICaNWsybNgwWrRogbe3N+vWrWPHjh037BsohCiDSr1PoxBCOND17etv5fr29YsXL1YB9dtvv73p8Rs2bMjXwv1W7espZFvrjIwMdfr06Wrbtm1Vb29v1WQyqfXq1VOffvrpfO3EVVVV161bp3bq1En18PBQfX191YEDB6qHDh3Kd0xee/ILFy7ku3/UqFGql5fXDdfv1q1bvjbdeS3b582bp06ePFkNCgpSPTw81LvuuitfG3RVVdVDhw6pPXv2VL29vdUqVaqojzzyiL3t+axZs2577bzvXd+SfNGiRWrv3r3VoKAg1WQyqbVq1VIfe+wxNT4+Pt/jTp48qQ4bNkz19/dX3d3d1Xbt2qnLli3Ld8zN2s/ntVK/PmNBbvZ4VS3Ze1EYN2tff7PXsbDvxc3a1xfU6jw0NLTA1ujXs9ls6ltvvaWGhoaqbm5uasuWLdVly5bd8L7mvebvvvvuDecA1Ndeey3ffYsXL1YbNWqkurm5qY0bN1aXLFlywzkLo6D27omJiepTTz2lhoSEqEajUQ0ODlbvvPNO9euvv7Yf89VXX6ldu3ZVK1eurLq5ual16tRRJ06cqCYnJ+c71xtvvKHWqFFD1el0t/x/3mKxqDNmzFAHDx5sf608PT3Vli1bqu++++4NWwCYzWb17bffVps0aaK6ubmplSpVUlu3bq2+/vrr+TIcOXJE7dq1q+rh4aEC6qhRo9Ts7Gx14sSJaosWLVQfHx/Vy8tLbdGihfr5558X6bUTQmhDUdVSWsEshBCiTNmwYQM9evRg4cKFt+wuKYQQQgjHkzViQgghhBBCCFHKpBATQgghhBBCiFImhZgQQgghhBBClDJZIyaEEEIIIYQQpUxGxIQQQgghhBCilEkhJoQQQgghhBClTDZ0dgCbzcb58+fx8fFBURSt4wghhBBCCCE0oqoqqampVK9eHZ3u5uNeUog5wPnz5wkJCdE6hhBCCCGEEKKMOHPmDDVr1rzp96UQcwAfHx8g98X29fXVOI0QQgghhBBCKykpKYSEhNhrhJuRQswB8qYj+vr6SiEmhBBCCCGEuO2SJWnWIYQQQgghhBClTAoxIYQQQgghhChlUogJIYQQQgghRCmTNWJCCCGEEEKUIaqqkpOTg9Vq1TqKKIBer8dgMJR42yopxIQQQgghhCgjzGYz8fHxZGRkaB1F3IKnpyfVqlXDZDIV+xxSiAkhhBBCCFEG2Gw2YmJi0Ov1VK9eHZPJVOJRF+FYqqpiNpu5cOECMTEx1KtX75abNt+KFGJCCCGEEEKUAWazGZvNRkhICJ6enlrHETfh4eGB0Wjk9OnTmM1m3N3di3UeadYhhBBCCCFEGVLcERZRehzxHsm7LIQQQgghhBClTAoxIYQQQgghhChlUogJIYQQQgghRCmTQkwIIYQQQogKavTo0SiKgqIoGI1GqlatSq9evZg5cyY2m61I55o9ezb+/v4lyhMbG2vPc7Pb7NmzS3SN8kK6JgohhBBCCFGB9e3bl1mzZmG1WklMTGTVqlU8++yzLFq0iF9//RWDofRKgpCQEOLj4+1fT58+nVWrVrFu3Tr7fX5+fqWWR0syIiaEEEIIIUQF5ubmRnBwMDVq1KBVq1a8/PLL/PLLL6xcuTLf6NP7779Ps2bN8PLyIiQkhCeffJK0tDQANmzYwJgxY0hOTraPXE2ZMgWA77//njZt2uDj40NwcDAPPPAASUlJBWbR6/UEBwfbb97e3hgMBoKDg8nKyqJ69eocPHgw32M+/PBDQkNDsdlsbNiwAUVRWL58Oc2bN8fd3Z0OHTpw4MCBfI/ZtGkTXbp0wcPDg5CQEJ555hnS09Md96I6gBRiQgghhBBCuJg77riDFi1asGTJEvt9Op2Ojz/+mIMHDzJnzhx+//13XnzxRQAiIyP58MMP8fX1JT4+nvj4eF544QUALBYLb7zxBnv37mXp0qXExsYyevToImcKCwujZ8+ezJo1K9/9s2bNYvTo0flaxk+cOJH33nuPHTt2EBgYyMCBA7FYLACcPHmSvn37MnToUPbt28eCBQvYtGkTEyZMKHImZ5JCTAghhBBCCBfUsGFDYmNj7V8/99xz9OjRg7CwMO644w7+7//+j59++gkAk8mEn58fiqLkG80CGDt2LP369aN27dp06NCBjz/+mJUrV9pH04pi/PjxzJs3j+zsbAB2797N/v37GTNmTL7jXnvtNXr16kWzZs2YM2cOiYmJ/PzzzwBMnTqVBx98kOeee4569eoRGRnJxx9/zHfffUdWVlZxXiqnkEJMCCGEcIDEtCyOXEzROoYQQhSaqqooimL/et26ddx5553UqFEDHx8fHn74YS5dukRGRsYtz7Nr1y4GDhxIrVq18PHxoVu3bgDExcUVOdPgwYPR6/X2omr27Nn24vB6HTt2tP93QEAADRo04PDhwwDs3buX2bNn4+3tbb/16dMHm81GTExMkTM5ixRiQgghRAmpqkrvHzfQ/MtVHEi6qnUcIYQolMOHDxMeHg7kdjMcMGAAzZs3Z/HixezatYvPPvsMALPZfNNzpKen06dPH3x9ffnxxx/ZsWOHvYi61eNuxmQyMXLkSGbNmoXZbGbu3LmMHTu2SOdIS0vjscceIzo62n7bu3cvx48fp06dOkXO5CzSNVEIIYQooaOXUtmXeBWAb/ac4sM+rbQNJIQQt/H777+zf/9+/vWvfwG5o1o2m4333nvPvhYrb1piHpPJhNVqzXffkSNHuHTpEtOmTSMkJASAnTt3lijb+PHjadq0KZ9//jk5OTkMGTLkhmO2bdtGrVq1ALhy5QrHjh2jUaNGALRq1YpDhw5Rt27dEuVwNhkRE0IIIUpoxfHz9v/+YV8s2TnWWxwthBClKzs7m4SEBM6dO8fu3bt56623uPvuuxkwYAAjR44EoG7dulgsFj755BNOnTrF999/z5dffpnvPGFhYaSlpbF+/XouXrxIRkYGtWrVwmQy2R/366+/8sYbb5Qob6NGjejQoQOTJk1ixIgReHh43HDM//73P9avX8+BAwcYPXo0VapUYfDgwQBMmjSJLVu2MGHCBKKjozl+/Di//PKLNOsQQgghKpqVJ/7eE+dSppnfjp2/xdFCCFG6Vq1aRbVq1QgLC6Nv37788ccffPzxx/zyyy/o9XoAWrRowfvvv8/bb79N06ZN+fHHH5k6dWq+80RGRvL4449z3333ERgYyDvvvENgYCCzZ89m4cKFNG7cmGnTpjF9+vQSZx43bhxms/mm0xKnTZvGs88+S+vWrUlISOC3337DZDIB0Lx5c/7880+OHTtGly5daNmyJa+++irVq1cvcS5HUlRVVbUOUd6lpKTg5+dHcnIyvr6+WscRQghRitLMFiq/+zNmq42hjWqy+PBZ+tetxvIHumkdTQhRzmRlZRETE0N4eDju7u5ax9HUG2+8wcKFC9m3b1+++zds2ECPHj24cuUK/v7+2oTj1u9VYWsDGRETQgghSuD3mCTMVhu1K3kx9Y4WAKw6mcC5lFt3GRNCCHGjtLQ0Dhw4wKeffsrTTz+tdRynkkJMCCGEKIG8aYn96lanXmUfutQKxKaqfLcvVttgQghRDk2YMIHWrVvTvXv3IndLLG+kEBNCCCGKSVVVVpzIXQ/Wv241AMZG5LaCnhl9Cpn9L4QQRTN79myys7NZsGCBff3a9bp3746qqppOS3QUKcQqGFVVsdpsWscQQgiXcPhiCnHJGbjpdXQPCwJgWOMQvE0GTlxOY1PcBY0TCiGEKKukEKtAkrPMPLBkK5PX77v9wUIIIUpsxfHcaYk9wqriaczdmtPbZOS+Jrl728yMjtEsmxBCiLJNCrEKZFPcReYfjOPdrUdYczL+9g8QQghRIiuvTUvsd21aYp6xEbUB+OlQHKnZllLPJYQQouyTQqwCuat+dZ5ok7uD+MilUSSlZ2mcSAghKq7UbAsb4y4CNxZiHWtWpkFlHzIsVhYeOqNFPCGEEGWcFGIVzHu9ImgS6EdiehajlkZhk4XiQgjhFOtjErHYbNQN8KZeZZ9831MUhTHXRsVmRp/SIp4QQogyTgqxCsbDaGD+0I64G/SsOhnPR1HHtI4khBAV0t9t66sV+P2RzcPQKwqbz1zk6MWU0owmhBCiHJBCrAJqGuTP+70jAJi0bi+74y9rG0gIISqY/G3rqxd4TDUfD3uRNkuadgghRJkRGxuLoihER0drmkMKsQrq8dZ1GdygBhabjRFLtpJmlsXiQgjhKAcvJHM2JRN3g55uoYE3PW5sy9zpiXP2xZAjW4sIISqw0aNHoygKiqJgNBoJDw/nxRdfJCvr754FsbGxjBs3jvDwcDw8PKhTpw6vvfYaZrO5wHNu2LDBfs6b3TZs2FDkrCEhIcTHx9O0adPiPl2HMGh6deE0iqLwzcB27Di/imOXUnlm1W5mDmqvdSwhhKgQ8trW3xEWhIfx5r9K76pXjUBPNxLSslh1Ip4B9WuUVkQhhCh1ffv2ZdasWVgsFnbt2sWoUaNQFIW3334bgCNHjmCz2fjqq6+oW7cuBw4c4JFHHiE9PZ3p06ffcL7IyEji4//uBP7ss8+SkpLCrFmz7PcFBATY/9tsNmMymW6bU6/XExwcXJKn6hAyIlaBVfZ048d7OqKQOy1m/oHTWkcSQogK4Xbrw/KY9HoeahYGyPREIUTxqKpKujlHk5taxKZvbm5uBAcHExISwuDBg+nZsydr1661fz+vUOvduze1a9dm0KBBvPDCCyxZsqTA85lMJoKDg+03Dw8P+zWCg4P58ssvadeuHd988w3h4eG4u7sDsGrVKjp37oy/vz+VK1dmwIABnDx50n7ef05NzBt5W79+PW3atMHT05PIyEiOHj1axHeraGRErILrFhbEK12a8MbGgzy2fCfta1QmvJK31rGEEKLcSsm2sOnMBQD61yt4fdj1xrYM54Ooo/x67BwX0rMI9HJ3dkQhRAWSYbHiPW2RJtdOe2kYXqbilQsHDhxgy5YthIaG3vK45OTkfKNaRXXixAkWL17MkiVL0Ov1AKSnp/P888/TvHlz0tLSePXVV7nnnnuIjo5Gp7v5ONR//vMf3nvvPQIDA3n88ccZO3YsmzdvLna225FCzAW82q0J62MS2XL2Ig8s2cpfo+/EqJfBUCGEKI51pxLIsanUr+xD7UJ8sNU0yJ+21QPYcf4yP+w/zb86NCiFlEIIUfqWLVuGt7c3OTk5ZGdno9Pp+PTTT296/IkTJ/jkk08KnJZYWGazme+++47AwL/X6w4dOjTfMTNnziQwMJBDhw7dcl3Ym2++Sbdu3QB46aWXuOuuu8jKyrKPtDmaFGIuwKDT8eOQDkR8tZpt5y7x+p8H+L87mmsdSwghyqXCTku83tiI2uw4f5lv95ziufb1URTFWfGEEBWMp1FP2kvDNLt2UfTo0YMvvviC9PR0PvjgAwwGww1FUZ5z587Rt29fhg8fziOPPFLsjKGhofmKMIDjx4/z6quvEhUVxcWLF7Fda5YUFxd3y0KsefO//z6uVi33Z3xSUhK1atUqdr5bkWERFxHm783XA9oC8NamQ/wRk6hxIiGEKH9UVbUXYv2LUIjd37QW7gY9By8ks/O8bCkihCg8RVHwMhk0uRX1QyMvLy/q1q1LixYtmDlzJlFRUXz77bc3HHf+/Hl69OhBZGQkX3/9dYleHy8vrxvuGzhwIJcvX2bGjBlERUURFRUFcNPujHmMRqP9v/Oeu82JHW+lEHMh9zapxbiWtVGBh5Zu42JGttaRhBCiXNmflMy51Ew8jXq6hgYV+nH+7iaGNqoJwExp2iGEcAE6nY6XX36ZV155hczMTPv9586do3v37rRu3ZpZs2bdcs1WcVy6dImjR4/yyiuvcOedd9KoUSOuXLni0Gs4ihRiLuajPq1oUNmH86mZjPt1e5G74QghhCtbcTx3E+c7wqribijalJ2xEbl7is07cJpMS47DswkhRFkzfPhw9Ho9n332GfB3EVarVi2mT5/OhQsXSEhIICEhwWHXrFSpEpUrV+brr7/mxIkT/P777zz//PMOO78jSSHmYrxMBuYPjcSk1/HrsXN8vvOE1pGEEKLcKM76sDzdw4II8/ciOdvCz0fOOjqaEEKUOQaDgQkTJvDOO++Qnp7O2rVrOXHiBOvXr6dmzZpUq1bNfnMUnU7H/Pnz2bVrF02bNuVf//oX7777rsPO70iKKkMiJZaSkoKfnx/Jycn4+vpqHadQPoo6ynOr9+Cm17FjfG+aVfXXOpIQQpRpV7PMVHn3Z6yqyqmnBxRrK5DX/zzAlD8PcGd4VdY93MMJKYUQ5VlWVhYxMTH59sQSZdOt3qvC1gYyIuainmlXn7vqVSfbauP+JVvIkGkyQghxS+tOJWJVVRpW8S32foyjW4SjAOtjEom9mubYgEIIIcoVKcRclKIozBrUjmBvdw5dSOH5NXu0jiSEEGXaihO568P61Sn+FJpQfy/uDK8KwGxp2iGEEC5NCjEXFujlzveDO6AAX+06yZLDZ7SOJIQQZZKqqqzKa1tfr2RrGca2zG3aMWtvDDZZHSCEEC5LCjEX17N2MBMjGwIw/rcdnElO1ziREEKUPXsTrxKfloWX0UCXWoG3f8AtDG5QA393I3HJGfwuezoKIYTLkkJM8EaPZrStHsCVLDMP/rwNqxM3rhNCiPIor239neFVcSti2/p/8jAaGNE0FIBZMj1RCCFclhRiApNez7whHfExGdgYd4E3Nx7SOpIQQpQpJWlbX5C8PcUWHz7DlUyzQ84phBCifJFCTABQJ8CHz/u3AeD1vw6yKe6CxomEEKJsuJJpZsvZS4DjCrHW1SrRLMiPbKuN+QdPO+ScQgghyhcpxITdQ83DeLh5GDZV5cGft8qntEIIAaw9lYBNVWkc6Euov5dDzqkoin1UbKZMTxRCCJckhZjI57N+rakb4E1ccgaPLNuO7PcthHB1eW3r+9et7tDzPtgsFKNOx87zl9mXeNWh5xZCCFH2SSEm8vFxMzL3no4YdAqLD5/lmz2ntI4khBCasakqq04kAI6blpgn0MudQQ1yi7tZ0fKzVgghXI0UYuIGbWtU5q07mgPw7KrdHL6QrHEiIYTQRnTCFRLTs/A2Gehcq4rDzz+mRe70xB/2n8ZstTr8/EIIUVpGjx6NoigoioLRaCQ8PJwXX3yRrKws+zGxsbGMGzeO8PBwPDw8qFOnDq+99hpmc8HLYTZs2GA/581uGzZsKFbevHNfvXq1WI93BINmVxZl2r87NmTtqQTWnkrk/iVbiRrXC/cStmwWQojyZsXx3G6JPcOrYtI7/mdgn7rBVPN2Jz4ti2XHzjOkUYjDryGEEKWlb9++zJo1C4vFwq5duxg1ahSKovD2228DcOTIEWw2G1999RV169blwIEDPPLII6SnpzN9+vQbzhcZGUl8fLz962effZaUlBRmzZplvy8gIMD5T8xJyt2I2GeffUZYWBju7u60b9+e7du33/L4hQsX0rBhQ9zd3WnWrBkrVqy46bGPP/44iqLw4YcfOjh1+aNTFObc3YFATzf2JV5l0rq9WkcSQohS5+i29f9k0OkY1SIckKYdQoiCqaqKmp2tza2IvQLc3NwIDg4mJCSEwYMH07NnT9auXWv/fl6h1rt3b2rXrs2gQYN44YUXWLJkSYHnM5lMBAcH228eHh72awQHB1OpUiVefvllatSogZeXF+3bt883Qnb69GkGDhxIpUqV8PLyokmTJqxYsYLY2Fh69OgBQKVKlVAUhdGjRxf5vSmpcjUitmDBAp5//nm+/PJL2rdvz4cffkifPn04evQoQUFBNxy/ZcsWRowYwdSpUxkwYABz585l8ODB7N69m6ZNm+Y79ueff2bbtm1Ur+7YxdjlWTUfD2bf3Z675v3Fx9uP0TO8KgMb1NA6lhBClIrLmdlsO+fYtvUFGRMRzrTNh1l5Ip7zqZlU9/Fw2rWEEOWQ2UzK5Gc1ubTv1I/Aza1Yjz1w4ABbtmwhNDT0lsclJycXe1RrwoQJHDp0iPnz51O9enV+/vln+vbty/79+6lXrx5PPfUUZrOZv/76Cy8vLw4dOoS3tzchISEsXryYoUOHcvToUXx9ffHwKP2fveVqROz999/nkUceYcyYMTRu3Jgvv/wST09PZs6cWeDxH330EX379mXixIk0atSIN954g1atWvHpp5/mO+7cuXM8/fTT/PjjjxiNxtJ4KuVG/3rVea59fQDG/BrF+dRMjRMJIUTpWHMyt2190yA/Qvwc07a+IPUr+9I5pAo2VeW7vTIqJoQov5YtW4a3t7d9JlpSUhITJ0686fEnTpzgk08+4bHHHivyteLi4pg1axYLFy6kS5cu1KlThxdeeIHOnTvbpy7GxcXRqVMnmjVrRu3atRkwYABdu3ZFr9fbi7+goCCCg4Px8/Mr3pMugXIzImY2m9m1axeTJ0+236fT6ejZsydbt24t8DFbt27l+eefz3dfnz59WLp0qf1rm83Gww8/zMSJE2nSpEmhsmRnZ5OdnW3/OiUlpQjPpPyZdmcLNpxOIjrhKg//vJU1D3VHrytXNbwQQhTZimvTEvs7cTQsz9iWtdl05iIzo2OY1KkRiqI4/ZpCiHLCZModmdLo2kXRo0cPvvjiC9LT0/nggw8wGAwMHTq0wGPPnTtH3759GT58OI888kiRo+3fvx+r1Ur9+vXz3Z+dnU3lypUBeOaZZ3jiiSdYs2YNPXv2ZOjQoTRv3rzI13KWcvPX9MWLF7FarVStWjXf/VWrViUhIaHAxyQkJNz2+LfffhuDwcAzzzxT6CxTp07Fz8/PfgsJqdiLq90MeuYPicTTqOf32CTe3XJE60hCCOFUuW3rnbs+7HrDG4fgZTRw/HIqm89cdPr1hBDlh6IoKG5u2tyK+KGQl5cXdevWpUWLFsycOZOoqCi+/fbbG447f/48PXr0IDIykq+//rpYr0taWhp6vZ5du3YRHR1tvx0+fJiPPsotXMePH8+pU6d4+OGH2b9/P23atOGTTz4p1vWcodwUYs6wa9cuPvroI2bPnl2kf2iTJ08mOTnZfjtz5owTU5YNDar48knf1gC88sd+os5e0jiREEI4z67zl7mQkY2PyUCnkECnX8/bZOTeJrkf6smeYkKIikCn0/Hyyy/zyiuvkJn599KWc+fO0b17d1q3bs2sWbPQFXOWVcuWLbFarSQlJVG3bt18t+DgYPtxISEhPP744yxZsoR///vfzJgxA8htBAJg1XDrkHJTiFWpUgW9Xk9iYmK++xMTE/O92NcLDg6+5fEbN24kKSmJWrVqYTAYMBgMnD59mn//+9+EhYXdNIubmxu+vr75bq5gTEQ49zWphVVVGbFkC8lZBe/5IIQQ5V1et8RetYMx6kvnV+XYiNw9xRYcPEOa2VIq1xRCCGcaPnw4er2ezz77DPi7CKtVqxbTp0/nwoULJCQk3HR2263Ur1+fBx98kJEjR7JkyRJiYmLYvn07U6dOZfny5QA899xzrF69mpiYGHbv3s0ff/xBo0aNAAgNDUVRFJYtW8aFCxdIS0tz3BMvpHJTiJlMJlq3bs369evt99lsNtavX0/Hjh0LfEzHjh3zHQ+wdu1a+/EPP/ww+/btyzecWb16dSZOnMjq1aud92TKKUVR+PKuNoT5exFzNZ0nVuwscltTIYQoD5zdtr4gnUKqUC/Ah3RLDgsPVfyZFkKIis9gMDBhwgTeeecd0tPTWbt2LSdOnGD9+vXUrFmTatWq2W/FMWvWLEaOHMm///1vGjRowODBg9mxYwe1atUCcke7nnrqKRo1akTfvn2pX78+n3/+OQA1atTg9ddf56WXXqJq1apMmDDBYc+7sBS1HP0lvWDBAkaNGsVXX31Fu3bt+PDDD/npp584cuQIVatWZeTIkdSoUYOpU6cCue3ru3XrxrRp07jrrruYP38+b731VoHt6/OEhYXx3HPP8dxzzxU6V0pKCn5+fiQnJ7vE6NjWMxfpMns9VlVl9t3t7XvgCCFERXAxI5ug6T+jAmefG0QNX89Su/a0TYeY/Ps+OodUYeOYnqV2XSFE2ZCVlUVMTAzh4eG4u7trHUfcwq3eq8LWBuVmRAzgvvvuY/r06bz66qtEREQQHR3NqlWr7A054uLi8u2+HRkZydy5c/n6669p0aIFixYtYunSpTctwkThdAypwuvdc1/Dp1bs4tilit01UgjhWtacjEcFmlf1L9UiDGBki3B0isKmMxflZ6sQQlRw5WpErKxytRExAKvNRs/vN7DhdBKtq1Viy9iemPR6rWMJIUSJPfTzVn7cf5qXOjVi6p0tSv36A+b9xfLj5zW7vhBCOzIiVn643IiYKDv0Oh3f39OBAA8Tu+Kv8J/f92sdSQghSsxqs7H6ZO6i8dJcH3a9MRG5072/2xdLjs2mSQYhhBDOJ4WYKLaavp7MHNQOgOlbj7D6RPxtHiGEEGXbzvNXuJiRjZ+bkY41q2iSYWD96lTxdON8aiZrTha9k5gQQojyQQoxUSJ3N6jJk23qAjDyl20kpmVpnEgIIYpv5YnzQOm2rf8nk17PQ81CAZgpe4oJ4ZJk5VDZ54j3SAoxUWLTe0XQNMiPpPRsRv8ShU1+eAghyikt2tYXJG9PsV+PnudCunzAJYSrMBqNAGRkZGicRNxO3nuU954Vh8FRYYTr8jAamD8kkjbfrGHVyXg+3HaU5zs21DqWEEIUyYX0LHacvwxAX40LsWZV/WlTPYCd5y/z4/7TPNehgaZ5hBClQ6/X4+/vT1JSEgCenp4oiqJxKnE9VVXJyMggKSkJf39/9CVoVieFmHCIJkF+fNC7JU+s2MlL6/fRLTSI1tUDtI4lhBCFtvpkAioQEexPdR8PreMwNiKcnecvMzP6FM+2ry9/jAnhIoKDgwHsxZgom/z9/e3vVXFJISYc5rHWdVhzKoGfj5xlxJKt7H60N96m4g/XCiFEaVpxbX1Y/7rVNU6S6/4mofxr9R72JyWzO/6KfLglhItQFIVq1aoRFBSExWLROo4ogNFoLNFIWB4pxITDKIrCNwPbsuP8JY5fTuXplbuZdXd7rWMJIcRtlYW29f9UycPEkEY1mXcgjpnRp6QQE8LF6PV6h/yxL8ouadYhHCrAw40fBndEpyjM3hvDvAOntY4khBC3tf3cZS5nmvF3N9KhZmWt49jlNe2Ye+A0mZYcjdMIIYRwJCnEhMN1CwvilS6NAXh8+U5OXUnTOJEQQtxaXrfE3rWDMejKzq/GO8KrUsvPk6tZFpYePad1HCGEEA5Udn7biArlv12b0CmkCinZFh5YshWL1aZ1JCGEuKm89WFlZVpiHp2iMKZFOAAz98ieYkIIUZFIISacwqDT8eM9HfFzMxJ17hJT/jygdSQhhChQYloWu+KvANq3rS/I6IjcQmx9TCKxV2WGgRBCVBRSiAmnCfX3YsbAtgBM3XSI32MSNU4khBA3Wn0yd1piq2qVCPbWvm39P4X5e3NHWBAqMGdvrNZxhBBCOIgUYsKphjeuxfiWtVGBh37eysWMbK0jCSFEPiuurQ/rXwZHw/KMbZnbtGP23hhsqqpxGiGEEI4ghZhwug/7tKJhFV/i07IY+2sUqvwRIYQoI3JsNtbY29aXjf3DCjKkYU383IzEXk1nQ6xs8iqEEBWBFGLC6bxMBuYP6YhJr+O3Y+f5bMdxrSMJIQQAUWcvcSXLTICHifY1yu4+XR5GAyOahgIwM1qadgghREUghZgoFS2CK/FuzwgAXlgbzb7Eq5rmEUIIyN+2Xl+G2tYXZOy1ph2LD5/lapZZ4zSlx5Z8lax1K0l98xVSXvk3tksXtI4khBAOUbZ/64gK5el29birXnWyrTbuX7yFDNmcVAihMfv6sHpld31YnjbVA2ga5EdWjpX5B+K0juNUqtWK5cBe0r/9nNT/TSZ7xS/YLl1EzUgne/NfWscTQgiHkEJMlBpFUZg1qB3VvN05fDGFf63eo3UkIYQLi0/NZE9Cbtv6PnXKfiGmXL+nWAWdnmi7dIGsFUtJfeNlMmZ+Qc7BfaCq6MPrYupyBwCWndtQc+SDPCFE+WfQOoBwLYFe7nw/uAO9ftjA17tP0rtOMEMbhWgdSwjhglZda1vfpnoAQV7uGqcpnIeahzFp/V52nL/MgaSrNA3y1zpSiak5Fiz7ozFv24z1+BH7/Yq3D8Y2HTC174S+anDuKNneXagpyeQc3IexRSsNUwshRMnJiJgodXfWDmZSp0YAjP9tO3HJ6RonEkK4opXloG39PwV5uTOwfg0AZkXHaJymZKwJ58lc+hOpU14i8/tvc4swRcHQoDGeox7B59WpeAwair5qMACKXo+pbUcAzFGbtYwuhBAOISNiQhP/696M32MS2X7+Mg8u2cofo+7AUMYXygshKo78bevLTyEGuU07fj5ylu/3xTL1zuaY9HqtIxWamp2FJXoX5qjNWGP/nl6p+FfC1C4SU7uO6AKq3PTxxnaRZK9fRc7RQ9iuXEZXqex2uhRCiNuRQkxowqjXMXdIR1p+vZpNZy7y5sZDvNatqdaxhBAuYuuZiyRnW6jsYaJt9fL1x3zfutUI9nYnIS2L5cfjuadhTa0j3ZKqqljPnMa8bROWPTsgOzv3GzodhibNMbXvhKFhE5RCfBinDwxCX7cB1hNHMW/fgnufAU5OL4QQziNDEEIzdQJ8+PKuNgD876+DbDwtm5QKIUpH3rTEPnWqlfm29f9k0OkY1fxa0449Zbdph5qRTvbGP0ib/n+kfzgNy7ZNkJ2Nrkog7nfdg8+rU/Ea8zjGxs0KVYTlMbXvBIB5+xZUm81Z8YUQwulkRExo6oFmYaw+mcB3+2J58Odt7H2sL5U8TFrHEkJUcOWpbX1BxkSE8/aWw6w4Ec/51Eyq+3hoHQm4Nvp18nju6Ne+3ZDX3dBgwNi8FaYOndHXqYeiKMW+hrFZBJkenqhXLpNz/AjGBo0dlF4IIUqXFGJCc5/2a82Wsxc5cTmNR5ZtZ+GwTiX6JS2EELdyLiWDvYlXUSgfbesL0qCKL5E1q7Dl7EW+3xdrb4CkFVtqCpbtWzFv34ztwt+zG3TVamDq0BlT63Yonl4OuZZiMmFq3Q7zpg1Ytm2SQkwIUW5JISY05+NmZN6QSCJnrmPx4bPM2H2SR1vX1TqWEKKCymtb37Z6AFU83TROU3xjW4az5exFZkWf4sXIhqX+AZZqs5Fz5CDmqM25+33lTRN0c8PUsh3GDp3Qh4Q6JZepfefcQuzAXmxpqei8fRx+DSGEcDYpxESZ0KZ6AG/d0ZyJ66J5bvUeOtcKpHGgn9axhBAVkL1tfb3qGicpmXsb1+KZVbs5eimVrWcvERly826DjmS7fAnz9i25a7SuXrHfrw+rjal9J4wRrVHcnLsvm75GTfQhoVjPnMayMwq37j2dej0hhHAGKcREmfF8xwasPZXAmlMJ3L94C9vH98bdUH7aMgshyj6L1cbaU4lA+Wtb/08+bkbubVyL2XtjmBl9yqmFmJqTQ87BvZi3bSbn2GFQVQAUTy+MbdrnbrpcrYbTrl8QY/tOud0YozZh6nanTGkXQpQ75atVlKjQdIrCnMHtCfJyY39SMhPXRmsdSQhRwWw5c5GUbAuBnm60KWdt6wsyNiK3e+KCg3GkmS0OP781MYHMXxeT+r/JZMyZQc7RQ6Cq6Os1xOPhcfi8Ng2PwfeWehEGYGrVFkwmbIkJ+fYkE0KI8kJGxESZEuztwexB7ek/7y8+3XGc3rWDGdig9H/BCyEqpr/b1gejqwAjKJ1rBVI3wJsTl9NYdOgMoyNql/icqtmMZe9uzNs2YY05Yb9f8fXD1K4jpvad0FUOLPF1Skpx98DYojWWHVsxR23GEF5H60hCCFEkMiImypx+9arzfIcGAIz5NYpzKRkaJxJCVBQrTpwHyv/6sDyKojCmxbU9xaJjSnQu69k4MhfNJWXKi2TOm51bhCkKhibN8Rz3JD7/fQv3/oPLRBGWJ29PMUv0TtSsTI3TCCFE0ciImCiT3rqjOX/EJrEn4QoPL93G2oe6l7tNV4UQZcvZlAz2JyWjUxR61w7WOo7DjGwRzn83HGBj3AWOX0qlXuXCdxBUMzMx796OOWoztrNx9vuVgCqYOnTC1KYDOv9KzojtEPrwOuiCqmJLSsSyZyemjl20jiSEEIUmf9mKMsnNoGf+0I54GQ38EZvEO1uOaB1JCFHO5U1LbF8jgMrluG39P9X09aRPndzCcvbe24+KqapKzqkTZMybTcqUF8laPC+3CNMbMLZsg9fjz+Hz8v9w79mvTBdhkDsimDcqZo7arHEaIYQoGhkRE2VW/cq+fNKvFWN/3c5//9hPj7AgOtQsnfbMQoiKJ68QK+/dEgsyNqI2K0/EM3tvDP/r3rTAGQS2tFQsO7dh3rYZW1KC/X5d1WqYOnTG2Lo9Om/v0oztEMY2HchavhRrXCzW82fRV6+pdSQhhCgUKcREmTa6RThrTiYw/2AcI5ZsJfrRPvi5m7SOJYQoZ8xWK2tP5RYf/epWjPVh1xtYvzqVPUycT81kzckE+l1bA6fabOQcP4Jl2yYsB/aC1Zr7AJMJY0QbTB06ow8NL9et33U+vhiatiBn3x7MUZvxuOc+rSMJIUShSCEmyjRFUfjyrjZsO3eJ2KvpPL58J3OHdCzXfzQIIUrf5riLpJlzCPJyo1W1sj3drjjcDHoeah7GR1HHmBkdQ59Aj9xNl6M2o165bD9OHxKaO/rVsg2Ku4eGiR3L1L4zOfv2YNkZhfuAIShGo9aRhBDitqQQE2Wen7uJeUM60nnWeuYfjKNPnWCHtGgWQriOvGmJfetUqxBt6wsypmktTmzczH0795Oy7QeUa5su4+GJqXU7TO07o69RMaftGRo0QvGvhHr1CpYD0ZhattU6khBC3JYUYqJc6FCzCv/r3pT//LGfCSt3ExlShfqVfbWOJYQoJ1ZcK8QqStv661kvJGKJ2kL4jq38mJFiv19fpz6mDp0wNmuJYqrYU7oVnQ5Tu0iy1yzHvG2zFGJCiHJBCjFRbkzq1Ih1MYn8EZvE/Yu3snVsT9wMeq1jCSHKuLjkdA5eyG1b36t2Va3jOIRqsWDZtxvzts1YTx6z35/p7smXamV2VG/AsieHutQ0blO7jmSvXYH1+BFsly6Uqf3OhBCiINK+XpQbep2O7wd3oLKHiT0JV3j5931aRxJClAN50xI71qxMgEf5bltvPX+WzCULSJ0yicwfZ+UWYYqCoVFTPEc/hunl/2Oadz1WXMlhT8IVreOWKl1AFQz1GwFgjtqicRohhLg9GRET5UoNX09mDmrP3Qs28v62o/SqHUzfCtiKWgjhOOW9bb2alYVlzw7MUZuxxsXa71cqBWBq1wlTu47oKgUAEADc07Am8w/GMTM6hlbVArQJrRFT+07kHD2EefsW3PoMQNHLrAkhRNklhZgodwY1qMGEtvX4dMdxRv2yjb2P9SXYu+J0/xJCOE52jpV1pxIB6F+O2tarqor1dAzmqM1Y9uwEc3buN/R6DE1bYGrfCUP9RigF7Bc2NqI28w/G8eP+WKb3isDdhaZwG5o2R/HyRk1JJufIQYxNmmsdSQghbkoKMVEuvdsrgj9PJ7E/KZlRS6NY+WC3CtsJTQhRfJviLpBuySHY252IYH+t49yWLT0Ny66o3E2XE87b79cFVf1702WfWzcquiM8iBBfT86kZLD0yFnubxrq7NhlhmIwYmzTAfOf6zBHbZZCTAhRpskaMVEuuRv0zB8aiYdBz5pTCXyw7ajWkYQQZdD1bevLauMK1WYj59gRMr7/htQpL5G1dGFuEWY0YmzbAa8JL+A9aQpu3XvdtgiD3PW0o1uEAzAz+pSz45c5pvaRAOQc2o8tJVnjNEIIcXMyIibKrcaBfnzQpyWPL9/J5PX76B4aROvqrrUeQghxa3+3rS9768NsyVcx79iKJWoztksX7ffraoRg6tAZU6u2KB6exTr36Ihw3th4kHWnEolLTqeWn5ejYpd5+uDq6MNqY409hWXHNtzu7KN1JCGEKJAUYqJce7RVHdacTGDJkbPcv2QLux/pg4+bUetYQogyIPZqGocvpqBXFHrVDtY6DgCq1UrOkYOYt20i5/ABsNlyv+HujqlVO0wdOqOvWavE16ldyZseYUH8EZvEnL0x/Ldr0xKfszwxte9EZuwpzFGbMN3Ru8yOhgohXJsUYqJcUxSFGQPbsuP8ZU5cTuPpVbuYfXcHrWMJIcqAvGmJkSFV8HfXdkNj26ULmKO2YN6+BfW66XL68Lq5my43b4Xi5tjW+mMjavNHbBKzomP4T5cmLrWO1hjRmsylP2G7eAHryeMY6tbXOpIQQtxACjFR7gV4uPHjPR3o/t0fzNkbS+/awTzQLEzrWEIIjWndtl7NsWDZvxdL1CZyjh2x3694eWNs2wFT+07oqzov25BGNXlqpZGYq+n8GZtEj/CKsZl1YShu7hhbtsWybRPmqM1SiAkhyiRp1iEqhC6hQfy3S2MAHl++k1NX0jROJITQUlaOlfUxeW3rS7cQsyacJ3PpT6S+/hKZ33+TW4QpCoYGjfEc9Qg+r03DY9AwpxZhAJ5GA/c3yZ3m6JpNOzoBYNm7GzUzQ+M0QghxIxkRExXGK12bsD4mkU1nLjJi8RY2jemJUS+fNQjhijaevkCGxUp1Hw+aV/UvlWvmnDxO1vKfscb+XfQo/pUwtYvM3XQ5oEqp5Lje2IjafL37JIsOn+XTfmb8NJ6iWZr0tcLQVauBLf4c5t3bcevUXetIQgiRj/yVKioMg07Hj0M64u9uZPv5y7y6Yb/WkYQQGllxIncPrr51gkulUYOanU36t5/nFmE6HYamLfAc/xQ+r7yJe9+BmhRhAO1qBNA40JesHCsLDsZpkkEriqLYW9mbt23WOI0QQtxICjFRodTy82LGgHYAvL35MOtPJWicSAihhZX2tvXVS+V6lj07ICsTXeVAfF6ditfYJzA2boai0/bXrKIojI2oDcDM6BhNs2jB2Lo96A3Yzp3Beta1ClEhRNknhZiocIY1DuGRVrVRgYeXbuNCepbWkYQQpejUlTSOXkrFoFPoWQoNKlRVJXvznwCYOnVF5+vn9GsWxUPNwjDoFKLOXeJgkmttcKzz8sbYPAIA87ZN2oYRQoh/kEJMVEgf9mlFoyq+xKdlMebX7aiqqnUkIUQpyRsN6xRSpVTWRFnjYrGdOwMGI8a2HZ1+vaKq6u3OgGsjg7NcsmlHZwDMu7ejms0apxFCiL+Vu0Lss88+IywsDHd3d9q3b8/27dtvefzChQtp2LAh7u7uNGvWjBUrVuT7/pQpU2jYsCFeXl5UqlSJnj17EhUV5cynIEqBp9HAvCEdcdPrWH78PJ/uOK51JCFEKfm7bX3pTEs0XxsNM7Zsjc7Lu1SuWVR50xO/2xeLxWrTOE3p0tetjxJQBbKysOzdrXUcIYSwK1eF2IIFC3j++ed57bXX2L17Ny1atKBPnz4kJSUVePyWLVsYMWIE48aNY8+ePQwePJjBgwdz4MAB+zH169fn008/Zf/+/WzatImwsDB69+7NhQsXSutpCSdpEVyJd3tFAPDC2mj2JlzRNpAQwumycqz8Xopt623paViidwJgiuzm9OsVV7961ajq5c6FjGyWHz+vdZxSpeh0fzftiJLpiUKIsqNcFWLvv/8+jzzyCGPGjKFx48Z8+eWXeHp6MnPmzAKP/+ijj+jbty8TJ06kUaNGvPHGG7Rq1YpPP/3UfswDDzxAz549qV27Nk2aNOH9998nJSWFffv2ldbTEk40oW09BtSrjtlq4/4lW0k352gdSQjhRH/GJpGZY6WGjwdNg5y/VsuyYyvk5KCrWQt9rTCnX6+4DDodI5uHAS66p1jbjqAoWE+dwJqUqHUcIYQAylEhZjab2bVrFz179rTfp9Pp6NmzJ1u3bi3wMVu3bs13PECfPn1uerzZbObrr7/Gz8+PFi1a3DRLdnY2KSkp+W6ibFIUhVl3t6eatztHLqbwrzUyLUWIimyFvVtiNae3rVdtNsyb/wLALbJrqbTJL4kxEeEArDgeT0JapsZpSpfOvxKGRk0BMEdJK3shRNlQbgqxixcvYrVaqVo1fwesqlWrkpBQcIvyhISEQh2/bNkyvL29cXd354MPPmDt2rVUqXLzPV+mTp2Kn5+f/RYSElLMZyVKQxVPN364pyMKMGP3KRYdOqN1JCGEk5Tm+rCc40ewXboA7h4YW7Z1+vVKqlGgHx1rVsaqqny/L1brOKXO1L4TkDuKqVqtGqcRQohyVIg5U48ePYiOjmbLli307duXe++996brzgAmT55McnKy/XbmjPxhX9bdEV6Vlzo1AuCRZds5fTVd40RCCEc7cTmV45dz29bfWQpt6/OadJjadkBxc3P69Rzh+j3FXK2brKFxMxQfX9S0VHIOyvIDIYT2yk0hVqVKFfR6PYmJ+ed2JyYmEhwcXOBjgoODC3W8l5cXdevWpUOHDnz77bcYDAa+/fbbm2Zxc3PD19c3302Ufa93b0b7GpW5mmXhwZ+3kmNzrc5hQlR0eaNhXWoF4utmdOq1bFcu2/+YN0V2deq1HOneJrXwNOo5cjGFbWcvaR2nVCl6fe5aMWR6ohCibCg3hZjJZKJ169asX7/efp/NZmP9+vV07Fjwvi0dO3bMdzzA2rVrb3r89efNzs4ueWhRphj1OuYO6YiPycDmMxd546+DWkcSQjjQ39MSnd8t0bxtE6gq+roN0Fd1/vUcxdfNyLBGudPpXbFph/Fa98ScIwexXZVOukIIbZWbQgzg+eefZ8aMGcyZM4fDhw/zxBNPkJ6ezpgxYwAYOXIkkydPth//7LPPsmrVKt577z2OHDnClClT2LlzJxMmTAAgPT2dl19+mW3btnH69Gl27drF2LFjOXfuHMOHD9fkOQrnql3Jm68G5K7l+L+Nh/jr9M2noAohyo9MSw5/xOb+/9zfyevDVKs1txAjt0lHeZM3PXH+wTiX6ySrD6yKvk49UFXMOwpu3CWEEKWlXBVi9913H9OnT+fVV18lIiKC6OhoVq1aZW/IERcXR3x8vP34yMhI5s6dy9dff02LFi1YtGgRS5cupWnT3M5Jer2eI0eOMHToUOrXr8/AgQO5dOkSGzdupEmTJpo8R+F8I5qGMqpFGDZV5cGft3I5U0Y/hSjvNsQmkZVjJcTXk8aBzp0unrM/GjU1BcXHF0OzCKdeyxm6hgZSp5I3aeYcFh92vTXOpvadgdzpiapMURdCaEhRXW21rhOkpKTg5+dHcnKyrBcrJ1KzLbSesYbjl1MZ0rAmi4Z3KvOtp4UQN/f0yl18uuM4j7Wuw5d3ObeDYdrnH2A9cRS3Xv1x7zfIqddyljc3HuSVP/bTLTSQDaPu1DpOqVLNZlKmTIKsTLwefxZD/UZaRxJCVDCFrQ3K1YiYEI7i42Zk3pCOGHU6lhw5y9e7T2odSQhRTKqqsuLEecD568OsifFYTxwFRcHUobNTr+VMo1qEowB/nr7AicupWscpVYrJhKl1OwDM26RphxBCO1KICZfVunoAU+9sDsBzq/dwMClZ40RCiOI4fjmVU1fSMep03BHm3Lb15i25GzgbmjRHVynAqddyppq+nvSpk1u0zo6O0ThN6bPvKbY/GltamsZphBCuSgox4dL+1aEBfeoEk5VjZcSSLWRaXGvhuhAVQV63xK6hgfg4sW29mp2Necc2AEydujntOqVlTEQ4ALP3xmB1sbVS+pq10NWsBdYcLLuitI4jhHBRUogJl6ZTFObc3YEgLzf2JyUzcd1erSMJIYqotNrWW/bsgKxMdJUDMdRr6NRrlYa7G9QgwMPEudRM1p5KvP0DKpi8UTFz1GaX29xaCFE2SCEmXF5Vb3e+u7sDAJ/tOM4vR89qnEgIUVgZlhw22NvWO68QU1WV7GvTEk2duqLoyv+vTzeDngebhQIwywX3FDO1agtGI7aE81jjYrWOI4RwQYaiPiAmJoaNGzdy+vRpMjIyCAwMpGXLlnTs2BF3d3dnZBTC6frUrca/OzTgvW1HGfvrdvY9FkANX0+tYwkhbuOPmCSyrTZC/TxpWMV5XWutcbHYzsaBwYCxbUenXae0jY2ozSfbj7P06DkuZWRT2dNN60ilRvHwxNiiFZadUZi3bcIQGq51JCGEiyn0R3o//vgj7dq1o06dOkyaNImlS5eyceNGvvnmG/r27UvVqlV58sknOX36tDPzCuE0b93ZnFbVKnE508xDP29zuTUTQpRHed0S+9er7tQtKMxb/gTAGNEGnZe3065T2iKCK9EyuBJmq425B1zv93fenmKWPTtRs7I0TiOEcDWFKsRatmzJxx9/zOjRozl9+jTx8fHs2rWLTZs2cejQIVJSUvjll1+w2Wy0adOGhQsXOju3EA5n0uuZN6QjXkYDG04nMW3zYa0jCSFuIbdt/bX1YXWcNy3Rlp6GZc8uoGI06finsdeadsx0wemJ+tp10QUGgTkbS/QureMIIVxMoQqxadOmERUVxZNPPklISMgN33dzc6N79+58+eWXHDlyhNq1azs8qBCloX5lXz7r3xqA1zYcYOuZixonEkLczNFLqcReTcek13FHuPPa1lt2bIUcC7oaIehrhTntOlp5oFkoJr2O6ISr7Im/onWcUqUoynVNOzZpnEYI4WoKVYj16dOn0CesXLkyrVu3LnYgUTLmXVHYrrrWL1JHG9k8jBFNa2FVVR74eSvJWWatIwkhCpDXLbFbaCBepiIveS4U1Waz7x3mFtnVqdMftRLg4cbgBjUA1xwVM7bpADod1tMxWBPOax1HCOFCCr1G7KeffsJs/vsP0rNnz2K7bg1NRkYG77zzjmPTiSKxno0jc94cUt9+nezNG1BljVOxKIrCF/3bEO7vRezVdB5bvlNaGwtRBq04nvtHc7+61Z12jZzjR7BdvADu7hhbtXPadbQ2NiJ3JsuP+0+TlWPVOE3p0vn6YWjSHMhtZS+EEKWl0IXYiBEjuHr1qv3rxo0bExsba/86NTWVyZMnOzKbKCqjEX1IKGRnkbV4PumfTscaf07rVOWSn7uJeUMiMegUFhyMY/beGK0jCSGuk2a28FfcBcC5bevNm3ObdJjadERxq7gdBXvWrkpNXw+uZJn59ajr/d7Im55o2bkNNceicRohhKsodCH2zxEBGSEoe/RVq+H19ETch9wPbu5YY0+R9t6bZK34BdUiv1iKqn3NyvyvezMAJqzcxdGLKRonEkLk+SMmCbPVRri/F/Ur+zjlGrarV8g5uA/I3TusItPrdIxu4bpNOwwNm6D4+aOmp2M5sFfrOEIIF1H+d6QU+Sg6HW6du+Mz6TUMTVuAzUb2upWkTX+DnONHtY5X7rwY2ZA7woLIsFgZsWQr2S42ZUeIsiqvW6Iz29abt20CVUVfpz76qs4bdSsr8gqxNScTOJOcrnGa0qXodJjaRQJg2SbTE4UQpUMKsQpK518Jr7FP4Dn6MRRfP2wXkkj/4gMy5n+HLT1N63jlhl6n4/t7OlLZw8SehCtMXr9P60hCuDxVVVl5bf8wZ7WtV63W3EKMij8alqdOgA/dQ4NQgTl7Y7WOU+ryCrGcY4exXZKOuUII5ytSm6nVq1fj5+cHgM1mY/369Rw4cAAg3/oxUXYYm7fEUK8hWSuWYt7yF5btW8g5tB/3wfdibNmmQnYAc7TqPh7MGtSeQQs28kHUUXrWrkr/es5rDiCEuLXDF1M4nZyBm15Hj/Agp1wj50A0akoyio8vxqYRTrlGWTQmIpwNp5OYtfcUL3dpjM6FfkfoKlfBUL8hOceOYN6+Bfd+g7SOJISo4BS1kIu9dLrCDZ7ZXLBTX0pKCn5+fiQnJ+Pr66t1nJvKiTlJ5sIfsV1rz2to2ASPYSPQBVTROFn58MyqXXyy/TgmvY5xLWszKbIRof5eWscSwuW8t/UIL6yNpk+dYFY92N0p10j7/AOsJ47i1qu/S/1Bnm7Oodr7S0k15/DHyB50D3Pe/mxlkXnPTjK//wbFvxI+r7yJUsi/fYQQ4nqFrQ0K/RPGZrMV6ibKLkN4Hbyffxm3foNAbyDnyEFS3/kf2RvWolpl7dPtvNMzgr51qmG22vhi5wnqfrqM8b9t5+TlVK2jCeFS/m5b75xpidbEBKwnjoKiYOrQ2SnXKKu8TAbub1oLgFnRrtct1tisBYqnF+rVK+QcPaR1HCFEBeewj3psNhvLli1z1OmEkygGA+69+uM98RX0deqB2UzWr4tJ++htrGdOax2vTHM36Fn5YDc2jLyDO8OrkmNT+XbPKRp8toKRS7dxRLoqCuF0qdkWNsblrt/p76T9w/I2cDY0aY6uUoBTrlGW5e0ptvDQGVKyXavjrmIwYmzTHgCzNO0QQjhZiQuxEydO8PLLL1OzZk3uueceR2QSpUAfFIzXk8/jcd/DKB6e2M7GkfbhNDJ/WYSana11vDKtW1gQ6x7uwZYxPelXtxpWVeX7fbE0/nwF9y/ewoGkq1pHFKLC+j02EYvNRp1K3tRzQtt6NTsb846tAJgiXaNJxz+1r1GZRlV8ycyxsuBgnNZxSl3enmI5B/diS5UP2IQQzlOsQiwzM5PvvvuOrl270qBBA7Zs2cKrr77K2bNnHZ1POJGiKJjad8L7pSkYW7YFVcX85zpS33kdy+EDWscr8zqGVGHFA93YMb43dzeogQosOBhHsy9XMeSnTeyJv6J1RCEqnBXH89rWO2daomXPTsjKRFc5EEP9Rk65RlmnKIp9VGzmHtfbU0xfrQb6WuFgs2HZsU3rOEKICqxIhdiOHTt47LHHCA4O5sMPP+Tuu+9GURQ+//xzHn/8capWda1FvRWFzscXz4fH4fnIBJRKAahXLpMx41Myvv9WPg0shDbVA1h6XxeiH+3D8MYhKMDPR87SasZqBsz7i6izl7SOKESFkNu2PrcQc0bbelVVyd7yJwCmyC4u3ajhoeah6BWFbecucehCstZxSp2pQ+6omDlqM4XsaSaEEEVW6N8yzZs3Z/jw4VSuXJktW7awe/du/v3vf0v78wrE2KgpPi++iqlbT1AULHt2kDZtivwiKqQWwZX4aVgnDjzRjweahqJTFJYfP0+HmWvp/cMfbDydpHVEIcq1gxeSOZOSgbtBT/cwx7ett8bFYjsbBwYDxmt7SrmqYG8P7rq2TYdLNu2IaAMmN2wXErHGnNA6jhCigip0IXb06FG6du1Kjx49aNy4sTMzCQ0pbu543D0M7+deQlcjBDUzg8wF35P++QdYkxK1jlcuNA7048chHTnyZH9GtwhHryisPZVI1zm/02PO7/wekyiFrRDFkDca1iMsCA9jkbbBLJS8Jh3GiDbovLwdfv7yZmzLcAC+2xeDxepaXZEVd3eMLdsAuaNiQgjhDIUuxE6dOkWDBg144oknqFmzJi+88AJ79uyREbEKSh8SivdzL+E+cAgYjVhPHiNt+htkrV2BmpOjdbxyoV5lH2bd3Z7jE+7i0VZ1MOp0bDidxJ3f/0HnWetZdSJeCjIhisC+PswJbett6em568Nw3SYd/9S/bnWCvNxISs+2F8GuJK9phyV6F2pmpsZphBAVUaELsRo1avCf//yHEydO8P3335OQkECnTp3Iyclh9uzZHDt2zJk5hQYUvR63Hr3xefE1DA0aQ04O2St/Je39t8iJdb0F3MUVXsmbrwa05eTTdzGhbT3c9Dq2nL1Iv7l/0u7btfx69JwUZELcRkq2hU1nLgDO2T/MsmMr5FjQ1QhBHxru8POXR0a9jpHNc1+LmdGu9zNfHxqOLrg6WCyY9+zQOo4QogIq1krkO+64gx9++IH4+Hg+/fRTfv/9dxo2bEjz5s0dnU+UAbrKVfB89Gk8HhyL4u2DLeE86Z+8S+biefIpYRGE+HnxSb/WxDwzkOc7NMDTqGfn+cvcvWAjEV+vZuGhOGxSkAlRoHWnEsixqdQL8KFOgGPb1qs2G+atudMS3SK7ykyP64yJyC3Elh07T0Kaa/28z+0snLtW0LJtk8ZphBAVUYlaQvn5+fHkk0+yc+dOdu/eTffu3R0US5Q1iqJgat0O70mv5S5iV1XMm/8k9e0pWPZHax2vXKnm48F7vVsS+8xAXurUCG+TgX2JV7l30RaafbmSuftjsdpcaz2GELeTNzXOGW3rc44fwXYhCdzdMbZq5/Dzl2eNA/1oX6MyVlXlh32ntY5T6oytO4Bej/VsHNazrrenmhDCuRzWmzciIoKPP/7YUacTZZTOyxvP+0fi9cRz6KoEoqYkkzHrS9JnfYntquybVRSBXu5MvbMFp58dyKtdm+DnZuTQhRQe/HkbjT5fyezoUy63QF6Igji7bX1ekw5Tmw4obm4OP395Nzbi7+mJrjaNWuftjbFZBCBNO4QQjqeohfypescdd9z+ZIrC+vXrSxyqvElJScHPz4/k5GR8fX21jlNqVLOZ7HUryP59Ddhs4OaO+4DBmDp2den9d4orOcvMpzuO8/62o1zONAMQ5u/F5E6NGNUiHDeDXuOEQmhjX+JVWny1Cg+DnssvDsHdgf8v2K5eIfX//gM2G94vvoo+uLrDzl1RJGeZqfb+L2TmWNk6ticdalbROlKpshw9RMZXH4O7B75T3kYxmbSOJIQo4wpbGxS6/++GDRsIDQ3lrrvuwmg0OiSkKN8Ukwn3/oMxRrQl86cfsMbFkLV4PpZd2/EY/iD6ajW0jliu+Lmb+E+XJjzbvj5f7DzB9K1HiL2azmPLd/LGxoNMimzE+FZ1HPpHqBDlQd5o2B3hVR3+79+8bRPYbOjr1JMi7Cb83E0MaxzC9/timRUd43KFmKFeQ5RKAahXLmPZvwdT6/ZaRxJCVBCFHhF79913mTVrFpcuXeLBBx9k7NixNG3a1Nn5ygVXHRG7nmqzYd7yF1nLl0J2Fuh0uN3RB7de/VGkcC+WDEsOM3af5J0tRzifmrtIPtjbnYkdG/JY67p4mRy/j5IQZVG32ev5K+4Cn/VrzZNt6znsvKrVSuobL6OmJOMxcjymiDYOO3dFsyE2kR7f/YGPyUDCvwfj6YR93MqyrDXLyV71G/o69fF+6nmt4wghyrjC1gaFnj82ceJEDh06xNKlS0lNTaVTp060a9eOL7/8kpSUFIeEFuWXotPh1rk7PpNew9C0BdhsZK9bSdr0N8g5cVTreOWSp9HAs+0bcPLpAXzevzUhvp4kpGXx77XRhH/8G9M2HSI126J1TCGcKjnLzOYzFwHHt63PORCNmpKM4uOLsWmEQ89d0XQNDaJ2JS9SzTksPnxG6zilztS2IygK1pPHsF5I1DqOEKKCKPJCno4dOzJjxgzi4+N56qmnmDlzJtWrV5diTACg86+E19gn8Bz9GIqvH7YLSaR//gEZ87/Dlp6udbxyyd2g54k29Tjx9F3MGNCW2pW8uJCRzeTf9xH60W/8788DXM0yax1TCKdYeyoRq6rSsIov4ZW8HXru7LwmHe07oRhca4SnqHSKwugW15p27InROE3p01UKyN1PE7BEbdE4jRCioih2R4Xdu3fz559/cvjwYZo2bSrrxkQ+xuYt8Zk0BVNkVwAs27eQ9vYUzLt3uFzXLUcx6fWMb1WHo0/dxZy729Ogsg9Xssy89ucBQj/6jf/+sY9LGdlaxxTCoVaeOA84vluiNTEB6/GjoCiYOnZx6LkrqlEtwlGADaeTOHk5Ves4pc7UoTMA5h1bUa1WjdMIISqCIhVi58+f56233qJ+/foMGzaMgIAAoqKi2LZtGx4eHs7KKMopxcMDj2EP4PX0C+iqVkNNSyXzh2/JmPEptssXtY5Xbhl0Oka2COfgE/2YPzSSpkF+pGRb+L+Nhwj7+DcmrYsmKT1L65hClFi+tvUOnpaY17Le0LgZukoBDj13RVXLz4tetYMBmL3X9UbFDI2boXj7oKamkHN4v9ZxhBAVQKELsf79+1OnTh2ioqJ49913OXv2LNOnT6dx48bOzCcqAEN4Xbz//R/c+g0CvYGcIwdJfed/ZG9YK58qloBep+O+JrXY+1hfFg/vRMvgSqSZc3hnyxHCPvqNf63ebW/yIUR5tDfxKvFpWXga9XQNDXTYeVWzGfPObQCYIrs57LyuYGzL2gDM2et6G88rBgPGth0AMG+TPcWEECVX6K6JOp2OatWqERQUhKIoNz1u9+7dDgtXXkjXxMKzJiWQufBHrCePA6CrWQvPex9CX7OWxsnKP1VVWX78PG/8dZDt5y8DYNLrGN+yNpM6NaKWn5fGCYUomqmbDvHy7/sYWL86v97f1WHnNUdtJnPB9+gqV8F78v9k38MiyMqxUv39X7iSZWb1g93o7YQNtssya1ICadOmgKLg89+30PlX0jqSEKIMcvg+Yq+99ppDggnXpg8KxuvJ57Fs30LWr4uxnY0j7YOpmLrdiXufgShublpHLLcURWFA/RrcVa86a08l8MZfB9l05iKf7zzBjN2nGNUijMmdG1PbwQ0PhHCWFcdz14f1r+vY/b3Mm/8EkM3ni8HdoOfBZqF8uuM4M6NjXK4Q0wcFo69dF+upE5h3bsO9Zz+tIwkhyrFCj4iJm5MRseKxpaaQtfQnLHt2AqBUCsBj2IMYGzXROFnFoKoqf55O4o2/DvJ7bBIAekXhwWahvNy5MQ2qyL9VUXZdyTQTOP1nrKpK7DMDCfV3zIhuTlws6R9OA4MBn1enofOWDyaKanf8ZVrPWINJryP++bsJ8HCtD9DMO7aSOW+OjKgKIW7K4fuICeFoOh9fPB8ej+f4p1AqBaBeuUzGjE/I+P5bbKmyHUJJKYpC97CqrB95B5vH9KRvnWpYVZXv9sXS6PMVjFi8hQNJV7WOKUSB1p5KwKqqNA70dVgRBn836TBGtJYirJhaBleiRVV/zFYbc/ef1jpOqTM2bwXu7tguXcR68pjWcYQQ5VihCrG+ffuybdu22x6XmprK22+/zWeffVbiYMJ1GBs3w+fFVzF1uxMUBcueHaRNm4I5arO0uneQyJAqrHywG9vH9WJQ/RqowPyDcTT7chVDf9rEnvgrWkcUIh97t0QHTn2zpadj2b0DkCYdJaEoCmMjcpt2zIx2ve6JipsbplbtAGnaIYQomUIVYsOHD2fo0KE0btyYSZMmsXDhQjZv3syuXbtYt24dH3/8Mffeey/VqlVj9+7dDBw40Nm5RQWjuLnjcfdwvJ97CV2NENTMDDIXfE/65x9gTUrUOl6F0bZGZX65vwt7Hu3DsEYhKMCSI2dpNWM1A+f9xfZzl7SOKAQ2J7Wtt+zcCjkWdDVC0IeGO+y8rujBZqGY9Dr2JFwhOsH1Psgxte8EgGX/Hmzp6RqnEUKUV4VeI5adnc3ChQtZsGABmzZtIjk5OfcEikLjxo3p06cP48aNo1GjRk4NXBbJGjHHUq1WzH+tJ2vVb2CxgMGAW6/+uPXojWIodH8ZUQiHLiTz5sZDzD8Yh+3aj4LetYP5b9cmdK7luHbhQhRF3hokb5OBiy/cg5tBX+JzqjYbaW9PwXYhCY/hD8omzg5w76LNLDx0hmfa1eejvq20jlOqVFUl7f23sJ07g/s99+HWpYfWkYQQZUhha4NiN+tITk4mMzOTypUrYzQaix20IpBCzDlsly6SuWguOUcPAaALro7HvQ9hCKutcbKK59ilFKZuOsz3+2KxXvuR0D00iFe7NqF72K23rBDC0d7ceJBX/tjP3Q1qsPQ+xxRMOccOk/7lR+Dmju+UaShu7g45rytbdSKefnP/JMDDxPl/3e2Qgrk8yd60gawl89FVq4H3C6/Iz0khhJ3Tm3X4+fkRHBzs8kWYcB5d5Sp4Pvo0Hg+ORfH2wZZwnvRP3iVz8TzUTNmo2JHqV/Zl1t3tOT7hLh5tVQejTseG00nc8f0fdJm9ntUn4mW9nig1K47nTkvs78Bpidmbc5t0mNp2kCLMQXrVrkoNHw8uZ5r59dg5reOUOlOrtmAwYos/h/WM6zUtEUKUnHRNFGWaoiiYWrfDe9JrGNt2BFXFvPlPUt+egmV/tNbxKpzwSt58NaAtJ5++i6fa1sNNr2PzmYv0nfsn7b9dy29Hz0lBJpzqcmY2266tVXTU+jDb1SvkHNwLgCnScRtDuzq9TseoFrlr7WbuccGmHZ5eGJu3BMAiTTuEEMUghZgoF3Re3niOGIXXE8+hqxKImpJMxqwvSZ/1JbarrrdQ3NlC/Lz4tF9rYp4ZyL/aN8DDoGfH+csMWrCRll+vZtGhM/Y1ZUI40pqTCdhUlaZBfoT4OaZtvXnbJrDZ0Neuhz7YsZtDu7oxEbmF2OqT8ZxJdr2mFaYOuU07zHu2o2ZnaZxGCFHeSCEmyhVDvYZ4v/Bf3Hr2BZ2OnP3RpL79OtmbN6DabFrHq3Cq+Xjwfp+WxD47kEmRjfA2GdibeJXhizbT/MtVzDtwGqu87sKBHN22XrVacwsxwNRJWtY7Wt0AH7rWCkQFvtsXq3WcUqevUx9dlUDIzsayd7fWcYQQ5UyRCjGr1cpff/3F1atXnRRHiNtTTCbc+w/G+/n/oK8VDtlZZC2eT/qn07EmnNc6XoUU5OXOtJ4tiH1mIP/t0gQ/NyMHLyTzwJKtNP5iJXP2xmCxSkEmSub6tvX96zmmEMs5sBc1JRnFxxdjswiHnFPkN7ZlbgOlWdExLjd1WVEUjNda2ecV/EIIUVhFKsT0ej29e/fmyhWZCia0p69eA69nJuI+5H5wc8cae4q0994ka+WvqBaL1vEqpMqebvyvRzNinx3IG92bEeBh4tilVEb/EkWDz5YzY/dJzFar1jFFObU7/goXMrLxMRnoFOKY7ROyt1xr0tG+k2x/4STDGoXgbTJw8koaG+MuaB2n1JnadgSdDmvsKayJ8VrHEUKUI0Wemti0aVNOnTrljCxCFJmi0+HWuTs+k17D0KQ5WK1kr11B2vQ3yDlxVOt4FZa/u4lXujYh9pmBvH1nC4K83Ii5ms6jy3ZQ95PlfLbjOFk5UpCJollxPHdEu2ftYIz6ks+ctyYlYD1+BBRF9g1zIi+Tgfub1AJgZrTr/X2g8/XD0LgZAOYoadohhCi8Iv+m+7//+z9eeOEFli1bRnx8PCkpKfluQmhB518Jz7FP4Dn6MRRfP2wXkkj//AMy5n+HLd31FpCXFh83Iy92akTMMwP5oHdLqnm7cyYlgwkrd1H749/4YNtRMiw5WscU5YR9WqKDuiWar42GGRo3Q1cpwCHnFAUbE5E7PXHhoTOkZLvejATTtemJlh3bUHPkZ54QonCKvKGzTvd37Xb95oWqqqIoClYXnJYkGzqXLWpmJlnLf7b/EaZ4++A++F6MLdvIhptOlpVjZeaeU0zbfJgzKRkABHq68e+ODXmyTV183GTfQVGwixnZBE3/GRU489wgavp6luh8qtlMyusvQWYGno88jbFRE8cEFQVSVZVGn6/g6KVUZgxoy/hWdbSOVKpUq5XUN15GTUnGc9QjGFu01jqSEEJDha0Nijxh/o8//ihRMCGcTfHwwGPYAxhbtyPzpx+xJcaT+cO3WHZuw2PYCHQBVbSOWGG5G/Q82bYe41vV5ru9sUzdfIhTV9J5af1e3tlymOfa1+fpdvXxdzdpHVWUMWtOxqMCzav6l7gIA7Ds2QGZGegqV8HQoFHJA4pbUhSFsRG1mbR+LzOjT7lcIabo9ZjadSR73SrM2zZLISaEKJQij4iJG8mIWNml5uSQ/ccastesAGsOmEy49x2EqUsPFL1e63gVXo7Nxtz9p3lz0yGOXUoFwM/NyDPt6vNch/oEeLhpnFCUFQ//vJUf9p9mUmQjpvVsUeLzpX0wFeuZ07gPuAe3O/o4IKG4nfjUTEI+/BWrqnL4yf40rOJavw+tFy+Q9tZ/QVHw+c//oQuorHUkIYRGClsbFGs19NWrV3nvvfcYP34848eP54MPPiA5ObnYYYvis88+IywsDHd3d9q3b8/27dtvefzChQtp2LAh7u7uNGvWjBUrVti/Z7FYmDRpEs2aNcPLy4vq1aszcuRIzp+XFugVhWIw4N6rP94TX0Ffux6YzWT9uoi0j97GejZO63gVnkGnY2SLcA490Y95QzrSJNCP5GwLb2w8SOhHv/HSur0kpcsmqK7OpqqsOpkAOKZtfU5cLNYzp8FgwNiuU4nPJwqnmo+H/f2b5YJNO/RVAtHXawCqinnHVq3jCCHKgSIXYjt37qROnTp88MEHXL58mcuXL/P+++9Tp04ddu927maGCxYs4Pnnn+e1115j9+7dtGjRgj59+pCUlFTg8Vu2bGHEiBGMGzeOPXv2MHjwYAYPHsyBAwcAyMjIYPfu3fz3v/9l9+7dLFmyhKNHjzJo0CCnPg9R+vRBwXg9+S887n0YPDyxnY0j7YOpZP66CDU7W+t4FZ5ep+P+pqHse7wvi4Z3IiLYnzRzDm9vOUzYR7/xr9W7OZ+aqXVMoZGd5y9zMSMbXzcjHWuWfOpw3vpQY4vW6Ly9S3w+UXhjrzXtmLM31iX3FjS17wyAefsWVNnsXghxG0WemtilSxfq1q3LjBkzMFzbkyUnJ4fx48dz6tQp/vrrL6cEBWjfvj1t27bl008/BcBmsxESEsLTTz/NSy+9dMPx9913H+np6Sxbtsx+X4cOHYiIiODLL78s8Bo7duygXbt2nD59mlq1ahUql0xNLF9sKclkLV2IJXonAEqlADyGPSiL+UuRqqosP36eN/46yPbzlwFw0+sY17I2kzs3dsgaIVF+TNmwn9f/OsjQRjVZNLxzic6lZqSTMuUlyLHg9cyLGMJqOyilKAyL1UaND37hQkY2v97XhYENamgdqVSpFgupUyahZmbg+ejTGBvK7xUhXJHTpibu3LmTSZMm2YswAIPBwIsvvsjOnTuLl7YQzGYzu3btomfPnvb7dDodPXv2ZOvWgqcAbN26Nd/xAH369Lnp8QDJyckoioK/v/9Nj8nOzpa2/eWYztcPz5Hj8Rz/FEqlANQrl8mY8QkZP3yLLVXey9KgKAoD6tdg27herH6wG51DqpBttfH5zhNEfLWKc9c6LgrX8Hfb+uolPpd5x1bIsaCrXhN9aHiJzyeKxqjX8XDzMMA19xRTjEaMrdsDsqeYEOL2ilyI+fr6Ehd349qaM2fO4OPj45BQBbl48SJWq5WqVavmu79q1aokJCQU+JiEhIQiHZ+VlcWkSZMYMWLELavXqVOn4ufnZ7+FhIQU8dmIssDYuBk+L76KqdudoChYdu8gbdqU3Ckl0sOmVCiKQu861fhr9J38MbIHTQL9uJRp5rHlO+U9cBEX0rPYcW1UtG8J9w9TVRXzlo0AmCK7ynYVGhkTkVsALzt+nsQ011sDauqQuy4x58Be+XBPCHFLRS7E7rvvPsaNG8eCBQs4c+YMZ86cYf78+YwfP54RI0Y4I2OpsFgs3HvvvaiqyhdffHHLYydPnkxycrL9dubMmVJKKRxNcXPH4+7heD33EroaIaiZGWTO/470Lz7EeiFR63guQ1EUuodV5adhkZj0OpYfP8/3+2K1jiVKweqTCahARLA/1X08SnQu6/Gj2C4kgps7ptbtHBNQFFnTIH/aVQ8gx6byw/5YreOUOn31muhDQsFqxbIrSus4QogyrMiF2PTp0xkyZAgjR44kLCyMsLAwRo8ezbBhw3j77bedkRGAKlWqoNfrSUzM/8dxYmIiwcHBBT4mODi4UMfnFWGnT59m7dq1t13n5ebmhq+vb76bKN8MIaF4P/cS7gOHgNGI9cRR0t59g6y1K1BzcrSO5zIaB/rxeremADwrDTxcQt60xH51St4tMXvznwCY2rRHcXMv8flE8Y1tmbs2b2b0KZcc3TZ1uNa0Y9tml3z+QojCKVIhZrVa2bZtG1OmTOHKlStER0cTHR3N5cuX+eCDD3Bzc96eQCaTidatW7N+/Xr7fTabjfXr19OxY8cCH9OxY8d8xwOsXbs23/F5Rdjx48dZt24dlSvLvh+uStHrcevRG58XX8PQoDHk5JC98lfS3n+LnFjXW+uglRciG9KmegBXsyw8vnyH/BFTgVltNladvLY+rF7J1ofZrl4h5+BeAEydupU4myiZ+5vUwt2g59CFFPvUU1dibNkGTCZsSQlY5feHEOImilSI6fV6evfuzdWrV/H09KRZs2Y0a9YMT8/S6XD2/PPPM2PGDObMmcPhw4d54oknSE9PZ8yYMQCMHDmSyZMn249/9tlnWbVqFe+99x5HjhxhypQp7Ny5kwkTJgC5RdiwYcPYuXMnP/74I1arlYSEBBISEjCbzaXynETZo6tcBc9Hn8bjwTEo3j7YEs6T/sm7ZC6eh5olIzTOZtDpmDWoHUadjt+OnWfugdNaRxJOsuP8ZS5nmvF3N9KhZsk+BDNHbQabDX3teuiDS970Q5SMn7uJoY1qAi7atMPdA2NEG0Cadgghbq7IUxObNm3KqVPa/FC97777mD59Oq+++ioRERFER0ezatUqe0OOuLg44uPj7cdHRkYyd+5cvv76a1q0aMGiRYtYunQpTZvmTn06d+4cv/76K2fPniUiIoJq1arZb1u2bNHkOYqyQVEUTK3b4z3pNYxtO+Zu0Ln5T1Lffh3LwX1ax6vwmgb581q33LbPT6/cTUKaFMAV0YrjuT+ve9cOxqAr8q8jO9Vqxbz1WpOOTl0dkk2UXN6eYvMOxJFhcb0p3qb2uU07LNE75UM8IUSBiryP2KpVq5g8eTJvvPEGrVu3xsvLK9/3XXG9lOwjVvHlHD9C5sIfsV28AIqC+z334da5u9axKjSL1UaHmWvZHX+FwQ1qsOTeztIFr4Jp+80adp6/zKxB7RgdUfz9viz79pAx+ysUbx98Xp2Kct32KkI7NlWlzifLiL2azveDO/DQtbb2rkJVVdLefh1bUgIewx/E1LGL1pGEEKXEafuI9e/fn7179zJo0CBq1qxJpUqVqFSpEv7+/lSqVKlEoYUoqwz1GuL9wn8xRXYFVSVryXyyVv0m65ecyKjXMWtQe4w6HUuPnmPBwRu3zRDlV2JaFjsd1Lbe3qSjQycpwsoQnaIwpkVuK3uXnJ6oKPZW9uZtmzROI4Qoi4r8G+uPP/5wRg4hyjzFZMJ96AgUH1+yVy8je81y1PQ03O+5D6UE06rEzTWv6s8rXRrz2p8HmLByFz3CqlLVW7rhVQSrrzXpaFWtEsHexW9bb01KxHr8CCgKpg4y4lDWjGoRzpQ/D/BHbBIxV9IIr+StdaRSZWzdnqzlS7GeOY31/Fn01WtqHUkIUYYU6a9Hi8XC//73P6pXr063bt0KvAlRkSmKgnufAbgPvR8UBfPmP8n8Yaa0uHeiyZ0bExHsz6VMMxNW7tI6jnAQR7WtN2/9CwBD42boAqTrbVkT6u9Fz9q567hn743ROE3p0/n4YmjaApCmHUKIGxWpEDMajezbJ40KhHDr1B2Ph8aBXo8leicZ336Omp2ldawKKW+KokGnsOjwGRYekimK5V2OzcbqkwlAydrWq2Yz5u1bAXKnDYsyKa9px6zoGKw2m8ZpSp+9acfOKFSLReM0QoiypMjzqR566CG+/fZbZ2QRolwxtWyD5/inwGQi5+gh0r/4CFt6mtaxKqSI4Eq83LkxAE+u2MWFdCl6y7Pt5y5zJctMJXcT7WsEFPs8luidkJmBElAld+8/USYNblgTf3cjZ1Iy+D0mSes4pc5QvxFKpQDUzAws+6O1jiOEKEOKXIjl5OTwxRdf0KZNGx577DGef/75fDchXImxQWO8nvgXiqcX1rgY0j+dju3qFa1jVUj/6dKYZkF+XMzI5ulVu7WOI0pgxfHzAPSpE4y+BOsrzdeadLhFdpF1mmWYu0HPA01DARdt2qHTYWoXCYA5Spp2COEMNlVl/akErWMUWZF/cx04cIBWrVrh4+PDsWPH2LNnj/0WHR3thIhClG2G0HC8Jvwbxb8StsQE0j55F2tS+fthUNaZ9Hpm390evaKw4GAciw+f0TqSKKaV1xp19CtBt8ScM6exnjkNegPGa3/kirIrb3riz0fOcjkzW+M0pc/ULhIUBevxo1gvXtA6jhAViqqqTFi5i54/bOC9rUe0jlMk0jVRCAfQB1fH++mJpH/1EbakRNI/mY7no09jCAnVOlqF0qpaAC91asSbmw7x5IqddAsNooqnm9axRBEkpGWyOz531LhPCRp15I2GGVu0Quft45BswnlaVatE86r+7Eu8yrwDcTzVtp7WkUqVrlIAhvqNyDl6CMv2zej7D9Y6khAVgqqqPLt6N1/sPIECVPUqX52VHTqXIynJ9eZ+C5FHVykArwkvoA8JRU1PI/3z98k5dljrWBXOf7s2oUmgH0np2TyzSrooljerrnVLbFM9oNhbEagZ6Vj27ADA1Em69ZYHiqIwNiJ3T7FZLjg9Efh7T7HtW1GtVo3TCFH+qarKC2uj+WT7cQC+HdSu3G0cX+hCzNPTkwsX/h5Ov+uuu4iPj7d/nZiYSLVqJWtDLER5p/P2weuJf6Gv1xCys0mf8RmWvVIsOJKbQc+sQe3QKQrzDsSx9MhZrSOJIljhgLb15h3bwGJBV60G+rDajoomnOzBZmEYdTp2xV9hb4LrraU1NGmB4uWNmpJMzpGDWscRolxTVZWXf9/H+9uOAvD1gLaMiSh/vw8KXYhlZWWhqqr967/++ovMzMx8x1z/fSFcleLujtcjT2Fo0QqsOWR89w3mrRu1jlWhtK1RmRcjGwLw+PKdLrnmpDzKsdlYeyqvbX3xCjFVVTFvyd07zNSpG4qiOCyfcK4qnm4MapC7XcEsF9xTTDEYMLbtAMieYkKU1GsbDjBtc+6so8/6teaRVnU0TlQ8Dp2aKL8QhcilGIx4PjweU8cuoKpkLvyRrLUr5MMKB3qtW1MaVfElMT2LZ6WLYrmw7ewlrmZZqOxhom314rWttx4/iu1CIri5Y2rdzsEJhbPlNe34YV8s2TmuNz0vb0+xnEP7saUka5xGiPLpjb8O8MbG3FHlj/q04slyvOZU+v0K4SSKTof7sAdw69UfgOyVv5K1dCGqC25o6gzuBj2zBrVHpyj8sP80vx09p3UkcRt/t62vVuy29dlbcpt0mNq0R3ErX4uyBfSuE0x1Hw8uZZr57dh5reOUOn3VarnTaW02zDu2ah1HiHJn2qZDvLrhAADTe0XwTPv6GicqmUL/JlQUJd+I1z+/FkLcSFEU3PsNwn3wcADMG38nc94cWajtIO1rVubfHRoA8NjyHVzJNGucSNxKSdvW25KvknNgLwCmyK4OyyVKj0GnY9S1xfSuuKcYgKlDZwAs2zbLLAkhiuC9rUeY/Ps+AN66ozn/7thQ40QlV+hCTFVV6tevT0BAAAEBAaSlpdGyZUv71w0blv8XQwhncet6Jx4PjAGdDsuuKDJmfoFqlqLBEV7v3pQGlX2IT8viX2tkimJZdT41k+iEqyjkbuRcHOZtm8BmQ1+7LvpqNRwbUJSavAX1q08mcC4lQ+M0pc/YohW4uWO7dAHryWNaxxGiXPgo6igvrI0G4PVuTZncubG2gRyk0PuIzZo1y5k5hKjwTG3ao3h6kjHna3IOHyD9yw/xGv8UiqeX1tHKNQ+jgZmD2tN51jrm7I3l3sa16F+vutaxxD/kta1vWz2AwGLs86JarbmFGGCKlJb15Vm9yj50qRXIxrgLfLcvtsL8QVVYips7ppZtMW/biHnbZgx1G2gdSYgy7fMdx3lu9R4AXunSmFe7NdU4keMUuhAbNWqUM3MI4RKMjZvh9fizpH/zOdbYU6R9+h5ejz2Dzs9f62jlWmRIFf7VoQHvbzvKo8t2cOCJfvi7m7SOJa6z4kTueqDiTkvMObgPNfkqircPxuYRDkwmtDAmIpyNcReYGX2Klzo1crmlDsYOnTBv24hl3x7UjHT5QE6Im/h61wmeWpm7DdCkyEb8r3szjRM5ljTrEKKUGcLr4v3Uv1F8/bAlnCftk3exXkjUOla590aPZtQL8OFcaib/XrNH6zjiOharjbWncv+NF3e00pzXpKN9JxSD0WHZhDaGNw7By2jgxOU0NsVduP0DKhh9SCi6ajUgx4J59w6t4whRJs2KPsVjy3cC8HyHBky9s3mF+9BGCjEhNKCvXgPvpyeiqxKIevkS6Z9Mx3o2TutY5Zqn0cDMQe1QgJnRMaw+EX/bx4jSsfXsRVKyLVTxdKNNMdrWW5MSyTl2BBQld0sIUe55m4zc1yQEyP3/1dUoimJv2mHetkmadgjxDz/si2Xcr9sBeKZdfab3iqhwRRhIISaEZnSVq+D19ER0NUJQ01JJ+/x9ck7Iwu2S6Fwr0N7Kdvyy7SRnSUOUsmDF8dyiuG+dYHTF+EVq3pq7gbOhUVN0AZUdmk1oJ29PsZ8OxZGabdE4TekztmoHBgO282exyQdxQtjNP3CaUb9EoQJPtKnLh31aVsgiDKQQE0JTOh9fvJ98Hn2depCVRfrXH2PZH611rHLtzR7NqVPJm7MpmUxcF611HEHJ2tarZjOW7bn7LUnL+oolMqQK9Sv7kGGxsvDQGa3jlDqdlxfGZi0BMEdt1jiNEGXDokNneOjnbdhUlfEta/Npv9YVtgiDEhRiZrOZo0ePkpOT48g8QrgcxcMDr0efwdC0BeTkkDH7K/mlXAJeJgPfDmwHwIzdp1h3KkHjRK7tbEoG+xLz2tYXvRCzRO9EzcxACaiCoWETxwcUmlEUxT4q5rp7inUCwLx7u2xpIlzeL0fPMmLJFqyqyugW4Xw1oG2xZlGUJ0UuxDIyMhg3bhyenp40adKEuLjc4fSnn36aadOmOTygEK5AMRrxHPUoxnaRoKpkLvie7N9Xax2r3OoWFsSEtvUAGPfbdpec9lRW5LWtb1+jMpU93Yr8ePPm3CYdbh27oOhkEkdF83DzMHSKwuYzFzl6MUXrOKVOX6c+uspVICsLy17ZB1G4rmXHzjF84RZybCoPNgvlm4EVvwiDYhRikydPZu/evWzYsAF397/3gunZsycLFixwaDghXImi1+Nx38OYevQGIGvZz2T+ulgWcRfT1DubE+7vRVxyBi+u26t1HJe14kTxpyVaz5zGeuY06A0Y20c6OpooA6r7eNj/bcxyxaYdOh3G9tdGxaI2aZxGCG2sOhHP0IWbsdhs3NekFrPvbo/eRT54K/KzXLp0KZ9++imdO3fON2ezSZMmnDx50qHhhHA1iqLgMXAI7gOHAGDesJbM+d+hWq0aJyt/vE1G+xTFL3ed4PcY2SKgtJmtVvvU0OK0rc/ektukw9iiFTpvH4dmE2XH2IhwAObsiyHHZtM4Tekzte0IioL11AmsSTKVWriWdacSGLxgI2arjaGNavL94A4YXKQIg2IUYhcuXCAoKOiG+9PT0yv0YjohSpNbj9543D8SdDosO7aSMfsrWT9QDD3Cq/JEm7pA7hTFNLNMUSxNm+MukmrOIcjLjVbVKhXpsWpGOpbdua2LTZ2kSUdFNqB+dap4upGQlmWfyupKdH7+GBrnblIr64OFK9kQm8ig+RvJttoYVL8Gc4d0xKh3nSIMilGItWnThuXLl9u/ziu+vvnmGzp27Oi4ZEK4OFO7SDxHPwYGAzkH95H+9SeomZlaxyp33r6zBaF+nsReTeel9fu0juNSVp7Ia1tfrchz/c07t4HFgq5aDfRhdZwRT5QRJr2eh5uFAa65pxiA6drUW8uObajSBE24gE1xFxgwbyOZOVb6163GT8MiMen1WscqdUUuxN566y1efvllnnjiCXJycvjoo4/o3bs3s2bN4s0333RGRiFclrFpC7weexbc3bGeOk7aZ+9hS0nWOla54uNm5JtrUxQ/23GcP2OTNE7kOorbtl5VVczXpiWaOnWT2RYuYGzL3OmJvx07x4X0LI3TlD5Do2YoPr6oaankHNqvdRwhnGrrmYv0m/sn6ZYcetcOZvG9nXEzuF4RBsUoxDp37kx0dDQ5OTk0a9aMNWvWEBQUxNatW2ndurUzMgrh0gx16uH91L9RfHyxnT9L+ifTsV26oHWscqVn7WAebZU7qjL2tyjSzfKJs7OdSU7nQFIyOkWhd53gIj3WeuIotqREcHPD1KqdkxKKsqRpkD9tqgeQY1P5Yf9preOUOkWvz10rBpi3SdMOUXFtP3eJvnP/JM2cw53hVVl6X2fcXbQIg2LuI1anTh1mzJjB9u3bOXToED/88APNmjVzdDYhxDX6GiF4PT0RJaAKtksXSPv4Xaznz2odq1x5t1cEIb6enLqSzsu/yxRFZ8ubltihRmUCPIrWtj6vSYepTQeU67rziootr2nHt3tOuWS32LzOoDlHD2G7clnjNEI43u74y/T5cQMp2Ra6hQby6/1d8DAatI6lqSIXYnq9nqSkG6f2XLp0Cb0Lzu0UorToqwTi/cxEdNVqoKamkPbpe+ScOqF1rHLD183IjAFtAfhk+zE2npYpis6U17a+f72iTUu0JV8lZ380AKZIadLhSkY0DcXdoOfghWR2nne9QkQfWBV9nfqgqph3bNU6jhAOtTfhCj2/38DVLAudQqqwbERXPF28CINiFGI3+5QqOzsbk8lU4kBCiJvT+frh/dTz6MPrQFYm6V9+hEXWExRan7rVGNeyNiow9rftZFhkiqIzZOdYWX9tu4Cirg8zb9sMNhv68Lroq9VwRjxRRvm7mxjSsCbgwk07OuTtKbYZ1QVb+YuK6UDSVXr+sIErWWY61KjMige64W0yah2rTCh0Kfrxxx8DuV0Sv/n/9u47rKmzfwP4fbLDBkWGoohawY2ogHtWq7ZabdVqXR12ONr6dr4ddtv+Ot9WrV3Wts46a917M5ShgooLxQUOZIfM8/sDTUtdBElOAvfnunIpJ+ckd44I+eZ5zvf56Sd4eHhY7zObzdi5cyfCw8OrPiERlSO4ucP9mRdQ8tuPMB0+hJI530E7YgxU7WKkjuYSvujTBhtOXsSJ3CK8tfUQvuwbKXWkamd31mUUGUwIcNegTWDF29aLZjMM8bsAlDXpoJrniTYNsSDtDBamncGX97epcdOWlC0jodMuhngtF6bjR6Fs2kzqSET35MjlfPT6fRuulOjRLtgP60d1g5eaRdgNFf4J99VXXwEoGxGbPXt2uWmIKpUKoaGhmD17dtUnJKKbCCoV3MY/C93i32DcnwDdgrkQi4ug7tZb6mhOz1ujwg8D2qP/wp34OiEDjzQLQceQ2lLHqlZuXB/2QGPb2tab0g9CzM+D4OEJZas2dkpHzqxHwwA08HbDmfwSrDh6DiOvt7WvKQSVCqq27WHYswPGhD0sxMilHbtagJ6/b8OlYj0iA32xcVR3eGs4e+6fKjw1MTMzE5mZmejWrRsOHDhg/TozMxMZGRnYsGEDoqOj7ZmViP5BkMuhHTEWqm69AAClfy5F6ZqVNfIid1s90CQY41o3hAhg/KoE6DhFsUpVtm29tWV9h44QFPzEtCaSCQLGtwkDUJOnJ3YGABgPpcJSVCRxGqLKOZlbiJ6/bUN2USlaBfhg0+Pd4atlEfZvNl8jtm3bNvj6VnyqCRHZjyCTQfPQI1D3HwwA0G9ZD92S+by2oAK+vD8SwZ5aHLtaiHe2p0kdp9o4k1eMw5cLIBcE9AmreNt68+UcmI4dAQQBqo5d7JiQnN3Y1qEAgC2ZOTidV/MKEXndEMjr1QfMZhiTEqSOQ2SzzGtF6PHbNpwv1KG5vzc2P94dtdxs655bU9g8+fqJJ5644/1z5sypdBgisp0gCND07geZuzt0SxfAGL8bYnEx3B5/AoKSowq346tV4fsB7fDgol34Mj4DQyPqIaYepyjeqxvTEmPr1bLp00/D3rJrwxQRLSDz479DTRbq44FeDQOwJTMHc1Mz8W73mrc8jjKmM8xLF8CQsAeqrj25qDm5jKz8YvT8fRvOFpQgvLYXtozuAX93LkNyOzaPiF27dq3c7dKlS9i6dSuWL1+OvLw8O0QkoopQxXaB29gJgFwB06EUFP80A2JpqdSxnNrA++pidKtQWEQR41clotRkljqSy1t74gIAoH+T4AofIxoMMCbuBcCW9VTmxppivxzIhKUGTrdWRbYHlEpYsi/AfKZmTtEk13OuoAQ9ftuK03nFaOLnia2jeyDAg0XYndg8IrZixYqbtlksFjz33HNo1KhRlYQiospRtoqE+4RJKJ7zHczHM1A860u4PT0JMk8vqaM5ra/7RmLTqWwcvVKAd7en4ZPeraWO5LIq27bemLofoq4Egl8tKMKb2yseuZCHw+vBW61EVn4JtmbmoLcN01yrA0GrhbJNFIz74mFI2ANFaJjUkYju6EKhDj1/24ZT14oR5uuOrWN6IMhTK3Usp2fziNgtH0Qmw9SpU62dFYlIOoom4XB/fioEdw+Yz2WheMYXsORelTqW0/LTqjF7QDsAwGdxR7HvPM9VZe08cxklRjOCPDRoHeBT4eOsTTpiu0CQVcmvJXJxWqUCI1s2AADMST0lcRppqKLL1hQzpuzn7AZyajlFpej1+zYczy1EA283bB3dE/W83KSO5RKq7DfeyZMnYTKx8xiRM1CENID75Fcg+PrBcjkHRd9+BnP2BaljOa1BTethZIsGsIgixq1KgJ5TFCvln23rK3pNi/nsGZizTgNyBVQdOtoxHbmaJ653T1x+5Byu6QwSp3E8ecPGkPkHAAY9jKn7pY5DdEuXi0vR8/etOHqlACFebtg2pica+LhLHctl2Dw1cerUqeW+FkURFy9exJo1azB27NgqC0ZE90ZeJwAek19B8fffwJJzEcXffg63pydxisttfNOvLTZnZuPw5QK8vzMdH/VsJXUkl3Pj+rAHGlf8+jD99dEwZetITqGlcqKCfNGijjfSLuVjUfoZPNeuidSRHEoQBKiiO6F09XIY4vdY29oTOYurJXr0nrcdhy8XINhTi61jeqChr4fUsVyKzSNiKSkp5W4HDx4EAHzxxRf4+uuvqzofEd0DmY8v3Ce9DHmDhhB1JSie/TWMR9KljuWUarmp8V3/simKn+45gqQLuRInci2Z14qQcbXwetv6gAodI+pKYExOBACoOnazZzxyQYIgWEfFauqaYsr2MYBMBnNWJswXz0sdh8jqms6APvO242BOHgI9NNg2pgca+3lKHcvl2Dwitm3bNnvkICI7kbm7w/3ZF1Ey93uYMg6j5OeZ0I4cD1Xb9lJHczpDIkIwvHl9LE7PwrhVCUh6+n6o5HKpY7mEG9MSO4XUhremYm3rDfviAKMRsqC6kDdksye62eMtG+DVzanYfyEXB3Py0MqGaw+rA5mnFxTNW8N0KAWGhD3QDh4mdSQi5Jca0Hf+dqRkX0MddzW2ju6B+2pxRkNl8KpoohpAUKvh9uTzUEa2BywW6ObPgX4XP1S5lW/7tYW/mxppl/Lx4c7DUsdxGWuvF2IVbVsviqJ17TBVx65cJ4luyd9dg4fuqwsA+KWmNu2Iud60Y38CRJNR4jRU0xXojeg3fwf2XchFbTc1tozugQh/b6ljuawKjYhFRkZW+JdkcnLyPQUiIvsQFApoR42H4O4Ow+7tKF2xGGJxEdR9B/JN8D/4u2sws38Uhi3di+l7DuPh8HqIDPKVOpZTKzWZsdXGtvXmE8dguZQNqNVQRUXbMx65uCfahGH50XOYd+gMPu3dusaNUiuaNoPg4wsx7xqMhw5AFdlO6khUQxUZjOi/YAfiz1+Fr0aFzY93R4s6PlLHcmkVKsQGDx5s5xhE5AiCTAbNw8MhuHtCv+Ev6DeugVhcVLaNbcOtHm1WH49EnMXSI2cxflUCEp/qU+Pe/Nlix+lL0JnMqOupRcs6FftkVL93BwBAFRUNQcMFP+n2+jYORJCHBheLSrH62AUMiQiROpJDCTIZVO1jod+0FsaE3SzESBLFBhMGLtyJPWevwFutxKbHu6N1ID+kvFcVKsSmTZtm7xxE5CCCIEDTdwAED3eULl8Mw54dEIuLoR05DoLC5stGq62Z/aOw7XQODuTkYfruI5jWrYXUkZzWupO2ta23FOTDdCgVAJt00N0pZDKMadUQn+49gjmpmTWuEAMAVXRH6Devg+nYUViuXoGsVm2pI1ENojOa8NCindhx5jK81EpsfLw7ooL9pI5VLVT6I/CkpCTMmzcP8+bNQ0pKSlVmIiIHUHfqDu3jTwJyOYyp+1Hy00yIei4aekMddw1mPBAFAPhwVzoOZF+TOJHzWnv870KsIgzxuwGLBfKGjSEPrmvPaFRNjG/TEEBZU5hP9xzBpeKa9bNK5lcbiibhAABD4l6J01BNUmoyY/Di3dh6+hI8VAqsH9kNHerWkjpWtWFzIXbp0iX07NkT7du3x5QpUzBlyhRERUWhV69euHz5sj0yEpGdqCLbwe2piYBKDdOxIyj+7mtYioukjuU0hjevj4fD68FkETF+VSKMZovUkZzOidxCHM8thEImoHdY4F33F81mGOL+btJBVBFNa3thYJNgWEQRr285gHpfrcLwpXuw5VQ2LKIodTyHUF5v2mFI3AvRwp9FZH96kxlD/9iNjaey4aaUY+1jXREbwtHYqmRzITZ58mQUFhYiPT0dubm5yM3NRVpaGgoKCjBlyhR7ZCQiO1I2bQb3516E4OYOc9ZpFM/4HJZrXEMLKJvGOat/FPy0KqRkX8One45IHcnp3Ghb3znEH15q5V33Nx0+BDE/D4KHJ5StI+0dj6qRPx7piJ8f7IAOwX4wWiz44/BZ9J63HU1nrsH/1YBRMmWL1hDc3SHm58F0lOtBkn0ZzGYMW7oXa09chFYhx5rHuqJLgzpSx6p2bC7E1q9fj1mzZiEiIsK6rVmzZpg5cybWrVtXpeGIyDEUDRrCffLLEHx8YcnJRtG3n8Gcky11LKcQ6KHFN/3aAgDe35mOtEt50gZyMuusbesrOC1xz/UmHR06QlDcvXAjukGrVOCJyDAkPHU/Uib0xXPtGsNTpcCJ3CK89o9Rsq2ZOdVylExQKKFsFwMAMCTskTgNVWdGswUjl8dh1bHz0CjkWDWiC7qHBkgdq1qyuRCzWCxQKm/+5alUKmHhUDmRy5IHBMFj8iuQ1QmAmHcNxTM+gynrtNSxnMLIFg3w0H11YbRYMO7PBJj4sw5A2QXc205fAlCx68PMl3NgOnYEEASoOnaxdzyqxtoE+mJW/3a4MHUQfnqwPdr/Y5Ss1+/b0HTmGny2t/qNkqmiy6YnmtIPwlKQL3Eaqo5MFgtGr4zHsiPnoJLLsHJY5wpNO6fKsbkQ69mzJ1544QVcuHDBuu38+fN46aWX0KtXryoNR0SOJfP1g/uklyEPaQCxuBjFs74qe+NcwwmCgNkD2sFHo0TSxWv4bO9RqSM5he2nL6HUZEaIlxuaV2BBzxvXhinCm0Pmx+sM6N55qJR4MrIREp+6H8lP98WzUX+Pkr26uWyUbMSyvdiamQOxGoySyQODIW/QELBYYNwfL3UcqmbM1z9sXJyeBaVMhuWPdkbfCjZhosqxuRCbMWMGCgoKEBoaikaNGqFRo0Zo2LAhCgoK8O2339ojIxE5kMzDE+7PvQR5k3DAoEfxjzNhPJAkdSzJBXlq8b++ZVMU392RhsOX+Wm0LW3rRYMBxoSybm+qTmxZT1UvMsgX3w0oGyX7ceDfo2SL07Ouj5KtxWd7j+Cyi4+SqaI7AwAMCXurRXFJzsEiinjqr32Yf+gMFDIBSx7tiAH3BUsdq9qzuRALCQlBcnIy1qxZgxdffBEvvvgi1q5di+TkZNSrV88eGcuZOXMmQkNDodFoEB0djcTExDvuv2TJEoSHh0Oj0aBly5ZYu3ZtufuXL1+O+++/H7Vq1YIgCEhNTbVjeiLXIGg0cH96IhSt2wJmE0p++wn6vTuljiW50a1CMaBJMAxmC8ZziqK1bX1Frg8zHkiCqCuB4OsHRXhze0ejGsxDpcRTbW8eJTueW1g2Svb1Kjy2bC+2uegomTIyClCrYbmcA3PmCanjUDVgEUU8s3of5h7IhFwQsHBIRwxqav/39FTJdcQEQUCfPn0wefJkTJ48Ge3aOWaV98WLF2Pq1KmYNm0akpOT0bp1a/Tt2xeXLl265f579+7FY489hieffBIpKSkYPHgwBg8ejLS0NOs+xcXF6Ny5Mz799FOHvAYiVyEolHAb/RRUsV0AUUTp0gUo3bTWJd+4VBVBEPD9gHbwViuReCEXX8ZlSB1JMsevFuLktSIoZTL0rMBF3IY9ZYW8qmNXCLJKL2FJZJN/j5K1C/aDwWzBovQs9Lw+Svb53qO4UqKXOmqFCWoNlG3K3ncZ4tm0g+6NKIqYtC4JP6WcgkwQMO/hGDzSrOYtmi4VQbTxXdWnn36K0NBQDB8+HAAwbNgwLFu2DIGBgVi7di1at25tl6AAEB0djfbt22PGjBkAyhqHhISEYPLkyXj99ddv2n/48OEoLi7G6tWrrdtiYmLQpk0bzJ49u9y+p0+fRsOGDZGSkoI2bdrYlKugoADe3t7Iz8+Hl5eX7S+MyImJogj9+r+g31Q2mqzq0hOaQY/U6DfTv6SewhOrEqGWy5D6TD+E1655/+//l5CBFzekoGdoHWwZ0/OO+5rPZaHoy48BuRye70yHzLPmnS9yHskXc/FD8knMP3QGRQYTAEAll2FIeD08E9UI3RrUuetUW6mZzmSi+H+fAkolvN79FILWTepI5IJEUcQLG5LxbeJxCAB+GxyDx1uFSh2rWqhobWDzO6nZs2cjJKSsUt60aRM2bdqEdevW4YEHHsArr7xS+cR3YTAYkJSUhN69e1u3yWQy9O7dG3Fxcbc8Ji4urtz+ANC3b9/b7l9Rer0eBQUF5W5E1ZUgCNA88BA0g4cBAAy7tkK38FeIZrPEyaQzrnVD9GsUBP31KYrmGjhF8e+29Xe/hkB/vWW9slVbFmEkubZBfpg9oD0uTh2EH/41Stbjt20In7UWX8Q59yiZvH4oZIHBgNEIQ/I+qeOQCxJFES9vSsW3iccBAD8/1IFFmARsLsSys7Othdjq1asxbNgw3H///Xj11Vexb5/9fhhcuXIFZrMZAQHlp8AEBAQgO/vW6x1lZ2fbtH9FTZ8+Hd7e3tbbjfNBVJ2pu/aEdtR4QCaDMSkBJXO+g2gwSB1LEoIg4IeB7eClViL+/FV8nXBM6kgOVWI0YXsF29aLuhIYU8p+N7BJBzkTD5UST7dthH1P3Y+kp+/HM1GN4KFS4NjVQry8KRV1v/oTI5fvxfbTznctmSAIUMWUtbLnmmJkK1EU8d+tB/FlfNn0+h8Gtsf4NmESp6qZbC7EfH19cfbsWQBlizvfGHESRRHmGvIJ+RtvvIH8/Hzr7cb5IKruVFHRcHviOUCphOlIGopnfw1LcbHUsSQR4u2OL/q0AQC8te0Qjl2tOSPj2zIvQW+2oIG3GyLuMi3TsC8eMBggCwyGvGEjByUkss2NUbILLw3C9wPaISrIFwazBQvTnHeUTBkVDcgVsJzLgvlcltRxyIVM256GT/aULU0z84EoPN2WP5ulYnMhNmTIEIwcORJ9+vTB1atX8cADDwAAUlJS0Lhx4yoPeEPt2rUhl8uRk5NTbntOTg4CA2+90FxgYKBN+1eUWq2Gl5dXuRtRTaFs1hLuz74AaN1gPn0KxTO/gCXvmtSxJPFkZBj6hAWg1GTGE6sSa8wUxb/b1gff8VoaURRhuN5tU9Wpq9Nfd0PkqVZiQlRj7H+6L/Y/dT8mtL15lGzU8jjsOH1J8lEymbsHlC3bAOCoGFXcBzvT8MGudADA//q2xfPtm0icqGazuRD76quvMGnSJDRr1gybNm2Ch4cHAODixYt4/vnnqzzgDSqVClFRUdiyZYt1m8ViwZYtWxAbG3vLY2JjY8vtD5Rd13a7/YmoYhQNG8Nj4n8geHnDkn0BRTM+h/lyzt0PrGYEQcBPD3aAp0qBPWevWOfaV2eiKGLt8QsAgP53mZZoPnEMlkvZgFoNVVS0I+IRVZmoYD98P/DvUbK210fJFqSdQffftiJi1lp8KfEomXV6YlJijZ0qThX3ye7DeGd7Wefwz/u0wZTo+yRORDZ3TZTS4sWLMXbsWHz//ffo0KEDvv76a/zxxx84evQoAgICMGbMGNStWxfTp08HUNa+vlu3bvjkk08wYMAALFq0CB9//DGSk5PRokULAEBubi6ysrJw4cIF6z5NmzZFYGBghUfO2DWRaipL7hUUz/4fLFcuQ/DwhPuEyZDXqy91LIf7PukEnl2zH1qFHAef7YfGfp5SR7KbjCsFCJ+1Fiq5DLmvDIG7SnHbfUt+/QHGA8lQdewK7SMjHZiSyD6SLuTi++QTWHAoC8XGvzsuPhIRgmeiGqFLfX+HjvyKFgsKP34bYu5VaEeOh6odP/CgW/si7ihe3pQKAPi4Zyu80bmZtIGqObt1TQSAjIwMTJo0Cb169UKvXr0wadIkZGTYfz2d4cOH4/PPP8c777yDNm3aIDU1FevXr7c25MjKysLFixet+3fs2BELFizADz/8gNatW2Pp0qVYuXKltQgDgFWrViEyMhIDBgwAAIwYMQKRkZE3tbcnopvJ/GrDffIrkNUNgVhUiKKZX8J0ouatrTWhbSP0DK0D3fUpihbX+XzLZmuvd0vsWt//jkWYpSAfxkOpAMrWDiOqDqKC/fDDwA64OHUQZg9oh8jAv0fJuv26Fc2+W4ev4jNw1UGjZIJMBlX0jaYdux3ynOR6/peQYS3C3uvWgkWYE7F5RGzZsmUYMWIE2rVrZ53iFx8fj3379mHRokUYOnSoXYI6M46IUU0n6nQonjML5pPHAYUCbqOfsl67UFOczitCi+/Wo9howjf92mJyh+o55eP+eduw6VQOvrw/Ei/FNL3tfqUb10C//i/IGzaCx2T7LW1CJLX9F3Lxw79GydRyGR5pFoIJbe0/SmbJu4bCD/4LiCI8Xn8P8jp3X2Cdao5Z+45j4rokAMBbXZrhgx6tJE5UM1S0NrC5EGvUqBFGjRqF999/v9z2adOmYd68eTh58mTlErswFmJEgGg0ouT3n2BKOwAIArTDHrd+UltT3PiF56aU49CzDyDM10PqSFWqyGBErc9WwGC24Mjz/W+7kLVoNqPwo7cg5l2DdtR4Xh9GNUKB3oiFaWfwfdJJpGT/3cAovLYXJrRthDGtQlHLTW2X5y7+cQZMR9Kg7tkXmoEP2+U5yPX8kHQCz6zZDwB4rWMEpvdqxaZJDmK3qYkXL17EmDFjbtr++OOPl5sWSEQ1i6BUwm3sBCijOwGiCN3i36HfukHqWA71bLvG6N6gDkqMZjxZDacobsu8BIPZgoY+7mha6/bXwZmOHIKYdw2CuweUrds6MCGRdLzUSjwT1RhJT9+PfU/dj6ciw+CuVODolQJM3ZiCul/9icdXxGHXmarvuGidnrgvDmINWUqI7uyX1FPWImxqTFMWYU7K5kKse/fu2LVr103bd+/ejS5dulRJKCJyTYJcDu2wx6Hu2RcAULp6BXSrlkne5tlRZIKAnx/qADelHNvPXMLs/SekjlSl/m5bH3THX+iGPddb1kd3gqBQOiQbkbMQBAHtgv3w44MdcGHqIHzXvx3aBPpAb7Zg/qEz6PrrVjT/bh2+js9Arq5qriVTNG8FwcMTYmEBTEcOVcljkuuad/A0nlyVCACY0uE+fN6nDYswJ3X7K63/YdWqVda/P/TQQ3jttdeQlJSEmJgYAGXXiC1ZsgTvvfeefVISkcsQBAGagQ9DcHdH6V/LYdi+CWJxIbTDRkOQy6WOZ3dhvh74pFdrTFmfjFc3H0D/JkEI9XH9KYrl29YH33Y/8+VLMGUcBgQBqlh+OEc1m5daiWfbNcYzUY2uX0t2EgvTsnDkSgFe2piC17ccwKPNQvBMVGN0Cqld6TfLglwOZftYGLZthCF+D5Qt2lTtCyGXsSjtDMb+mQARwHPtGuPrvpEswpxYha4Rk8kqNnAmCALMNXBInNeIEd2aIXEvdH/MAywWKJq3gtvopyCoVFLHsjuLKKL7r1uxK+syeobWwebRPVz+F+GRy/lo9t06qOUy5L46BG7KW3+Op1u1FIbtm6GIaAH3pyc5OCWR8yvQG7Hg0Bl8n3wCqdl51u3N/MuuJRvdKhR+WtuvJTNfykHRJ9MAQYDn2x9D5uNbhanJFSw9fBYjlu2FWRTxVGQYvh/YHjIX/93jqqr0GjGLxVKhW00swojo9lQdOsJt3DOAQglT+kEU//ANRJ1O6lh2JxMEzHmoA7QKObaevoQfkl2/idGNtvXdQ+vctggTDQYYE+MAsGU90e3cGCVLfrovEp/sgycjw+CmlOPw5QK8uCEFdb9ahTEr47E767JN07rldQIgD2sCiCIM++Ls+ArIGf2ZcQ6PLS8rwsa2DmUR5iIqtY7YreTl5WHGjBlV9XBEVE0oW7SG+zNTAI0G5lMnUDTzC1gK8qWOZXeN/Tzxcc+yNsEvb0rFmbxiiRPdm3Un/r4+7HaMB5IhlhRD8PWDIqLFbfcjorJZRO3r1sJPD3bAhZcGYVb/KLQO8EGpyYzfD55Gl7lb0GL2OvwvIQPXdIYKPaYq5saaYnshWiz2jE9OZPWx83h0yV6YLCJGtWyAnx/swCLMRdxzIbZlyxaMHDkSQUFBmDZtWlVkIqJqRtGoCTwm/geCpxcsF86h+NvPYbl6WepYdje5QxN0CqmNIoMJT69OdNmmJYV6I3aeKfv3ulMhZtizAwCgiu0KoYJT2okI8Nao8Fy7JkiZ0BcJT/bBE20alhslC/7qT4xZGY89dxklU7ZqC2g0EHOvwHzimANfAUll/YmLGLpkD4wWC4Y3r4+5g6Ih589fl1Gpf6mzZ8/i/fffR8OGDXH//fdDEASsWLEC2dnZVZ2PiKoJed0QuE9+BYJfbViuXkbRN5/BfOGc1LHsSi6TYc5DHaBRyLHpVA5+TjkldaRK2Xo6B0aLBY18PdDE79Zt683nsmDOygTkcqiiOzo4IVH1IAgCOtSthZ8fisaFlwZh5gNRaPWPUbLOc7eg5ez1+Cbh2C1HyQSVCqq2HQAAhoTdjo5PDrb5VDYGL94Fg9mCoRH18PvgGChYhLmUCv9rGY1GLFmyBH379kXTpk2RmpqKzz77DDKZDG+++Sb69esHpZJtiono9uS1/eEx5RXIgupCLCxA0YwvYDpVvVq8/9t9tbzwYY+WAICpG1NwNt/1pij+c1ri7ZqO6PeWtaxXtmoLmSebFhHdK2+NCs+3b4LUCX0R/8Tfo2Tpl/PxwoZkBH/1J8aujMfes1fKjZKpYjoDAIwHU2EpLpIqPtnZ9tM5eGjRLujNFjx0X10sGBILpZxFmKup8L9Y3bp18e2332Lo0KE4f/48li9fjkceecSe2YioGpJ5ecNj0n8gb9gYKNWhePb/YEw/KHUsu3ox+j7E1K2FQoMJE1bvd6kpimVt68sKsf63mZYo6nQwJpetWaPqxCYdRFVJEARE17v1KNlvB0+j0y+b0er79fg2sWyUTF6vPmR1QwCzCcakRKnjkx3szrqMgQt3QWcyo3/jIPzxSEeoasDyMNVRhQsxk8kEQRAgCALk/McmonsgaN3g/swUKJq1BExGlPwyG4Z98VLHshu5TIZfBkVDLZdh/cmLmHsgU+pIFXb4cgHOFpRAo5Cje2idW+5j2B8PGAyQBQaXFdhEZBf/HiUb36YhtAo50i7lY8r6v0fJzjVtAwAwxO92qQ9+6O7izl7BAwt2oNhowv1hgVg2rDPUCr4vd1UVLsQuXLiACRMmYOHChQgMDMTQoUOxYsUKl18bh4ikIahUcBv/LJTtYgCLBbqFc6HfvlnqWHYTXtsL73cvm6L40oYUnC8okThRxaw9UbaIc4/QOtDeom29KIow7L3epKNTV/5OIHKAG6Nkcx6KxsWpgzDjgSi0rONtHSWL3Z8LvSCDJfsC8k9U7+nfNUni+avot2AHigwm9Aytg5XDO0PDIsylVbgQ02g0GDVqFLZu3YpDhw4hIiICU6ZMgclkwkcffYRNmzZxHTEisokgl0M7YgxU3XoDAEpXLYVu1VKIRqPEyexjamxTdAj2Q77eiGfWuMYUxbu1rTefPAZLTjagUkMVFe3IaESEslGyie2b4MAz/RD3RG+Mb9MQBpUGKxT+AID5cxZi3J/xiPvXtWTkWpIv5qLv/O0o0BvRtb4/Vo3oessPx8i1VOqqvkaNGuHDDz/EmTNnsGbNGuj1egwcOBABAQFVnY+IqjlBJoPmoaFQDxgMADBs34yi/3uvWl43prg+RVEll2HN8Qv4/eBpqSPdUYHeiF1Zd25bb7jepEMV1QGCRuuwbERUniAIiKlXG3MeisaFqYPg26Xses1B+hwsTT2Bjr9sRuvv12NG4jHklVZsXTJyDgeyr6H379uRV2pEp5DaWDOyK9xVLMKqg3tqryKTyfDAAw9g6dKlOHfuHP773/9WVS4iqkEEQYCmVz+4jX0agpc3LFevoOTnWSj+cQbMl3Okjlelmvl7491uZYsdv7AhGRcKdRInur0tmTkwWUQ08fNE41u0rbcU5MN4MAUAoOrYzdHxiOg2fDQqPDqgJ2S1/eEJMz4LBLQKOQ5dysfk9ckI/vJPjP8zgaNkLiDtUh56z9uOa6UGxNSthbUju8FDxS7l1UWV9bn09/fH1KlTq+rhiKgGUraOgufr70Hdsy8gl8N0JA1F//cBSlevgKgvlTpelXmlYziignyRV2rEs2v2Oe0bobXHy64Pu+1oWMIewGKBPDQM8rr1HBmNiO5CEASoosta2Y/WX8CFqYPwbb+2aFHHGzqTGXMPZHKUzMkduZyPXr9vw5USPdoF+2H9qG7wUrMIq0644AARORVBo4Fm4MPweOVtKMKbA2YT9Fs3oPCTd2FIdt6ixRYKmQxzB0VDKZPhr2MXsCDtjNSRbiKKovX6sFu1rRfNZhjidgHgaBiRs1K2jwFkMphPn4Jn3hVM6nAfDj7TD3vH98bY1qHQ/GuUbNTyOHy65wiWHTmLgzl5KDaYpH4JNdaxqwXo+fs2XCrWIzLQFxtHdYe3RiV1LKpiglgd3tVIrKCgAN7e3sjPz4eXFxcyJaoqoijClH4QupVLIOZeAQDIw5pAO2Q45MGuPwLz4c50vL39EHw1Khx+/gEEejjPNVaHcvLQ6vv10CrkyH11yE2duYxpqSiZMxuCuwc835kOQclPaYmcUfGc72BKOwBVt97QDiq//us1nQHzDp3G90knkX45/5bHB3lo0NjPE439PNDY1+Pvv/t5cnTGTk7mFqLbr1txvlCHVgE+2Dq6B2q5qaWORTaoaG3AK/2IyGkJggBli9ZQNG0G/fZN0G9eB/Op4yj64iOoOnWDpt+DENzcpY5Zaa91isDyo+eQkn0Nz63Zj+XDOjtN+/e110fDejYMuGV7ZMOesiYdyg4dWYQROTFVTGeY0g7AuD8emgGDICj+/v/qq1Vhcof7MKl9E8Sdu4oNJy/i5LUinMgtwvHcQuTqDLhYVIqLRaXWxj3/5O+mthZlZUXa34Wan5aFQ2VkXitCj9+24XyhDs39vbH58e4swqoxFmJE5PQEpRKaPv2hahcD3aqlMB1IhmH3dhhT9kPTfxCU0Z0gyFxvprVSXjZFMerHDViZcR6L07MwokUDqWMBANaduP31YebLl2DKOAwIAtQduzg6GhHZQNG0GQQvb4gF+TClHYSyTdRN+wiCgI4htdExpHa57bk6PU7mFuHEtSKcyC3EidyyIu3EtUJcKtbjcknZLe7c1Zse01ejQhO/f46geaCxb9nfa7upneZDJ2eSlV+Mnr9vw9mCEoTX9sKW0T3g766ROhbZkc2FmNlsxty5c7FlyxZcunQJFoul3P1bt26tsnBERP8k8/WD+9gJMB07Ct2KxbDkXIRuyXwY4nZBM2QEFKFhUke0WasAH7zVpTne3ZGGSeuS0CM0AAEe0v7izS81YHdW2VTQWxViN64NUzRtBlktf4dmIyLbCHI5VB06Qr95HQwJe25ZiN2On1YNv7pqtK9b66b7CvTG60XajQLt+p/XinChUIdrpQYkXshF4oXcm471Uitvnup4/e+BHpoaWaSdKyhBj9+24nReMZr4eWLr6B6S/y4g+7O5EHvhhRcwd+5cDBgwAC1atKiR/1mISFqK+8Lh8fJbMOzejtINf8F8LgvF3/wflO1joRn4MGSernWt5hudI7Di6DkcyMnDpHVJWPJoJ0nzbM7MgVkU0bSWJ8J8PcrdJxoMMCbuBQCoOrFJB5ErUEWXFWKmY0dgyb0Kmd/NhZWtvNRKRAb5IjLI96b7ig0mnLpWVpQdv1r4j2KtCGcLSlCgNyL54jUkX7x207HuSgUaWQuzsuLsxshasKcWsmr4vvNCoQ49f9uGU9eKEebrjq1jeiDI03muGSb7sbkQW7RoEf744w/079/fHnmIiCpEkMuh7tYLyrbtUbp6BYz74spuh1Kg6TsQqs49IMhvvrbJGankcswdFI32P23E0iNnseRwFh5tVl+yPHdqW288kAyxpBiCrx8UES0cHY2IKkFWyx/yJuEwHz8KQ+JeaPo9aNfnc1cp0DLABy0DfG66T2c0ITOv+O9RtH9MezyTX4JiowkHc/JwMCfvpmM1Cjka3SjQfMtPewzxcoPcBaeo5xSVotfv23A8txANvN2wdXRP1PNykzoWOYjNhZhKpULjxo3tkYWIyGYyTy+4PTYWptguKF2xGOazZ1D651IY4vdA+/BwKO4LlzpihbQJ9MUbnZrhg13peH5tEro3qCPJtQHl29YH33S/Ye8OAIAqtotLXpdHVFOpYjpBd70QU98/QLL/v1qlAs38vdHM3/um+wxmM05bi7SiciNpmXlFKDWZkX45/5YdHpUyGcJ83W/Z4bGBtzuUcuf7eXW5uBQ9f9+Ko1cKEOLlhm1jeqKBj+s2oCLb2dy+/osvvsCpU6cwY8YMTku8ju3riZyDaLHAmLgXpWtWQiwuAgAoWreF9qFHIPP1kzjd3RnMZrT7cSMOXcrH8Ob1sWhoR4dnSM2+hsgfNsBNKUfuK0Og/kfHRPO5LBR9+TEgl8PznekuNwWUqCYTjUYUvvc6xJJiuD09GcqI5lJHsonJYkFWfsn1qY7lr0k7da0IBrPltscqZAJCfdytzUL+2Tgk1Me93M85R7laokfP37fhYE4egj212DG2Jxr7eTo8B9mH3drX7969G9u2bcO6devQvHlzKP/Vtnj58uW2pyUiqgKCTAZVTGcoW0WidP1qGPZsh+lAMgoPH4K6Vz+oe9zv1K3WVXI5fnkoGtE/b8Li9Cw82iwEQyNCHJrhxmhYr4YBN7050e+93rK+VSSLMCIXIyiVUEZFw7BrKwwJu12uEFPIZAjz9UCYrwf6/us+s8WCcwW6f0x1LCr391KT2TqyhpPlj5UJAup7u9001bGxryfCfN2hVVZ9g/FrOgP6zNuOgzl5CPTQYNuYHizCaiibv7t8fHzw8MMP2yMLEVGVENzcoR0yvGwqzvLFMJ86Dv36v2BIjIN28CNQNG/ttCP6UcF+eK1TBD7efRjPr92Pbg3qoLYD15C5UYj9+/owUaeDMTkRAKDqyCYdRK5IFd0Jhl1bYUo7AEthQbX5QEUuk6GBjzsa+Lij17/us4giLhbqbprqePz6iFqx0YTTecU4nVeMzZk5Nz12PS/tP0bSyv5s4ueJRr4ecFfZXqTllxrQd/52pGRfQx13NbaO7oH7alWPfweync1TE+lmnJpI5LxEUYQxdT9KVy2DmJ8HoKztuubhYZDXCZQ23G3oTWa0/XEDDl8uwMgWDTB/SKxDnjev1IDan62AWRSROWUgQn3+7pio37UNpSsWQxYYDI9X3nbaQpaI7qzo609gzjoNzUNDoe7eR+o4khJFETnFpTe13z+RW4jjuUUo0BvveHyQh+aW16Q19vOEl/rm2RcFeiP6ztuO+PNXUdtNjW1jeqBFHR87vTqSkt2mJhIRuRJBEKCKbA9ls5bQb14P/fbNMGUcRtFnH0DVtRc0ffpD0DjXWi1qhRxzH4pGzJzNWJB2Bo82C8Hg8Hp2f95Np7JhFkVE1PYqV4SJovh3k46OXVmEEbkwVXQn6LJOwxC/B6puvWv0/2dBEBDooUWghxad65dfE1EURVzVGf6xkHX5aY9XdQZcLCrFxaJS7Mq6fNNj+7up/x5Fu97pcdb+E4g/fxW+GhU2P96dRRhVrhBbunQp/vjjD2RlZcFgMJS7Lzk5uUqCERFVJUGtgWbAYCg7xKJ05RKYjqTBsG0jjEkJ0Dw4BMq2HZzqDUn7urXwSmw4Pt17BM+u2Y+uDfzhp7XvFMW1x289LdF88jgsOdmASg1Vu2i7ZiAi+1JGtofuz6WwXMqG+fRJKBqyE/atCIKA2m5q1HZTI6Ze7Zvuv6Yz4KR19KywXKfHS8V6XC4pu8Wdu1ruOG+1Epse747WgTevv0Y1j82F2DfffIM333wT48aNw59//onx48fj5MmT2LdvHyZOnGiPjEREVUbuHwD3pyfBmH4QpSuXwHL1MnTzf4Fh7y5ohwyHvK5jm2PcybvdW+DPY+dx9EoBXtyQgt8Gx9jtuSyiiPUnb7StL1+IWUfDojpA0HCRUSJXJmg0ULaJgjFxLwzxe1iIVZKvVoV2Wj+0C765I2+B3oiT5a5J+/t6tFn92yHqFsdQzWTzNWLh4eGYNm0aHnvsMXh6euLAgQMICwvDO++8g9zcXMyYMcNeWZ0WrxEjck2i0Qj9js3Qb14HGAyAIEDVsSvU/R6CzN051nKJP3cFnX7ZAosoYtXwLniwaV27PE/yxVxE/bgR7koFrr7ysLVjoqUgH4XvvwFYLPD4z1uQ17X/FEkisi/T6VMo/ub/AJUKXtM+haDlByxEVamitYHNq9tlZWWhY8eytW20Wi0KCwsBAKNHj8bChQsrGZeIyPEEpRKa3g/A87V3oWwTBYgiDHt2oOiTd6DfuxOi5fbr0jhKTL3amBrTFADwzJp9uKYz3OWIyrnRLbF3WPm29YaEPYDFAnloGIswompC3qAhZAFBgMEAQ8o+qeMQ1Vg2F2KBgYHIzc0FANSvXx/x8fEAgMzMTLABIxG5IpmvH9zGPA33516CLDAYYnExSpcuQNHXn8CUefLuD2Bn73dvgftqeeJiUSmmbkyxy3Pcqm29aLHAELcLAFvWE1UngiBAFd0JAGBM2CNxGqKay+ZCrGfPnli1ahUAYPz48XjppZfQp08fDB8+nOuLEZFLUzRpCo//vAnN4GGARgvLuSwUf/sZShbMhaUgX7JcWqUCvzwUDQHA3AOZWHv8QpU+fq7u7wvK/1mImQ4fgph3DYK7O5St21bpcxKRtJTtogG5HOazZ2A+f07qOEQ1ks3NOn744QdYrk/XmThxImrVqoW9e/fioYcewjPPPFPlAYmIHEmQy6Hu2hPKyHYoXfsnjAl7YNwfD+OhVGj6DoCqS08IcvndH6iKdQypjRejm+KrhAxMWL0P6c89AG+Nqkoee9OpHFhEEc39vVHf++9r4wx7dwIAlB06QlDevCYOEbkumYcnlC1aw3ggGYaEPdAOGS51JKIax+YRMZlMBoXi7/ptxIgR+OabbzB58mSoVFXzpoCISGoyTy+4DR8N9xdegzykAaAvRemqZSj67AMYMw5LkunDni3R2M8D5wt1+M+m1Cp73BsjbP/slmi+chmmo+llDUxiu1bZcxGR81DGdAYAGJISIBrsc/0pEd2ezYUYAOzatQuPP/44YmNjcf78eQDA77//jt27d1dpOCIiqSkaNIT7C69BO3w0BA9PWC5lo+T7b1D8y/ew5F5xaBY3pQJzHuwAAcDPKaew4fp1Xffin23r/zkt0RBXNhqmaNoM8tr+tzyWiFybokk4BF8/QFcC46FUqeMQ1Tg2F2LLli1D3759odVqkZKSAr1eDwDIz8/Hxx9/XOUBiYikJshkUEV3gucb70HVpQcgk8F0KAWFn7yH0g2rHfpJcpcGdTC5w30AgKdWJ6JAb7ynx0u+eA2XivXwUCnQqX7ZoqWi0Qhj4l4AgKoTm3QQVVeCTAZVh7KmHQY27SByOJsLsQ8//BCzZ8/Gjz/+COU/rhno1KkTkpOTqzQcEZEzEbRu0D48HB7/eRPyRvcBJiP0G1aj8P/eg/FgisM6x37csxXCfN1xrkCHV+5xiuK6E2XTEvuEBUJ1/do344EkiMXFEHz9oIhoca9xiciJqTrEAoIA84kMmC9fkjoOUY1icyGWkZGBrl1vvl7A29sbeXl5VZGJiMipyYPqwv35l6Ad8xQEH1+IuVdRMvd7lPzwLcw52XZ/fneVAnMejAYA/JB8EptPVf451x6/xbTE6006VDGdIcgqNYOdiFyEzNcPiqbNAMA6Ek5EjlGpdcROnDhx0/bdu3cjLCysSkIRETk7QRCgatMOnq+9C3XvBwC5AqaMwyj67H3oVi2DWKqz6/N3C62Die2bAACe/CsRhZWYoni1RI+E8+Xb1pvPn4X59ClALreuM0RE1duN/+uGfXEQzWaJ0xDVHDYXYk8//TReeOEFJCQkQBAEXLhwAfPnz8fLL7+M5557zh4ZiYiclqBWQ9N/EDxefQeKZi0BiwWG7ZtQOH0aDPvj7Tpd8ZNerRDq446s/BK8tuWAzcdvPJUNEUDLOt6o5+UGADDsud6yvmUkZF7eVRmXiJyUonkrCB6eEAvyYdwfL3UcohrD5kLs9ddfx8iRI9GrVy8UFRWha9eueOqpp/DMM89g8uTJ9shIROT05P514P7URLg9NRGy2v4QCwugWzAXxd9+BvO5LLs8p4dKiZ8f7AAA+G7/CWzNzLHp+L/b1gcDAESdDobkRACAqiNb1hPVFIJCAXX33gAA3Z9LYLmWK3EioprB5kJMEAS8+eabyM3NRVpaGuLj43H58mV88MEH9shHRORSlM1awuPVd6AeMBhQqWE+fQpFX02HbukCWIqLqvz5ejYMwLNRjQGUTVEsMlRsimJZ2/qya8tuTEs07I8HDHrIAoIgb9SkyrMSkfNSdesNeYOGQGkpdIt/g2ixSB2JqNqr9FXYKpUKzZo1Q4cOHeDh4VGVmYiIXJqgUELTqx88X38Xysh2gCjCsHcniqZPg37Pjip/g/N/vVujvrcbTucV440tByt0zP4LubhSooeXWomOIbUhXs8IlI2GCYJQpRmJyLkJcjm0I8cBSiVMx45afx4Qkf0oKrrjE088UaH95syZU+kwRETViczHF26jn4Iptit0KxbDcvE8SpcthCF+N7QPD4cirHGVPI+nWomfBnbA/fO3Y8a+43gkIgTdQuvc8Zh11xeD7hMWAKVcBtOJY7DkXARUaqjaxVRJLiJyLXL/AGgGDkHpisUo/WsZFE0jIPcPkDoWUbVV4RGxuXPnYtu2bcjLy8O1a9dueyMiovIUje+Dx9T/QvPwcEDrBsv5syie8TlK5v8CS0F+lTxHn0aBeLptWefaJ/5KQLHBdMf9b1wfZp2WeGM0rG0HCFptlWQiItej6tQN8iZNAaMRuoW/cooikR1VeETsueeew8KFC5GZmYnx48fj8ccfh5+fnz2zERFVG4JcDnWXHlBGtkPpmpUwJu6FMSkBxrRUaPoMgKprTwiKCv9IvqXP+0Ri/YlsnLpWjDe3HcTXfdvecr/LxaXYd6HsYvwHGgfDUpAP46EUAICqE5t0ENVkgkwGtxFjUfjZ+zCfPgX9to3Q9OondSyiaqnCI2IzZ87ExYsX8eqrr+Kvv/5CSEgIhg0bhg0bNti1PTMRUXUi8/CE2/DRcH/xdcjrNwT0epSuXo6izz+A8Wj6PT22l1qJHwe2BwB8k3AMu85cuuV+N9rWtw7wQbCnFoaEPYDZDHloGOR1Q+4pAxG5PpmvH7SDhwEA9Ov/gvnCeYkTEVVPNjXrUKvVeOyxx7Bp0yYcPnwYzZs3x/PPP4/Q0FAUFVV9NzAioupKEdIA7lNegXbEGAgenrBcykHJD9+ieM53sFy9UunH7ds4CE+0aQgRwBN/JaLEePMUxbXHy64P6984CKLFAkP8bgBsWU9Ef1O2j4WieSvAbEbJgl8gmu483ZmIbFfprokymQyCIEAURZi5CjsRkc0EmQyqDh3h+cb7UHXrBchkMKUdQOGn76J0/V8QDYZKPe4X90eirqcWJ3KL8Pa2Q+XuM1ss2HCyrBB7oHEQTEfSIF7LheDuDmXrqHt+TURUPQiCAO2wxyG4u8Ny4Rz0G9dIHYmo2rGpENPr9Vi4cCH69OmD++67D4cOHcKMGTOQlZXFFvZERJUkaLXQDnoUHi+/VXaRvMkE/cY1KPz0XRgPJNs8/dtHo8IP16cofhWfgb1n/x5h23chF1d1BnirlYgNqQ3Dnh0AAGWHjhCUyqp7UUTk8mSeXtA+MhIAoN+yHqYzmRInIqpeKlyIPf/88wgKCsInn3yCgQMH4uzZs1iyZAn69+8PmazSA2tERHSdPDAY7s++CLexT0Pw8YV4LRclv/6A4tn/gzn7gk2P1b9JMMa2DoUIYPyqBOiuT1G80bb+/kaBEHKvwpRxGACgiuW0RCK6mbJ1FJRt2wOiCN2CuZUeqSeimwliBT9qlclkqF+/PiIjI++40Ofy5curLJyrKCgogLe3N/Lz8+Hl5SV1HCKqBkSDAfot66HfthEwmQCZDKouPaHpOwCCpmLt5a/pDGj+3VpcLCrFK7Hh+L8+bdD+p43YfyEXcx7qgBFnU2DYtgmKps3g/swUO78iInJVYkkxCv/vfYgF+VB16Qntw8OkjkTk1CpaG1R4KGvMmDHo0aMHfHx84O3tfdubvc2cOROhoaHQaDSIjo5GYmLiHfdfsmQJwsPDodFo0LJlS6xdu7bc/aIo4p133kFQUBC0Wi169+6N48eP2/MlEBHdlaBSQfPAQ/B8bVrZBfMWCww7NqNw+jQY9sVVaG0fX60K3w8om6L4RXwGVmWcx/7rbev71a8NY+JeAGXrBhER3Y7g5g7t8DEAAMOurTAdz5A4EVH1UOERMWewePFijBkzBrNnz0Z0dDS+/vprLFmyBBkZGahTp85N++/duxddu3bF9OnTMXDgQCxYsACffvopkpOT0aJFCwDAp59+iunTp+PXX39Fw4YN8fbbb+PQoUM4fPgwNBpNhXJxRIyI7M14JB2lK/+A5XIOAEAeGgbtw8MhD2lw12NHr4jDvENnoJLLYDBbEBnoi/i2PtAt+AWCjy883/oIAqeYE9Fd6JbMhyFuFwRfP3i+8naFR+eJapqK1gYuVYhFR0ejffv2mDFjBgDAYrEgJCQEkydPxuuvv37T/sOHD0dxcTFWr15t3RYTE4M2bdpg9uzZEEURwcHB+M9//oOXX34ZAJCfn4+AgADMnTsXI0aMqFAuFmJE5AiiyQTDzi0o3bgWMOgBQYAqujPU/QdBdoeGSbk6PZrNWoec4lIAwJudm+H1tPUwnz4F9QMPQdOnv6NeAhG5MFFfisLPPoSYewXKDh3hNmKM1JGInFKVT02UmsFgQFJSEnr37m3dJpPJ0Lt3b8TFxd3ymLi4uHL7A0Dfvn2t+2dmZiI7O7vcPt7e3oiOjr7tYwJl3SMLCgrK3YiI7E1QKKDu2Reer79rvXjeEL8LRdPfgX73doi3WUrET6vG7AHtrF8/7A2YT58qu+4supOj4hORixPUGriNHAsIAoyJe2FMPyh1JCKX5jKF2JUrV2A2mxEQEFBue0BAALKzs295THZ29h33v/GnLY8JANOnTy93XVxISIjNr4eIqLJkPr5we/xJuE/6D2TB9SDqSlC6fBGKvvwYplO3vsZ1cHg9fNqrNf4T0xQRp8rWFlO2ioTMy/7X9hJR9aEIa1K27iEA3R/zYCkqkjgRketymULMmbzxxhvIz8+33s6ePSt1JCKqgRRhTeDx0hvQDB0BQesGy8XzKJ7xBUp+/xmWvGs37f9qpwh81jUcxqSyJkeqjmzSQUS20zwwCLKAIIiFBShdvlDqOEQuy2UKsdq1a0MulyMnJ6fc9pycHAQGBt7ymMDAwDvuf+NPWx4TANRqNby8vMrdiIikIMjlUHfqDo833ocqtkvZlKGUfSj85F3ot2yAaDKW29+wPwEw6CELCIK8UROJUhORKxOUSriNHAfIZDCmJsGQsk/qSEQuyWUKMZVKhaioKGzZssW6zWKxYMuWLYiNjb3lMbGxseX2B4BNmzZZ92/YsCECAwPL7VNQUICEhITbPiYRkTOSeXhA++goeLz4OuShYYBBj9I1K1D02QcwHkkDULZch2HPDgCAqmPXO64JSUR0J/KQBlBfb/RTunQhLPl50gYickEuU4gBwNSpU/Hjjz/i119/xZEjR/Dcc8+huLgY48ePB1C21tkbb7xh3f+FF17A+vXr8cUXX+Do0aN49913sX//fkyaNAkAIAgCXnzxRXz44YdYtWoVDh06hDFjxiA4OBiDBw+W4iUSEd0TeUgDuE96GdrHxkHw9ILl8iWU/DgDxT/PgnF/PCw5FwGVCqp2MVJHJSIXp+79AOT16kPUlUC3+He4UCNuIqegkDqALYYPH47Lly/jnXfeQXZ2Ntq0aYP169dbm21kZWVB9o+1cDp27IgFCxbgrbfewn//+180adIEK1eutK4hBgCvvvoqiouLMWHCBOTl5aFz585Yv359hdcQIyJyNoJMBlX7GChbtkbpxjUw7NwKU/pBmK53OFO27QBBy/V/iOjeCHI5tCPHlTUKOpoOY/zusinSRFQhLrWOmLPiOmJE5MzMORdRumIxTMeOAgA8pv4X8nr1JU5FRNWFfvsmlK5aBqjV8Hz5bchq1ZY6EpGkquWCzs6KhRgROTtRFGE6dgQQRSjDm0sdh4iqEdFiQfGsL2E+dQLysCZwf/4lCDKXuvqFqEpVuwWdiYio8gRBgLJpMxZhRFTlBJkMbo+NBVRqmE8dh2HXVqkjEbkEFmJEREREdE9ktfyhHfQIAKB0zUqYcy5KnIjI+bEQIyIiIqJ7pozpDEV4c8Bkgm7BXIhms9SRiJwaCzEiIiIiumeCIEA77HFA6wbz2TPQb14vdSQip8ZCjIiIiIiqhMzHF9ohIwAA+k1rYD57RuJERM6LhRgRERERVRll2/ZQtG4LWCwoWfgrRKNR6khETomFGBERERFVGUEQoB06EoKnFyzZF1C6fpXUkYicEgsxIiIiIqpSMg8PaB8dBQAwbN8M06kTEicicj4sxIiIiIioyilbtIayfSwgitAtnAtRXyp1JCKnwkKMiIiIiOxCO3gYBF8/WK5eQelfy6WOQ+RUWIgRERERkV0IWi3cRowBABj27oTxaLrEiYicBwsxIiIiIrIbRZNwqDr3AADoFv8OsaRY4kREzoGFGBERERHZlWbgw5D5B0DMz4NuxR9SxyFyCizEiIiIiMiuBJUK2sfGAoIAY1ICjAdTpI5EJDkWYkRERERkd4rQMKh79gUA6JbMh6WwQOJERNJiIUZEREREDqHuOwCyoLoQi4ugWzIfoihKHYlIMizEiIiIiMghBIUSbqPGA3I5TGkHYNwfL3UkIsmwECMiIiIih5EH14O674MAAN2KxbBcy5U4EZE0WIgRERERkUOpe/SBvEFDoLQUusW/QbRYpI5E5HAsxIiIiIjIoQS5HNrHxgFKJUzHjsKwd6fUkYgcjoUYERERETmcvE4ANAOHAABK/1oG8+UciRMRORYLMSIiIiKShKpTN8ibNAWMRugW/sopilSjsBAjIiIiIkkIMhncRowFNBqYT5+CfttGqSMROQwLMSIiIiKSjMzXD9rBwwAA+vV/wXzhvMSJiByDhRgRERERSUrZPhaK5q0AsxklC36BaDJJHYnI7liIEREREZGkBEGA9tFRENzdYblwDvqNa6SORGR3LMSIiIiISHIyL29oHxkJANBvWQ/TmUyJExHZFwsxIiIiInIKytZRULZtD4gidAvmQjQYpI5EZDcsxIiIiIjIaWiHjIDg5Q3L5RyUrlkhdRwiu2EhRkREREROQ3Bzh3b4GACAYdc2mI5nSJyIyD5YiBERERGRU1FGNIcqtgsAoGTRrxBLdRInIqp6LMSIiIiIyOloHhwKwa82xGu50K1cInUcoirHQoyIiIiInI6g0cBt5FhAEGBM3Atj+kGpIxFVKRZiREREROSUFGFNoOrWCwCg+2MeLEVFEiciqjosxIiIiIjIaWkeGARZQBDEwgKULlsAURSljkRUJViIEREREZHTEpRKuI0cB8hkMB5IhjF1v9SRiKoECzEiIiIicmrykAZQ9+kPAChduhCW/DxpAxFVARZiREREROT01L0fgLxefYi6EugW/84piuTyWIgRERERkdMT5HJoR44DFAqYjqbDGL9b6khE94SFGBERERG5BHlgMDT9BwEAdKuWwnL1isSJiCqPhRgRERERuQxV116QhzUG9HqULPwVosUidSSiSmEhRkREREQuQ5DJ4PbYWEClhvnUcRh2bZU6ElGlsBAjIiIiIpciq+UP7aBHAACla1bCnHNR4kREtmMhRkREREQuRxnTGYrw5oDJBN2CuRDNZqkjEdmEhRgRERERuRxBEKAd9jigdYP57BnoN6+XOhKRTViIEREREZFLkvn4QjtkBABAv2kNzGfPSJyIqOJYiBERERGRy1K2bQ9F67aAxVLWRdFolDoSUYWwECMiIiIilyUIArRDR0Lw8IQl+wJK16+SOhJRhbAQIyIiIiKXJvPwKLteDIBh+2aYTp2QOBHR3bEQIyIiIiKXp2zRGsr2sYAoQrdwLkR9qdSRiO6IhRgRERERVQvawcMg+PrBcvUKSv9aLnUcojtiIUZERERE1YKg1cJtxBgAgGHvThiPpkuciOj2WIgRERERUbWhaBIOVeceAADd4t8hlhRLnIjo1liIEREREVG1ohn4MGT+dSDm50G34g+p4xDdkssUYrm5uRg1ahS8vLzg4+ODJ598EkVFRXc8prS0FBMnTkStWrXg4eGBoUOHIicnp9w+U6ZMQVRUFNRqNdq0aWPHV0BEREREjiCoVNA+Ng4QBBiTEmA8mCJ1JKKbuEwhNmrUKKSnp2PTpk1YvXo1du7ciQkTJtzxmJdeegl//fUXlixZgh07duDChQsYMmTITfs98cQTGD58uL2iExEREZGDKULDoO7ZFwCgWzIflsICiRMRlSeIoihKHeJujhw5gmbNmmHfvn1o164dAGD9+vXo378/zp07h+Dg4JuOyc/Ph7+/PxYsWIBHHnkEAHD06FFEREQgLi4OMTEx5fZ/9913sXLlSqSmptqcr6CgAN7e3sjPz4eXl5ftL5CIiIiIqpxoMqLoq09guXgeihat4Tb+WQiCIHUsquYqWhu4xIhYXFwcfHx8rEUYAPTu3RsymQwJCQm3PCYpKQlGoxG9e/e2bgsPD0f9+vURFxd3T3n0ej0KCgrK3YiIiIjIuQgKJdxGjQfkcpjSDsC4P17qSERWLlGIZWdno06dOuW2KRQK+Pn5ITs7+7bHqFQq+Pj4lNseEBBw22Mqavr06fD29rbeQkJC7unxiIiIiMg+5MH1oO77IABAt2IxLNdyJU5EVEbSQuz111+HIAh3vB09elTKiLf0xhtvID8/33o7e/as1JGIiIiI6DbUPfpA3qAhUFoK3eLfIFosUkcigkLKJ//Pf/6DcePG3XGfsLAwBAYG4tKlS+W2m0wm5ObmIjAw8JbHBQYGwmAwIC8vr9yoWE5Ozm2PqSi1Wg21Wn1Pj0FEREREjiHI5dA+Ng5FX3wI07GjMOzdCXXn7lLHohpO0kLM398f/v7+d90vNjYWeXl5SEpKQlRUFABg69atsFgsiI6OvuUxUVFRUCqV2LJlC4YOHQoAyMjIQFZWFmJjY6vuRRARERGR05PXCYBm4BCUrliM0r+WQdE0AnL/AKljUQ3mEteIRUREoF+/fnj66aeRmJiIPXv2YNKkSRgxYoS1Y+L58+cRHh6OxMREAIC3tzeefPJJTJ06Fdu2bUNSUhLGjx+P2NjYch0TT5w4gdTUVGRnZ0On0yE1NRWpqakwGAySvFYiIiIisg9Vp26QN2kKGI3QLfyVUxRJUpKOiNli/vz5mDRpEnr16gWZTIahQ4fim2++sd5vNBqRkZGBkpIS67avvvrKuq9er0ffvn0xa9asco/71FNPYceOHdavIyMjAQCZmZkIDQ2174siIiIiIocRZDK4jRiLws/eh/n0Kei3bYSmVz+pY1EN5RLriDk7riNGRERE5DoMiXuhW/QbIJfD46X/Qh5cV+pIVI1Uq3XEiIiIiIiqirJ9LBTNWwFmM0oW/ALRZJI6EtVALMSIiIiIqEYRBAHaR0dBcHeH5cI56DeukToS1UAsxIiIiIioxpF5eUP7yEgAgH7LepjOZEqciGoaFmJEREREVCMpW0dB2bY9IIrQLZgLkV2zXZao00E0m6WOYRMWYkRERERUY2mHjIDg5Q3L5RyUrlkhdRyygSiKMGWeQMnCuSh491WYjqZLHckmLtO+noiIiIioqglu7tAOH4OSH7+FYdc2KFu0gaJJU6lj0R1Yiopg3B8PQ8JuWHKyrdtNR9OhbN5KwmS2YSFGRERERDWaMqI5VDFdYIjfhZJFv8LzlbchaLRSx6J/EC0WmE9kwBC/G8ZDqcCNaYgqFZRt2kEV0xnyBg0lzWgrFmJEREREVONpHhoK47EjEHOvQLdyCdxGjJE6EgGw5F2DYV8cDAl7IeZesW6XhzSAMroTVG3bu2zRzEKMiIiIiGo8QaOB28ixKJ75JYyJe2Fs2calprlVJ6LZDNORNBgS9sB0+BAgimV3aLRQRXUoG/2qGyJtyCrAQoyIiIiICIAirAlU3XrBsH0zdH/Mg/yVdyDz8JA6Vo1huXoZhoQ9MCTGQSzIt26XhzWGKqYzlK3aQlCpJExYtViIERERERFdp3lgEExH0mHJuYjSZQugHfM0BEGQOla1JZqMMB46AEP8bpiPH7VuFzw8oWwXA1VMJ8jrBEqY0H5YiBERERERXScolXAbOQ5F//sUxgPJUKTuhyqyvdSxqh1z9gUYEvbAuD8eYnFx2UZBgOK+CKhiOkHRvDUERfUuVar3qyMiIiIispE8pAHUvR+AfuMalC5dCEVYE8i8faSO5fJEvR7GA0llo1+nT1m3C94+UHXoCFV0R8j8akuY0LFYiBERERER/Yu6T3+YDh+C+VwWdIt/h9vTkzhFsZLMZ8+UXfuVnAiUlpZtlMmgaNYSqpjOUIQ3hyCTSRtSAizEiIiIiIj+RZDLoR05DkVffgzT0XQY43dDFdtF6lguQ9TpYEhOgCF+Dyznz1q3y2r5QxnTCar2sZB5eUuYUHosxIiIiIiIbkEeGAxN/0EoXbUMulVLobgvArJaNWfqnK1EUYQ582TZossHkgCjsewOuQLKVpFlbecbNamRo1+3wkKMiIiIiOg2VF17wZh2AOZTJ1Cy8Fe4P/8SC4l/sRQVwrg/vmz061K2dbssMBiqmE5QRkVD5s5lAP6NhRgRERER0W0IMhncHhuLws8+hPnUcRh2bYW6W2+pY0lOtFhgOn4UxvjdMKYdAMzmsjtUKijbtCsb/WrQkNfV3QELMSIiIiKiO5DV8ofmoaEoXboApWtWQhHeHPKAIKljScKSdw2GfXEwJOyBmHvVul0e0qBs0eXIdhA0WgkTug4WYkREREREd6GK7QJT2gGYjqZDt2Au3Ke8CkEulzqWQ4hmM0xH0mCI3w3TkTRAFMvu0LpBFdUBqujOkNetJ21IF8RCjIiIiIjoLgRBgHbY4yj87AOYz56BfvN6aPoOkDqWXZmvXIYxcQ8MiXEQC/Kt2+VhTcpGv1pFQlCpJEzo2liIERERERFVgMzHF9ohI6CbPwf6TWugbNYC8pAGUseqUqLJCOOhVBji98B8/Kh1u+DhCWX7GKiiO0FeJ1DChNUHCzEiIiIiogpStm0PY1oqTAeSUbJgLjym/heCUil1rHtmzr5Q1nZ+fwLEkuKyjYIAxX0RZYsuN28FQcHSoSrxbBIRERERVZAgCNAOHYmik8dhybmI0vWroH1wqNSxKkXU62E8kARD/G6YT5+ybhd8fKHq0BGqDh0h86slYcLqjYUYEREREZENZB4e0A57HCVzvoNh+2Yom7eGIqyx1LEqRBRFmM9lwRi/G4bkfYC+tOwOmQyK5q2giu4ERXhzrpXmACzEiIiIiIhspGzRGsr2sTDui4Nu4Vx4vPwWBLVG6li3JepKYEhKhCFhDyznz1q3y2r5QxnTCar2sZB5eUuYsOZhIUZEREREVAnawcNgOpEBy9UrKP1rObSPjJQ6UjmiKMKceQKG+D0wHkgCjMayOxQKKFtFlrWdb9SEo18SYSFGRERERFQJglYLtxFjUPzd1zDs3QlFi9ZQhjeXOhYsRYUwXl902XIpx7pdFhhc1nY+Khoyd3cJExLAQoyIiIiIqNIUTcKh6twDht3boFv8OxSvvA3BzfFFjmixwHT8aNmiy2kHALO57A6VGsrIdlDFdIa8figEQXB4Nro1FmJERERERPdAM/BhmDLSYbl8CboVf8Bt1HiHPbcl7xoMiXthSNgD8Vqudbs8pEHZ6Fdkewga5712rSZjIUZEREREdA8ElQrax8ah+NvPYExKgLFlGyhbRdrt+USzGabDh2BI2APTkTRAFMvu0LpBFdWh7NqvuvXs9vxUNViIERERERHdI0VoGNQ9+0K/ZT10S+ZD3rARZJ5eVfoc5iuXy9rO74uDWFhg3S5v1ASq6M5QtoqEoFJV6XOS/bAQIyIiIiKqAuq+A2A8fAiWi+ehWzIfbuOfvedrskSjEcZDqWWLLp/IsG4XPDyhbB8LVXQnyOsE3Gt0kgALMSIiIiKiKiAolHAbNR5FX02HKe0AjPvjoWofW6nHMmdfgCFuN4xJCRBLiq8/gQBF02ZQxXSGollLCAq+lXdl/NcjIiIiIqoi8uB6UPd9EPq1K6FbsRiKxk0h8/Wr0LGivhTG1KSy0a8zmdbtgo8vVB06QhXdqcKPRc6PhRgRERERURVS9+gDU/oBmM9kQrf4N7hNmHLbRZNFUYT57BkY4/fAkLIP0JeW3SGTQdG8VdnoV9NmXHS5GmIhRkRERERUhQS5HNrHxqHoiw9hOnYUhr07oe7cvdw+YkkxDEmJZYsuXzhn3S6r7V/WeKN9DGRe3g5OTo7EQoyIiIiIqIrJ6wRAM3AISlcsRulfy6BoGgFZ7TownzoBQ/xuGA8kAyZj2c4KBZSt2kIV0wnyRvdx0eUagoUYEREREZEdqDp1gzEtFebjGSiZMxuwWGC5nGO9XxZUt2zR5bYdIHN3lzApSYGFGBERERGRHQgyGdxGjEXhZ+/DknOxbKNKDWVkO6hiOkNeP5SjXzUYCzEiIiIiIjuR+frBbfRTMMTtgrJZSyjbtIOg0Ugdi5wACzEiIiIiIjtSRrSAMqKF1DHIybAPJhERERERkYOxECMiIiIiInIwFmJEREREREQOxkKMiIiIiIjIwViIERERERERORgLMSIiIiIiIgdjIUZERERERORgLMSIiIiIiIgcjIUYERERERGRg7EQIyIiIiIicjAWYkRERERERA7GQoyIiIiIiMjBWIgRERERERE5GAsxIiIiIiIiB3OZQiw3NxejRo2Cl5cXfHx88OSTT6KoqOiOx5SWlmLixImoVasWPDw8MHToUOTk5FjvP3DgAB577DGEhIRAq9UiIiIC//vf/+z9UoiIiIiIqIZzmUJs1KhRSE9Px6ZNm7B69Wrs3LkTEyZMuOMxL730Ev766y8sWbIEO3bswIULFzBkyBDr/UlJSahTpw7mzZuH9PR0vPnmm3jjjTcwY8YMe78cIiIiIiKqwQRRFEWpQ9zNkSNH0KxZM+zbtw/t2rUDAKxfvx79+/fHuXPnEBwcfNMx+fn58Pf3x4IFC/DII48AAI4ePYqIiAjExcUhJibmls81ceJEHDlyBFu3bq1wvoKCAnh7eyM/Px9eXl6VeIVERERERFQdVLQ2cIkRsbi4OPj4+FiLMADo3bs3ZDIZEhISbnlMUlISjEYjevfubd0WHh6O+vXrIy4u7rbPlZ+fDz8/vzvm0ev1KCgoKHcjIiIiIiKqKIXUASoiOzsbderUKbdNoVDAz88P2dnZtz1GpVLBx8en3PaAgIDbHrN3714sXrwYa9asuWOe6dOn47333rtpOwsyIiIiIqKa7UZNcLeJh5IWYq+//jo+/fTTO+5z5MgRh2RJS0vDoEGDMG3aNNx///133PeNN97A1KlTrV+fP38ezZo1Q0hIiL1jEhERERGRCygsLIS3t/dt75e0EPvPf/6DcePG3XGfsLAwBAYG4tKlS+W2m0wm5ObmIjAw8JbHBQYGwmAwIC8vr9yoWE5Ozk3HHD58GL169cKECRPw1ltv3TW3Wq2GWq22fu3h4YGzZ8/C09MTgiDc9Xh7KigoQEhICM6ePcvr1eyA59e+eH7ti+fXvnh+7Yvn1754fu2L59e+nO38iqKIwsLCW/ax+CdJCzF/f3/4+/vfdb/Y2Fjk5eUhKSkJUVFRAICtW7fCYrEgOjr6lsdERUVBqVRiy5YtGDp0KAAgIyMDWVlZiI2Nte6Xnp6Onj17YuzYsfjoo48q9TpkMhnq1atXqWPtxcvLyym+Easrnl/74vm1L55f++L5tS+eX/vi+bUvnl/7cqbze6eRsBtcollHREQE+vXrh6effhqJiYnYs2cPJk2ahBEjRlgrzfPnzyM8PByJiYkAyl78k08+ialTp2Lbtm1ISkrC+PHjERsba+2YmJaWhh49euD+++/H1KlTkZ2djezsbFy+fFmy10pERERERNWfSzTrAID58+dj0qRJ6NWrF2QyGYYOHYpvvvnGer/RaERGRgZKSkqs27766ivrvnq9Hn379sWsWbOs9y9duhSXL1/GvHnzMG/ePOv2Bg0a4PTp0w55XUREREREVPO4TCHm5+eHBQsW3Pb+0NDQmzqTaDQazJw5EzNnzrzlMe+++y7efffdqowpObVajWnTppW7ho2qDs+vffH82hfPr33x/NoXz6998fzaF8+vfbnq+XWJBZ2JiIiIiIiqE5e4RoyIiIiIiKg6YSFGRERERETkYCzEiIiIiIiIHIyFGBERERERkYOxEHNBM2fORGhoKDQaDaKjo61rp91Keno6hg4ditDQUAiCgK+//tpxQV2ULef3xx9/RJcuXeDr6wtfX1/07t37jvuTbed3+fLlaNeuHXx8fODu7o42bdrg999/d2Ba12PL+f2nRYsWQRAEDB482L4BXZwt53fu3LkQBKHcTaPRODCt67H1+zcvLw8TJ05EUFAQ1Go17rvvPqxdu9ZBaV2PLee3e/fuN33/CoKAAQMGODCxa7H1+/frr79G06ZNodVqERISgpdeegmlpaUOSut6bDm/RqMR77//Pho1agSNRoPWrVtj/fr1DkxbQSK5lEWLFokqlUqcM2eOmJ6eLj799NOij4+PmJOTc8v9ExMTxZdffllcuHChGBgYKH711VeODexibD2/I0eOFGfOnCmmpKSIR44cEceNGyd6e3uL586dc3By12Dr+d22bZu4fPly8fDhw+KJEyfEr7/+WpTL5eL69esdnNw12Hp+b8jMzBTr1q0rdunSRRw0aJBjwrogW8/vL7/8Inp5eYkXL1603rKzsx2c2nXYen71er3Yrl07sX///uLu3bvFzMxMcfv27WJqaqqDk7sGW8/v1atXy33vpqWliXK5XPzll18cG9xF2Hp+58+fL6rVanH+/PliZmamuGHDBjEoKEh86aWXHJzcNdh6fl999VUxODhYXLNmjXjy5Elx1qxZokajEZOTkx2c/M5YiLmYDh06iBMnTrR+bTabxeDgYHH69Ol3PbZBgwYsxO7iXs6vKIqiyWQSPT09xV9//dVeEV3avZ5fURTFyMhI8a233rJHPJdXmfNrMpnEjh07ij/99JM4duxYFmJ3YOv5/eWXX0Rvb28HpXN9tp7f7777TgwLCxMNBoOjIrq0e/35+9VXX4menp5iUVGRvSK6NFvP78SJE8WePXuW2zZ16lSxU6dOds3pqmw9v0FBQeKMGTPKbRsyZIg4atQou+a0FacmuhCDwYCkpCT07t3buk0mk6F3796Ii4uTMFn1UBXnt6SkBEajEX5+fvaK6bLu9fyKoogtW7YgIyMDXbt2tWdUl1TZ8/v++++jTp06ePLJJx0R02VV9vwWFRWhQYMGCAkJwaBBg5Cenu6IuC6nMud31apViI2NxcSJExEQEIAWLVrg448/htlsdlRsl1EVv99+/vlnjBgxAu7u7vaK6bIqc347duyIpKQk6/S6U6dOYe3atejfv79DMruSypxfvV5/01RwrVaL3bt32zWrrRRSB6CKu3LlCsxmMwICAsptDwgIwNGjRyVKVX1Uxfl97bXXEBwcXO6HBZWp7PnNz89H3bp1odfrIZfLMWvWLPTp08fecV1OZc7v7t278fPPPyM1NdUBCV1bZc5v06ZNMWfOHLRq1Qr5+fn4/PPP0bFjR6Snp6NevXqOiO0yKnN+T506ha1bt2LUqFFYu3YtTpw4geeffx5GoxHTpk1zRGyXca+/3xITE5GWloaff/7ZXhFdWmXO78iRI3HlyhV07twZoijCZDLh2WefxX//+19HRHYplTm/ffv2xZdffomuXbuiUaNG2LJlC5YvX+50H9RwRIyoinzyySdYtGgRVqxYwQvyq5CnpydSU1Oxb98+fPTRR5g6dSq2b98udSyXV1hYiNGjR+PHH39E7dq1pY5TLcXGxmLMmDFo06YNunXrhuXLl8Pf3x/ff/+91NGqBYvFgjp16uCHH35AVFQUhg8fjjfffBOzZ8+WOlq18/PPP6Nly5bo0KGD1FGqje3bt+Pjjz/GrFmzkJycjOXLl2PNmjX44IMPpI5WLfzvf/9DkyZNEB4eDpVKhUmTJmH8+PGQyZyr9OGImAupXbs25HI5cnJyym3PyclBYGCgRKmqj3s5v59//jk++eQTbN68Ga1atbJnTJdV2fMrk8nQuHFjAECbNm1w5MgRTJ8+Hd27d7dnXJdj6/k9efIkTp8+jQcffNC6zWKxAAAUCgUyMjLQqFEj+4Z2IVXx81epVCIyMhInTpywR0SXVpnzGxQUBKVSCblcbt0WERGB7OxsGAwGqFQqu2Z2Jffy/VtcXIxFixbh/ffft2dEl1aZ8/v2229j9OjReOqppwAALVu2RHFxMSZMmIA333zT6QoGKVXm/Pr7+2PlypUoLS3F1atXERwcjNdffx1hYWGOiFxh/Fd2ISqVClFRUdiyZYt1m8ViwZYtWxAbGythsuqhsuf3//7v//DBBx9g/fr1aNeunSOiuqSq+v61WCzQ6/X2iOjSbD2/4eHhOHToEFJTU623hx56CD169EBqaipCQkIcGd/pVcX3r9lsxqFDhxAUFGSvmC6rMue3U6dOOHHihPUDBAA4duwYgoKCWIT9y718/y5ZsgR6vR6PP/64vWO6rMqc35KSkpuKrRsfKoiiaL+wLuhevn81Gg3q1q0Lk8mEZcuWYdCgQfaOaxuJm4WQjRYtWiSq1Wpx7ty54uHDh8UJEyaIPj4+1pbIo0ePFl9//XXr/nq9XkxJSRFTUlLEoKAg8eWXXxZTUlLE48ePS/USnJqt5/eTTz4RVSqVuHTp0nJtfgsLC6V6CU7N1vP78ccfixs3bhRPnjwpHj58WPz8889FhUIh/vjjj1K9BKdm6/n9N3ZNvDNbz+97770nbtiwQTx58qSYlJQkjhgxQtRoNGJ6erpUL8Gp2Xp+s7KyRE9PT3HSpEliRkaGuHr1arFOnTrihx9+KNVLcGqV/fnQuXNncfjw4Y6O63JsPb/Tpk0TPT09xYULF4qnTp0SN27cKDZq1EgcNmyYVC/Bqdl6fuPj48Vly5aJJ0+eFHfu3Cn27NlTbNiwoXjt2jWJXsGtsRBzQd9++61Yv359UaVSiR06dBDj4+Ot93Xr1k0cO3as9evMzEwRwE23bt26OT64i7Dl/DZo0OCW53fatGmOD+4ibDm/b775pti4cWNRo9GIvr6+YmxsrLho0SIJUrsOW87vv7EQuztbzu+LL75o3TcgIEDs37+/061h42xs/f7du3evGB0dLarVajEsLEz86KOPRJPJ5ODUrsPW83v06FERgLhx40YHJ3VNtpxfo9Eovvvuu2KjRo1EjUYjhoSEiM8//7zTFQrOxJbzu337djEiIkJUq9VirVq1xNGjR4vnz5+XIPWdCaLI8U8iIiIiIiJH4jViREREREREDsZCjIiIiIiIyMFYiBERERERETkYCzEiIiIiIiIHYyFGRERERETkYCzEiIiIiIiIHIyFGBERERERkYOxECMiIiIiInIwFmJERFQjhIaG4uuvv67w/tu3b4cgCMjLy7NbpooaN24cBg8eLHUMIiKqQoIoiqLUIYiIiG4QBOGO90+bNg3vvvuuzY97+fJluLu7w83NrUL7GwwG5ObmIiAg4K6Z7tWPP/6IGTNm4OTJk1AoFGjYsCGGDRuGN954AwCQn58PURTh4+Nj1xxEROQ4CqkDEBER/dPFixetf1+8eDHeeecdZGRkWLd5eHhY/y6KIsxmMxSKu/868/f3tymHSqVCYGCgTcdUxpw5c/Diiy/im2++Qbdu3aDX63Hw4EGkpaVZ9/H29rZ7DiIicixOTSQiIqcSGBhovXl7e0MQBOvXR48ehaenJ9atW4eoqCio1Wrs3r0bJ0+exKBBgxAQEAAPDw+0b98emzdvLve4/56aKAgCfvrpJzz88MNwc3NDkyZNsGrVKuv9/56aOHfuXPj4+GDDhg2IiIiAh4cH+vXrV65wNJlMmDJlCnx8fFCrVi289tprGDt27B2nFa5atQrDhg3Dk08+icaNG6N58+Z47LHH8NFHH1n3+efUxNOnT0MQhJtu3bt3t+6/e/dudOnSBVqtFiEhIZgyZQqKi4ut98+aNQtNmjSBRqNBQEAAHnnkERv+hYiIqCqwECMiIpfz+uuv45NPPsGRI0fQqlUrFBUVoX///tiyZQtSUlLQr18/PPjgg8jKyrrj47z33nsYNmwYDh48iP79+2PUqFHIzc297f4lJSX4/PPP8fvvv2Pnzp3IysrCyy+/bL3/008/xfz58/HLL79gz549KCgowMqVK++YITAwEPHx8Thz5kyFXntISAguXrxovaWkpKBWrVro2rUrAODkyZPo168fhg4dioMHD2Lx4sXYvXs3Jk2aBADYv38/pkyZgvfffx8ZGRlYv3699VgiInIgkYiIyEn98ssvore3t/Xrbdu2iQDElStX3vXY5s2bi99++6316wYNGohfffWV9WsA4ltvvWX9uqioSAQgrlu3rtxzXbt2zZoFgHjixAnrMTNnzhQDAgKsXwcEBIifffaZ9WuTySTWr19fHDRo0G1zXrhwQYyJiREBiPfdd584duxYcfHixaLZbLbuM3bs2Fs+hk6nE6Ojo8WBAwda93/yySfFCRMmlNtv165dokwmE3U6nbhs2TLRy8tLLCgouG0mIiKyP46IERGRy2nXrl25r4uKivDyyy8jIiICPj4+8PDwwJEjR+46ItaqVSvr393d3eHl5YVLly7ddn83Nzc0atTI+nVQUJB1//z8fOTk5KBDhw7W++VyOaKiou6YISgoCHFxcTh06BBeeOEFmEwmjB07Fv369YPFYrnjsU888QQKCwuxYMECyGRlv9IPHDiAuXPnwsPDw3rr27cvLBYLMjMz0adPHzRo0ABhYWEYPXo05s+fj5KSkjs+DxERVT0WYkRE5HLc3d3Lff3yyy9jxYoV+Pjjj7Fr1y6kpqaiZcuWMBgMd3wcpVJZ7mtBEO5Y/Nxqf7GKmg+3aNECzz//PObNm4dNmzZh06ZN2LFjx233//DDD7FhwwasWrUKnp6e1u1FRUV45plnkJqaar0dOHAAx48fR6NGjeDp6Ynk5GQsXLgQQUFBeOedd9C6dWunaNNPRFSTsGsiERG5vD179mDcuHF4+OGHAZQVI6dPn3ZoBm9vbwQEBGDfvn3Wa67MZjOSk5PRpk0bmx6rWbNmAFCuwcY/LVu2DO+//z7WrVtXboQOANq2bYvDhw+jcePGt318hUKB3r17o3fv3pg2bRp8fHywdetWDBkyxKacRERUeSzEiIjI5TVp0gTLly/Hgw8+CEEQ8Pbbb991Wp89TJ48GdOnT0fjxo0RHh6Ob7/9FteuXbvjOmTPPfccgoOD0bNnT9SrVw8XL17Ehx9+CH9/f8TGxt60f1paGsaMGYPXXnsNzZs3R3Z2NoCydvt+fn547bXXEBMTg0mTJuGpp56Cu7s7Dh8+jE2bNmHGjBlYvXo1Tp06ha5du8LX1xdr166FxWJB06ZN7XZeiIjoZpyaSERELu/LL7+Er68vOnbsiAcffBB9+/ZF27ZtHZ7jtddew2OPPYYxY8YgNjbWen2WRqO57TG9e/dGfHw8Hn30Udx3330YOnQoNBoNtmzZglq1at20//79+1FSUoIPP/wQQUFB1tuN0axWrVphx44dOHbsGLp06YLIyEi88847CA4OBgD4+Phg+fLl6NmzJyIiIjB79mwsXLgQzZs3t89JISKiWxLEqprcTkREROVYLBZERERg2LBh+OCDD6SOQ0REToRTE4mIiKrImTNnsHHjRnTr1g16vR4zZsxAZmYmRo4cKXU0IiJyMpyaSEREVEVkMhnmzp2L9u3bo1OnTjh06BA2b96MiIgIqaMREZGT4dREIiIiIiIiB+OIGBERERERkYOxECMiIiIiInIwFmJEREREREQOxkKMiIiIiIjIwViIERERERERORgLMSIiIiIiIgdjIUZERERERORgLMSIiIiIiIgc7P8BQ+GSXw+excIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the training MAE\n",
    "sns.lineplot(data=results, x=\"Train Sizes\", y=\"R2 Train\", label=\"R2 Train\", color=\"#0081a7\")\n",
    "\n",
    "# Plot the testing MAE\n",
    "sns.lineplot(data=results, x=\"Train Sizes\", y=\"R2 Test\", label=\"R2 Test\", color=\"#f07167\")\n",
    "\n",
    "# Adding some plot details\n",
    "plt.title(\"R2 Comparison for Train and Test Sets\")\n",
    "plt.ylabel(\"R2\")\n",
    "plt.xlabel(\"Training Sizes\")\n",
    "plt.legend(title=\"Data Type\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90ba46e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5d96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
