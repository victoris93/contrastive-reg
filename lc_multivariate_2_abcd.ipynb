{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs3/well/margulies/users/cpy397/python/neuro/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import yaml\n",
    "import wandb\n",
    "import xarray as xr\n",
    "import asyncio\n",
    "import submitit\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from nilearn.connectome import sym_matrix_to_vec, vec_to_sym_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "# from augmentations import augs, aug_args\n",
    "import glob, os, shutil\n",
    "from nilearn.datasets import fetch_atlas_schaefer_2018\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from ContModeling.utils import gaussian_kernel, cauchy, standardize, save_embeddings\n",
    "from ContModeling.losses import LogEuclideanLoss, NormLoss, KernelizedSupCon, OutlierRobustMSE\n",
    "from ContModeling.models import PhenoProj\n",
    "from ContModeling.helper_classes import MatData\n",
    "from ContModeling.viz_func import wandb_plot_acc_vs_baseline, wandb_plot_test_recon_corr, wandb_plot_individual_recon\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run, train_ratio, train_dataset, test_dataset, mean, std, B_init_fMRI, cfg, model=None, device=device):\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    # MODEL DIMS\n",
    "    input_dim_feat = cfg.input_dim_feat\n",
    "    input_dim_target = cfg.input_dim_target\n",
    "    hidden_dim = cfg.hidden_dim\n",
    "    output_dim_target = cfg.output_dim_target\n",
    "    output_dim_feat = cfg.output_dim_feat\n",
    "    kernel = SUPCON_KERNELS[cfg.SupCon_kernel]\n",
    "    \n",
    "    # TRAINING PARAMS\n",
    "    lr = cfg.lr\n",
    "    batch_size = cfg.batch_size\n",
    "    dropout_rate = cfg.dropout_rate\n",
    "    weight_decay = cfg.weight_decay\n",
    "    num_epochs = cfg.num_epochs\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    mean= torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    if model is None:\n",
    "        model = PhenoProj(\n",
    "            input_dim_feat,\n",
    "            input_dim_target,\n",
    "            hidden_dim,\n",
    "            output_dim_target,\n",
    "            output_dim_feat,\n",
    "            dropout_rate,\n",
    "            cfg\n",
    "        ).to(device)\n",
    "\n",
    "    if cfg.mat_ae_pretrained:\n",
    "        print(\"Loading pretrained MatrixAutoencoder...\")\n",
    "        state_dict = torch.load(f\"{cfg.output_dir}/{cfg.pretrained_mat_ae_exp}/saved_models/autoencoder_weights_fold{cfg.best_mat_ae_fold}.pth\")\n",
    "        model.matrix_ae.load_state_dict(state_dict)\n",
    "    else:\n",
    "        model.matrix_ae.enc_mat1.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "        model.matrix_ae.enc_mat2.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "    \n",
    "    if cfg.target_ae_pretrained:\n",
    "        print(\"Loading pretrained TargetAutoencoder...\")\n",
    "        state_dict = torch.load(f\"{cfg.output_dir}/{cfg.pretrained_target_ae_exp}/saved_models/autoencoder_weights_fold{cfg.best_target_ae_fold}.pth\")\n",
    "        model.target_ae.load_state_dict(state_dict)\n",
    "\n",
    "    criterion_pft = KernelizedSupCon(\n",
    "        method=\"expw\",\n",
    "        temperature=cfg.pft_temperature,\n",
    "        base_temperature= cfg.pft_base_temperature,\n",
    "        reg_term = cfg.pft_reg_term,\n",
    "        kernel=kernel,\n",
    "        krnl_sigma=cfg.pft_sigma,\n",
    "    )\n",
    "\n",
    "    criterion_ptt = KernelizedSupCon(\n",
    "        method=\"expw\",\n",
    "        temperature=cfg.ptt_temperature,\n",
    "        base_temperature= cfg.ptt_base_temperature,\n",
    "        reg_term = cfg.ptt_reg_term,\n",
    "        kernel=kernel,\n",
    "        krnl_sigma=cfg.ptt_sigma,\n",
    "    )\n",
    "    \n",
    "    feature_autoencoder_crit = EMB_LOSSES[cfg.feature_autoencoder_crit]\n",
    "    target_decoding_crit = EMB_LOSSES[cfg.target_decoding_crit]\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1, patience = cfg.scheduler_patience)\n",
    "\n",
    "    loss_terms = []\n",
    "    validation = []\n",
    "    autoencoder_features = []\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    wandb.init(project=cfg.project,\n",
    "        mode = \"offline\",\n",
    "        name=f\"{cfg.experiment_name}_run{run}_train_ratio_{train_ratio}\",\n",
    "        dir = cfg.output_dir,\n",
    "        config = OmegaConf.to_container(cfg, resolve=True))\n",
    "\n",
    "    with tqdm(range(num_epochs), desc=\"Epochs\", leave=False) as pbar:\n",
    "        for epoch in pbar:\n",
    "            model.train()\n",
    "\n",
    "            loss_terms_batch = defaultdict(lambda:0)\n",
    "            for features, targets in train_loader:\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                features = features.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                ## FEATURE ENCODING\n",
    "                embedded_feat = model.encode_features(features)\n",
    "                ## FEATURE DECODING\n",
    "                if not cfg.mat_ae_pretrained:\n",
    "                    reconstructed_feat = model.decode_features(embedded_feat)\n",
    "                    ## FEATURE DECODING LOSS\n",
    "                    feature_autoencoder_loss = feature_autoencoder_crit(features, reconstructed_feat) / 10_000\n",
    "                \n",
    "                ## REDUCED FEAT TO TARGET EMBEDDING\n",
    "                embedded_feat_vectorized = sym_matrix_to_vec(embedded_feat.detach().cpu().numpy(), discard_diagonal = True)\n",
    "                embedded_feat_vectorized = torch.tensor(embedded_feat_vectorized).to(device)\n",
    "\n",
    "                features_vectorized = sym_matrix_to_vec(features.detach().cpu().numpy(), discard_diagonal = True)\n",
    "                features_vectorized = torch.tensor(features_vectorized).to(device)\n",
    "                features_vectorized = nn.functional.normalize(features_vectorized, p=2, dim=1)\n",
    "\n",
    "                ## TARGET DECODING FROM MAT EMBEDDINGs\n",
    "                reduced_feat_embedding = model.transfer_embedding(embedded_feat_vectorized)\n",
    "                out_target_decoded = model.decode_targets(reduced_feat_embedding)\n",
    "\n",
    "                ## KERNLIZED LOSS: MAT embedding vs MAT\n",
    "\n",
    "                if cfg.SupConLoss_on_mat:\n",
    "                    kernel_embedded_feature_loss, direction_reg_features = criterion_ptt(reduced_feat_embedding.unsqueeze(1), features_vectorized)\n",
    "                    kernel_embedded_feature_loss = 100 * kernel_embedded_feature_loss\n",
    "                    direction_reg_features = 100 * direction_reg_features\n",
    "\n",
    "\n",
    "                ## KERNLIZED LOSS: MAT embedding vs targets\n",
    "                kernel_embedded_target_loss, direction_reg_target = criterion_ptt(reduced_feat_embedding.unsqueeze(1), targets)\n",
    "                kernel_embedded_target_loss = 100 * kernel_embedded_target_loss\n",
    "                direction_reg_target = 100 * direction_reg_target\n",
    "\n",
    "                ## LOSS: TARGET DECODING FROM TARGET EMBEDDING\n",
    "                if cfg.target_decoding_crit == 'Huber' and cfg.huber_delta != 'None':\n",
    "                    target_decoding_crit = nn.HuberLoss(delta = cfg.huber_delta)\n",
    "                \n",
    "                target_decoding_from_reduced_emb_loss = target_decoding_crit(targets, out_target_decoded) / 10\n",
    "\n",
    "\n",
    "                ## SUM ALL LOSSES\n",
    "                loss = kernel_embedded_target_loss + target_decoding_from_reduced_emb_loss\n",
    "                \n",
    "                if cfg.SupConLoss_on_mat:\n",
    "                    loss += kernel_embedded_feature_loss\n",
    "\n",
    "                if not cfg.mat_ae_pretrained:\n",
    "                    loss += feature_autoencoder_loss\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                if cfg.clip_grad:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                if cfg.log_gradients:\n",
    "                    for name, param in model.named_parameters():\n",
    "                        if param.grad is not None:\n",
    "                            wandb.log({\n",
    "                                \"Epoch\": epoch,\n",
    "                                f\"Gradient Norm/{name}\": param.grad.norm().item()\n",
    "                                })  \n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_terms_batch['loss'] = loss.item() / len(features)\n",
    "                loss_terms_batch['kernel_embedded_target_loss'] = kernel_embedded_target_loss.item() / len(features)\n",
    "                loss_terms_batch['target_decoding_from_reduced_emb_loss'] = target_decoding_from_reduced_emb_loss.item() / len(features)\n",
    "                loss_terms_batch['direction_reg_target_loss'] = direction_reg_target.item() / len(features)\n",
    "                \n",
    "                if cfg.SupConLoss_on_mat:\n",
    "                    loss_terms_batch['direction_reg_features_loss'] = direction_reg_features.item() / len(features)\n",
    "                    loss_terms_batch['kernel_embedded_feature_loss'] = kernel_embedded_feature_loss.item() / len(features)\n",
    "                \n",
    "                if not cfg.mat_ae_pretrained:\n",
    "                    loss_terms_batch['feature_autoencoder_loss'] = feature_autoencoder_loss.item() / len(features)\n",
    "                    wandb.log({\n",
    "                        'Epoch': epoch,\n",
    "                        'feature_autoencoder_loss': loss_terms_batch['feature_autoencoder_loss']\n",
    "                    })\n",
    "                \n",
    "                wandb.log({\n",
    "                    'Epoch': epoch,\n",
    "                    'Run': run,\n",
    "                    'total_loss': loss_terms_batch['loss'],\n",
    "                    'kernel_embedded_target_loss': loss_terms_batch['kernel_embedded_target_loss'],\n",
    "                    'direction_reg_target_loss': loss_terms_batch['direction_reg_target_loss'],\n",
    "                    'target_decoding_from_reduced_emb_loss': loss_terms_batch['target_decoding_from_reduced_emb_loss']\n",
    "                })\n",
    "\n",
    "            if cfg.SupConLoss_on_mat:\n",
    "                wandb.log({\n",
    "                    'Epoch': epoch,\n",
    "                    'Run': run,\n",
    "                    'direction_reg_features_loss': loss_terms_batch['direction_reg_features_loss'],\n",
    "                    'kernel_embedded_feature_loss': loss_terms_batch['kernel_embedded_feature_loss'],\n",
    "                })\n",
    "\n",
    "            loss_terms_batch['epoch'] = epoch\n",
    "            loss_terms.append(loss_terms_batch)\n",
    "\n",
    "            model.eval()\n",
    "            mape_batch = 0\n",
    "            corr_batch = 0\n",
    "            with torch.no_grad():\n",
    "                for (features, targets) in test_loader:\n",
    "                    \n",
    "                    features, targets = features.to(device), targets.to(device)                    \n",
    "                    out_feat = model.encode_features(features)\n",
    "                    out_feat = torch.tensor(sym_matrix_to_vec(out_feat.detach().cpu().numpy(), discard_diagonal = True)).float().to(device)\n",
    "                    transfer_out_feat = model.transfer_embedding(out_feat)\n",
    "                    out_target_decoded = model.decode_targets(transfer_out_feat)\n",
    "                    \n",
    "                    epsilon = 1e-8\n",
    "                    mape =  torch.mean(torch.abs((targets - out_target_decoded)) / torch.abs((targets + epsilon))) * 100\n",
    "                    corr =  spearmanr(targets.cpu().numpy().flatten(), out_target_decoded.cpu().numpy().flatten())[0]\n",
    "                    mape_batch+=mape.item()\n",
    "                    corr_batch += corr\n",
    "\n",
    "                mape_batch = mape_batch/len(test_loader)\n",
    "                corr_batch = corr_batch/len(test_loader)\n",
    "                validation.append(mape_batch)\n",
    "\n",
    "            wandb.log({\n",
    "                'Target MAPE/val' : mape_batch,\n",
    "                'Target Corr/val': corr_batch,\n",
    "                })\n",
    "            \n",
    "            scheduler.step(mape_batch)\n",
    "            if np.log10(scheduler._last_lr[0]) < -4:\n",
    "                break\n",
    "\n",
    "            pbar.set_postfix_str(\n",
    "                f\"Epoch {epoch} \"\n",
    "                f\"| Loss {loss_terms[-1]['loss']:.02f} \"\n",
    "                f\"| Corr {corr_batch:.02f} \"\n",
    "            )\n",
    "    wandb.finish()\n",
    "    loss_terms = pd.DataFrame(loss_terms)\n",
    "    return loss_terms, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_LOSSES ={\n",
    "    'Norm': NormLoss(),\n",
    "    'LogEuclidean': LogEuclideanLoss(),\n",
    "    'MSE': nn.functional.mse_loss,\n",
    "    'MSERobust': OutlierRobustMSE(),\n",
    "    'Huber': nn.HuberLoss(),\n",
    "    'cosine': nn.functional.cosine_embedding_loss,\n",
    "}\n",
    "\n",
    "SUPCON_KERNELS = {\n",
    "    'cauchy': cauchy,\n",
    "    'gaussian_kernel': gaussian_kernel,\n",
    "    'None': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRun(submitit.helpers.Checkpointable):\n",
    "    def __init__(self):\n",
    "        self.results = None\n",
    "        self.embeddings = None\n",
    "\n",
    "    def __call__(self, train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state=None, device=None, save_model = True, path: Path = None):\n",
    "        if self.results is None:\n",
    "            if device is None:\n",
    "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                print(f\"Device {device}, ratio {train_ratio}\", flush=True)\n",
    "            if not isinstance(random_state, np.random.RandomState):\n",
    "                random_state = np.random.RandomState(random_state)\n",
    "\n",
    "            augmentations = cfg.augmentation\n",
    "\n",
    "            recon_mat_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.reconstructed_dir)\n",
    "            os.makedirs(recon_mat_dir, exist_ok=True)\n",
    "    \n",
    "            predictions = {}\n",
    "            autoencoder_features = {}\n",
    "            losses = []\n",
    "            self.embeddings = {'train': [], 'test': []}\n",
    "            self.run = run\n",
    "\n",
    "            if cfg.mat_ae_pretrained:\n",
    "                print(\"Loading test indices from the pretraining experiment...\")\n",
    "                test_indices = np.load(f\"{cfg.output_dir}/{cfg.pretrained_mat_ae_exp}/test_idx.npy\")\n",
    "                train_indices = np.setdiff1d(indices, test_indices)\n",
    "            elif cfg.external_test_mode:\n",
    "                test_scanners = list(cfg.test_scanners)\n",
    "                xr_dataset = xr.open_dataset(cfg.dataset_path)\n",
    "                scanner_mask = np.sum([xr_dataset.isin(scanner).scanner.values for scanner in test_scanners],\n",
    "                                    axis = 0).astype(bool)\n",
    "                test_indices = indices[scanner_mask]\n",
    "                train_indices = indices[~scanner_mask]\n",
    "                del xr_dataset\n",
    "            else:\n",
    "                run_indices = random_state.choice(indices, run_size, replace=False)\n",
    "                train_indices, test_indices = train_test_split(run_indices, test_size=test_size, random_state=random_state)\n",
    "                \n",
    "            train_dataset = Subset(dataset, train_indices)\n",
    "            test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "            train_features = train_dataset.dataset.matrices[train_dataset.indices]\n",
    "            train_targets = train_dataset.dataset.targets[train_dataset.indices].numpy()\n",
    "            std_train_targets, mean, std= standardize(train_targets)\n",
    "            # train_targets = np.log1p(train_targets+1)\n",
    "            # scaler = MinMaxScaler().fit(train_targets)\n",
    "            # train_targets = scaler.transform(train_targets)\n",
    "\n",
    "            input_dim_feat =cfg.input_dim_feat\n",
    "            output_dim_feat = cfg.output_dim_feat\n",
    "\n",
    "            ## Weight initialization for bilinear layer\n",
    "            mean_f = torch.mean(train_features, dim=0).to(device)\n",
    "            [D,V] = torch.linalg.eigh(mean_f,UPLO = \"U\")\n",
    "            B_init_fMRI = V[:,input_dim_feat-output_dim_feat:] \n",
    "            test_features= test_dataset.dataset.matrices[test_dataset.indices].numpy()\n",
    "            test_targets = test_dataset.dataset.targets[test_dataset.indices].numpy()\n",
    "            # test_targets = np.log1p(test_targets+1)\n",
    "            # test_targets = scaler.transform(test_targets)\n",
    "\n",
    "            ### Augmentation\n",
    "            if augmentations != 'None':\n",
    "#                 aug_params = {}\n",
    "                if not isinstance(augmentations, list):\n",
    "                    augmentations = [augmentations]\n",
    "                n_augs = len(augmentations)\n",
    "                vect_train_features = sym_matrix_to_vec(train_features, discard_diagonal=True)\n",
    "                n_samples = len(train_dataset)\n",
    "                n_features = vect_train_features.shape[-1]\n",
    "                new_train_features = np.zeros((n_samples + n_samples * n_augs, 1, n_features))\n",
    "                new_train_features[:n_samples, 0, :] = vect_train_features\n",
    "\n",
    "                for i, aug in enumerate(augmentations):\n",
    "                    transform = augs[aug]\n",
    "                    transform_args = aug_args[aug]\n",
    "#                     aug_params[aug] = transform_args # to save later in the metrics df\n",
    "\n",
    "                    num_aug = i + 1\n",
    "                    aug_features = np.array([transform(sample, **transform_args) for sample in train_features])\n",
    "                    aug_features = sym_matrix_to_vec(aug_features, discard_diagonal=True)\n",
    "\n",
    "                    new_train_features[n_samples * num_aug: n_samples * (num_aug + 1), 0, :] = aug_features\n",
    "\n",
    "                train_features = new_train_features\n",
    "                train_targets = np.concatenate([train_targets]*(n_augs + 1), axis=0)\n",
    "            \n",
    "            train_dataset = TensorDataset(train_features, torch.from_numpy(train_targets).to(torch.float32))\n",
    "            test_dataset = TensorDataset(torch.from_numpy(test_features).to(torch.float32), torch.from_numpy(test_targets).to(torch.float32))\n",
    "\n",
    "            loss_terms, model = train(run, train_ratio, train_dataset, test_dataset,mean, std, B_init_fMRI, cfg, device=device)\n",
    "            losses.append(loss_terms.eval(\"train_ratio = @train_ratio\").eval(\"run = @run\"))\n",
    "\n",
    "            wandb.init(project=cfg.project,\n",
    "                mode = \"offline\",\n",
    "                name=f\"TEST_{cfg.experiment_name}_run{run}_train_ratio_{train_ratio}\",\n",
    "                dir = cfg.output_dir,\n",
    "                config = OmegaConf.to_container(cfg, resolve=True))\n",
    "            \n",
    "            embedding_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.embedding_dir)\n",
    "            os.makedirs(embedding_dir, exist_ok=True)\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                train_dataset = Subset(dataset, train_indices)\n",
    "                train_features = train_dataset.dataset.matrices[train_dataset.indices].numpy()\n",
    "                train_targets = train_dataset.dataset.targets[train_dataset.indices].numpy()\n",
    "                # train_targets = np.log1p(train_targets+1)\n",
    "                train_dataset = TensorDataset(torch.from_numpy(train_features).to(torch.float32), torch.from_numpy(train_targets).to(torch.float32))\n",
    "\n",
    "                for label, d, d_indices in (('train', train_dataset, train_indices), ('test', test_dataset, test_indices)):\n",
    "                    is_test = True\n",
    "                    if label == 'train':\n",
    "                        is_test = False\n",
    "                    \n",
    "                    X, y = zip(*d)\n",
    "                    X = torch.stack(X).to(device)\n",
    "                    y = torch.stack(y).to(device)\n",
    "                    X_embedded, y_embedded = model.forward(X, y)\n",
    "                                        \n",
    "                    if label == 'test' and train_ratio == 1.0:\n",
    "                        np.save(f'{recon_mat_dir}/test_idx_run{run}',d_indices)\n",
    "                        recon_mat = model.decode_features(X_embedded)\n",
    "                        mape_mat = torch.abs((X - recon_mat) / (X + 1e-10)) * 100\n",
    "                        \n",
    "                        wandb_plot_test_recon_corr(wandb, cfg.experiment_name, cfg.work_dir, recon_mat.cpu().numpy(), X.cpu().numpy(), mape_mat.cpu().numpy(), True, run)\n",
    "                        wandb_plot_individual_recon(wandb, cfg.experiment_name, cfg.work_dir, d_indices, recon_mat.cpu().numpy(), X.cpu().numpy(), mape_mat.cpu().numpy(), 0, True, run)\n",
    "\n",
    "                        np.save(f'{recon_mat_dir}/recon_mat_run{run}', recon_mat.cpu().numpy())\n",
    "                        np.save(f'{recon_mat_dir}/mape_mat_run{run}', mape_mat.cpu().numpy())\n",
    "\n",
    "                    X_embedded = X_embedded.cpu().numpy()\n",
    "                    X_embedded = torch.tensor(sym_matrix_to_vec(X_embedded, discard_diagonal=True)).to(torch.float32).to(device)\n",
    "                    X_emb_reduced = model.transfer_embedding(X_embedded).to(device)\n",
    "\n",
    "                    y_pred = model.decode_targets(X_emb_reduced)\n",
    "                    # y_pred = np.exp(y_pred.cpu().numpy())-1\n",
    "                    # y_pred = torch.tensor(y_pred).to(device)\n",
    "\n",
    "                    # y = np.exp(y.cpu().numpy())-1\n",
    "                    # y = torch.tensor(y).to(device)\n",
    "\n",
    "                    save_embeddings(X_embedded, \"mat\", cfg, is_test, run)\n",
    "                    save_embeddings(X_emb_reduced, \"joint\", cfg, is_test, run)\n",
    "\n",
    "                    if label == 'test':\n",
    "                        epsilon = 1e-8\n",
    "                        mape =  100 * torch.mean(torch.abs((y - y_pred)) / torch.abs((y + epsilon))).item()\n",
    "                        corr =  spearmanr(y.cpu().numpy().flatten(), y_pred.cpu().numpy().flatten())[0]\n",
    "\n",
    "                        wandb.log({\n",
    "                            'Run': run,\n",
    "                            'Test | Target MAPE/val' : mape,\n",
    "                            'Test | Target Corr/val': corr,\n",
    "                            'Test | Train ratio' : train_ratio\n",
    "                            })\n",
    "            \n",
    "                    predictions[(train_ratio, run, label)] = (y.cpu().numpy(), y_pred.cpu().numpy(), d_indices)\n",
    "                    for i, idx in enumerate(d_indices):\n",
    "                        self.embeddings[label].append({\n",
    "                            'index': idx,\n",
    "                            'target_embedded': y_embedded[i].cpu().numpy(),\n",
    "                            'feature_embedded': X_emb_reduced[i].cpu().numpy()\n",
    "                        })\n",
    "            wandb.finish()\n",
    "            \n",
    "            self.results = (losses, predictions, self.embeddings)\n",
    "\n",
    "        if save_model:\n",
    "            saved_models_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.model_weight_dir)\n",
    "            os.makedirs(saved_models_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"{saved_models_dir}/model_weights_run{run}.pth\")\n",
    "\n",
    "        return self.results\n",
    "\n",
    "    def checkpoint(self, *args, **kwargs):\n",
    "        print(\"Checkpointing\", flush=True)\n",
    "        return super().checkpoint(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ratio = 0.3\n",
    "# train_ratio = 1.0\n",
    "# dataset_path = \"/gpfs3/well/margulies/users/cpy397/contrastive-learning/data/abcd_dataset_400parcels_1.nc\"\n",
    "# dataset = MatData(dataset_path, [\"nihtbx_totalcomp_agecorrected\"], synth_exp = False, threshold=0)\n",
    "# n_sub = len(dataset)\n",
    "# indices = np.arange(n_sub)\n",
    "# train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "# test_size = int(test_ratio * n_sub)\n",
    "# run_size = test_size + train_size\n",
    "# random_state = np.random.RandomState(seed=42)\n",
    "# run_indices = random_state.choice(indices, run_size, replace=False)\n",
    "# train_indices, test_indices = train_test_split(run_indices, test_size=0.3, random_state=random_state)\n",
    "# train_dataset = Subset(dataset, train_indices)\n",
    "# test_dataset = Subset(dataset, test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features = train_dataset.dataset.matrices[train_dataset.indices]\n",
    "# train_targets = train_dataset.dataset.targets[train_dataset.indices].numpy()\n",
    "# std_train_targets, mean, std= standardize(train_targets)\n",
    "# # scaler = MinMaxScaler().fit(train_targets)\n",
    "# # train_targets = scaler.transform(train_targets)\n",
    "\n",
    "# input_dim_feat =cfg.input_dim_feat\n",
    "# output_dim_feat = cfg.output_dim_feat\n",
    "\n",
    "# ## Weight initialization for bilinear layer\n",
    "# mean_f = torch.mean(train_features, dim=0).to(device)\n",
    "# [D,V] = torch.linalg.eigh(mean_f,UPLO = \"U\")\n",
    "# B_init_fMRI = V[:,input_dim_feat-output_dim_feat:] \n",
    "# test_features= test_dataset.dataset.matrices[test_dataset.indices].numpy()\n",
    "# test_targets = test_dataset.dataset.targets[test_dataset.indices].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=28, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=228, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PhenoProj(\n",
    "#     cfg.input_dim_feat,\n",
    "#     cfg.input_dim_target,\n",
    "#     cfg.hidden_dim,\n",
    "#     cfg.output_dim_target,\n",
    "#     cfg.output_dim_feat,\n",
    "#     cfg.dropout_rate,\n",
    "#     cfg\n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrices = train_loader.dataset.dataset.matrices[:3]\n",
    "# matrices = matrices.to(device)\n",
    "# targets = train_loader.dataset.dataset.targets[:3]\n",
    "# targets = targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim_feat=cfg.input_dim_feat,\n",
    "# input_dim_target=cfg.input_dim_target,\n",
    "# hidden_dim=cfg.hidden_dim,\n",
    "# output_dim_target=cfg.output_dim_target,\n",
    "# output_dim_feat=cfg.output_dim_feat,\n",
    "# dropout_rate=cfg.dropout_rate,\n",
    "\n",
    "# enc_mat1 = nn.Linear(in_features=400, out_features=70 ,bias=False)\n",
    "# enc_mat2 = nn.Linear(in_features=400, out_features=70, bias=False)\n",
    "\n",
    "# enc_mat1.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "# enc_mat2.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "\n",
    "# enc_mat1.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "# enc_mat2.weight = torch.nn.Parameter(enc_mat1.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project: PhenProj\n",
      "experiment_name: abs_abcd_cog\n",
      "hypothesis: '-'\n",
      "input_dim_feat: 400\n",
      "output_dim_feat: 100\n",
      "hidden_dim: 100\n",
      "input_dim_target: 1\n",
      "output_dim_target: 50\n",
      "skip_enc1: false\n",
      "ReEig: false\n",
      "mat_ae_pretrained: false\n",
      "target_ae_pretrained: false\n",
      "pretrained_mat_ae_exp: internal_mat_ae_abcd\n",
      "pretrained_target_ae_exp: target_ae\n",
      "best_mat_ae_fold: 4\n",
      "best_target_ae_fold: 1\n",
      "synth_exp: false\n",
      "multi_gpu: true\n",
      "num_epochs: 100\n",
      "batch_size: 128\n",
      "n_runs: 1\n",
      "lr: 0.001\n",
      "weight_decay: 0\n",
      "dropout_rate: 0\n",
      "scheduler_patience: 10\n",
      "test_ratio: 0.3\n",
      "train_ratio: 1.0\n",
      "log_gradients: true\n",
      "clip_grad: true\n",
      "external_test_mode: false\n",
      "test_scanners:\n",
      "- GE MEDICAL SYSTEMS_DISCOVERY MR750\n",
      "- Philips Medical Systems_Achieva dStream\n",
      "- Philips Medical Systems_Ingenia\n",
      "SupCon_kernel: cauchy\n",
      "SupConLoss_on_mat: false\n",
      "pft_base_temperature: 0.07\n",
      "pft_temperature: 0.07\n",
      "pft_sigma: 1\n",
      "pft_reg_term: 0.01\n",
      "ptt_base_temperature: 0.07\n",
      "ptt_temperature: 0.07\n",
      "ptt_sigma: 1\n",
      "ptt_reg_term: 0.01\n",
      "feature_autoencoder_crit: Norm\n",
      "joint_embedding_crit: cosine\n",
      "target_decoding_crit: MSE\n",
      "huber_delta: 10\n",
      "augmentation: None\n",
      "mat_threshold: 0\n",
      "dataset_path: /gpfs3/well/margulies/users/cpy397/contrastive-learning/data/abcd_dataset_400parcels_1.nc\n",
      "targets:\n",
      "- nihtbx_totalcomp_agecorrected\n",
      "standardize_targets: false\n",
      "work_dir: /gpfs3/well/margulies/users/cpy397/contrastive-learning\n",
      "reconstructed_dir: recon_mat\n",
      "embedding_dir: embeddings\n",
      "model_weight_dir: saved_models\n",
      "output_dir: /gpfs3/well/margulies/users/cpy397/contrastive-learning/results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\".\"):\n",
    "    cfg = compose(config_name='main_model_config.yaml')\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Run:   0%|                                          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda, ratio 1.0\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wslv3cdj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>█▇▁▂▂▂▄▂▁▂▂▃▃▁▂▇▃▅▂▃▂▄▃▂▂▄▂▃▄▅▅▁▄▂▅▄▃▄▄▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>█▂▂▁▁▂▂▁▃▂▃▂▃▂▂▃▂▃▄▄▄▃▃▃▄▄▃▄▄▅▅▄▄▄▅▃▄▂▃▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>▅▃▁▁▁▃▂▂▂▁▃▁▃▁▄▄▃▂▄▃▃▄▄▂▃▄▅▅▅▆█▆▆▇▇█▅▆▅▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>▁▄▁▁▁▁▂▄▂▂▂▂▃▂▂▃▃▃▅▆▅▃▆▅▃▅▅▅▆█▆▅▅▆▇▄▆▅▅▅</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>█▄▇▃▂▄▂▅▃▃▃▂▁▂▃▂▃▃▃▄▃▂▂▁▂▃▅▂▃▃▁▄▁▂▃▂▁▄▁▂</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>▅▃▂▂▁▂▂▁▁▁▄▃▃▄▄▂▄▅▆▆▆█▅▇▃▅▇▅▄▅█▆▇▆▇▄▅▇▄▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>▄▆█▂▂▄▂▁▂▃▅▅▁▁▂▂▂▂▃▂▂▃▂▂▃▂▂▄▂▂▂▄▂▃▃▃▁▃▆▄</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>▁▅▆▆▆▅▇█▆█▇█▇▇▅▇▇▄▇▅▇▆▆▅▇▆▅▅▇▇▄▆▆▄▆██▇█▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>█▅▄▂▂▁▆▁▃▃▁▂▃▂▄▃▃▂▄▂▄▂▂▅▃▃▂▁▃▇▃▃▆▂▃▂▄▂▅▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>▁▁▆▅▇▃▂▂▆██▅▅▆▇▆▁▅▃▁▅▆▅▄▁▅▅▂▃▆▇▂▂▄▆▁▅▄▄▄</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>▁▂▇▄▄██▆▇▃▆▅▆▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▁</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>▁▁▂▅▆▇▆█▅▆█▄▂▂▃▃▃▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▂</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat1.weight</td><td>▁▁▆▅▇█▃▆▂▃▂▂▂▂▃▂▂▂▃▃▁▁▂▁▁▁▂▂▁▂▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat2.weight</td><td>▁▅█▃▂▄▂▄▄▃▄▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>▁▂▂▂▁▁▂▁▁▁▂▃▃▄█▄▂▂▂▂▃▂▂▂▂▁▂▂▁▄▂▁▂▂▂▁▆▃▃▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▃▂▄▃▅█▃▁▃▇</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>▁▁▁▂▁▂▂▂▃▂▂▂▃▁▃▂▂▃▂▂▃▃▃▂▃▆▃▄▂▄▄▅▄▄▅▅▅█▃▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▃▂▂▂▄▂▂▂▆▂▃▂▂▆▄▂▂▂▆▂█</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>▁▅▄▄▄▇█▆▅▃▃▅▃▅▅▅▅▃▃▄▄▃▃▄▃▃▄▄▄▄▃▂▃▂▂▃▃▂▂▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>▁▂▆▄█▇▄▃█▅█▇▇▇▇▅▅▆▄▄▆▆▃▄▄▆▆▅▆▆▃▅▅▃▆▅▇▆▄▆</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>▁▂▂▂▁▂▁▂▁▂▁▂▁▂▁▃▃▃▃▃▃▄▃▄▂▃▃▃▅▃█▃▃▄▂▂▃▄▄▅</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>▁▁▁▂▂▂▁▁▁▂▁▂▂▂▂▂▃▃▂▂▃▄▃▂▄▆▇▃▃▃▆▄▃▄▃▄▂▄█▆</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>▁▁▁▁▁▁▁▁▂▁▂▂▁▁▃▂▂▃▃▄▂▃▄▂▂▄▃▃▅▃▃▂▅▂▂█▃▆▇▇</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>▁▁▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▂▂▂▃▃▃▃▃▃▂▃▃▄▃▅█▃▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>▁▂▂▂▂▁▃▂▂▂▂▃▂▂▄▄▄▆▅▄▄▅▄▅▇▄▆█▅▅▃▅▄▅▄▅▅▃▄▄</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>▁▃▂▃▂▂▂▂▂▂▂▁▁▂▂▃▃▃▅▅▄▄▃▄▅▄▃▃▄▆▄▅▄▆▇▂▃▃▅█</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>▁▃▃▂▃▃▅▅▅▃█▅▇▄█▅▆▆▅▆▇▆▇▃▇▆▇▇▇▅▄▅▆▄▄▇▆▆▅▅</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>▁▂▂▂▃▅▅▆▂█▅▄▅▄▆▇▆▆▆▇▆▅▄▅█▆▅▅▇▅▄▄▅▆▇▃▅▇▅▅</td></tr><tr><td>Run</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Target Corr/val</td><td>▁▇▃▇█▃▃▄█▂▄▂▆▁▁▃▃▃</td></tr><tr><td>Target MAPE/val</td><td>█▇█▇▇█▅▅▄▄▅▄▄▃▂▃▁▂</td></tr><tr><td>direction_reg_target_loss</td><td>▆▄▄▄▅▃▅▇█▁▄▆▄█▇▄▇▄▆▄▅▄▃▇▃▄▃▄▄▇▂▄▃▃█▃▄▄▅▅</td></tr><tr><td>feature_autoencoder_loss</td><td>█▇▆▅▃▃▄▃▃▂▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▁▂▁▁▁▂</td></tr><tr><td>kernel_embedded_target_loss</td><td>█▄▁▂▂▃▂▃▇▂▃▃▁▃▃▃▂▇▂▂▂▃▂▂▁▂▂▂▁▂▂▂▁▂▂▂▂▁▂▁</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>▄▄▄▄▄▄▃▄▃▃▃▃▄█▃▃▃▃▃▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▄▁▃▁▁▁</td></tr><tr><td>total_loss</td><td>██▅▄▄▄▃▃▃▄▃█▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▅▂▁▂▁▁▂▁▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>18</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>0.484</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>0.01588</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>0.03919</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>0.28399</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>0.03082</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>0.03746</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>0.02168</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>0.62992</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>0.03686</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>0.03686</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat1.weight</td><td>0.00972</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat2.weight</td><td>0.00972</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>0.15947</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>0.01051</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>0.02461</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>0.05214</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>0.35981</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>0.24893</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>0.01196</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>0.01875</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>0.11316</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>0.20245</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>0.07863</td></tr><tr><td>Run</td><td>0</td></tr><tr><td>Target Corr/val</td><td>0.15142</td></tr><tr><td>Target MAPE/val</td><td>65.71161</td></tr><tr><td>direction_reg_target_loss</td><td>4.1687</td></tr><tr><td>feature_autoencoder_loss</td><td>0.40059</td></tr><tr><td>kernel_embedded_target_loss</td><td>9.67366</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>6.34444</td></tr><tr><td>total_loss</td><td>16.41868</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /gpfs3/well/margulies/users/cpy397/contrastive-learning/results/wandb/offline-run-20241125_065829-wslv3cdj<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./results/wandb/offline-run-20241125_065829-wslv3cdj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wslv3cdj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs:   0%|                                           | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   0%|        | 0/100 [00:03<?, ?it/s, Epoch 0 | Loss 27.86 | Corr 0.18 ]\u001b[A\n",
      "Epochs:   1%| | 1/100 [00:03<06:23,  3.88s/it, Epoch 0 | Loss 27.86 | Corr 0.18 \u001b[A\n",
      "Epochs:   1%| | 1/100 [00:07<06:23,  3.88s/it, Epoch 1 | Loss 27.95 | Corr 0.22 \u001b[A\n",
      "Epochs:   2%| | 2/100 [00:07<05:55,  3.63s/it, Epoch 1 | Loss 27.95 | Corr 0.22 \u001b[A\n",
      "Epochs:   2%| | 2/100 [00:10<05:55,  3.63s/it, Epoch 2 | Loss 28.52 | Corr 0.20 \u001b[A\n",
      "Epochs:   3%| | 3/100 [00:10<05:50,  3.62s/it, Epoch 2 | Loss 28.52 | Corr 0.20 \u001b[A\n",
      "Epochs:   3%| | 3/100 [00:14<05:50,  3.62s/it, Epoch 3 | Loss 27.38 | Corr 0.23 \u001b[A\n",
      "Epochs:   4%| | 4/100 [00:14<05:46,  3.61s/it, Epoch 3 | Loss 27.38 | Corr 0.23 \u001b[A\n",
      "Epochs:   4%| | 4/100 [00:18<05:46,  3.61s/it, Epoch 4 | Loss 25.46 | Corr 0.19 \u001b[A\n",
      "Epochs:   5%| | 5/100 [00:18<05:44,  3.63s/it, Epoch 4 | Loss 25.46 | Corr 0.19 \u001b[A\n",
      "Epochs:   5%| | 5/100 [00:21<05:44,  3.63s/it, Epoch 5 | Loss 27.34 | Corr 0.22 \u001b[A\n",
      "Epochs:   6%| | 6/100 [00:21<05:40,  3.62s/it, Epoch 5 | Loss 27.34 | Corr 0.22 \u001b[A\n",
      "Epochs:   6%| | 6/100 [00:25<05:40,  3.62s/it, Epoch 6 | Loss 25.99 | Corr 0.14 \u001b[A\n",
      "Epochs:   7%| | 7/100 [00:25<05:35,  3.60s/it, Epoch 6 | Loss 25.99 | Corr 0.14 \u001b[A\n",
      "Epochs:   7%| | 7/100 [00:28<05:35,  3.60s/it, Epoch 7 | Loss 25.74 | Corr 0.19 \u001b[A\n",
      "Epochs:   8%| | 8/100 [00:28<05:26,  3.54s/it, Epoch 7 | Loss 25.74 | Corr 0.19 \u001b[A\n",
      "Epochs:   8%| | 8/100 [00:32<05:26,  3.54s/it, Epoch 8 | Loss 25.63 | Corr 0.12 \u001b[A\n",
      "Epochs:   9%| | 9/100 [00:32<05:22,  3.54s/it, Epoch 8 | Loss 25.63 | Corr 0.12 \u001b[A\n",
      "Epochs:   9%| | 9/100 [00:35<05:22,  3.54s/it, Epoch 9 | Loss 24.62 | Corr 0.21 \u001b[A\n",
      "Epochs:  10%| | 10/100 [00:35<05:20,  3.56s/it, Epoch 9 | Loss 24.62 | Corr 0.21\u001b[A\n",
      "Epochs:  10%| | 10/100 [00:39<05:20,  3.56s/it, Epoch 10 | Loss 22.48 | Corr 0.1\u001b[A\n",
      "Epochs:  11%| | 11/100 [00:39<05:18,  3.58s/it, Epoch 10 | Loss 22.48 | Corr 0.1\u001b[A\n",
      "Epochs:  11%| | 11/100 [00:43<05:18,  3.58s/it, Epoch 11 | Loss 22.31 | Corr 0.2\u001b[A\n",
      "Epochs:  12%| | 12/100 [00:43<05:16,  3.59s/it, Epoch 11 | Loss 22.31 | Corr 0.2\u001b[A\n",
      "Epochs:  12%| | 12/100 [00:46<05:16,  3.59s/it, Epoch 12 | Loss 22.58 | Corr 0.1\u001b[A\n",
      "Epochs:  13%|▏| 13/100 [00:46<05:13,  3.60s/it, Epoch 12 | Loss 22.58 | Corr 0.1\u001b[A\n",
      "Epochs:  13%|▏| 13/100 [00:50<05:13,  3.60s/it, Epoch 13 | Loss 22.05 | Corr 0.2\u001b[A\n",
      "Epochs:  14%|▏| 14/100 [00:50<05:07,  3.58s/it, Epoch 13 | Loss 22.05 | Corr 0.2\u001b[A\n",
      "Epochs:  14%|▏| 14/100 [00:53<05:07,  3.58s/it, Epoch 14 | Loss 20.55 | Corr 0.1\u001b[A\n",
      "Epochs:  15%|▏| 15/100 [00:53<05:05,  3.59s/it, Epoch 14 | Loss 20.55 | Corr 0.1\u001b[A\n",
      "Epochs:  15%|▏| 15/100 [00:57<05:05,  3.59s/it, Epoch 15 | Loss 20.51 | Corr 0.2\u001b[A\n",
      "Epochs:  16%|▏| 16/100 [00:57<05:02,  3.60s/it, Epoch 15 | Loss 20.51 | Corr 0.2\u001b[A\n",
      "Epochs:  16%|▏| 16/100 [01:01<05:02,  3.60s/it, Epoch 16 | Loss 17.98 | Corr 0.1\u001b[A\n",
      "Epochs:  17%|▏| 17/100 [01:01<04:58,  3.60s/it, Epoch 16 | Loss 17.98 | Corr 0.1\u001b[A\n",
      "Epochs:  17%|▏| 17/100 [01:04<04:58,  3.60s/it, Epoch 17 | Loss 20.55 | Corr 0.2\u001b[A\n",
      "Epochs:  18%|▏| 18/100 [01:04<04:56,  3.61s/it, Epoch 17 | Loss 20.55 | Corr 0.2\u001b[A\n",
      "Epochs:  18%|▏| 18/100 [01:08<04:56,  3.61s/it, Epoch 18 | Loss 16.98 | Corr 0.2\u001b[A\n",
      "Epochs:  19%|▏| 19/100 [01:08<04:51,  3.60s/it, Epoch 18 | Loss 16.98 | Corr 0.2\u001b[A\n",
      "Epochs:  19%|▏| 19/100 [01:11<04:51,  3.60s/it, Epoch 19 | Loss 16.50 | Corr 0.2\u001b[A\n",
      "Epochs:  20%|▏| 20/100 [01:11<04:44,  3.56s/it, Epoch 19 | Loss 16.50 | Corr 0.2\u001b[A\n",
      "Epochs:  20%|▏| 20/100 [01:15<04:44,  3.56s/it, Epoch 20 | Loss 16.63 | Corr 0.1\u001b[A\n",
      "Epochs:  21%|▏| 21/100 [01:15<04:43,  3.59s/it, Epoch 20 | Loss 16.63 | Corr 0.1\u001b[A\n",
      "Epochs:  21%|▏| 21/100 [01:19<04:43,  3.59s/it, Epoch 21 | Loss 15.88 | Corr 0.1\u001b[A\n",
      "Epochs:  22%|▏| 22/100 [01:19<04:41,  3.61s/it, Epoch 21 | Loss 15.88 | Corr 0.1\u001b[A\n",
      "Epochs:  22%|▏| 22/100 [01:22<04:41,  3.61s/it, Epoch 22 | Loss 14.74 | Corr 0.2\u001b[A\n",
      "Epochs:  23%|▏| 23/100 [01:22<04:37,  3.61s/it, Epoch 22 | Loss 14.74 | Corr 0.2\u001b[A\n",
      "Epochs:  23%|▏| 23/100 [01:26<04:37,  3.61s/it, Epoch 23 | Loss 14.08 | Corr 0.1\u001b[A\n",
      "Epochs:  24%|▏| 24/100 [01:26<04:34,  3.61s/it, Epoch 23 | Loss 14.08 | Corr 0.1\u001b[A\n",
      "Epochs:  24%|▏| 24/100 [01:29<04:34,  3.61s/it, Epoch 24 | Loss 15.51 | Corr 0.1\u001b[A\n",
      "Epochs:  25%|▎| 25/100 [01:29<04:30,  3.60s/it, Epoch 24 | Loss 15.51 | Corr 0.1\u001b[A\n",
      "Epochs:  25%|▎| 25/100 [01:33<04:30,  3.60s/it, Epoch 25 | Loss 14.59 | Corr 0.2\u001b[A\n",
      "Epochs:  26%|▎| 26/100 [01:33<04:24,  3.57s/it, Epoch 25 | Loss 14.59 | Corr 0.2\u001b[A\n",
      "Epochs:  26%|▎| 26/100 [01:37<04:24,  3.57s/it, Epoch 26 | Loss 12.80 | Corr 0.1\u001b[A\n",
      "Epochs:  27%|▎| 27/100 [01:37<04:21,  3.59s/it, Epoch 26 | Loss 12.80 | Corr 0.1\u001b[A\n",
      "Epochs:  27%|▎| 27/100 [01:40<04:21,  3.59s/it, Epoch 27 | Loss 13.05 | Corr 0.1\u001b[A\n",
      "Epochs:  28%|▎| 28/100 [01:40<04:19,  3.60s/it, Epoch 27 | Loss 13.05 | Corr 0.1\u001b[A\n",
      "Epochs:  28%|▎| 28/100 [01:44<04:19,  3.60s/it, Epoch 28 | Loss 11.30 | Corr 0.1\u001b[A\n",
      "Epochs:  29%|▎| 29/100 [01:44<04:15,  3.60s/it, Epoch 28 | Loss 11.30 | Corr 0.1\u001b[A\n",
      "Epochs:  29%|▎| 29/100 [01:47<04:15,  3.60s/it, Epoch 29 | Loss 12.68 | Corr 0.2\u001b[A\n",
      "Epochs:  30%|▎| 30/100 [01:47<04:12,  3.60s/it, Epoch 29 | Loss 12.68 | Corr 0.2\u001b[A\n",
      "Epochs:  30%|▎| 30/100 [01:51<04:12,  3.60s/it, Epoch 30 | Loss 10.80 | Corr 0.1\u001b[A\n",
      "Epochs:  31%|▎| 31/100 [01:51<04:07,  3.59s/it, Epoch 30 | Loss 10.80 | Corr 0.1\u001b[A\n",
      "Epochs:  31%|▎| 31/100 [01:55<04:07,  3.59s/it, Epoch 31 | Loss 10.89 | Corr 0.2\u001b[A\n",
      "Epochs:  32%|▎| 32/100 [01:55<04:02,  3.57s/it, Epoch 31 | Loss 10.89 | Corr 0.2\u001b[A\n",
      "Epochs:  32%|▎| 32/100 [01:58<04:02,  3.57s/it, Epoch 32 | Loss 11.63 | Corr 0.2\u001b[A\n",
      "Epochs:  33%|▎| 33/100 [01:58<03:59,  3.58s/it, Epoch 32 | Loss 11.63 | Corr 0.2\u001b[A\n",
      "Epochs:  33%|▎| 33/100 [02:02<03:59,  3.58s/it, Epoch 33 | Loss 10.63 | Corr 0.1\u001b[A\n",
      "Epochs:  34%|▎| 34/100 [02:02<03:56,  3.59s/it, Epoch 33 | Loss 10.63 | Corr 0.1\u001b[A\n",
      "Epochs:  34%|▎| 34/100 [02:05<03:56,  3.59s/it, Epoch 34 | Loss 9.46 | Corr 0.17\u001b[A\n",
      "Epochs:  35%|▎| 35/100 [02:05<03:54,  3.61s/it, Epoch 34 | Loss 9.46 | Corr 0.17\u001b[A\n",
      "Epochs:  35%|▎| 35/100 [02:09<03:54,  3.61s/it, Epoch 35 | Loss 11.59 | Corr 0.2\u001b[A\n",
      "Epochs:  36%|▎| 36/100 [02:09<03:50,  3.61s/it, Epoch 35 | Loss 11.59 | Corr 0.2\u001b[A\n",
      "Epochs:  36%|▎| 36/100 [02:13<03:50,  3.61s/it, Epoch 36 | Loss 10.90 | Corr 0.2\u001b[A\n",
      "Epochs:  37%|▎| 37/100 [02:13<03:46,  3.59s/it, Epoch 36 | Loss 10.90 | Corr 0.2\u001b[A\n",
      "Epochs:  37%|▎| 37/100 [02:16<03:46,  3.59s/it, Epoch 37 | Loss 10.17 | Corr 0.1\u001b[A\n",
      "Epochs:  38%|▍| 38/100 [02:16<03:41,  3.57s/it, Epoch 37 | Loss 10.17 | Corr 0.1\u001b[A\n",
      "Epochs:  38%|▍| 38/100 [02:20<03:41,  3.57s/it, Epoch 38 | Loss 10.37 | Corr 0.2\u001b[A\n",
      "Epochs:  39%|▍| 39/100 [02:20<03:39,  3.60s/it, Epoch 38 | Loss 10.37 | Corr 0.2\u001b[A\n",
      "Epochs:  39%|▍| 39/100 [02:23<03:39,  3.60s/it, Epoch 39 | Loss 11.70 | Corr 0.2\u001b[A\n",
      "Epochs:  40%|▍| 40/100 [02:23<03:36,  3.61s/it, Epoch 39 | Loss 11.70 | Corr 0.2\u001b[A\n",
      "Epochs:  40%|▍| 40/100 [02:27<03:36,  3.61s/it, Epoch 40 | Loss 10.43 | Corr 0.2\u001b[A\n",
      "Epochs:  41%|▍| 41/100 [02:27<03:32,  3.60s/it, Epoch 40 | Loss 10.43 | Corr 0.2\u001b[A\n",
      "Epochs:  41%|▍| 41/100 [02:31<03:32,  3.60s/it, Epoch 41 | Loss 9.75 | Corr 0.18\u001b[A\n",
      "Epochs:  42%|▍| 42/100 [02:31<03:28,  3.59s/it, Epoch 41 | Loss 9.75 | Corr 0.18\u001b[A\n",
      "Epochs:  42%|▍| 42/100 [02:34<03:28,  3.59s/it, Epoch 42 | Loss 10.24 | Corr 0.1\u001b[A\n",
      "Epochs:  43%|▍| 43/100 [02:34<03:23,  3.57s/it, Epoch 42 | Loss 10.24 | Corr 0.1\u001b[A\n",
      "Epochs:  43%|▍| 43/100 [02:38<03:23,  3.57s/it, Epoch 43 | Loss 10.57 | Corr 0.2\u001b[A\n",
      "Epochs:  44%|▍| 44/100 [02:38<03:19,  3.55s/it, Epoch 43 | Loss 10.57 | Corr 0.2\u001b[A\n",
      "Epochs:  44%|▍| 44/100 [02:41<03:19,  3.55s/it, Epoch 44 | Loss 10.81 | Corr 0.2\u001b[A\n",
      "Epochs:  45%|▍| 45/100 [02:41<03:16,  3.58s/it, Epoch 44 | Loss 10.81 | Corr 0.2\u001b[A\n",
      "Epochs:  45%|▍| 45/100 [02:45<03:16,  3.58s/it, Epoch 45 | Loss 11.97 | Corr 0.2\u001b[A\n",
      "Epochs:  46%|▍| 46/100 [02:45<03:14,  3.59s/it, Epoch 45 | Loss 11.97 | Corr 0.2\u001b[A\n",
      "Epochs:  46%|▍| 46/100 [02:48<03:14,  3.59s/it, Epoch 46 | Loss 10.35 | Corr 0.2\u001b[A\n",
      "Epochs:  47%|▍| 47/100 [02:48<03:11,  3.61s/it, Epoch 46 | Loss 10.35 | Corr 0.2\u001b[A\n",
      "Epochs:  47%|▍| 47/100 [02:52<03:11,  3.61s/it, Epoch 47 | Loss 9.96 | Corr 0.17\u001b[A\n",
      "Epochs:  48%|▍| 48/100 [02:52<03:07,  3.61s/it, Epoch 47 | Loss 9.96 | Corr 0.17\u001b[A\n",
      "Epochs:  48%|▍| 48/100 [02:56<03:07,  3.61s/it, Epoch 48 | Loss 9.52 | Corr 0.23\u001b[A\n",
      "Epochs:  49%|▍| 49/100 [02:56<03:03,  3.60s/it, Epoch 48 | Loss 9.52 | Corr 0.23\u001b[A\n",
      "Epochs:  49%|▍| 49/100 [02:59<03:03,  3.60s/it, Epoch 49 | Loss 10.70 | Corr 0.1\u001b[A\n",
      "Epochs:  50%|▌| 50/100 [02:59<02:59,  3.60s/it, Epoch 49 | Loss 10.70 | Corr 0.1\u001b[A\n",
      "Epochs:  50%|▌| 50/100 [03:03<02:59,  3.60s/it, Epoch 50 | Loss 9.79 | Corr 0.22\u001b[A\n",
      "Epochs:  51%|▌| 51/100 [03:03<02:55,  3.59s/it, Epoch 50 | Loss 9.79 | Corr 0.22\u001b[A\n",
      "Epochs:  51%|▌| 51/100 [03:06<02:55,  3.59s/it, Epoch 51 | Loss 9.98 | Corr 0.20\u001b[A\n",
      "Epochs:  52%|▌| 52/100 [03:06<02:52,  3.59s/it, Epoch 51 | Loss 9.98 | Corr 0.20\u001b[A\n",
      "Epochs:  52%|▌| 52/100 [03:10<02:52,  3.59s/it, Epoch 52 | Loss 10.62 | Corr 0.2\u001b[A\n",
      "Epochs:  53%|▌| 53/100 [03:10<02:49,  3.61s/it, Epoch 52 | Loss 10.62 | Corr 0.2\u001b[A\n",
      "Epochs:  53%|▌| 53/100 [03:14<02:49,  3.61s/it, Epoch 53 | Loss 11.53 | Corr 0.2\u001b[A\n",
      "Epochs:  54%|▌| 54/100 [03:14<02:46,  3.62s/it, Epoch 53 | Loss 11.53 | Corr 0.2\u001b[A\n",
      "Epochs:  54%|▌| 54/100 [03:17<02:46,  3.62s/it, Epoch 54 | Loss 10.47 | Corr 0.1\u001b[A\n",
      "Epochs:  55%|▌| 55/100 [03:17<02:43,  3.63s/it, Epoch 54 | Loss 10.47 | Corr 0.1\u001b[A\n",
      "Epochs:  55%|▌| 55/100 [03:21<02:43,  3.63s/it, Epoch 55 | Loss 8.71 | Corr 0.21\u001b[A\n",
      "Epochs:  56%|▌| 56/100 [03:21<02:39,  3.63s/it, Epoch 55 | Loss 8.71 | Corr 0.21\u001b[A\n",
      "Epochs:  56%|▌| 56/100 [03:25<02:39,  3.63s/it, Epoch 56 | Loss 9.74 | Corr 0.21\u001b[A\n",
      "Epochs:  57%|▌| 57/100 [03:25<02:35,  3.62s/it, Epoch 56 | Loss 9.74 | Corr 0.21\u001b[A\n",
      "Epochs:  57%|▌| 57/100 [03:28<02:35,  3.62s/it, Epoch 57 | Loss 10.09 | Corr 0.1\u001b[A\n",
      "Epochs:  58%|▌| 58/100 [03:28<02:32,  3.63s/it, Epoch 57 | Loss 10.09 | Corr 0.1\u001b[A\n",
      "Epochs:  58%|▌| 58/100 [03:32<02:32,  3.63s/it, Epoch 58 | Loss 9.61 | Corr 0.18\u001b[A\n",
      "Epochs:  59%|▌| 59/100 [03:32<02:28,  3.63s/it, Epoch 58 | Loss 9.61 | Corr 0.18\u001b[A\n",
      "Epochs:  59%|▌| 59/100 [03:35<02:28,  3.63s/it, Epoch 59 | Loss 9.36 | Corr 0.22\u001b[A\n",
      "Epochs:  60%|▌| 60/100 [03:35<02:24,  3.61s/it, Epoch 59 | Loss 9.36 | Corr 0.22\u001b[A\n",
      "Epochs:  60%|▌| 60/100 [03:39<02:24,  3.61s/it, Epoch 60 | Loss 10.11 | Corr 0.1\u001b[A\n",
      "Epochs:  61%|▌| 61/100 [03:39<02:20,  3.60s/it, Epoch 60 | Loss 10.11 | Corr 0.1\u001b[A\n",
      "Epochs:  61%|▌| 61/100 [03:43<02:20,  3.60s/it, Epoch 61 | Loss 9.90 | Corr 0.24\u001b[A\n",
      "Epochs:  62%|▌| 62/100 [03:43<02:16,  3.59s/it, Epoch 61 | Loss 9.90 | Corr 0.24\u001b[A\n",
      "Epochs:  62%|▌| 62/100 [03:46<02:16,  3.59s/it, Epoch 62 | Loss 9.55 | Corr 0.20\u001b[A\n",
      "Epochs:  63%|▋| 63/100 [03:46<02:12,  3.59s/it, Epoch 62 | Loss 9.55 | Corr 0.20\u001b[A\n",
      "Epochs:  63%|▋| 63/100 [03:50<02:12,  3.59s/it, Epoch 63 | Loss 10.49 | Corr 0.1\u001b[A\n",
      "Epochs:  64%|▋| 64/100 [03:50<02:10,  3.62s/it, Epoch 63 | Loss 10.49 | Corr 0.1\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>▇▁▂▂▁▂▃▄▃▂▃▃▃▃▂▄▂▄▅▃▄▂▄▃▄▅▇▄▄▄▅▄█▅▆▃▆▃█▄</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>▁▁▃▁▂▂▂▅▄▆▃▃▆▃▅▄▅▅▅▄▅▆█▆▄█▆▅▅▇▅▆▇▇▆▇▄▅▆▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>▂▁▁▂▃▄▁▂▂▃▃▄▄▂▃▃▃▄▃▄▅▄▄▃▆▅▅▄▃▅▆█▅▅▅▆▆▅▆▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>▁▂▁▂▃▃▃▂▃▃▅▃▄▇▅▅▆▄▆▃█▅▄▇▅▇▇▆▇▇▆▅▄▆▇▅█▇▆▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>▄█▄▁▄▃▃▄▃▃▃▃▃▂▃▁▂▃▂▂▃▃▂▂▄▃▂▂▁▃▂▂▂▂▃▄▁▄▃▄</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>▁▁▁▂▂▅▄▃▄▄▆▅▅▄▅▅▅▆▆▅▇▄▄▇▄▄▆▆▅█▅▅▅▄▆█▆▇▆▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>██▂▂▂▂▂▁▂▂▃▂▂▃▂▃▂▂▂▃▃▃▂▂▃▃▃▃▃▃▃▃▃▃▃▃▄▅▆▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>▃▄▄▃▄▄▂▃▄▃▃▃▂▂▃▁▄▄▂▂▁▂▃▁▆▂▇▆▄▆▆▅▇▇▂▄▃█▇▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>▆▃▄▇▅█▃▃▅▅▆▄▇▄▅▃▅▄▃▂▃▆▆▅▁▂▂▂▂▃▄▂▂▄▅▃▃▃▁▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>▇▆▇▆█▃█▆▆▄▇▆▄▆▅▁▃▄▆▅▅▆▃▃▅▁▂▅▅▂▃▄▅▂▃▃▃▃▄▃</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>▃▅▂▃▂▂▂▁▁▂▁▂▁▁▁▂▁▁▂▂▂▃█▃▂▃▂▂▁▁▂▄▂▂▂▃▃▃▂▁</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>▁▆▆▃▂▃▃▃▂▃▃▂▁▂▂▁▂▆▃▂▂▃▁▃█▂▃▄▂▂▂▃▃▅▄▄▄▃▄▅</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat1.weight</td><td>▁▁▄▃▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁█▁▁▁▁▁▁▃▄▂▆▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat2.weight</td><td>▂▂▂▁▁▁▁▁▁▁▁▁▇▁▁▂▁█▂▂▁▁▁▁▁▃▁▂▄▅▆▁▂▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>▆▄▄▂▃▅▂▅▅█▇▄▂▃▄▄▂▄▅▂▃▂▂▂▂▃▃▁▄▁▁▂▂▁▁▂▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▃▂▄▄▃▄█▅▂▄▃▂▂▃▂▃▂▄▂▂▂▃▂▂▂▂▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>▁▂▁▂▁▂▃▂▂▂▃▃▆▃▅▄▅▄▃▅▆▆▃▄█▅▃▃▄▄▆▄▅▄▅▂▆▂▄▇</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>▁▁▂▂▂▁▂▂▃▃▃▂▃▃▃▃▆▆▄▃▆▆▂▆▄▃█▇▄▃▄▄▅▂▃▃▅▅▅▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>▇█▆█▅▃▃▅▅▄▃▄▃▃▃▃▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>▂▅▄▆▄▆▅▄▅▅▅███▅▆▆▅▅▆▆▄▃▃▄▃▂▂▂▂▂▂▂▁▁▁▁▂▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>▁▂▁▃▂▃▃▃▄▇▇▇▅▄▇▆▅▅█▆▅▇▄▄▆▇▅▄▃▇▄▄▃▄▂▃▄▅▃▄</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>▁▁▂▂▁▁▁▂▂▂▃▄▂▂▄▆▄▅▆▆▃▅▃▆▃▄▄▂▄▇▃▄▂▃▂▃▄▄▂█</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>▁▁▁▁▂▂▇▂▂▂▃▆▂▃▃▇▅▆█▅▄▄▃▃▇▅▇▅▇▅▆▅▅▂▄█▆▇▆▆</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>▁▁▁▁▁▂▄▃▃▄▄▅▃▄▆▅▃▅▄▃▄▆▅▅▇▇▃▅▄█▂▃▅▃▇▃▄▂▃▅</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>▁▃▂▂▃▃▃▄▅▃▇█▅▇▅▄▆▅▇▄▃▄▄▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>▁▁▁▁▁▁▁▂▁▂▂▂▂▂▃▂▃▄█▃▂▅▃▂▂▆▇▅▄▃▃▂▇▃▅▅▃▃▅▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>▄▅▄▇▇▇█▇█▇▄█▄▆▅▃▃▄▃▃▁▂▂▂▁▁▁▁▁▁▂▁▂▁▂▃▂▁▁▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>▁▂▂█▇▆▅▇▅▆▆▇▅▄▄▆▆▅▄▅▃▄▃▂▄▂▂▂▁▂▁▂▂▁▂▃▂▃▁▂</td></tr><tr><td>Run</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Target Corr/val</td><td>▄▅▅▆▄▅▁▅▂▃▂█▇▃▂▃▅▄▃▆▆▂▄▅▅▄▅█▆▅▆▅▆▅▅▄▄▆▄▄</td></tr><tr><td>Target MAPE/val</td><td>█████▇▇▇▆▆▆▅▅▄▄▁▂▂▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>direction_reg_target_loss</td><td>▆▄▅▇▂▄▃▁▆▃▄▄▅▅▄▅▄▄▅▆▃▅▇▅▄▅▃▃█▄▄▅▄▄▄▄▃▃▃▅</td></tr><tr><td>feature_autoencoder_loss</td><td>▆▇█▅▆██▃▄▇▆▆▆▅▅▅▂▅▃▄▅▂▂▄▄▃▅▃▁▃▄▇▄▄▄▂▃▄▅▃</td></tr><tr><td>kernel_embedded_target_loss</td><td>▄▂▄▃▄▅▄▃▅▄▃▅▃▂▄▄▄▂▃▄▃▂▃▃▄▄▃▂▃▅▁▁▂▄▅▂█▃▂▂</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>███▇▇▇▇▇▅▅▅▅▄▄▄▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>██▇▆▆▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▁▁▂▁▁▂▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>64</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>0.76606</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>0.02646</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>0.0425</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>0.41126</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>0.06022</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>0.03785</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>0.04452</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>0.40915</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>0.02788</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>0.02788</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat1.weight</td><td>0.00253</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat2.weight</td><td>0.00253</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>0.16728</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>0.00801</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>0.01187</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>0.00163</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>0.04692</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>0.14254</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>0.01056</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>0.0182</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>0.11823</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>0.00914</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>0.01681</td></tr><tr><td>Run</td><td>0</td></tr><tr><td>Target Corr/val</td><td>0.19779</td></tr><tr><td>Target MAPE/val</td><td>15.3559</td></tr><tr><td>direction_reg_target_loss</td><td>4.11325</td></tr><tr><td>feature_autoencoder_loss</td><td>0.58693</td></tr><tr><td>kernel_embedded_target_loss</td><td>9.34277</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>0.09384</td></tr><tr><td>total_loss</td><td>10.02354</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /gpfs3/well/margulies/users/cpy397/contrastive-learning/results/wandb/offline-run-20241125_070030-3bp8jm3e<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./results/wandb/offline-run-20241125_070030-3bp8jm3e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs3/well/margulies/users/cpy397/contrastive-learning/contrastive_phenotypes/src/ContModeling/viz_func.py:107: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  correlations[i // cols, i % cols] = spearmanr(flat_true[:, i], flat_recon[:, i])[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>▁</td></tr><tr><td>Test | Target Corr/val</td><td>▁</td></tr><tr><td>Test | Target MAPE/val</td><td>▁</td></tr><tr><td>Test | Train ratio</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>0</td></tr><tr><td>Test | Target Corr/val</td><td>0.20252</td></tr><tr><td>Test | Target MAPE/val</td><td>15.66894</td></tr><tr><td>Test | Train ratio</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /gpfs3/well/margulies/users/cpy397/contrastive-learning/results/wandb/offline-run-20241125_070429-7c04c6z0<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./results/wandb/offline-run-20241125_070429-7c04c6z0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Run: 100%|█████████████████████████████████| 1/1 [08:40<00:00, 520.85s/it]/gpfs3/well/margulies/users/cpy397/python/neuro/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2387: UserWarning: Run (wslv3cdj) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "Model Run: 100%|█████████████████████████████████| 1/1 [08:40<00:00, 520.85s/it]\n"
     ]
    }
   ],
   "source": [
    "def main(cfg=cfg):\n",
    "\n",
    "    results_dir = os.path.join(cfg.output_dir, cfg.experiment_name)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    random_state = np.random.RandomState(seed=42)\n",
    "\n",
    "    dataset_path = cfg.dataset_path\n",
    "\n",
    "    if isinstance(cfg.targets, str):\n",
    "        \n",
    "        targets =[cfg.targets]\n",
    "    else:\n",
    "        targets = list(cfg.targets)\n",
    "        \n",
    "    test_ratio = cfg.test_ratio\n",
    "\n",
    "    dataset = MatData(dataset_path, targets, synth_exp = cfg.synth_exp, threshold=cfg.mat_threshold)\n",
    "    n_sub = len(dataset)\n",
    "    test_size = int(test_ratio * n_sub)\n",
    "    indices = np.arange(n_sub)\n",
    "    n_runs = cfg.n_runs\n",
    "    multi_gpu = cfg.multi_gpu\n",
    "    train_ratio = cfg.train_ratio\n",
    "    \n",
    "    multi_gpu = False\n",
    "    if multi_gpu:\n",
    "        print(\"Using multi-gpu\")\n",
    "        log_folder = Path(\"logs\")\n",
    "        executor = submitit.AutoExecutor(folder=str(log_folder / \"%j\"))\n",
    "        executor.update_parameters(\n",
    "            timeout_min=120,\n",
    "            slurm_partition=\"gpu_short\",\n",
    "            gpus_per_node=1,\n",
    "            tasks_per_node=1,\n",
    "            nodes=1\n",
    "            #slurm_constraint=\"v100-32g\",\n",
    "        )\n",
    "        run_jobs = []\n",
    "\n",
    "        with executor.batch():\n",
    "            train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "            run_size = test_size + train_size\n",
    "            for run in tqdm(range(n_runs)):\n",
    "                run_model = ModelRun()\n",
    "                job = executor.submit(run_model, train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state=random_state, device=None)\n",
    "                run_jobs.append(job)\n",
    "\n",
    "        async def get_result(run_jobs):\n",
    "            run_results = []\n",
    "            for aws in tqdm(asyncio.as_completed([j.awaitable().result() for j in run_jobs]), total=len(run_jobs)):\n",
    "                res = await aws\n",
    "                run_results.append(res)\n",
    "            return run_results\n",
    "        run_results = asyncio.run(get_result(run_jobs))\n",
    "\n",
    "    else:\n",
    "        run_results = []\n",
    "        train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "        run_size = test_size + train_size\n",
    "        for run in tqdm(range(n_runs), desc=\"Model Run\"):\n",
    "            run_model = ModelRun()\n",
    "            job = run_model(train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state=random_state, device=None)\n",
    "            run_results.append(job)\n",
    "\n",
    "    losses, predictions, embeddings = zip(*run_results)\n",
    "\n",
    "    prediction_metrics = predictions[0]\n",
    "    for prediction in predictions[1:]:\n",
    "        prediction_metrics.update(prediction)\n",
    "\n",
    "    pred_results = []\n",
    "    for k, v in prediction_metrics.items():\n",
    "        true_targets, predicted_targets, indices = v\n",
    "        \n",
    "        true_targets_dict = {\"train_ratio\": [k[0]] * len(true_targets),\n",
    "                             \"model_run\":[k[1]] * len(true_targets),\n",
    "                             \"dataset\":[k[2]] * len(true_targets)\n",
    "                            }\n",
    "        predicted_targets_dict = {\"indices\": indices}\n",
    "        \n",
    "        for i, target in enumerate(targets):\n",
    "            true_targets_dict[target] = true_targets[:, i]\n",
    "            predicted_targets_dict[f\"{target}_pred\"] = predicted_targets[:, i]\n",
    "            \n",
    "            \n",
    "        true_targets = pd.DataFrame(true_targets_dict)\n",
    "        predicted_targets = pd.DataFrame(predicted_targets_dict)\n",
    "        \n",
    "        pred_results.append(pd.concat([true_targets, predicted_targets], axis = 1))\n",
    "    pred_results = pd.concat(pred_results)\n",
    "    pred_results.to_csv(f\"{results_dir}/pred_results.csv\", index=False)\n",
    "\n",
    "    prediction_mape_by_element = []\n",
    "    for k, v in prediction_metrics.items():\n",
    "        true_targets, predicted_targets, indices = v\n",
    "        \n",
    "        mape_by_element = np.abs(true_targets - predicted_targets) / (np.abs(true_targets)+1e-10)\n",
    "        \n",
    "        for i, mape in enumerate(mape_by_element):\n",
    "            prediction_mape_by_element.append(\n",
    "                {\n",
    "                    'train_ratio': k[0],\n",
    "                    'model_run': k[1],\n",
    "                    'dataset': k[2],\n",
    "                    'mape': mape\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(prediction_mape_by_element)\n",
    "    df = pd.concat([df.drop('mape', axis=1), df['mape'].apply(pd.Series)], axis=1)\n",
    "    df.columns = ['train_ratio', 'model_run', 'dataset'] + targets\n",
    "    df= df.groupby(['train_ratio', 'model_run', 'dataset']).agg('mean').reset_index()\n",
    "    df.to_csv(f\"{results_dir}/mape.csv\", index = False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
