{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs3/well/margulies/users/cpy397/python/neuro/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import yaml\n",
    "import wandb\n",
    "import xarray as xr\n",
    "import asyncio\n",
    "import submitit\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from nilearn.connectome import sym_matrix_to_vec, vec_to_sym_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "# from augmentations import augs, aug_args\n",
    "import glob, os, shutil\n",
    "from nilearn.datasets import fetch_atlas_schaefer_2018\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from ContModeling.utils import gaussian_kernel, cauchy, standardize, save_embeddings\n",
    "from ContModeling.losses import LogEuclideanLoss, NormLoss, KernelizedSupCon, OutlierRobustMSE\n",
    "from ContModeling.models import PhenoProj\n",
    "from ContModeling.helper_classes import MatData\n",
    "from ContModeling.viz_func import wandb_plot_acc_vs_baseline, wandb_plot_test_recon_corr, wandb_plot_individual_recon\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run, train_ratio, train_dataset, test_dataset, mean, std, B_init_fMRI, cfg, model=None, device=device):\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    # MODEL DIMS\n",
    "    input_dim_feat = cfg.input_dim_feat\n",
    "    input_dim_target = cfg.input_dim_target\n",
    "    hidden_dim = cfg.hidden_dim\n",
    "    output_dim_target = cfg.output_dim_target\n",
    "    output_dim_feat = cfg.output_dim_feat\n",
    "    kernel = SUPCON_KERNELS[cfg.SupCon_kernel]\n",
    "    \n",
    "    # TRAINING PARAMS\n",
    "    lr = cfg.lr\n",
    "    batch_size = cfg.batch_size\n",
    "    dropout_rate = cfg.dropout_rate\n",
    "    weight_decay = cfg.weight_decay\n",
    "    num_epochs = cfg.num_epochs\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    mean= torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    if model is None:\n",
    "        model = PhenoProj(\n",
    "            input_dim_feat,\n",
    "            input_dim_target,\n",
    "            hidden_dim,\n",
    "            output_dim_target,\n",
    "            output_dim_feat,\n",
    "            dropout_rate,\n",
    "            cfg\n",
    "        ).to(device)\n",
    "\n",
    "    if cfg.mat_ae_pretrained:\n",
    "        print(\"Loading pretrained MatrixAutoencoder...\")\n",
    "        state_dict = torch.load(f\"{cfg.output_dir}/{cfg.pretrained_mat_ae_exp}/saved_models/autoencoder_weights_fold{cfg.best_mat_ae_fold}.pth\")\n",
    "        model.matrix_ae.load_state_dict(state_dict)\n",
    "    else:\n",
    "        model.matrix_ae.enc_mat1.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "        model.matrix_ae.enc_mat2.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "    \n",
    "    if cfg.target_ae_pretrained:\n",
    "        print(\"Loading pretrained TargetAutoencoder...\")\n",
    "        state_dict = torch.load(f\"{cfg.output_dir}/{cfg.pretrained_target_ae_exp}/saved_models/autoencoder_weights_fold{cfg.best_target_ae_fold}.pth\")\n",
    "        model.target_ae.load_state_dict(state_dict)\n",
    "\n",
    "    criterion_pft = KernelizedSupCon(\n",
    "        method=\"expw\",\n",
    "        temperature=cfg.pft_temperature,\n",
    "        base_temperature= cfg.pft_base_temperature,\n",
    "        reg_term = cfg.pft_reg_term,\n",
    "        kernel=kernel,\n",
    "        krnl_sigma=cfg.pft_sigma,\n",
    "    )\n",
    "\n",
    "    criterion_ptt = KernelizedSupCon(\n",
    "        method=\"expw\",\n",
    "        temperature=cfg.ptt_temperature,\n",
    "        base_temperature= cfg.ptt_base_temperature,\n",
    "        reg_term = cfg.ptt_reg_term,\n",
    "        kernel=kernel,\n",
    "        krnl_sigma=cfg.ptt_sigma,\n",
    "    )\n",
    "    \n",
    "    feature_autoencoder_crit = EMB_LOSSES[cfg.feature_autoencoder_crit]\n",
    "    target_decoding_crit = EMB_LOSSES[cfg.target_decoding_crit]\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1, patience = cfg.scheduler_patience)\n",
    "\n",
    "    loss_terms = []\n",
    "    validation = []\n",
    "    autoencoder_features = []\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    wandb.init(project=cfg.project,\n",
    "        mode = \"offline\",\n",
    "        name=f\"{cfg.experiment_name}_run{run}_train_ratio_{train_ratio}\",\n",
    "        dir = cfg.output_dir,\n",
    "        config = OmegaConf.to_container(cfg, resolve=True))\n",
    "\n",
    "    with tqdm(range(num_epochs), desc=\"Epochs\", leave=False) as pbar:\n",
    "        for epoch in pbar:\n",
    "            model.train()\n",
    "\n",
    "            loss_terms_batch = defaultdict(lambda:0)\n",
    "            for features, targets in train_loader:\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                features = features.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                ## FEATURE ENCODING\n",
    "                embedded_feat = model.encode_features(features)\n",
    "                ## FEATURE DECODING\n",
    "                if not cfg.mat_ae_pretrained:\n",
    "                    reconstructed_feat = model.decode_features(embedded_feat)\n",
    "                    ## FEATURE DECODING LOSS\n",
    "                    feature_autoencoder_loss = feature_autoencoder_crit(features, reconstructed_feat) / 10_000\n",
    "                \n",
    "                ## REDUCED FEAT TO TARGET EMBEDDING\n",
    "                embedded_feat_vectorized = sym_matrix_to_vec(embedded_feat.detach().cpu().numpy(), discard_diagonal = True)\n",
    "                embedded_feat_vectorized = torch.tensor(embedded_feat_vectorized).to(device)\n",
    "\n",
    "                features_vectorized = sym_matrix_to_vec(features.detach().cpu().numpy(), discard_diagonal = True)\n",
    "                features_vectorized = torch.tensor(features_vectorized).to(device)\n",
    "                features_vectorized = nn.functional.normalize(features_vectorized, p=2, dim=1)\n",
    "\n",
    "                ## TARGET DECODING FROM MAT EMBEDDINGs\n",
    "                reduced_feat_embedding = model.transfer_embedding(embedded_feat_vectorized)\n",
    "                out_target_decoded = model.decode_targets(reduced_feat_embedding)\n",
    "\n",
    "                ## KERNLIZED LOSS: MAT embedding vs MAT\n",
    "\n",
    "                if cfg.SupConLoss_on_mat:\n",
    "                    kernel_embedded_feature_loss, direction_reg_features = criterion_ptt(reduced_feat_embedding.unsqueeze(1), features_vectorized)\n",
    "                    kernel_embedded_feature_loss = 100 * kernel_embedded_feature_loss\n",
    "                    direction_reg_features = 100 * direction_reg_features\n",
    "\n",
    "\n",
    "                ## KERNLIZED LOSS: MAT embedding vs targets\n",
    "                kernel_embedded_target_loss, direction_reg_target = criterion_ptt(reduced_feat_embedding.unsqueeze(1), targets)\n",
    "                kernel_embedded_target_loss = 100 * kernel_embedded_target_loss\n",
    "                direction_reg_target = 100 * direction_reg_target\n",
    "\n",
    "                ## LOSS: TARGET DECODING FROM TARGET EMBEDDING\n",
    "                if cfg.target_decoding_crit == 'Huber' and cfg.huber_delta != 'None':\n",
    "                    target_decoding_crit = nn.HuberLoss(delta = cfg.huber_delta)\n",
    "                \n",
    "                target_decoding_from_reduced_emb_loss = target_decoding_crit(targets, out_target_decoded) / 10\n",
    "\n",
    "\n",
    "                ## SUM ALL LOSSES\n",
    "                loss = kernel_embedded_target_loss + target_decoding_from_reduced_emb_loss\n",
    "                \n",
    "                if cfg.SupConLoss_on_mat:\n",
    "                    loss += kernel_embedded_feature_loss\n",
    "\n",
    "                if not cfg.mat_ae_pretrained:\n",
    "                    loss += feature_autoencoder_loss\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                if cfg.clip_grad:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                if cfg.log_gradients:\n",
    "                    for name, param in model.named_parameters():\n",
    "                        if param.grad is not None:\n",
    "                            wandb.log({\n",
    "                                \"Epoch\": epoch,\n",
    "                                f\"Gradient Norm/{name}\": param.grad.norm().item()\n",
    "                                })  \n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_terms_batch['loss'] = loss.item() / len(features)\n",
    "                loss_terms_batch['kernel_embedded_target_loss'] = kernel_embedded_target_loss.item() / len(features)\n",
    "                loss_terms_batch['target_decoding_from_reduced_emb_loss'] = target_decoding_from_reduced_emb_loss.item() / len(features)\n",
    "                loss_terms_batch['direction_reg_target_loss'] = direction_reg_target.item() / len(features)\n",
    "                \n",
    "                if cfg.SupConLoss_on_mat:\n",
    "                    loss_terms_batch['direction_reg_features_loss'] = direction_reg_features.item() / len(features)\n",
    "                    loss_terms_batch['kernel_embedded_feature_loss'] = kernel_embedded_feature_loss.item() / len(features)\n",
    "                \n",
    "                if not cfg.mat_ae_pretrained:\n",
    "                    loss_terms_batch['feature_autoencoder_loss'] = feature_autoencoder_loss.item() / len(features)\n",
    "                    wandb.log({\n",
    "                        'Epoch': epoch,\n",
    "                        'feature_autoencoder_loss': loss_terms_batch['feature_autoencoder_loss']\n",
    "                    })\n",
    "                \n",
    "                wandb.log({\n",
    "                    'Epoch': epoch,\n",
    "                    'Run': run,\n",
    "                    'total_loss': loss_terms_batch['loss'],\n",
    "                    'kernel_embedded_target_loss': loss_terms_batch['kernel_embedded_target_loss'],\n",
    "                    'kernel_embedded_feature_loss': loss_terms_batch['kernel_embedded_feature_loss'],\n",
    "                    'direction_reg_target_loss': loss_terms_batch['direction_reg_target_loss'],\n",
    "                    'target_decoding_from_reduced_emb_loss': loss_terms_batch['target_decoding_from_reduced_emb_loss']\n",
    "                })\n",
    "\n",
    "            if cfg.SupConLoss_on_mat:\n",
    "                wandb.log({\n",
    "                    'Epoch': epoch,\n",
    "                    'Run': run,\n",
    "                    'direction_reg_features_loss': loss_terms_batch['direction_reg_features_loss'],\n",
    "                    'kernel_embedded_feature_loss': loss_terms_batch['kernel_embedded_feature_loss'],\n",
    "                })\n",
    "\n",
    "            loss_terms_batch['epoch'] = epoch\n",
    "            loss_terms.append(loss_terms_batch)\n",
    "\n",
    "            model.eval()\n",
    "            mape_batch = 0\n",
    "            corr_batch = 0\n",
    "            with torch.no_grad():\n",
    "                for (features, targets) in test_loader:\n",
    "                    \n",
    "                    features, targets = features.to(device), targets.to(device)                    \n",
    "                    out_feat = model.encode_features(features)\n",
    "                    out_feat = torch.tensor(sym_matrix_to_vec(out_feat.detach().cpu().numpy(), discard_diagonal = True)).float().to(device)\n",
    "                    transfer_out_feat = model.transfer_embedding(out_feat)\n",
    "                    out_target_decoded = model.decode_targets(transfer_out_feat)\n",
    "                    \n",
    "                    epsilon = 1e-8\n",
    "                    mape =  torch.mean(torch.abs((targets - out_target_decoded)) / torch.abs((targets + epsilon))) * 100\n",
    "                    corr =  spearmanr(targets.cpu().numpy().flatten(), out_target_decoded.cpu().numpy().flatten())[0]\n",
    "                    mape_batch+=mape.item()\n",
    "                    corr_batch += corr\n",
    "\n",
    "                mape_batch = mape_batch/len(test_loader)\n",
    "                corr_batch = corr_batch/len(test_loader)\n",
    "                validation.append(mape_batch)\n",
    "\n",
    "            wandb.log({\n",
    "                'Target MAPE/val' : mape_batch,\n",
    "                'Target Corr/val': corr_batch,\n",
    "                })\n",
    "            \n",
    "            scheduler.step(mape_batch)\n",
    "            if np.log10(scheduler._last_lr[0]) < -4:\n",
    "                break\n",
    "\n",
    "            pbar.set_postfix_str(\n",
    "                f\"Epoch {epoch} \"\n",
    "                f\"| Loss {loss_terms[-1]['loss']:.02f} \"\n",
    "                f\"| Corr {corr_batch:.02f} \"\n",
    "            )\n",
    "    wandb.finish()\n",
    "    loss_terms = pd.DataFrame(loss_terms)\n",
    "    return loss_terms, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_LOSSES ={\n",
    "    'Norm': NormLoss(),\n",
    "    'LogEuclidean': LogEuclideanLoss(),\n",
    "    'MSE': nn.functional.mse_loss,\n",
    "    'MSERobust': OutlierRobustMSE(),\n",
    "    'Huber': nn.HuberLoss(),\n",
    "    'cosine': nn.functional.cosine_embedding_loss,\n",
    "}\n",
    "\n",
    "SUPCON_KERNELS = {\n",
    "    'cauchy': cauchy,\n",
    "    'gaussian_kernel': gaussian_kernel,\n",
    "    'None': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRun(submitit.helpers.Checkpointable):\n",
    "    def __init__(self):\n",
    "        self.results = None\n",
    "        self.embeddings = None\n",
    "\n",
    "    def __call__(self, train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state=None, device=None, save_model = True, path: Path = None):\n",
    "        if self.results is None:\n",
    "            if device is None:\n",
    "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                print(f\"Device {device}, ratio {train_ratio}\", flush=True)\n",
    "            if not isinstance(random_state, np.random.RandomState):\n",
    "                random_state = np.random.RandomState(random_state)\n",
    "\n",
    "            augmentations = cfg.augmentation\n",
    "\n",
    "            recon_mat_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.reconstructed_dir)\n",
    "            os.makedirs(recon_mat_dir, exist_ok=True)\n",
    "    \n",
    "            predictions = {}\n",
    "            autoencoder_features = {}\n",
    "            losses = []\n",
    "            self.embeddings = {'train': [], 'test': []}\n",
    "            self.run = run\n",
    "\n",
    "            if cfg.mat_ae_pretrained:\n",
    "                print(\"Loading test indices from the pretraining experiment...\")\n",
    "                test_indices = np.load(f\"{cfg.output_dir}/{cfg.pretrained_mat_ae_exp}/test_idx.npy\")\n",
    "                train_indices = np.setdiff1d(indices, test_indices)\n",
    "            elif cfg.external_test_mode:\n",
    "                test_scanners = list(cfg.test_scanners)\n",
    "                xr_dataset = xr.open_dataset(cfg.dataset_path)\n",
    "                scanner_mask = np.sum([xr_dataset.isin(scanner).scanner.values for scanner in test_scanners],\n",
    "                                    axis = 0).astype(bool)\n",
    "                test_indices = indices[scanner_mask]\n",
    "                train_indices = indices[~scanner_mask]\n",
    "                del xr_dataset\n",
    "            else:\n",
    "                run_indices = random_state.choice(indices, run_size, replace=False)\n",
    "                train_indices, test_indices = train_test_split(run_indices, test_size=test_size, random_state=random_state)\n",
    "                \n",
    "            train_dataset = Subset(dataset, train_indices)\n",
    "            test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "            train_features = train_dataset.dataset.matrices[train_dataset.indices]\n",
    "            train_targets = train_dataset.dataset.targets[train_dataset.indices].numpy()\n",
    "            std_train_targets, mean, std= standardize(train_targets)\n",
    "            train_targets = np.log1p(train_targets+1)\n",
    "            # scaler = MinMaxScaler().fit(train_targets)\n",
    "            # train_targets = scaler.transform(train_targets)\n",
    "\n",
    "            input_dim_feat =cfg.input_dim_feat\n",
    "            output_dim_feat = cfg.output_dim_feat\n",
    "\n",
    "            ## Weight initialization for bilinear layer\n",
    "            mean_f = torch.mean(train_features, dim=0).to(device)\n",
    "            [D,V] = torch.linalg.eigh(mean_f,UPLO = \"U\")\n",
    "            B_init_fMRI = V[:,input_dim_feat-output_dim_feat:] \n",
    "            test_features= test_dataset.dataset.matrices[test_dataset.indices].numpy()\n",
    "            test_targets = test_dataset.dataset.targets[test_dataset.indices].numpy()\n",
    "            test_targets = np.log1p(test_targets+1)\n",
    "            # test_targets = scaler.transform(test_targets)\n",
    "\n",
    "            ### Augmentation\n",
    "            if augmentations != 'None':\n",
    "#                 aug_params = {}\n",
    "                if not isinstance(augmentations, list):\n",
    "                    augmentations = [augmentations]\n",
    "                n_augs = len(augmentations)\n",
    "                vect_train_features = sym_matrix_to_vec(train_features, discard_diagonal=True)\n",
    "                n_samples = len(train_dataset)\n",
    "                n_features = vect_train_features.shape[-1]\n",
    "                new_train_features = np.zeros((n_samples + n_samples * n_augs, 1, n_features))\n",
    "                new_train_features[:n_samples, 0, :] = vect_train_features\n",
    "\n",
    "                for i, aug in enumerate(augmentations):\n",
    "                    transform = augs[aug]\n",
    "                    transform_args = aug_args[aug]\n",
    "#                     aug_params[aug] = transform_args # to save later in the metrics df\n",
    "\n",
    "                    num_aug = i + 1\n",
    "                    aug_features = np.array([transform(sample, **transform_args) for sample in train_features])\n",
    "                    aug_features = sym_matrix_to_vec(aug_features, discard_diagonal=True)\n",
    "\n",
    "                    new_train_features[n_samples * num_aug: n_samples * (num_aug + 1), 0, :] = aug_features\n",
    "\n",
    "                train_features = new_train_features\n",
    "                train_targets = np.concatenate([train_targets]*(n_augs + 1), axis=0)\n",
    "            \n",
    "            train_dataset = TensorDataset(train_features, torch.from_numpy(train_targets).to(torch.float32))\n",
    "            test_dataset = TensorDataset(torch.from_numpy(test_features).to(torch.float32), torch.from_numpy(test_targets).to(torch.float32))\n",
    "\n",
    "            loss_terms, model = train(run, train_ratio, train_dataset, test_dataset,mean, std, B_init_fMRI, cfg, device=device)\n",
    "            losses.append(loss_terms.eval(\"train_ratio = @train_ratio\").eval(\"run = @run\"))\n",
    "\n",
    "            wandb.init(project=cfg.project,\n",
    "                mode = \"offline\",\n",
    "                name=f\"TEST_{cfg.experiment_name}_run{run}_train_ratio_{train_ratio}\",\n",
    "                dir = cfg.output_dir,\n",
    "                config = OmegaConf.to_container(cfg, resolve=True))\n",
    "            \n",
    "            embedding_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.embedding_dir)\n",
    "            os.makedirs(embedding_dir, exist_ok=True)\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                train_dataset = Subset(dataset, train_indices)\n",
    "                train_features = train_dataset.dataset.matrices[train_dataset.indices].numpy()\n",
    "                train_targets = train_dataset.dataset.targets[train_dataset.indices].numpy()\n",
    "                train_targets = np.log1p(train_targets+1)\n",
    "                train_dataset = TensorDataset(torch.from_numpy(train_features).to(torch.float32), torch.from_numpy(train_targets).to(torch.float32))\n",
    "\n",
    "                for label, d, d_indices in (('train', train_dataset, train_indices), ('test', test_dataset, test_indices)):\n",
    "                    is_test = True\n",
    "                    if label == 'train':\n",
    "                        is_test = False\n",
    "                    \n",
    "                    X, y = zip(*d)\n",
    "                    X = torch.stack(X).to(device)\n",
    "                    y = torch.stack(y).to(device)\n",
    "                    X_embedded, y_embedded = model.forward(X, y)\n",
    "                                        \n",
    "                    if label == 'test' and train_ratio == 1.0:\n",
    "                        np.save(f'{recon_mat_dir}/test_idx_run{run}',d_indices)\n",
    "                        recon_mat = model.decode_features(X_embedded)\n",
    "                        mape_mat = torch.abs((X - recon_mat) / (X + 1e-10)) * 100\n",
    "                        \n",
    "                        wandb_plot_test_recon_corr(wandb, cfg.experiment_name, cfg.work_dir, recon_mat.cpu().numpy(), X.cpu().numpy(), mape_mat.cpu().numpy(), True, run)\n",
    "                        wandb_plot_individual_recon(wandb, cfg.experiment_name, cfg.work_dir, d_indices, recon_mat.cpu().numpy(), X.cpu().numpy(), mape_mat.cpu().numpy(), 0, True, run)\n",
    "\n",
    "                        np.save(f'{recon_mat_dir}/recon_mat_run{run}', recon_mat.cpu().numpy())\n",
    "                        np.save(f'{recon_mat_dir}/mape_mat_run{run}', mape_mat.cpu().numpy())\n",
    "\n",
    "                    X_embedded = X_embedded.cpu().numpy()\n",
    "                    X_embedded = torch.tensor(sym_matrix_to_vec(X_embedded, discard_diagonal=True)).to(torch.float32).to(device)\n",
    "                    X_emb_reduced = model.transfer_embedding(X_embedded).to(device)\n",
    "\n",
    "                    y_pred = model.decode_targets(X_emb_reduced)\n",
    "                    y_pred = np.exp(y_pred.cpu().numpy())-1\n",
    "                    y_pred = torch.tensor(y_pred).to(device)\n",
    "\n",
    "                    y = np.exp(y.cpu().numpy())-1\n",
    "                    y = torch.tensor(y).to(device)\n",
    "\n",
    "                    save_embeddings(X_embedded, \"mat\", cfg, is_test, run)\n",
    "                    save_embeddings(X_emb_reduced, \"joint\", cfg, is_test, run)\n",
    "\n",
    "                    if label == 'test':\n",
    "                        epsilon = 1e-8\n",
    "                        mape =  100 * torch.mean(torch.abs((y - y_pred)) / torch.abs((y + epsilon))).item()\n",
    "                        corr =  spearmanr(y.cpu().numpy().flatten(), y_pred.cpu().numpy().flatten())[0]\n",
    "\n",
    "                        wandb.log({\n",
    "                            'Run': run,\n",
    "                            'Test | Target MAPE/val' : mape,\n",
    "                            'Test | Target Corr/val': corr,\n",
    "                            'Test | Train ratio' : train_ratio\n",
    "                            })\n",
    "            \n",
    "                    predictions[(train_ratio, run, label)] = (y.cpu().numpy(), y_pred.cpu().numpy(), d_indices)\n",
    "                    for i, idx in enumerate(d_indices):\n",
    "                        self.embeddings[label].append({\n",
    "                            'index': idx,\n",
    "                            'target_embedded': y_embedded[i].cpu().numpy(),\n",
    "                            'feature_embedded': X_emb_reduced[i].cpu().numpy()\n",
    "                        })\n",
    "            wandb.finish()\n",
    "            \n",
    "            self.results = (losses, predictions, self.embeddings)\n",
    "\n",
    "        if save_model:\n",
    "            saved_models_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.model_weight_dir)\n",
    "            os.makedirs(saved_models_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"{saved_models_dir}/model_weights_run{run}.pth\")\n",
    "\n",
    "        return self.results\n",
    "\n",
    "    def checkpoint(self, *args, **kwargs):\n",
    "        print(\"Checkpointing\", flush=True)\n",
    "        return super().checkpoint(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project: PhenProj\n",
      "experiment_name: multivar_camcan_nonlin_pred_head\n",
      "hypothesis: '-'\n",
      "input_dim_feat: 400\n",
      "output_dim_feat: 200\n",
      "hidden_dim: 100\n",
      "input_dim_target: 19\n",
      "output_dim_target: 50\n",
      "skip_enc1: false\n",
      "ReEig: false\n",
      "mat_ae_pretrained: false\n",
      "target_ae_pretrained: false\n",
      "pretrained_mat_ae_exp: internal_mat_ae_abcd\n",
      "pretrained_target_ae_exp: target_ae\n",
      "best_mat_ae_fold: 4\n",
      "best_target_ae_fold: 1\n",
      "synth_exp: false\n",
      "multi_gpu: true\n",
      "num_epochs: 100\n",
      "batch_size: 28\n",
      "n_runs: 1\n",
      "lr: 0.001\n",
      "weight_decay: 0\n",
      "dropout_rate: 0\n",
      "scheduler_patience: 10\n",
      "test_ratio: 0.3\n",
      "train_ratio: 1.0\n",
      "log_gradients: true\n",
      "clip_grad: true\n",
      "external_test_mode: false\n",
      "test_scanners:\n",
      "- GE MEDICAL SYSTEMS_DISCOVERY MR750\n",
      "- Philips Medical Systems_Achieva dStream\n",
      "- Philips Medical Systems_Ingenia\n",
      "SupCon_kernel: cauchy\n",
      "SupConLoss_on_mat: false\n",
      "pft_base_temperature: 0.07\n",
      "pft_temperature: 0.07\n",
      "pft_sigma: 1\n",
      "pft_reg_term: 0.01\n",
      "ptt_base_temperature: 0.07\n",
      "ptt_temperature: 0.07\n",
      "ptt_sigma: 1\n",
      "ptt_reg_term: 0.01\n",
      "feature_autoencoder_crit: Norm\n",
      "joint_embedding_crit: cosine\n",
      "target_decoding_crit: MSE\n",
      "huber_delta: 10\n",
      "augmentation: None\n",
      "mat_threshold: 0\n",
      "dataset_path: /gpfs3/well/margulies/users/cpy397/contrastive-learning/data/camcan_400parcels_2.nc\n",
      "targets:\n",
      "- age\n",
      "- benton_faces\n",
      "- cardio_measure_pulse_mean\n",
      "- cardio_measure_bp_sys_mean\n",
      "- cardio_measure_bp_dia_mean\n",
      "- cattell\n",
      "- famous_faces\n",
      "- hotel_time\n",
      "- picture_priming_baseline_acc\n",
      "- picture_priming_baseline_rt\n",
      "- rt_choice\n",
      "- rt_simple\n",
      "- syn_sem_prop_error\n",
      "- syn_sem_rt\n",
      "- tip_of_tongue\n",
      "- VSTM_colour_K_mean\n",
      "- VSTM_colour_K_precision\n",
      "- VSTM_colour_K_doubt\n",
      "- VSTM_colour_MSE\n",
      "standardize_targets: false\n",
      "work_dir: /gpfs3/well/margulies/users/cpy397/contrastive-learning\n",
      "reconstructed_dir: recon_mat\n",
      "embedding_dir: embeddings\n",
      "model_weight_dir: saved_models\n",
      "output_dir: /gpfs3/well/margulies/users/cpy397/contrastive-learning/results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\".\"):\n",
    "    cfg = compose(config_name='main_model_config.yaml')\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ratio = 0.3\n",
    "# train_ratio = 1.0\n",
    "# dataset_path = \"/gpfs3/well/margulies/users/cpy397/contrastive-learning/data/abcd_dataset_400parcels_1.nc\"\n",
    "# dataset = MatData(dataset_path, [\"nihtbx_totalcomp_agecorrected\"], synth_exp = False, threshold=0)\n",
    "# n_sub = len(dataset)\n",
    "# indices = np.arange(n_sub)\n",
    "# train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "# test_size = int(test_ratio * n_sub)\n",
    "# run_size = test_size + train_size\n",
    "# random_state = np.random.RandomState(seed=42)\n",
    "# run_indices = random_state.choice(indices, run_size, replace=False)\n",
    "# train_indices, test_indices = train_test_split(run_indices, test_size=0.3, random_state=random_state)\n",
    "# train_dataset = Subset(dataset, train_indices)\n",
    "# test_dataset = Subset(dataset, test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features = train_dataset.dataset.matrices[train_dataset.indices]\n",
    "# train_targets = train_dataset.dataset.targets[train_dataset.indices].numpy()\n",
    "# std_train_targets, mean, std= standardize(train_targets)\n",
    "# # scaler = MinMaxScaler().fit(train_targets)\n",
    "# # train_targets = scaler.transform(train_targets)\n",
    "\n",
    "# input_dim_feat =cfg.input_dim_feat\n",
    "# output_dim_feat = cfg.output_dim_feat\n",
    "\n",
    "# ## Weight initialization for bilinear layer\n",
    "# mean_f = torch.mean(train_features, dim=0).to(device)\n",
    "# [D,V] = torch.linalg.eigh(mean_f,UPLO = \"U\")\n",
    "# B_init_fMRI = V[:,input_dim_feat-output_dim_feat:] \n",
    "# test_features= test_dataset.dataset.matrices[test_dataset.indices].numpy()\n",
    "# test_targets = test_dataset.dataset.targets[test_dataset.indices].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=28, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=228, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PhenoProj(\n",
    "#     cfg.input_dim_feat,\n",
    "#     cfg.input_dim_target,\n",
    "#     cfg.hidden_dim,\n",
    "#     cfg.output_dim_target,\n",
    "#     cfg.output_dim_feat,\n",
    "#     cfg.dropout_rate,\n",
    "#     cfg\n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrices = train_loader.dataset.dataset.matrices[:3]\n",
    "# matrices = matrices.to(device)\n",
    "# targets = train_loader.dataset.dataset.targets[:3]\n",
    "# targets = targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim_feat=cfg.input_dim_feat,\n",
    "# input_dim_target=cfg.input_dim_target,\n",
    "# hidden_dim=cfg.hidden_dim,\n",
    "# output_dim_target=cfg.output_dim_target,\n",
    "# output_dim_feat=cfg.output_dim_feat,\n",
    "# dropout_rate=cfg.dropout_rate,\n",
    "\n",
    "# enc_mat1 = nn.Linear(in_features=400, out_features=70 ,bias=False)\n",
    "# enc_mat2 = nn.Linear(in_features=400, out_features=70, bias=False)\n",
    "\n",
    "# enc_mat1.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "# enc_mat2.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "\n",
    "# enc_mat1.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "# enc_mat2.weight = torch.nn.Parameter(enc_mat1.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\".\"):\n",
    "    cfg = compose(config_name='main_model_config.yaml')\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Run:   0%|                                          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda, ratio 1.0\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs:   0%|                                           | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   0%|       | 0/100 [00:00<?, ?it/s, Epoch 0 | Loss 70.73 | Corr -0.13 ]\u001b[A\n",
      "Epochs:   1%| | 1/100 [00:00<00:41,  2.36it/s, Epoch 0 | Loss 70.73 | Corr -0.13\u001b[A\n",
      "Epochs:   1%| | 1/100 [00:00<00:41,  2.36it/s, Epoch 1 | Loss 55.77 | Corr 0.01 \u001b[A\n",
      "Epochs:   2%| | 2/100 [00:00<00:39,  2.46it/s, Epoch 1 | Loss 55.77 | Corr 0.01 \u001b[A\n",
      "Epochs:   2%| | 2/100 [00:01<00:39,  2.46it/s, Epoch 2 | Loss 47.03 | Corr 0.22 \u001b[A\n",
      "Epochs:   3%| | 3/100 [00:01<00:38,  2.54it/s, Epoch 2 | Loss 47.03 | Corr 0.22 \u001b[A\n",
      "Epochs:   3%| | 3/100 [00:01<00:38,  2.54it/s, Epoch 3 | Loss 47.92 | Corr 0.52 \u001b[A\n",
      "Epochs:   4%| | 4/100 [00:01<00:38,  2.50it/s, Epoch 3 | Loss 47.92 | Corr 0.52 \u001b[A\n",
      "Epochs:   4%| | 4/100 [00:01<00:38,  2.50it/s, Epoch 4 | Loss 42.71 | Corr 0.77 \u001b[A\n",
      "Epochs:   5%| | 5/100 [00:01<00:37,  2.55it/s, Epoch 4 | Loss 42.71 | Corr 0.77 \u001b[A\n",
      "Epochs:   5%| | 5/100 [00:02<00:37,  2.55it/s, Epoch 5 | Loss 38.47 | Corr 0.81 \u001b[A\n",
      "Epochs:   6%| | 6/100 [00:02<00:36,  2.58it/s, Epoch 5 | Loss 38.47 | Corr 0.81 \u001b[A\n",
      "Epochs:   6%| | 6/100 [00:02<00:36,  2.58it/s, Epoch 6 | Loss 38.63 | Corr 0.81 \u001b[A\n",
      "Epochs:   7%| | 7/100 [00:02<00:37,  2.51it/s, Epoch 6 | Loss 38.63 | Corr 0.81 \u001b[A\n",
      "Epochs:   7%| | 7/100 [00:03<00:37,  2.51it/s, Epoch 7 | Loss 40.73 | Corr 0.83 \u001b[A\n",
      "Epochs:   8%| | 8/100 [00:03<00:36,  2.55it/s, Epoch 7 | Loss 40.73 | Corr 0.83 \u001b[A\n",
      "Epochs:   8%| | 8/100 [00:03<00:36,  2.55it/s, Epoch 8 | Loss 45.13 | Corr 0.87 \u001b[A\n",
      "Epochs:   9%| | 9/100 [00:03<00:36,  2.51it/s, Epoch 8 | Loss 45.13 | Corr 0.87 \u001b[A\n",
      "Epochs:   9%| | 9/100 [00:03<00:36,  2.51it/s, Epoch 9 | Loss 40.58 | Corr 0.89 \u001b[A\n",
      "Epochs:  10%| | 10/100 [00:03<00:35,  2.55it/s, Epoch 9 | Loss 40.58 | Corr 0.89\u001b[A\n",
      "Epochs:  10%| | 10/100 [00:04<00:35,  2.55it/s, Epoch 10 | Loss 37.64 | Corr 0.8\u001b[A\n",
      "Epochs:  11%| | 11/100 [00:04<00:34,  2.57it/s, Epoch 10 | Loss 37.64 | Corr 0.8\u001b[A\n",
      "Epochs:  11%| | 11/100 [00:04<00:34,  2.57it/s, Epoch 11 | Loss 45.54 | Corr 0.9\u001b[A\n",
      "Epochs:  12%| | 12/100 [00:04<00:35,  2.51it/s, Epoch 11 | Loss 45.54 | Corr 0.9\u001b[A\n",
      "Epochs:  12%| | 12/100 [00:05<00:35,  2.51it/s, Epoch 12 | Loss 40.06 | Corr 0.8\u001b[A\n",
      "Epochs:  13%|▏| 13/100 [00:05<00:34,  2.54it/s, Epoch 12 | Loss 40.06 | Corr 0.8\u001b[A\n",
      "Epochs:  13%|▏| 13/100 [00:05<00:34,  2.54it/s, Epoch 13 | Loss 38.83 | Corr 0.9\u001b[A\n",
      "Epochs:  14%|▏| 14/100 [00:05<00:34,  2.49it/s, Epoch 13 | Loss 38.83 | Corr 0.9\u001b[A\n",
      "Epochs:  14%|▏| 14/100 [00:05<00:34,  2.49it/s, Epoch 14 | Loss 40.81 | Corr 0.9\u001b[A\n",
      "Epochs:  15%|▏| 15/100 [00:05<00:33,  2.52it/s, Epoch 14 | Loss 40.81 | Corr 0.9\u001b[A\n",
      "Epochs:  15%|▏| 15/100 [00:06<00:33,  2.52it/s, Epoch 15 | Loss 40.66 | Corr 0.9\u001b[A\n",
      "Epochs:  16%|▏| 16/100 [00:06<00:33,  2.49it/s, Epoch 15 | Loss 40.66 | Corr 0.9\u001b[A\n",
      "Epochs:  16%|▏| 16/100 [00:06<00:33,  2.49it/s, Epoch 16 | Loss 44.30 | Corr 0.9\u001b[A\n",
      "Epochs:  17%|▏| 17/100 [00:06<00:33,  2.45it/s, Epoch 16 | Loss 44.30 | Corr 0.9\u001b[A\n",
      "Epochs:  17%|▏| 17/100 [00:07<00:33,  2.45it/s, Epoch 17 | Loss 41.13 | Corr 0.9\u001b[A\n",
      "Epochs:  18%|▏| 18/100 [00:07<00:32,  2.49it/s, Epoch 17 | Loss 41.13 | Corr 0.9\u001b[A\n",
      "Epochs:  18%|▏| 18/100 [00:07<00:32,  2.49it/s, Epoch 18 | Loss 44.51 | Corr 0.9\u001b[A\n",
      "Epochs:  19%|▏| 19/100 [00:07<00:32,  2.47it/s, Epoch 18 | Loss 44.51 | Corr 0.9\u001b[A\n",
      "Epochs:  19%|▏| 19/100 [00:07<00:32,  2.47it/s, Epoch 19 | Loss 37.53 | Corr 0.9\u001b[A\n",
      "Epochs:  20%|▏| 20/100 [00:07<00:32,  2.49it/s, Epoch 19 | Loss 37.53 | Corr 0.9\u001b[A\n",
      "Epochs:  20%|▏| 20/100 [00:08<00:32,  2.49it/s, Epoch 20 | Loss 46.00 | Corr 0.9\u001b[A\n",
      "Epochs:  21%|▏| 21/100 [00:08<00:31,  2.53it/s, Epoch 20 | Loss 46.00 | Corr 0.9\u001b[A\n",
      "Epochs:  21%|▏| 21/100 [00:08<00:31,  2.53it/s, Epoch 21 | Loss 45.73 | Corr 0.9\u001b[A\n",
      "Epochs:  22%|▏| 22/100 [00:08<00:31,  2.47it/s, Epoch 21 | Loss 45.73 | Corr 0.9\u001b[A\n",
      "Epochs:  22%|▏| 22/100 [00:09<00:31,  2.47it/s, Epoch 22 | Loss 45.76 | Corr 0.9\u001b[A\n",
      "Epochs:  23%|▏| 23/100 [00:09<00:30,  2.50it/s, Epoch 22 | Loss 45.76 | Corr 0.9\u001b[A\n",
      "Epochs:  23%|▏| 23/100 [00:09<00:30,  2.50it/s, Epoch 23 | Loss 43.96 | Corr 0.9\u001b[A\n",
      "Epochs:  24%|▏| 24/100 [00:09<00:30,  2.53it/s, Epoch 23 | Loss 43.96 | Corr 0.9\u001b[A\n",
      "Epochs:  24%|▏| 24/100 [00:09<00:30,  2.53it/s, Epoch 24 | Loss 42.56 | Corr 0.9\u001b[A\n",
      "Epochs:  25%|▎| 25/100 [00:09<00:30,  2.49it/s, Epoch 24 | Loss 42.56 | Corr 0.9\u001b[A\n",
      "Epochs:  25%|▎| 25/100 [00:10<00:30,  2.49it/s, Epoch 25 | Loss 44.78 | Corr 0.9\u001b[A\n",
      "Epochs:  26%|▎| 26/100 [00:10<00:29,  2.53it/s, Epoch 25 | Loss 44.78 | Corr 0.9\u001b[A\n",
      "Epochs:  26%|▎| 26/100 [00:10<00:29,  2.53it/s, Epoch 26 | Loss 40.74 | Corr 0.9\u001b[A\n",
      "Epochs:  27%|▎| 27/100 [00:10<00:29,  2.48it/s, Epoch 26 | Loss 40.74 | Corr 0.9\u001b[A\n",
      "Epochs:  27%|▎| 27/100 [00:11<00:29,  2.48it/s, Epoch 27 | Loss 39.33 | Corr 0.9\u001b[A\n",
      "Epochs:  28%|▎| 28/100 [00:11<00:28,  2.51it/s, Epoch 27 | Loss 39.33 | Corr 0.9\u001b[A\n",
      "Epochs:  28%|▎| 28/100 [00:11<00:28,  2.51it/s, Epoch 28 | Loss 41.13 | Corr 0.9\u001b[A\n",
      "Epochs:  29%|▎| 29/100 [00:11<00:27,  2.55it/s, Epoch 28 | Loss 41.13 | Corr 0.9\u001b[A\n",
      "Epochs:  29%|▎| 29/100 [00:11<00:27,  2.55it/s, Epoch 29 | Loss 40.17 | Corr 0.9\u001b[A\n",
      "Epochs:  30%|▎| 30/100 [00:11<00:28,  2.50it/s, Epoch 29 | Loss 40.17 | Corr 0.9\u001b[A\n",
      "Epochs:  30%|▎| 30/100 [00:12<00:28,  2.50it/s, Epoch 30 | Loss 38.05 | Corr 0.9\u001b[A\n",
      "Epochs:  31%|▎| 31/100 [00:12<00:27,  2.54it/s, Epoch 30 | Loss 38.05 | Corr 0.9\u001b[A\n",
      "Epochs:  31%|▎| 31/100 [00:12<00:27,  2.54it/s, Epoch 31 | Loss 39.55 | Corr 0.9\u001b[A\n",
      "Epochs:  32%|▎| 32/100 [00:12<00:27,  2.50it/s, Epoch 31 | Loss 39.55 | Corr 0.9\u001b[A\n",
      "Epochs:  32%|▎| 32/100 [00:13<00:27,  2.50it/s, Epoch 32 | Loss 39.73 | Corr 0.9\u001b[A\n",
      "Epochs:  33%|▎| 33/100 [00:13<00:26,  2.53it/s, Epoch 32 | Loss 39.73 | Corr 0.9\u001b[A\n",
      "Epochs:  33%|▎| 33/100 [00:13<00:26,  2.53it/s, Epoch 33 | Loss 42.38 | Corr 0.9\u001b[A\n",
      "Epochs:  34%|▎| 34/100 [00:13<00:25,  2.55it/s, Epoch 33 | Loss 42.38 | Corr 0.9\u001b[A\n",
      "Epochs:  34%|▎| 34/100 [00:13<00:25,  2.55it/s, Epoch 34 | Loss 43.86 | Corr 0.9\u001b[A\n",
      "Epochs:  35%|▎| 35/100 [00:13<00:26,  2.49it/s, Epoch 34 | Loss 43.86 | Corr 0.9\u001b[A\n",
      "Epochs:  35%|▎| 35/100 [00:14<00:26,  2.49it/s, Epoch 35 | Loss 41.30 | Corr 0.9\u001b[A\n",
      "Epochs:  36%|▎| 36/100 [00:14<00:25,  2.52it/s, Epoch 35 | Loss 41.30 | Corr 0.9\u001b[A\n",
      "Epochs:  36%|▎| 36/100 [00:14<00:25,  2.52it/s, Epoch 36 | Loss 42.47 | Corr 0.9\u001b[A\n",
      "Epochs:  37%|▎| 37/100 [00:14<00:25,  2.50it/s, Epoch 36 | Loss 42.47 | Corr 0.9\u001b[A\n",
      "Epochs:  37%|▎| 37/100 [00:15<00:25,  2.50it/s, Epoch 37 | Loss 37.66 | Corr 0.9\u001b[A\n",
      "Epochs:  38%|▍| 38/100 [00:15<00:24,  2.51it/s, Epoch 37 | Loss 37.66 | Corr 0.9\u001b[A\n",
      "Epochs:  38%|▍| 38/100 [00:15<00:24,  2.51it/s, Epoch 38 | Loss 42.36 | Corr 0.9\u001b[A\n",
      "Epochs:  39%|▍| 39/100 [00:15<00:24,  2.52it/s, Epoch 38 | Loss 42.36 | Corr 0.9\u001b[A\n",
      "Epochs:  39%|▍| 39/100 [00:15<00:24,  2.52it/s, Epoch 39 | Loss 39.08 | Corr 0.9\u001b[A\n",
      "Epochs:  40%|▍| 40/100 [00:15<00:24,  2.45it/s, Epoch 39 | Loss 39.08 | Corr 0.9\u001b[A\n",
      "Epochs:  40%|▍| 40/100 [00:16<00:24,  2.45it/s, Epoch 40 | Loss 40.62 | Corr 0.9\u001b[A\n",
      "Epochs:  41%|▍| 41/100 [00:16<00:24,  2.45it/s, Epoch 40 | Loss 40.62 | Corr 0.9\u001b[A\n",
      "Epochs:  41%|▍| 41/100 [00:16<00:24,  2.45it/s, Epoch 41 | Loss 39.08 | Corr 0.9\u001b[A\n",
      "Epochs:  42%|▍| 42/100 [00:16<00:23,  2.48it/s, Epoch 41 | Loss 39.08 | Corr 0.9\u001b[A\n",
      "Epochs:  42%|▍| 42/100 [00:17<00:23,  2.48it/s, Epoch 42 | Loss 42.70 | Corr 0.9\u001b[A\n",
      "Epochs:  43%|▍| 43/100 [00:17<00:23,  2.44it/s, Epoch 42 | Loss 42.70 | Corr 0.9\u001b[A\n",
      "Epochs:  43%|▍| 43/100 [00:17<00:23,  2.44it/s, Epoch 43 | Loss 43.54 | Corr 0.9\u001b[A\n",
      "Epochs:  44%|▍| 44/100 [00:17<00:22,  2.47it/s, Epoch 43 | Loss 43.54 | Corr 0.9\u001b[A\n",
      "Epochs:  44%|▍| 44/100 [00:18<00:22,  2.47it/s, Epoch 44 | Loss 37.67 | Corr 0.9\u001b[A\n",
      "Epochs:  45%|▍| 45/100 [00:18<00:22,  2.43it/s, Epoch 44 | Loss 37.67 | Corr 0.9\u001b[A\n",
      "Epochs:  45%|▍| 45/100 [00:18<00:22,  2.43it/s, Epoch 45 | Loss 45.49 | Corr 0.9\u001b[A\n",
      "Epochs:  46%|▍| 46/100 [00:18<00:22,  2.45it/s, Epoch 45 | Loss 45.49 | Corr 0.9\u001b[A\n",
      "Epochs:  46%|▍| 46/100 [00:18<00:22,  2.45it/s, Epoch 46 | Loss 40.87 | Corr 0.9\u001b[A\n",
      "Epochs:  47%|▍| 47/100 [00:18<00:21,  2.47it/s, Epoch 46 | Loss 40.87 | Corr 0.9\u001b[A\n",
      "Epochs:  47%|▍| 47/100 [00:19<00:21,  2.47it/s, Epoch 47 | Loss 42.57 | Corr 0.9\u001b[A\n",
      "Epochs:  48%|▍| 48/100 [00:19<00:21,  2.41it/s, Epoch 47 | Loss 42.57 | Corr 0.9\u001b[A\n",
      "Epochs:  48%|▍| 48/100 [00:19<00:21,  2.41it/s, Epoch 48 | Loss 46.05 | Corr 0.9\u001b[A\n",
      "Epochs:  49%|▍| 49/100 [00:19<00:20,  2.45it/s, Epoch 48 | Loss 46.05 | Corr 0.9\u001b[A\n",
      "Epochs:  49%|▍| 49/100 [00:20<00:20,  2.45it/s, Epoch 49 | Loss 43.70 | Corr 0.9\u001b[A\n",
      "Epochs:  50%|▌| 50/100 [00:20<00:20,  2.40it/s, Epoch 49 | Loss 43.70 | Corr 0.9\u001b[A\n",
      "Epochs:  50%|▌| 50/100 [00:20<00:20,  2.40it/s, Epoch 50 | Loss 40.64 | Corr 0.9\u001b[A\n",
      "Epochs:  51%|▌| 51/100 [00:20<00:20,  2.45it/s, Epoch 50 | Loss 40.64 | Corr 0.9\u001b[A\n",
      "Epochs:  51%|▌| 51/100 [00:20<00:20,  2.45it/s, Epoch 51 | Loss 39.73 | Corr 0.9\u001b[A\n",
      "Epochs:  52%|▌| 52/100 [00:20<00:19,  2.47it/s, Epoch 51 | Loss 39.73 | Corr 0.9\u001b[A\n",
      "Epochs:  52%|▌| 52/100 [00:21<00:19,  2.47it/s, Epoch 52 | Loss 39.61 | Corr 0.9\u001b[A\n",
      "Epochs:  53%|▌| 53/100 [00:21<00:19,  2.40it/s, Epoch 52 | Loss 39.61 | Corr 0.9\u001b[A\n",
      "Epochs:  53%|▌| 53/100 [00:21<00:19,  2.40it/s, Epoch 53 | Loss 44.69 | Corr 0.9\u001b[A\n",
      "Epochs:  54%|▌| 54/100 [00:21<00:18,  2.44it/s, Epoch 53 | Loss 44.69 | Corr 0.9\u001b[A\n",
      "Epochs:  54%|▌| 54/100 [00:22<00:18,  2.44it/s, Epoch 54 | Loss 41.71 | Corr 0.9\u001b[A\n",
      "Epochs:  55%|▌| 55/100 [00:22<00:18,  2.41it/s, Epoch 54 | Loss 41.71 | Corr 0.9\u001b[A\n",
      "Epochs:  55%|▌| 55/100 [00:22<00:18,  2.41it/s, Epoch 55 | Loss 38.94 | Corr 0.9\u001b[A\n",
      "Epochs:  56%|▌| 56/100 [00:22<00:18,  2.44it/s, Epoch 55 | Loss 38.94 | Corr 0.9\u001b[A\n",
      "Epochs:  56%|▌| 56/100 [00:22<00:18,  2.44it/s, Epoch 56 | Loss 40.64 | Corr 0.9\u001b[A\n",
      "Epochs:  57%|▌| 57/100 [00:22<00:17,  2.47it/s, Epoch 56 | Loss 40.64 | Corr 0.9\u001b[A\n",
      "Epochs:  57%|▌| 57/100 [00:23<00:17,  2.47it/s, Epoch 57 | Loss 43.25 | Corr 0.9\u001b[A\n",
      "Epochs:  58%|▌| 58/100 [00:23<00:17,  2.42it/s, Epoch 57 | Loss 43.25 | Corr 0.9\u001b[A\n",
      "Epochs:  58%|▌| 58/100 [00:23<00:17,  2.42it/s, Epoch 58 | Loss 43.60 | Corr 0.9\u001b[A\n",
      "Epochs:  59%|▌| 59/100 [00:23<00:16,  2.45it/s, Epoch 58 | Loss 43.60 | Corr 0.9\u001b[A\n",
      "Epochs:  59%|▌| 59/100 [00:24<00:16,  2.45it/s, Epoch 59 | Loss 42.05 | Corr 0.9\u001b[A\n",
      "Epochs:  60%|▌| 60/100 [00:24<00:16,  2.48it/s, Epoch 59 | Loss 42.05 | Corr 0.9\u001b[A\n",
      "Epochs:  60%|▌| 60/100 [00:24<00:16,  2.48it/s, Epoch 60 | Loss 43.27 | Corr 0.9\u001b[A\n",
      "Epochs:  61%|▌| 61/100 [00:24<00:16,  2.42it/s, Epoch 60 | Loss 43.27 | Corr 0.9\u001b[A\n",
      "Epochs:  61%|▌| 61/100 [00:24<00:16,  2.42it/s, Epoch 61 | Loss 36.52 | Corr 0.9\u001b[A\n",
      "Epochs:  62%|▌| 62/100 [00:24<00:15,  2.46it/s, Epoch 61 | Loss 36.52 | Corr 0.9\u001b[A\n",
      "Epochs:  62%|▌| 62/100 [00:25<00:15,  2.46it/s, Epoch 62 | Loss 42.20 | Corr 0.9\u001b[A\n",
      "Epochs:  63%|▋| 63/100 [00:25<00:15,  2.40it/s, Epoch 62 | Loss 42.20 | Corr 0.9\u001b[A\n",
      "Epochs:  63%|▋| 63/100 [00:25<00:15,  2.40it/s, Epoch 63 | Loss 39.28 | Corr 0.9\u001b[A\n",
      "Epochs:  64%|▋| 64/100 [00:25<00:14,  2.43it/s, Epoch 63 | Loss 39.28 | Corr 0.9\u001b[A\n",
      "Epochs:  64%|▋| 64/100 [00:26<00:14,  2.43it/s, Epoch 64 | Loss 40.59 | Corr 0.9\u001b[A\n",
      "Epochs:  65%|▋| 65/100 [00:26<00:14,  2.46it/s, Epoch 64 | Loss 40.59 | Corr 0.9\u001b[A\n",
      "Epochs:  65%|▋| 65/100 [00:26<00:14,  2.46it/s, Epoch 65 | Loss 42.79 | Corr 0.9\u001b[A\n",
      "Epochs:  66%|▋| 66/100 [00:26<00:14,  2.42it/s, Epoch 65 | Loss 42.79 | Corr 0.9\u001b[A\n",
      "Epochs:  66%|▋| 66/100 [00:26<00:14,  2.42it/s, Epoch 66 | Loss 43.71 | Corr 0.9\u001b[A\n",
      "Epochs:  67%|▋| 67/100 [00:26<00:13,  2.48it/s, Epoch 66 | Loss 43.71 | Corr 0.9\u001b[A\n",
      "Epochs:  67%|▋| 67/100 [00:27<00:13,  2.48it/s, Epoch 67 | Loss 39.16 | Corr 0.9\u001b[A\n",
      "Epochs:  68%|▋| 68/100 [00:27<00:12,  2.47it/s, Epoch 67 | Loss 39.16 | Corr 0.9\u001b[A\n",
      "Epochs:  68%|▋| 68/100 [00:27<00:12,  2.47it/s, Epoch 68 | Loss 43.51 | Corr 0.9\u001b[A\n",
      "Epochs:  69%|▋| 69/100 [00:27<00:12,  2.48it/s, Epoch 68 | Loss 43.51 | Corr 0.9\u001b[A\n",
      "Epochs:  69%|▋| 69/100 [00:28<00:12,  2.48it/s, Epoch 69 | Loss 41.51 | Corr 0.9\u001b[A\n",
      "Epochs:  70%|▋| 70/100 [00:28<00:12,  2.50it/s, Epoch 69 | Loss 41.51 | Corr 0.9\u001b[A\n",
      "Epochs:  70%|▋| 70/100 [00:28<00:12,  2.50it/s, Epoch 70 | Loss 44.11 | Corr 0.9\u001b[A\n",
      "Epochs:  71%|▋| 71/100 [00:28<00:11,  2.44it/s, Epoch 70 | Loss 44.11 | Corr 0.9\u001b[A\n",
      "Epochs:  71%|▋| 71/100 [00:29<00:11,  2.44it/s, Epoch 71 | Loss 40.62 | Corr 0.9\u001b[A\n",
      "Epochs:  72%|▋| 72/100 [00:29<00:11,  2.49it/s, Epoch 71 | Loss 40.62 | Corr 0.9\u001b[A\n",
      "Epochs:  72%|▋| 72/100 [00:29<00:11,  2.49it/s, Epoch 72 | Loss 45.00 | Corr 0.9\u001b[A\n",
      "Epochs:  73%|▋| 73/100 [00:29<00:10,  2.48it/s, Epoch 72 | Loss 45.00 | Corr 0.9\u001b[A\n",
      "Epochs:  73%|▋| 73/100 [00:29<00:10,  2.48it/s, Epoch 73 | Loss 39.70 | Corr 0.9\u001b[A\n",
      "Epochs:  74%|▋| 74/100 [00:29<00:10,  2.49it/s, Epoch 73 | Loss 39.70 | Corr 0.9\u001b[A\n",
      "Epochs:  74%|▋| 74/100 [00:30<00:10,  2.49it/s, Epoch 74 | Loss 40.28 | Corr 0.9\u001b[A\n",
      "Epochs:  75%|▊| 75/100 [00:30<00:09,  2.52it/s, Epoch 74 | Loss 40.28 | Corr 0.9\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇█</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>█▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>██▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▁▂▁▁▁▂▁▂▁▂▁▂▁▂▂▂</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>▃██▃▃▂▂▂▂▂▂▂▃▂▂▂▁▁▁▂▁▁▂▂▁▁▁▃▄▂▁▃▂▂▂▁▁▂▃▁</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>▇▅▃▃▄▅▄▄▄▂▂▂▂▃▂▂▁▂▁▂▂▂▂▂▁▂▂▂▃▄▅▆▇▄▁▂▄▃█▁</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>▅▆▅▃▄▃▄▃▂▁▃▃▂▁▂▁▄▃▂▁▃▃▁▂▂▃▃█▆▃▄▂▁▃▂▆▂▁▅▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>▇█▆▆▃▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▄▂▁▂▂▁▁▃▃▂▁▂▂▃▂▂▁▄▂▁</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>▁▃▃▅▃▃▃▃▃▄▃▃█▃▂▃▄▂▃▃▃▃▃▄▃▃▃▃▃▆▅▃▃▄▆▅▃▆▃▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>▁█▃▃▂▃▁▂▃▁▂▂▂▂▁▁▁▃▂▃▃▇▄▄▃▅▅▄▅▄▅▅▆▄▄▅▅▆▅▅</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>█▁▂▁▃▂▁▂▁▂▂▁▂▃▁▁▁▂▁▁▂▂▂▂▁▁▁▂▁▁▁▁▂▂▁▁▂▂▂▂</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>▁▁▆█████████████████▇██████████████▇████</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>▁▅▃▃▄▄▄▄▃▆▂▅▃▄▃▃▃▂▃▇▃█▄▄▃▅▅▃▅▂█▅▅▃▂▃▃▄▃▇</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>▁▁▁▁▃▅▂▃▅▅▄▅▇▆▃▃▂▂▄▄█▇▅▃▄▃▂▂▅▂▅▆▂▄▃▇▂▃▂▃</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat1.weight</td><td>▃▂▄█▂▃▂▃▄▂▄▂▇▇▆▅▃▂▁▁▂▁▂▁▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat2.weight</td><td>▂▂▃▂▂▅▅▂▃▃▂▃▃▂▂▃▂▂█▄▃▃▂▃▂▁▂▁▂▂▁▁▂▁▂▁▁▁▂▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>▁▁▁▂▄▆▅▆█▄▅█▃▄▇▂▃▄▂▅▃▅▂▂▂▄▄▂▂▄▂▂▄▂▂▄▂▃▃▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>▁▁▁▄▄█▆█▅▇▃▄▃▂▂▃▂▃▆▇▂▅▅▇▇▅▃▂▃▂▅▁▃▃▄▃▃▆▅▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>▁▁▂▃▂▂▃▃▂▂▃▂▅▂▂▂▂█▂▃▃▁▂▄▂▂▃▃▁▁▄▂▁▂▂▅▄▂▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>▁▁▁▁▁▂▂▃▂▃▂▃▂▄▂▂▂▃▂▂▂█▂▂▂▂▄▂▃▃▂▂▂▅▃▁▂▂▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>▁▁▆█▅▅▆▃▂▂▁▁▁▂▁▁▁▂▁▁▁▂▂▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>▁▃▃▅▆▄▅▃▃▃▇▃▅▂▃▂▂▃▅▂▆▄▅▅█▃▃▁▃▆▃▂▅▂▄▃▄▁▂▄</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>▁▁▁▃▂▃▅▅▅▃▃▃▅█▂▂▂▃▂▃▄▆▅▂▂▃▃▄▂▂▁▂▃▂▂█▄▂▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>▁▁▁▁▂▃▃▂▇█▅▇▂▂▂▅▂▂▃▂▆▃▃▄▂▄▂▃▂▂▂▃▁▂▂▁▂▅▅▅</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>▁▁▁▁▁▂▂▄▂▃▄▂█▂▃▄▃▃▃▅▃▂▁▂▄█▄▅▃▂▄▂▃▃▁▃▃▂▁▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>▁▁▁▂▂▁▂▂▃▂▂▅▃▃▂▃▂▅▅▃▃▂▂█▅▂▄▂▂▂▆▂▄▂▂▃▂▂▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>▁▁▂▂▅▅▅▃▃▃▃▂▃▂▃▂▂▂▂▃▆▂▃▂▂▂▂▂▃▂▁▅▂▂▂▂█▂▂▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>▁▁▁▁▁▁▃▂▄▅▂▂▃▃▂▂▂▂▁▂▂▂▂▁▃▂▃▃▂▄▁▂▂▂▅▂▃▂█▆</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>▁▁▁▃▃▆█▃▃▂▁▃▂▂▄▂▁▂▁▃▃▂▂▁▃▄▅▂▃▂▁▁▃▂▂▂▂▂▁▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>▁▁▁▁▃▃▃▄▃▃▂▂▃▃▂▂▂▄▃▃▆▄▂▂▃█▅▂▃▂▂▂▃▂▂▁▂▁▂▂</td></tr><tr><td>Run</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Target Corr/val</td><td>▁▃▇▇▇▇▇▇████████████████████████████████</td></tr><tr><td>Target MAPE/val</td><td>█▅▄▄▃▂▃▂▂▂▂▂▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>direction_reg_target_loss</td><td>▃▄▆▂▅▄▄▂▅▄▂▇▅▃▅▄▄▄█▆▃▆▃▃▂▅▂▅▅▃▃▂▃▃▁▃▄▂▃▃</td></tr><tr><td>feature_autoencoder_loss</td><td>██▆▄▃▂▃▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>kernel_embedded_feature_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>kernel_embedded_target_loss</td><td>▇█▆▂▃▁▁▂▂▁▂▃▂▁▁▂▂▁▁▂▂▁▂▁▂▁▂▁▂▂▃▂▁▁▂▂▂▁▃▂</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>█▇▆▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>▇▇█▂▂▁▂▂▂▂▃▃▂▂▂▁▂▁▂▂▂▂▁▁▂▂▂▂▂▂▂▁▂▁▂▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>75</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>0.11572</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>0.00284</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>0.00663</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>0.10062</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>0.02388</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>0.05096</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>0.01541</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>0.97489</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>0.10499</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>0.10499</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat1.weight</td><td>0.01513</td></tr><tr><td>Gradient Norm/matrix_ae.enc_mat2.weight</td><td>0.01513</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>0.00356</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>0.00018</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>0.00029</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>0.00023</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>0.0037</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>0.00535</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>0.00034</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>0.00045</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>0.00796</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>0.00048</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>0.00082</td></tr><tr><td>Run</td><td>0</td></tr><tr><td>Target Corr/val</td><td>0.98291</td></tr><tr><td>Target MAPE/val</td><td>6.79994</td></tr><tr><td>direction_reg_target_loss</td><td>29.71265</td></tr><tr><td>feature_autoencoder_loss</td><td>0.1124</td></tr><tr><td>kernel_embedded_feature_loss</td><td>0</td></tr><tr><td>kernel_embedded_target_loss</td><td>43.55067</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>0.00029</td></tr><tr><td>total_loss</td><td>43.66336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /gpfs3/well/margulies/users/cpy397/contrastive-learning/results/wandb/offline-run-20241114_105547-6rflrr7d<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./results/wandb/offline-run-20241114_105547-6rflrr7d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs3/well/margulies/users/cpy397/contrastive-learning/contrastive_phenotypes/src/ContModeling/viz_func.py:107: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  correlations[i // cols, i % cols] = spearmanr(flat_true[:, i], flat_recon[:, i])[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>▁</td></tr><tr><td>Test | Target Corr/val</td><td>▁</td></tr><tr><td>Test | Target MAPE/val</td><td>▁</td></tr><tr><td>Test | Train ratio</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>0</td></tr><tr><td>Test | Target Corr/val</td><td>0.98309</td></tr><tr><td>Test | Target MAPE/val</td><td>6.76515</td></tr><tr><td>Test | Train ratio</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /gpfs3/well/margulies/users/cpy397/contrastive-learning/results/wandb/offline-run-20241114_105623-um00db8b<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./results/wandb/offline-run-20241114_105623-um00db8b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Run: 100%|█████████████████████████████████| 1/1 [03:40<00:00, 220.13s/it]\n"
     ]
    }
   ],
   "source": [
    "def main(cfg=cfg):\n",
    "\n",
    "    results_dir = os.path.join(cfg.output_dir, cfg.experiment_name)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    random_state = np.random.RandomState(seed=42)\n",
    "\n",
    "    dataset_path = cfg.dataset_path\n",
    "\n",
    "    if isinstance(cfg.targets, str):\n",
    "        \n",
    "        targets =[cfg.targets]\n",
    "    else:\n",
    "        targets = list(cfg.targets)\n",
    "        \n",
    "    test_ratio = cfg.test_ratio\n",
    "\n",
    "    dataset = MatData(dataset_path, targets, synth_exp = cfg.synth_exp, threshold=cfg.mat_threshold)\n",
    "    n_sub = len(dataset)\n",
    "    test_size = int(test_ratio * n_sub)\n",
    "    indices = np.arange(n_sub)\n",
    "    n_runs = cfg.n_runs\n",
    "    multi_gpu = cfg.multi_gpu\n",
    "    train_ratio = cfg.train_ratio\n",
    "    \n",
    "    multi_gpu = False\n",
    "    if multi_gpu:\n",
    "        print(\"Using multi-gpu\")\n",
    "        log_folder = Path(\"logs\")\n",
    "        executor = submitit.AutoExecutor(folder=str(log_folder / \"%j\"))\n",
    "        executor.update_parameters(\n",
    "            timeout_min=120,\n",
    "            slurm_partition=\"gpu_short\",\n",
    "            gpus_per_node=1,\n",
    "            tasks_per_node=1,\n",
    "            nodes=1\n",
    "            #slurm_constraint=\"v100-32g\",\n",
    "        )\n",
    "        run_jobs = []\n",
    "\n",
    "        with executor.batch():\n",
    "            train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "            run_size = test_size + train_size\n",
    "            for run in tqdm(range(n_runs)):\n",
    "                run_model = ModelRun()\n",
    "                job = executor.submit(run_model, train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state=random_state, device=None)\n",
    "                run_jobs.append(job)\n",
    "\n",
    "        async def get_result(run_jobs):\n",
    "            run_results = []\n",
    "            for aws in tqdm(asyncio.as_completed([j.awaitable().result() for j in run_jobs]), total=len(run_jobs)):\n",
    "                res = await aws\n",
    "                run_results.append(res)\n",
    "            return run_results\n",
    "        run_results = asyncio.run(get_result(run_jobs))\n",
    "\n",
    "    else:\n",
    "        run_results = []\n",
    "        train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "        run_size = test_size + train_size\n",
    "        for run in tqdm(range(n_runs), desc=\"Model Run\"):\n",
    "            run_model = ModelRun()\n",
    "            job = run_model(train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state=random_state, device=None)\n",
    "            run_results.append(job)\n",
    "\n",
    "    losses, predictions, embeddings = zip(*run_results)\n",
    "\n",
    "    prediction_metrics = predictions[0]\n",
    "    for prediction in predictions[1:]:\n",
    "        prediction_metrics.update(prediction)\n",
    "\n",
    "    pred_results = []\n",
    "    for k, v in prediction_metrics.items():\n",
    "        true_targets, predicted_targets, indices = v\n",
    "        \n",
    "        true_targets_dict = {\"train_ratio\": [k[0]] * len(true_targets),\n",
    "                             \"model_run\":[k[1]] * len(true_targets),\n",
    "                             \"dataset\":[k[2]] * len(true_targets)\n",
    "                            }\n",
    "        predicted_targets_dict = {\"indices\": indices}\n",
    "        \n",
    "        for i, target in enumerate(targets):\n",
    "            true_targets_dict[target] = true_targets[:, i]\n",
    "            predicted_targets_dict[f\"{target}_pred\"] = predicted_targets[:, i]\n",
    "            \n",
    "            \n",
    "        true_targets = pd.DataFrame(true_targets_dict)\n",
    "        predicted_targets = pd.DataFrame(predicted_targets_dict)\n",
    "        \n",
    "        pred_results.append(pd.concat([true_targets, predicted_targets], axis = 1))\n",
    "    pred_results = pd.concat(pred_results)\n",
    "    pred_results.to_csv(f\"{results_dir}/pred_results.csv\", index=False)\n",
    "\n",
    "    prediction_mape_by_element = []\n",
    "    for k, v in prediction_metrics.items():\n",
    "        true_targets, predicted_targets, indices = v\n",
    "        \n",
    "        mape_by_element = np.abs(true_targets - predicted_targets) / (np.abs(true_targets)+1e-10)\n",
    "        \n",
    "        for i, mape in enumerate(mape_by_element):\n",
    "            prediction_mape_by_element.append(\n",
    "                {\n",
    "                    'train_ratio': k[0],\n",
    "                    'model_run': k[1],\n",
    "                    'dataset': k[2],\n",
    "                    'mape': mape\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(prediction_mape_by_element)\n",
    "    df = pd.concat([df.drop('mape', axis=1), df['mape'].apply(pd.Series)], axis=1)\n",
    "    df.columns = ['train_ratio', 'model_run', 'dataset'] + targets\n",
    "    df= df.groupby(['train_ratio', 'model_run', 'dataset']).agg('mean').reset_index()\n",
    "    df.to_csv(f\"{results_dir}/mape.csv\", index = False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
