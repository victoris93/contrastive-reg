{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import yaml\n",
    "import wandb\n",
    "import xarray as xr\n",
    "import asyncio\n",
    "import submitit\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from nilearn.connectome import sym_matrix_to_vec, vec_to_sym_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "# from augmentations import augs, aug_args\n",
    "import glob, os, shutil\n",
    "from nilearn.datasets import fetch_atlas_schaefer_2018\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from ContModeling.utils import gaussian_kernel, cauchy, standardize, save_embeddings\n",
    "from ContModeling.losses import LogEuclideanLoss, NormLoss, KernelizedSupCon, OutlierRobustMSE\n",
    "from ContModeling.models import PhenoProj\n",
    "from ContModeling.helper_classes import MatData\n",
    "from ContModeling.viz_func import wandb_plot_acc_vs_baseline, wandb_plot_test_recon_corr, wandb_plot_individual_recon\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run, train_ratio, train_dataset, test_dataset, mean, std, B_init_fMRI, cfg, model=None, device=device):\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    # MODEL DIMS\n",
    "    input_dim_feat = cfg.input_dim_feat\n",
    "    input_dim_target = cfg.input_dim_target\n",
    "    hidden_dim = cfg.hidden_dim\n",
    "    output_dim_target = cfg.output_dim_target\n",
    "    output_dim_feat = cfg.output_dim_feat\n",
    "    kernel = SUPCON_KERNELS[cfg.SupCon_kernel]\n",
    "    \n",
    "    # TRAINING PARAMS\n",
    "    lr = cfg.lr\n",
    "    batch_size = cfg.batch_size\n",
    "    dropout_rate = cfg.dropout_rate\n",
    "    weight_decay = cfg.weight_decay\n",
    "    num_epochs = cfg.num_epochs\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    mean= torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    if model is None:\n",
    "        model = PhenoProj(\n",
    "            input_dim_feat,\n",
    "            input_dim_target,\n",
    "            hidden_dim,\n",
    "            output_dim_target,\n",
    "            output_dim_feat,\n",
    "            dropout_rate,\n",
    "            cfg\n",
    "        ).to(device)\n",
    "\n",
    "    if cfg.mat_ae_pretrained:\n",
    "        print(\"Loading pretrained MatrixAutoencoder...\")\n",
    "        state_dict = torch.load(f\"{cfg.output_dir}/{cfg.pretrained_mat_ae_exp}/saved_models/autoencoder_weights_fold{cfg.best_mat_ae_fold}.pth\")\n",
    "        model.matrix_ae.load_state_dict(state_dict)\n",
    "    else:\n",
    "        model.matrix_ae.enc_mat1.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "        model.matrix_ae.enc_mat2.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "    \n",
    "    if cfg.target_ae_pretrained:\n",
    "        print(\"Loading pretrained TargetAutoencoder...\")\n",
    "        state_dict = torch.load(f\"{cfg.output_dir}/{cfg.pretrained_target_ae_exp}/saved_models/autoencoder_weights_fold{cfg.best_target_ae_fold}.pth\")\n",
    "        model.target_ae.load_state_dict(state_dict)\n",
    "\n",
    "    criterion_pft = KernelizedSupCon(\n",
    "        method=\"expw\",\n",
    "        temperature=cfg.pft_temperature,\n",
    "        base_temperature= cfg.pft_base_temperature,\n",
    "        reg_term = cfg.pft_reg_term,\n",
    "        kernel=kernel,\n",
    "        krnl_sigma=cfg.pft_sigma,\n",
    "    )\n",
    "\n",
    "    criterion_ptt = KernelizedSupCon(\n",
    "        method=\"expw\",\n",
    "        temperature=cfg.ptt_temperature,\n",
    "        base_temperature= cfg.ptt_base_temperature,\n",
    "        reg_term = cfg.ptt_reg_term,\n",
    "        kernel=kernel,\n",
    "        krnl_sigma=cfg.ptt_sigma,\n",
    "    )\n",
    "    \n",
    "    feature_autoencoder_crit = EMB_LOSSES[cfg.feature_autoencoder_crit]\n",
    "    target_decoding_crit = EMB_LOSSES[cfg.target_decoding_crit]\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1, patience = cfg.scheduler_patience)\n",
    "\n",
    "    loss_terms = []\n",
    "    validation = []\n",
    "    autoencoder_features = []\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    wandb.init(project=cfg.project,\n",
    "        mode = \"offline\",\n",
    "        name=f\"{cfg.experiment_name}_run{run}_train_ratio_{train_ratio}\",\n",
    "        dir = cfg.output_dir,\n",
    "        config = OmegaConf.to_container(cfg, resolve=True))\n",
    "\n",
    "    with tqdm(range(num_epochs), desc=\"Epochs\", leave=False) as pbar:\n",
    "        for epoch in pbar:\n",
    "            model.train()\n",
    "\n",
    "            loss_terms_batch = defaultdict(lambda:0)\n",
    "            for features, targets in train_loader:\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                features = features.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                ## FEATURE ENCODING\n",
    "                embedded_feat = model.encode_features(features)\n",
    "                ## FEATURE DECODING\n",
    "                \n",
    "                ## REDUCED FEAT TO TARGET EMBEDDING\n",
    "                embedded_feat_vectorized = sym_matrix_to_vec(embedded_feat.detach().cpu().numpy())\n",
    "                embedded_feat_vectorized = torch.tensor(embedded_feat_vectorized).to(torch.float32).to(device)\n",
    "\n",
    "                features_vectorized = sym_matrix_to_vec(features.detach().cpu().numpy())\n",
    "                features_vectorized = torch.tensor(features_vectorized).to(torch.float32).to(device)\n",
    "\n",
    "                ## KERNLIZED LOSS: MAT embedding vs MAT\n",
    "                # kernel_embedded_feature_loss, direction_reg_features = criterion_pft(embedded_feat_vectorized.unsqueeze(1), features_vectorized)\n",
    "                # kernel_embedded_feature_loss = 100 * kernel_embedded_feature_loss\n",
    "                # direction_reg_features = 100 * direction_reg_features\n",
    "\n",
    "                ## TARGET DECODING FROM MAT EMBEDDING\n",
    "                reduced_feat_embedding, reduced_feat_embedding_norm = model.transfer_embedding(embedded_feat_vectorized)\n",
    "\n",
    "                if not cfg.mat_ae_pretrained:\n",
    "                    inv_feat_embedding = model.inv_embedding(reduced_feat_embedding).detach().cpu().numpy()\n",
    "                    inv_feat_embedding = vec_to_sym_matrix(inv_feat_embedding)\n",
    "                    inv_feat_embedding = torch.tensor(inv_feat_embedding).to(torch.float32).to(device)\n",
    "                    reconstructed_feat = model.decode_features(inv_feat_embedding)\n",
    "                    ## FEATURE DECODING LOSS\n",
    "                    feature_autoencoder_loss = feature_autoencoder_crit(features, reconstructed_feat) / 10_000\n",
    "                    # reduced_feat_loss = feature_autoencoder_crit(embedded_feat, inv_feat_embedding) / 10_000\n",
    "                    \n",
    "                out_target_decoded = model.decode_targets(reduced_feat_embedding_norm)\n",
    "\n",
    "                ## KERNLIZED LOSS: MAT embedding vs targets\n",
    "                kernel_embedded_target_loss, direction_reg_target = criterion_ptt(reduced_feat_embedding_norm.unsqueeze(1), targets)\n",
    "                kernel_embedded_target_loss = 100 * kernel_embedded_target_loss\n",
    "                direction_reg_target = 100 * direction_reg_target\n",
    "\n",
    "                ## LOSS: TARGET DECODING FROM TARGET EMBEDDING\n",
    "                if cfg.target_decoding_crit == 'Huber' and cfg.huber_delta != 'None':\n",
    "                    target_decoding_crit = nn.HuberLoss(delta = cfg.huber_delta)\n",
    "                \n",
    "                target_decoding_from_reduced_emb_loss = target_decoding_crit(targets, out_target_decoded) / 100\n",
    "\n",
    "\n",
    "                ## SUM ALL LOSSES\n",
    "                loss = kernel_embedded_target_loss + target_decoding_from_reduced_emb_loss\n",
    "                # print(kernel_embedded_target_loss, kernel_embedded_target_loss.type, target_decoding_from_reduced_emb_loss, target_decoding_from_reduced_emb_loss.type, direction_reg, direction_reg.type)\n",
    "\n",
    "                if not cfg.mat_ae_pretrained:\n",
    "                    loss += feature_autoencoder_loss\n",
    "                    # loss += reduced_feat_loss\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                if cfg.clip_grad:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                if cfg.log_gradients:\n",
    "                    for name, param in model.named_parameters():\n",
    "                        if param.grad is not None:\n",
    "                            wandb.log({\n",
    "                                \"Epoch\": epoch,\n",
    "                                f\"Gradient Norm/{name}\": param.grad.norm().item()\n",
    "                                })  \n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_terms_batch['loss'] = loss.item() / len(features)\n",
    "                loss_terms_batch['kernel_embedded_target_loss'] = kernel_embedded_target_loss.item() / len(features)\n",
    "                loss_terms_batch['target_decoding_from_reduced_emb_loss'] = target_decoding_from_reduced_emb_loss.item() / len(features)\n",
    "                # loss_terms_batch['direction_reg_target_loss'] = direction_reg_target.item() / len(features)\n",
    "                \n",
    "                if not cfg.mat_ae_pretrained:\n",
    "                    loss_terms_batch['feature_autoencoder_loss'] = feature_autoencoder_loss.item() / len(features)\n",
    "                    # loss_terms_batch['reduced_feat_loss'] = reduced_feat_loss.item() / len(features)\n",
    "                    wandb.log({\n",
    "                        'Epoch': epoch,\n",
    "                        'feature_autoencoder_loss': loss_terms_batch['feature_autoencoder_loss'],\n",
    "                        # 'reduced_feat_loss': loss_terms_batch['reduced_feat_loss']\n",
    "                    })\n",
    "                \n",
    "                wandb.log({\n",
    "                    'Epoch': epoch,\n",
    "                    'Run': run,\n",
    "                    'total_loss': loss_terms_batch['loss'],\n",
    "                    'kernel_embedded_target_loss': loss_terms_batch['kernel_embedded_target_loss'],\n",
    "                    # 'direction_reg_target_loss': loss_terms_batch['direction_reg_target_loss'],\n",
    "                    # 'direction_reg_features_loss': loss_terms_batch['direction_reg_features_loss'],\n",
    "                    'target_decoding_from_reduced_emb_loss': loss_terms_batch['target_decoding_from_reduced_emb_loss']\n",
    "                })\n",
    "\n",
    "            loss_terms_batch['epoch'] = epoch\n",
    "            loss_terms.append(loss_terms_batch)\n",
    "\n",
    "            model.eval()\n",
    "            mape_batch = 0\n",
    "            corr_batch = 0\n",
    "            with torch.no_grad():\n",
    "                for (features, targets) in test_loader:\n",
    "                    \n",
    "                    features, targets = features.to(device), targets.to(device)                    \n",
    "                    out_feat = model.encode_features(features)\n",
    "                    \n",
    "                    out_feat = torch.tensor(sym_matrix_to_vec(out_feat.detach().cpu().numpy())).to(torch.float32).to(device)\n",
    "                    transfer_out_feat, transfer_out_feat_norm = model.transfer_embedding(out_feat)\n",
    "                    out_target_decoded = model.decode_targets(transfer_out_feat_norm)\n",
    "                    \n",
    "                    epsilon = 1e-8\n",
    "                    mape =  torch.mean(torch.abs((targets - out_target_decoded)) / torch.abs((targets + epsilon))) * 100\n",
    "                    corr =  spearmanr(targets.cpu().numpy().flatten(), out_target_decoded.cpu().numpy().flatten())[0]\n",
    "                    mape_batch+=mape.item()\n",
    "                    corr_batch += corr\n",
    "\n",
    "                mape_batch = mape_batch/len(test_loader)\n",
    "                corr_batch = corr_batch/len(test_loader)\n",
    "                validation.append(mape_batch)\n",
    "\n",
    "            wandb.log({\n",
    "                'Target MAPE/val' : mape_batch,\n",
    "                'Target Corr/val': corr_batch,\n",
    "                })\n",
    "            \n",
    "            scheduler.step(mape_batch)\n",
    "            if np.log10(scheduler._last_lr[0]) < -4:\n",
    "                break\n",
    "\n",
    "            pbar.set_postfix_str(\n",
    "                f\"Epoch {epoch} \"\n",
    "                f\"| Loss {loss_terms[-1]['loss']:.02f} \"\n",
    "                f\"| val Target MAPE {mape_batch:.02f}\"\n",
    "                f\"| val Target Corr {corr_batch:.02f} \"\n",
    "                f\"| log10 lr {np.log10(scheduler._last_lr[0])}\"\n",
    "            )\n",
    "    wandb.finish()\n",
    "    loss_terms = pd.DataFrame(loss_terms)\n",
    "    return loss_terms, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_LOSSES ={\n",
    "    'Norm': NormLoss(),\n",
    "    'LogEuclidean': LogEuclideanLoss(),\n",
    "    'MSE': nn.functional.mse_loss,\n",
    "    'MSERobust': OutlierRobustMSE(),\n",
    "    'Huber': nn.HuberLoss(),\n",
    "    'cosine': nn.functional.cosine_embedding_loss,\n",
    "}\n",
    "\n",
    "SUPCON_KERNELS = {\n",
    "    'cauchy': cauchy,\n",
    "    'gaussian_kernel': gaussian_kernel,\n",
    "    'None': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRun(submitit.helpers.Checkpointable):\n",
    "    def __init__(self):\n",
    "        self.results = None\n",
    "        self.embeddings = None\n",
    "\n",
    "    def __call__(self, train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state=None, device=None, save_model = True, path: Path = None):\n",
    "        if self.results is None:\n",
    "            if device is None:\n",
    "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                print(f\"Device {device}, ratio {train_ratio}\", flush=True)\n",
    "            if not isinstance(random_state, np.random.RandomState):\n",
    "                random_state = np.random.RandomState(random_state)\n",
    "\n",
    "            augmentations = cfg.augmentation\n",
    "            \n",
    "            recon_mat_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.reconstructed_dir)\n",
    "            os.makedirs(recon_mat_dir, exist_ok=True)\n",
    "    \n",
    "            predictions = {}\n",
    "            autoencoder_features = {}\n",
    "            losses = []\n",
    "            self.embeddings = {'train': [], 'test': []}\n",
    "            self.run = run\n",
    "\n",
    "            if cfg.mat_ae_pretrained:\n",
    "                print(\"Loading test indices from the pretraining experiment...\")\n",
    "                test_indices = np.load(f\"{cfg.output_dir}/{cfg.pretrained_mat_ae_exp}/test_idx.npy\")\n",
    "                train_indices = np.setdiff1d(indices, test_indices)\n",
    "                if train_ratio < 1.0:\n",
    "                    train_size = int(len(train_indices) * train_ratio)\n",
    "                    train_indices = random_state.choice(train_indices, train_size, replace=False)\n",
    "\n",
    "            elif cfg.external_test_mode:\n",
    "                test_scanners = list(cfg.test_scanners)\n",
    "                xr_dataset = xr.open_dataset(cfg.dataset_path)\n",
    "                scanner_mask = np.sum([xr_dataset.isin(scanner).scanner.values for scanner in test_scanners],\n",
    "                                    axis = 0).astype(bool)\n",
    "                test_indices = indices[scanner_mask]\n",
    "                train_indices = indices[~scanner_mask]\n",
    "                if train_ratio < 1.0:\n",
    "                    train_size = int(len(train_indices) * train_ratio)\n",
    "                    train_indices = random_state.choice(train_indices, train_size, replace=False)\n",
    "                del xr_dataset\n",
    "\n",
    "            else:\n",
    "                run_indices = random_state.choice(indices, run_size, replace=False)\n",
    "                train_indices, test_indices = train_test_split(run_indices, test_size=test_size, random_state=random_state)\n",
    "                \n",
    "            train_dataset = Subset(dataset, train_indices)\n",
    "            test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "            train_features = train_dataset.dataset.matrices[train_dataset.indices]\n",
    "            train_targets = train_dataset.dataset.targets[train_dataset.indices].numpy()\n",
    "            std_train_targets, mean, std= standardize(train_targets)\n",
    "            # scaler = MinMaxScaler().fit(train_targets)\n",
    "            # train_targets = scaler.transform(train_targets)\n",
    "\n",
    "            input_dim_feat =cfg.input_dim_feat\n",
    "            output_dim_feat = cfg.output_dim_feat\n",
    "\n",
    "            ## Weight initialization for bilinear layer\n",
    "            mean_f = torch.mean(train_features, dim=0).to(device)\n",
    "            [D,V] = torch.linalg.eigh(mean_f,UPLO = \"U\")\n",
    "            B_init_fMRI = V[:,input_dim_feat-output_dim_feat:] \n",
    "            test_features= test_dataset.dataset.matrices[test_dataset.indices].numpy()\n",
    "            test_targets = test_dataset.dataset.targets[test_dataset.indices].numpy()\n",
    "            # test_targets = scaler.transform(test_targets)\n",
    "\n",
    "            ### Augmentation\n",
    "            if augmentations != 'None':\n",
    "#                 aug_params = {}\n",
    "                if not isinstance(augmentations, list):\n",
    "                    augmentations = [augmentations]\n",
    "                n_augs = len(augmentations)\n",
    "                vect_train_features = sym_matrix_to_vec(train_features, discard_diagonal=True)\n",
    "                n_samples = len(train_dataset)\n",
    "                n_features = vect_train_features.shape[-1]\n",
    "                new_train_features = np.zeros((n_samples + n_samples * n_augs, 1, n_features))\n",
    "                new_train_features[:n_samples, 0, :] = vect_train_features\n",
    "\n",
    "                for i, aug in enumerate(augmentations):\n",
    "                    transform = augs[aug]\n",
    "                    transform_args = aug_args[aug]\n",
    "#                     aug_params[aug] = transform_args # to save later in the metrics df\n",
    "\n",
    "                    num_aug = i + 1\n",
    "                    aug_features = np.array([transform(sample, **transform_args) for sample in train_features])\n",
    "                    aug_features = sym_matrix_to_vec(aug_features, discard_diagonal=True)\n",
    "\n",
    "                    new_train_features[n_samples * num_aug: n_samples * (num_aug + 1), 0, :] = aug_features\n",
    "\n",
    "                train_features = new_train_features\n",
    "                train_targets = np.concatenate([train_targets]*(n_augs + 1), axis=0)\n",
    "            \n",
    "            train_dataset = TensorDataset(train_features, torch.from_numpy(train_targets).to(torch.float32))\n",
    "            test_dataset = TensorDataset(torch.from_numpy(test_features).to(torch.float32), torch.from_numpy(test_targets).to(torch.float32))\n",
    "\n",
    "            loss_terms, model = train(run, train_ratio, train_dataset, test_dataset,mean, std, B_init_fMRI, cfg, device=device)\n",
    "            losses.append(loss_terms.eval(\"train_ratio = @train_ratio\").eval(\"run = @run\"))\n",
    "\n",
    "            mean = torch.tensor(mean).to(device) #do we need this?\n",
    "            std  = torch.tensor(std).to(device)\n",
    "\n",
    "            wandb.init(project=cfg.project,\n",
    "                mode = \"offline\",\n",
    "                name=f\"TEST_{cfg.experiment_name}_run{run}_train_ratio_{train_ratio}\",\n",
    "                dir = cfg.output_dir,\n",
    "                config = OmegaConf.to_container(cfg, resolve=True))\n",
    "            \n",
    "            embedding_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.embedding_dir)\n",
    "            os.makedirs(embedding_dir, exist_ok=True)\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                train_dataset = Subset(dataset, train_indices)\n",
    "                train_features = train_dataset.dataset.matrices[train_dataset.indices].numpy()\n",
    "                train_targets = train_dataset.dataset.targets[train_dataset.indices].numpy()\n",
    "                train_dataset = TensorDataset(torch.from_numpy(train_features).to(torch.float32), torch.from_numpy(train_targets).to(torch.float32))\n",
    "                std_train_targets,_,_ = standardize(train_targets)\n",
    "\n",
    "                for label, d, d_indices in (('train', train_dataset, train_indices), ('test', test_dataset, test_indices)):\n",
    "                    is_test = True\n",
    "                    if label == 'train':\n",
    "                        is_test = False\n",
    "                    \n",
    "                    X, y = zip(*d)\n",
    "                    X = torch.stack(X).to(device)\n",
    "                    y = torch.stack(y).to(device)\n",
    "                    X_embedded = model.encode_features(X)\n",
    "                    X_embedded = X_embedded.cpu().numpy()\n",
    "                    X_embedded = torch.tensor(sym_matrix_to_vec(X_embedded)).to(torch.float32).to(device)\n",
    "                    X_emb_reduced, X_emb_reduced_norm = model.transfer_embedding(X_embedded)\n",
    "                    \n",
    "                    if label == 'test' and train_ratio == 1.0:\n",
    "                        np.save(f'{recon_mat_dir}/test_idx_run{run}',d_indices)\n",
    "                        inv_feat_embedding = model.inv_embedding(X_emb_reduced).detach().cpu().numpy()\n",
    "                        inv_feat_embedding = vec_to_sym_matrix(inv_feat_embedding)\n",
    "                        inv_feat_embedding = torch.tensor(inv_feat_embedding).to(torch.float32).to(device)\n",
    "                        recon_mat = model.decode_features(inv_feat_embedding)\n",
    "                        mape_mat = torch.abs((X - recon_mat) / (X + 1e-10)) * 100\n",
    "                        \n",
    "                        wandb_plot_test_recon_corr(wandb, cfg.experiment_name, cfg.work_dir, recon_mat.cpu().numpy(), X.cpu().numpy(), mape_mat.cpu().numpy(), True, run)\n",
    "                        wandb_plot_individual_recon(wandb, cfg.experiment_name, cfg.work_dir, d_indices, recon_mat.cpu().numpy(), X.cpu().numpy(), mape_mat.cpu().numpy(), 0, True, run)\n",
    "\n",
    "                        np.save(f'{recon_mat_dir}/recon_mat_run{run}', recon_mat.cpu().numpy())\n",
    "                        np.save(f'{recon_mat_dir}/mape_mat_run{run}', mape_mat.cpu().numpy())\n",
    "                    y_pred = model.decode_targets(X_emb_reduced_norm)\n",
    "\n",
    "                    save_embeddings(X_embedded, \"mat\", cfg, is_test, run)\n",
    "                    save_embeddings(X_emb_reduced_norm, \"joint\", cfg, is_test, run)\n",
    "\n",
    "                    if label == 'test':\n",
    "                        epsilon = 1e-8\n",
    "                        mape =  100 * torch.mean(torch.abs((y - y_pred)) / torch.abs((y + epsilon))).item()\n",
    "                        corr =  spearmanr(y.cpu().numpy().flatten(), y_pred.cpu().numpy().flatten())[0]\n",
    "\n",
    "                        wandb.log({\n",
    "                            'Run': run,\n",
    "                            'Test | Target MAPE/val' : mape,\n",
    "                            'Test | Target Corr/val': corr,\n",
    "                            'Test | Train ratio' : train_ratio\n",
    "                            })\n",
    "            \n",
    "                    predictions[(train_ratio, run, label)] = (y.cpu().numpy(), y_pred.cpu().numpy(), d_indices)\n",
    "                    for i, idx in enumerate(d_indices):\n",
    "                        self.embeddings[label].append({\n",
    "                            'index': idx,\n",
    "                            'joint_embedding': X_emb_reduced[i].cpu().numpy()\n",
    "                        })\n",
    "            wandb.finish()\n",
    "            \n",
    "            self.results = (losses, predictions, self.embeddings)\n",
    "\n",
    "        if save_model:\n",
    "            saved_models_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.model_weight_dir)\n",
    "            os.makedirs(saved_models_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"{saved_models_dir}/model_weights_run{run}.pth\")\n",
    "\n",
    "        return self.results\n",
    "\n",
    "    def checkpoint(self, *args, **kwargs):\n",
    "        print(\"Checkpointing\", flush=True)\n",
    "        return super().checkpoint(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ratio = 0.3\n",
    "# train_ratio = 1.0\n",
    "# dataset_path = \"/gpfs3/well/margulies/users/cpy397/contrastive-learning/data/abcd_dataset_400parcels_1.nc\"\n",
    "# dataset = MatData(dataset_path, [\"nihtbx_totalcomp_agecorrected\"], synth_exp = False, threshold=0)\n",
    "# n_sub = len(dataset)\n",
    "# indices = np.arange(n_sub)\n",
    "# train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "# test_size = int(test_ratio * n_sub)\n",
    "# run_size = test_size + train_size\n",
    "# random_state = np.random.RandomState(seed=42)\n",
    "# run_indices = random_state.choice(indices, run_size, replace=False)\n",
    "# train_indices, test_indices = train_test_split(run_indices, test_size=0.3, random_state=random_state)\n",
    "# train_dataset = Subset(dataset, train_indices)\n",
    "# test_dataset = Subset(dataset, test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features = train_dataset.dataset.matrices[train_dataset.indices]\n",
    "# train_targets = train_dataset.dataset.targets[train_dataset.indices].numpy()\n",
    "# std_train_targets, mean, std= standardize(train_targets)\n",
    "# # scaler = MinMaxScaler().fit(train_targets)\n",
    "# # train_targets = scaler.transform(train_targets)\n",
    "\n",
    "# input_dim_feat =cfg.input_dim_feat\n",
    "# output_dim_feat = cfg.output_dim_feat\n",
    "\n",
    "# ## Weight initialization for bilinear layer\n",
    "# mean_f = torch.mean(train_features, dim=0).to(device)\n",
    "# [D,V] = torch.linalg.eigh(mean_f,UPLO = \"U\")\n",
    "# B_init_fMRI = V[:,input_dim_feat-output_dim_feat:] \n",
    "# test_features= test_dataset.dataset.matrices[test_dataset.indices].numpy()\n",
    "# test_targets = test_dataset.dataset.targets[test_dataset.indices].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=28, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=228, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PhenoProj(\n",
    "#     cfg.input_dim_feat,\n",
    "#     cfg.input_dim_target,\n",
    "#     cfg.hidden_dim,\n",
    "#     cfg.output_dim_target,\n",
    "#     cfg.output_dim_feat,\n",
    "#     cfg.dropout_rate,\n",
    "#     cfg\n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrices = train_loader.dataset.dataset.matrices[:3]\n",
    "# matrices = matrices.to(device)\n",
    "# targets = train_loader.dataset.dataset.targets[:3]\n",
    "# targets = targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim_feat=cfg.input_dim_feat,\n",
    "# input_dim_target=cfg.input_dim_target,\n",
    "# hidden_dim=cfg.hidden_dim,\n",
    "# output_dim_target=cfg.output_dim_target,\n",
    "# output_dim_feat=cfg.output_dim_feat,\n",
    "# dropout_rate=cfg.dropout_rate,\n",
    "\n",
    "# enc_mat1 = nn.Linear(in_features=400, out_features=70 ,bias=False)\n",
    "# enc_mat2 = nn.Linear(in_features=400, out_features=70, bias=False)\n",
    "\n",
    "# enc_mat1.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "# enc_mat2.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "\n",
    "# enc_mat1.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "# enc_mat2.weight = torch.nn.Parameter(enc_mat1.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project: PhenProj\n",
      "experiment_name: inv_embed\n",
      "hypothesis: '-'\n",
      "input_dim_feat: 400\n",
      "output_dim_feat: 100\n",
      "hidden_dim: 100\n",
      "input_dim_target: 1\n",
      "output_dim_target: 50\n",
      "skip_enc1: false\n",
      "ReEig: false\n",
      "mat_ae_pretrained: false\n",
      "target_ae_pretrained: false\n",
      "pretrained_mat_ae_exp: internal_mat_ae_abcd\n",
      "pretrained_target_ae_exp: target_ae\n",
      "best_mat_ae_fold: 4\n",
      "best_target_ae_fold: 1\n",
      "synth_exp: false\n",
      "multi_gpu: true\n",
      "num_epochs: 100\n",
      "batch_size: 128\n",
      "n_runs: 20\n",
      "lr: 0.001\n",
      "weight_decay: 0\n",
      "dropout_rate: 0\n",
      "scheduler_patience: 10\n",
      "test_ratio: 0.3\n",
      "train_ratio: 1.0\n",
      "log_gradients: true\n",
      "clip_grad: true\n",
      "external_test_mode: true\n",
      "test_scanners:\n",
      "- GE MEDICAL SYSTEMS_DISCOVERY MR750\n",
      "- Philips Medical Systems_Achieva dStream\n",
      "- Philips Medical Systems_Ingenia\n",
      "SupCon_kernel: cauchy\n",
      "SupConLoss_on_mat: false\n",
      "pft_base_temperature: 0.07\n",
      "pft_temperature: 0.07\n",
      "pft_sigma: 1\n",
      "pft_reg_term: 0.01\n",
      "ptt_base_temperature: 0.07\n",
      "ptt_temperature: 0.07\n",
      "ptt_sigma: 1\n",
      "ptt_reg_term: 0.01\n",
      "feature_autoencoder_crit: Norm\n",
      "joint_embedding_crit: cosine\n",
      "target_decoding_crit: MSE\n",
      "huber_delta: 10\n",
      "augmentation: None\n",
      "mat_threshold: 0\n",
      "dataset_path: /data/parietal/store/work/vshevche/data/abcd_dataset_400parcels_1.nc\n",
      "targets:\n",
      "- nihtbx_totalcomp_agecorrected\n",
      "standardize_targets: false\n",
      "work_dir: /data/parietal/store/work/vshevche/\n",
      "reconstructed_dir: recon_mat\n",
      "embedding_dir: embeddings\n",
      "model_weight_dir: saved_models\n",
      "output_dir: /data/parietal/store/work/vshevche/results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\".\"):\n",
    "    cfg = compose(config_name='main_model_config.yaml')\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da88418ee4a140eb8a5e349fb1ae21c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Run:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda, ratio 1.0\n",
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100265d30d464d91afa22c0f8556d1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>▇▃▃▃▅▇▄█▂▄▄▃▅▆▂▆▂▂▃▅▂▅▄▄▁▂▃▅▅▃▆▂▅▄▃▂▃▂▃▁</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>▁▁▅▇▇█▇█▇▇▆▇▅▆▇▇▇▆█▆▆█▇▆▇▇▇▇▇▇▇▆▅▇▆▇▇▆▇▅</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>▁▃▃▄▅▄▃▄▃▃▇▃▂▄▆▃▆▅▇▆▅▃▆▆▆▅▆▆▅▇▄█▇▇▆█▅▇▅▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>▁▁▅▄▄▅▄▅▅▄▄▅▅▆▆▃▅▇▅▆▄▄▅▆▄▅▇▄▄▅█▆▅▆▆█▆▅▆▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.bias</td><td>▃█▂▃▂▇▃▄▂▃▂▁▁▁▁▃▄▂▂▂▃▄▂▂▁▁▃▃▃▄▂▂▃▅▃▅█▃▅▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.weight</td><td>▂▃▄▆█▁▄▆▅▅▂▁▂▂▂▄▅▂▂▃▅▅▃▃▄▄▃▃▃▄▃▃▃▄▄▄▃▂▄▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>▃▆▄▃▃▆▁▄▁▆▅▃▅▆▅▆▇▄▂▆▄▅▄▃▇▃▄▃▄▆▄▄▇▂▅▄█▃▁▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>▁▃▃▃▅▃▄▄▅▄▅▅▅▅▆▆█▅▇▆▇▄▇▅▇▇▆▆▅▇▄▇▅▅▇▄▆▅▆█</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>▃▁▁▂▃▃▂▃▄▄▄▃▄▃▅▄▄▄▆▃▅▄▅▆▆▄▄▄▆▄▃▄▅▅▆▅▄▆█▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>▁▄▃▃▃▃▅▂▄▄▅▅▆▃█▅▅▅▃▅▄▃▃▇▇▄▅▄▆▆▅▄▇▅▄▅▆▅▇▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>▇█▄▇▆▃▃▄▃▄▃▃▃▁▂▄▃▃▄▃▄▂▄▃▂▄▅▂▃▄▃▃▄▆▅▃▂▆▆▂</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>▇▅▆▄▅▅▂▄▅▂▃▅▃▃▃▅▅▁▃▅▃▄▁▃▅▄▄▅▇▄▆▃▃▄▅▆▆█▇▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.bias</td><td>█▇▄▂▄▄▂▂▂▄▂▁▃▅▂▂▃▁▁▅▁▃▃▂▂▂▃▂▅▂▂▂▂▂▃▅▂▄▂█</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.weight</td><td>█▅▂▃▄▄▁▁▃▅▂▂▄▃█▃▃▇▄▇▄▄▁▄▃▆▄▄▅▇▃▃▅▇▆▄▅▆▅▃</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>▁█▄▄▁▁▁▂▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>█▄▂▂▁▁▁▂▁▃▃▃▂▂▃▂▃▃▂▃▃▄▄▂▃▃▃▃▃▂▄▃▄▄▆▄▄▃▃▅</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>█▃▁▁▁▂▁▁▁▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>▂▁▂▂▁▂▃▇▅▅▄█▆▅▂▂▃▁▅▃▂▂▁▂▂▂▂▂▂▂▂▂▂▁▂▂▂▄▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>▁▁▁▂▂▅▅▅▃▃▃▃▅▅▃█▂▆▄▃▂▂▂▃▃▅▂▃▂▂▂▂▂▁▁▂▂▁▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▃█▂▃▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▂▂▁▂▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>▁█▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>█▂▃▂▂▂▃▃▃▄▂▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>▂▁▁▁▁▂▂▂▂▂▄▃▃█▂▄▃▃▃▅▃▄▄▃▄▂▄▂▂▃▁▁▂▂▂▃▂▂▁▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▅▄▄█▇▆▂▃▂▄▂▂▃▂▁▃▂▂▂▂▃▂▂▅▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>▁▁▁▁▁▂▂▄▄▂▂▂▅█▂▂▆▂▁▅▄▂▇▂▂▂▂▂▂▃▃▂▂▂▂▂▂▂▂▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>▁▁▁▁▁▂▁▂▂▁▃▂██▂▂▂▅▃█▂▃▃▂▂▂▁▂▃▂▂▂▂▂▁▂▂▁▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>▃▂▃▂▃▂▃▃▅▄▃▄▆▇█▇▆▅▅▄▄▅▂▂▃▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>▁▂▂▃▁▁▁▁▁▁▁▁▂▃▂▄▅▃▄▃█▃▂▃▄▅▃▃▃▄▅▂▃▃▃▃▂▃▃▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>▁█▄▄▃▂▃▂▅▃▃▇▆▅█▃▄▃▄▅▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>▁▃▇▆▅▃▃▆▄▃▅▄▆▄▆▇█▆▆▄▂▂▂▁▁▂▁▂▁▁▂▂▁▂▁▁▂▂▂▂</td></tr><tr><td>Run</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Target Corr/val</td><td>▆▅▄▅▇▆█▄▄▆▆▄▄▄▅▅▆▁▅▄▅▄▅▄▅▇▄▇▇▅▄▃▄▅▃▃▅▆▄▁</td></tr><tr><td>Target MAPE/val</td><td>█████▇▇▇▇▇▆▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>feature_autoencoder_loss</td><td>█▃▃▂▂▂▂▁▂▂▂▂▂▃▂▂▂▁▂▂▁▂▂▂▁▂▁▂▁▁▁▂▃▁▁▂▂▁▂▂</td></tr><tr><td>kernel_embedded_target_loss</td><td>▅▄▃▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▂▂▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>▄█▄▄▄▄▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>77</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>0.93397</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>0.00729</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>0.01195</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.bias</td><td>0.00683</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.weight</td><td>0.21229</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>0.16285</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>0.01024</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>0.02113</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>0.23359</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.bias</td><td>0.01333</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.weight</td><td>0.02001</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>0.00898</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>0.00898</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>0.00164</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>0.00013</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>0.00024</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>8e-05</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>0.00103</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>0.00262</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>0.0002</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>0.00033</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>0.00159</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>0.00053</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>0.00021</td></tr><tr><td>Run</td><td>0</td></tr><tr><td>Target Corr/val</td><td>0.1587</td></tr><tr><td>Target MAPE/val</td><td>18.34719</td></tr><tr><td>feature_autoencoder_loss</td><td>0.89817</td></tr><tr><td>kernel_embedded_target_loss</td><td>4.62019</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>0.00121</td></tr><tr><td>total_loss</td><td>5.51957</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_160726-k48jwg3w<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_160726-k48jwg3w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mind/vshevche/contrastive-learning/contrastive_phenotypes/src/ContModeling/viz_func.py:107: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  correlations[i // cols, i % cols] = spearmanr(flat_true[:, i], flat_recon[:, i])[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>▁</td></tr><tr><td>Test | Target Corr/val</td><td>▁</td></tr><tr><td>Test | Target MAPE/val</td><td>▁</td></tr><tr><td>Test | Train ratio</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>0</td></tr><tr><td>Test | Target Corr/val</td><td>0.22207</td></tr><tr><td>Test | Target MAPE/val</td><td>18.10224</td></tr><tr><td>Test | Train ratio</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_161108-ee1i2n1d<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_161108-ee1i2n1d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda, ratio 1.0\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e1587ca45245b18f4b0e4d38cbb6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>▄▂▆▃▄▆▃▃▃▆▂▃▃▆▃▄█▃▄▂▃▁▁▃█▃▄▃▅▆▃▄▄▃▅▄▂▆▁▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>▁▄▇█▇▇▆▅▇▆▅▇▇▇▇▅▅▇▇▇▇▆▇▇▆▆▆▆▅▇▆▄▅▄█▆▆▆▇▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>▁▃▃▄▅▃▅▄▄▃▅▆▅▆▅▅▅█▅▆▇▆▅▆▅▆▄▆▅▆▇▇▆▆▆█▆▆▇▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>▁▂▂▄▄▄▅▅▅▅▄▄▄▄▄▄▄▄█▆▄▆▄▆▄▆▄▆▆▅▆▄▆▆▄▇▆▅▆▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.bias</td><td>▅▅▃▃▆▇▄▂▁▂▄▆▄▄▃▂▄▅▂▃▃▅▄▄▄▄▂▄▆▄▃▄▄▁▃▃▄▄▂█</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.weight</td><td>█▁▅▄▆▁▅▄▄▅▄▃▅▄▂▄▅▆▃▅▃▃▂▄▄▄▅▃▃▄▃▃▄▃▃▄▄▄▃▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>▃▄▅▄▃▂▅▅▃▄▆▄▅▅▆▃▄▃▆▄▃▁▄▃▃▇▃▆▂▄▂▄▁▂▅▅▄█▅▂</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>▃▂▇▁▄▂▅▄▃▆▄▅▆▅▄▃▅▅▄▂█▅▄█▆▇▄▇▃▂▃▁▃█▆▅▄▇▇▅</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>▁▁▃▂▄▂▃▂▅▂▅▄▂▄▅▅▅▄█▄▅▆▃▃▆▅▃▅▃▃▇▆▅▄▇▇▇█▅█</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>▁▅▃▂▁▄▃▂▄▃▃▃▂▄▂▅▂▃▄▃▄▃▅▂▄▄▄▄▃▄▄▄▆▃▂▆█▄▇▄</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>█▄▅▃▃▃▃▂▂▃▅▃▁▃▂▂▃▁▃▃▂▁▁▄▃▅▃▂▅▄▃▅▂▄▃▂▃▃▄▃</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>▅▅▆▆▆▅▄▂▄▃▄▅▅▅▃▃▅▁▃▄▄▄▄▆▃▆▄▄▆▆▄▅▅▅▄▇█▆▇▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.bias</td><td>█▂▂▂▁▂▁▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▁▂▁▁▁▁▁▁▂▁▂▁▃▂▂▂▁</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.weight</td><td>▅▆▅▇▄▆▂▁▃▂▆▃█▅▂█▆▅█▃▃▆▅▃▇▃▅▄▃▄▇▄▃▄▃▆▄▄▅▅</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>▆█▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▂▁▁▁▁▁▁▂▂▃▂▂▂▂▂▂▃▃▂</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>▇█▃▃▁▁▂▁▂▂▁▂▂▁▂▂▁▃▄▁▂▄▂▂▂▁▂▂▁▃▃▂▃▃▄▃▂▆▄▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>▂▄▁▁▁▁▁▁▂▁▁▂█▂█▂▇▃▂▁▂▂▂▂▁▂▁▁▁▂▂▁▂▂▁▁▁▂▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>▁▁▁▁▁▁▁▁▂▂█▃▃▃▅▁▁▂▂▁▁▁▂▁▂▁▁▁▂▁▂▁▁▁▁▁▁▁▂▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>▂▁▁▁▁▃▁▂▄▅▄▄▇█▄▂▄▃▃▃▄▂▂▃▃▄▂▅▃▃▃▄▂▂▂▂▂▃▅▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>▁▁▁▁▂▂▁▂▁▄▅▁▅▄▅▄▇▄▆█▂▃▃▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>█▃▄▄▄▄▂▂▃▂▃▄▂▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>▁▁▇▅█▃▂▂▃▂▂▃▄▄▄▂▂▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▄▃▃▃▃▄▂█▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▁▂▄▇▃▅▂▃▄▃█▂▃▃▂▂▁▂▂▂▂▃▃▂▂▁▂▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>▁▁▁▁▁▁▁▁▂▃▂▄▄▃▂█▄▅▄▄▅▃▅▄▄▁▃▂▂▂▃▂▃▄▂▃▄▂▄▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▂█▃▅█▅▄▆▂▃▂▂▂▂▂▃▃▃▄▂▂▃▁▃▃▃▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>▃▄▃▂▂▂▃▆▅▆▆▅▄█▄▅▄▃▂▃▂▃▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▁▂█▁▁▂▂▂▂▂▂▂▁▂▂▃▂▁▁▁▂▂▁▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>▁█▃▅▃▃▆▃▆▄▄█▆▅▇▇▅▄▅▅▂▂▁▂▁▂▁▂▁▁▁▁▁▁▂▁▁▂▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>▇▆█▅▂▄▄▆▄▄▆▄▅▅▃▄▃▂▃▂▁▁▁▁▂▁▂▁▃▂▂▁▂▁▂▂▁▂▁▂</td></tr><tr><td>Run</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Target Corr/val</td><td>▅▇▇▆██▅▄▆▁▇▅▆█▆▇▆▄▄▅█▇▇▅▇▅▅▆▆▆▆▆▅▆▇▆▄▄▆▇</td></tr><tr><td>Target MAPE/val</td><td>█████▇▇▆▆▆▅▅▄▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>feature_autoencoder_loss</td><td>█▄▅▄▃▄▄▃▃▃▁▂▃▃▃▂▂▃▂▅▃▁▃▃▂▂▂▂▂▄▄▂▂▂▃▃▁▃▃▁</td></tr><tr><td>kernel_embedded_target_loss</td><td>█▅▅▄▅▄▄▄▄▄▄▄▃▄▄▄▃▂▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▁▁▁▂▁▁</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>██████▇▇▇▆▅▅▅▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>██▇▆▅▅▄▅▄▄▄▃▄▃▃▃▃▂▂▃▂▂▂▃▃▃▂▂▂█▂▂▂▂▂▁▃▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>75</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>0.90352</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>0.00827</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>0.01843</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.bias</td><td>0.00947</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.weight</td><td>0.20876</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>0.2314</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>0.01093</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>0.0206</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>0.28725</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.bias</td><td>0.02069</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.weight</td><td>0.02791</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>0.02683</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>0.02683</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>0.00973</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>0.00061</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>0.00114</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>0.00012</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>0.00298</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>0.01215</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>0.00092</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>0.00139</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>0.00864</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>0.00116</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>0.00079</td></tr><tr><td>Run</td><td>1</td></tr><tr><td>Target Corr/val</td><td>0.14014</td></tr><tr><td>Target MAPE/val</td><td>19.03854</td></tr><tr><td>feature_autoencoder_loss</td><td>1.07538</td></tr><tr><td>kernel_embedded_target_loss</td><td>4.34714</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>0.0014</td></tr><tr><td>total_loss</td><td>5.42392</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_161400-wjrcw70i<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_161400-wjrcw70i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mind/vshevche/contrastive-learning/contrastive_phenotypes/src/ContModeling/viz_func.py:107: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  correlations[i // cols, i % cols] = spearmanr(flat_true[:, i], flat_recon[:, i])[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>▁</td></tr><tr><td>Test | Target Corr/val</td><td>▁</td></tr><tr><td>Test | Target MAPE/val</td><td>▁</td></tr><tr><td>Test | Train ratio</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>1</td></tr><tr><td>Test | Target Corr/val</td><td>0.21672</td></tr><tr><td>Test | Target MAPE/val</td><td>18.69191</td></tr><tr><td>Test | Train ratio</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_161737-h2317g1a<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_161737-h2317g1a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda, ratio 1.0\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd51365eb7974187887961d12c96692e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>▆▆▅▆█▂▅█▅▆█▅▂▇▆▄▆▄▄▄▅▆▂▄█▂▅▇▂▄▄▂▃▅▄▄▃▇▃▁</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>▇▆▁▇██▇▇█▇▇██▇█▇▇██▇▆▇▆▆▇▆▇▆█▇█▇▆█▇▇▇▇▆▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>▁▁▃▂▄▃▄▃▃▃▄▅▄▅▆▆▅▄▆▂█▅▅▅▆▅▄▆▅▅▆▇▄█▇▄▆█▇▄</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>▂▁▃▄▄▅▅▆▄▄▅▅▅▅▄▄▇▅▃▅▅█▅▇▆▅▅▅▄▇▅▇▆▆▅▇▆▆▄▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.bias</td><td>█▂▃▂▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▂▂▁▁▁▂▁▂</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.weight</td><td>▆▅██▃▆▅▃▆▁▇▆▅▆▅▅▄▇▅▅▄▅▆▅▆▅▂▅▅▆▄▄▃▅▄▅▆▄▄▄</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>▁▁▅▆▆▄▆▂▁▆▂▃▁▇▄██▁▁▄▅▅▆▃▆▆▂█▅▇▂▅▆▆▅▃▃▂▅▁</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>▁▅▅▅▃▅▅▅▅▇▅▆▆▆▆▅██▆▇▅▆▇▆▆▆▇▇▇▆▆█▆▇▇▇▇█▅▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>▁▃▃▃▃▃▄▄▅▄▆▄▆▅▆▆▇▆▅▇▆▆▅▅▆▅▆▄▆▄▆▆█▆▅▆▇▇▇█</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>▁▃▃▃▄▄▄▇▅▅▄▆▃▅█▄▆▃▇▆▅▅▇▄▆▄▆▄▅▆▅▅▇██▇▆▇▅▅</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>▆█▅▃▄▂▃▃▃▂▄▂▃▂▁▄▁▃▃▃▄▄▄▂▁▄▅▅▄▃▅▂▄▄▂▅▂▂▂▄</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>▁█▅▆▆▃▄▇▅▆▃▆▅▃▅▄▅▇▄▆▂▄▄▇▅▄▄▅▅▄▆▃▆▆▅▇▆▅▅▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.bias</td><td>▃█▁▁▂▁▁▂▁▁▁▁▁▂▁▁▂▂▂▂▁▁▂▂▁▁▁▁▁▁▂▁▂▁▂▃▂▃▂▂</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.weight</td><td>▇█▄▃▆▃▃▂▂▂▁▃▇▄▂▆▇▄▁▃▃▇▅▃▃▄▅▂▃▃▆▆▄▃▄▄▃▄▂▃</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>▅█▄▃▂▁▁▁▁▁▁▁▁▁▂▁▁▂▁▂▁▂▁▂▁▂▂▂▂▂▂▁▂▂▂▂▃▂▂▂</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>▁▄█▆▂▃▂▂▂▁▂▃▂▂▂▂▃▂▃▃▂▂▂▄▂▃▅▂▂▃▃▂▂▃▃▃▆▄▄▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>█▂▂▃▂▃▂▂▂▂▂▄▅▂▅▂▅▇▅▂▂▅▂▃▃▃▂▃▃▁▂▂▃▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>▁▁▁▁▁▁▁▁▁▄▂▁▁▃▇▂▆█▄▃█▅▃▂▃▄▃▂▃▃▄▂▁▂▃▂▂▂▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>▁▁▁▁▁▁▁▁▂▂▂▁▂▂▆▇▅▇▆▄▃█▆▇▃▂▂▂▁▂▂▃▁▂▃▂▁▂▂▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>▁▁▁▁▁▁▁▁▁▁▂▁▃▂▂▄▂▃▃▃▇▂▃▄▄▃▂▃█▆▄▂▁▂▂▁▁▂▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>▁▆█▇▄▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>▄█▅▃▂▄▃▃▂▄▄▅▄▄▃▄▅▄▃▆▃▃▃▄▂▂▃▂▂▂▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▃▂▅▂▅▇▃▃▅▂█▃▃▄▅▂▅▂▃▁▂▂▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>▁▁▁▂▁▁▂▁▃▂▂▄▃▃▃▂▇▅▃▃▃▄▄█▃▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▄▃▃█▂▄▃▂▄▆▃▂▃▂▃▁▃▂▂▄▂▃▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>▁▁▁▁▁▁▁▁▂▃▄▄▄▂█▅▄▄▂▅▆▃▃▆▇▂▃▃▂▂▃▂▃▅▃▃▃▂▂▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>▁▃▂▃▂▂▂▂▂▂▂▂▂▃▃▃▄▆▄▅▆█▆▆▆▅▅▃▄▃▂▁▁▁▁▁▂▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>▁▁▁▁▁▁▂▁▁▁▂▂▁▁▁▂▃▂▂▂▂▅▃▃▃▄▂▄█▅▄▄▄▄▃▃▃▂▂▄</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>▃▄▄▇▄▃▃▄▄▅▅▅▅▅█▄▄▃▃▆▆▄▅▄▃▃▃▂▂▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>▁▁█▄▄▃▃▃▄▆▇▅▄▄▄▇▅▆▆▄▅▄▃▂▂▂▂▁▂▁▁▁▁▁▂▁▁▁▁▃</td></tr><tr><td>Run</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Target Corr/val</td><td>▁▆▇▆▅▆▃█▆▆▆▆▄▆▅▆▇▇▇▇▆▆▅▇▆▅▅▅▄▆▆▆▄▇▅▆▅▄▅▅</td></tr><tr><td>Target MAPE/val</td><td>██████▇▇▇▇▇▇▆▆▆▅▄▄▄▃▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>feature_autoencoder_loss</td><td>██▃▄▃▂▃▃▃▃▃▃▂▃▂▂▁▃▂▂▃▃▂▂▃▂▃▂▁▁▂▃▂▃▂▂▂▂▂▂</td></tr><tr><td>kernel_embedded_target_loss</td><td>▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>▄▄█▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>█▇▇▆▅▅▅▄▄▅▄▅▄▃▃▄▃▃▂▂▂▂▂▂▂▂▁▆▂▂▆▁▁▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>61</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>0.89925</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>0.01081</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>0.01961</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.bias</td><td>0.0167</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.weight</td><td>0.20819</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>0.27901</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>0.01494</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>0.03032</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>0.2538</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.bias</td><td>0.02894</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.weight</td><td>0.02179</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>0.03015</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>0.03015</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>0.00891</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>0.00068</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>0.00138</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>0.00021</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>0.00629</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>0.01719</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>0.00116</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>0.00193</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>0.01616</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>0.00213</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>0.00178</td></tr><tr><td>Run</td><td>2</td></tr><tr><td>Target Corr/val</td><td>0.22911</td></tr><tr><td>Target MAPE/val</td><td>17.82952</td></tr><tr><td>feature_autoencoder_loss</td><td>0.97304</td></tr><tr><td>kernel_embedded_target_loss</td><td>4.92287</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>0.00447</td></tr><tr><td>total_loss</td><td>5.90038</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_162026-75p75dej<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_162026-75p75dej/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mind/vshevche/contrastive-learning/contrastive_phenotypes/src/ContModeling/viz_func.py:107: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  correlations[i // cols, i % cols] = spearmanr(flat_true[:, i], flat_recon[:, i])[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>▁</td></tr><tr><td>Test | Target Corr/val</td><td>▁</td></tr><tr><td>Test | Target MAPE/val</td><td>▁</td></tr><tr><td>Test | Train ratio</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>2</td></tr><tr><td>Test | Target Corr/val</td><td>0.22395</td></tr><tr><td>Test | Target MAPE/val</td><td>18.02046</td></tr><tr><td>Test | Train ratio</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_162331-ar259gwi<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_162331-ar259gwi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda, ratio 1.0\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f3d36589b64ae1b8ca7b243c52777b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>▄▂▃▄▂▂▃▄▆▃▃▃█▅▇▂▃▄▄▅▃▆▁▂▃▄▁▃▆▁▁▄▄▅▃▁▂▃▄▂</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>▁▂▆██▆▇▇█▇▇▇█▇▇▇▇▇▇▆▇▆▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>▂▁▂▂▃▃▅▄▄▃▄▃▃▃▃▃▅▄▃▁█▆▆▃▄▆▄▇▆▄▄▇▆▅▅█▆▇▅█</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>▃▁▃▄▅▃▅▆▆▇▅▅▆▇▅▅▇▆▄▇▆▄▆▄▆█▆▇▆█▇▅█▇▆▇▅▆█▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.bias</td><td>▇▄▇▄▄▃▃▂▂▄▁▂▃▃▃▂▃▁▂▄▂▂▃▃▂▂▃▁▄▂▃▃█▂▇▆▂▁▁▄</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.weight</td><td>▄▃▇█▇▄▃▃▂▅▄▄▃▂▃▂▃▁▃▂▄▄▃▃▂▁▁▃▃▂▂▃▃▃▄▂▂▃▂▄</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>▃▄▄▃▄▅▅▄▄▄▅▂▅█▄▃▆▄▅▄▃▄▁▅▂▄▄▄▄▇▄▇▆█▆▃▄▃▅▂</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>▄▁▁▃▃▃▆▅▃▂▄▆▃▂▄▄▄▄▅▅▄▅▄▇▃▄▆▄▄▅▄▄▅▆▆▅▅▅▆█</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>▂▁▄▄▄▂▃▄▄▆▃▃▄▄▆▃▅▃▄▄▇▆▄▄▄▃▆▄▅▄▄▆▄▅▄▇▆█▅▆</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>▃▁▃▂▃▁▂▂▃▁▂▄▄▃▃▃▂▅█▄▆▅▃▂█▅▅▂▄▃▆▃▃█▆▅▄▆▅▄</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>▅█▅▅▄▂▂▂▂▁▂▃▁▄▃▂▃▂▃▂▃▃▃▂▃▂▂▁▂▁▂▄▃▄▂▂▅▃▂▂</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>▁▂▂▅▅▇▆▃▃▄▂▄▂▄▄▃▃▁▄▃▄▃▄▄▆▂▃▃▅▄▆▂▃▃▆█▅▆▆▇</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.bias</td><td>▅▄▄█▃▄▄▄▂▂▃▂▅▃▄▄▄▃▆▆▃▃▄▅▃▂▁▃▅▄▄▅▃▂▄▄▂▄▄▄</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.weight</td><td>▆▄▇▅▅▃▁▁▅▃▇▇▃▄▇▁▇▅▄▅▂▅▅▆▅▄▄▅▄▅▆▅▄▆█▄█▅▆▆</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>█▂▃▁▁▂▂▂▁▂▂▂▃▂▁▂▂▂▁▂▂▂▃▁▂▃▂▁▂▂▂▁▁▃▃▃▄▅▂▃</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>▁█▂▃▂▂▂▁▂▁▁▂▁▁▂▂▂▃▂▃▃▂▃▂▃▃▃▂▂▃▂▃▂▂▄▃▂▃▃▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>▁▁█▂▂▂▂▂▃▃▃▃▂▂▆▄▄▂▂▃▃▂▄▂▃▄▃▂▄▃▃▂▂▁▂▃▂▁▃▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>▁▁▂▁▁▁▂▁▂▇▂█▃▄▆▃▄▃▃▃▄▂▄▇▂▆▃▂▂▂▂▃▂▂▄▂▁▂▃▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>▁▁▁▁▁▂▂▃▁▄▆▃▄█▃▃▃▆▅▃▄▂▆▃▅▆▃▂▂▃▂▂▂▃▂▂▃▃▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▂▁▂▃▂▃▂▃▃▅▃▅▄█▂▂▆▇▃▂▂▂▂▁▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>█▇▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>▂▃█▆▄▅▃▄▄▄▄▅▅▇▇▇█▃▇▆▅▃▅▃▃▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>▁▂▁▁▁▁▂▂▃▂▇▄▃▆█▆▃▃█▃▂▆▇▄▂▃▂▃▄▂▃▂▃▂▂▂▂▄▃▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>▁▂▁▁▁▁▁▁▁▂▂▂▂▂▃▄▂▃█▂▅▆▆▇▄▃▃▂▄▃▃▃▃▃▄▃▅▂▁▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>▁▁▂▁▁▁▁▁▁▁▂▁▂▂▇▂█▆▃▄▃█▃▃▂▄▃▃▆▃▂▂▁▂▁▂▂▃▃▃</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>▁▁▁▁▁▁▃▂▁▂▂▂▃▃▂▂▃▄▆▄▆▆▃▂█▆▃▃▂▂▃▃▂▃▂▃▂▃▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>▂▂▁▂▁▂▃▃▃▃▂▅▅▆▇▆▄▅█▂▄▃▂▂▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>▁▁▂▁▁▁▁▁▁▂▂▃▃▂▂▃▄▃█▂▅▇▆▆▂▂▅▆▃▅▃▂▃▂▄▁▃▅▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>▄▆▄▄▃▃▃▃▅▄▅▇▆▅▄▅█▃▃▂▄▃▂▁▂▂▁▁▁▁▂▁▁▁▁▁▁▂▂▂</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>▄▃▃▄▂▃▄▅▆▃█▄▄█▆▅▅▅▆▃▂▃▂▂▃▁▁▁▁▁▃▂▂▁▁▂▁▁▁▁</td></tr><tr><td>Run</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Target Corr/val</td><td>▃▆▅▆▄▃▂▃█▁▆▆▆▃▆▇▅▅▇▇▆▄▄▄▃▄▆▅▆▆▆▆▅▂▅▅▃▂▃▅</td></tr><tr><td>Target MAPE/val</td><td>██████▇▇▇▇▇▇▆▆▅▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>feature_autoencoder_loss</td><td>▃▅█▇█▆▄▆▇▆▁▄▅▇▄▄▅▆▃▃▄▃▃▆▃▁▂▂▃▅▃▅▁▂▅▃▂▄▁▂</td></tr><tr><td>kernel_embedded_target_loss</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>███▇▇▇▇▇▇▇▆▅▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>▅█▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>66</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.0.weight</td><td>0.87582</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.bias</td><td>0.01069</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.1.weight</td><td>0.02026</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.bias</td><td>0.0181</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.12.weight</td><td>0.23063</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.4.weight</td><td>0.2771</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.bias</td><td>0.01471</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.5.weight</td><td>0.03161</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.8.weight</td><td>0.30757</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.bias</td><td>0.03029</td></tr><tr><td>Gradient Norm/feat_to_target_embedding.9.weight</td><td>0.02439</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat1.weight</td><td>0.03922</td></tr><tr><td>Gradient Norm/matrix_ae.dec_mat2.weight</td><td>0.03922</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.0.weight</td><td>0.01613</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.bias</td><td>0.00175</td></tr><tr><td>Gradient Norm/target_ae.decode_target.1.weight</td><td>0.00329</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.bias</td><td>0.00023</td></tr><tr><td>Gradient Norm/target_ae.decode_target.12.weight</td><td>0.00561</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.4.weight</td><td>0.02947</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.bias</td><td>0.00227</td></tr><tr><td>Gradient Norm/target_ae.decode_target.5.weight</td><td>0.00337</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.bias</td><td>0.0</td></tr><tr><td>Gradient Norm/target_ae.decode_target.8.weight</td><td>0.02263</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.bias</td><td>0.00215</td></tr><tr><td>Gradient Norm/target_ae.decode_target.9.weight</td><td>0.00142</td></tr><tr><td>Run</td><td>3</td></tr><tr><td>Target Corr/val</td><td>0.24118</td></tr><tr><td>Target MAPE/val</td><td>18.81676</td></tr><tr><td>feature_autoencoder_loss</td><td>1.0511</td></tr><tr><td>kernel_embedded_target_loss</td><td>4.83833</td></tr><tr><td>target_decoding_from_reduced_emb_loss</td><td>0.00335</td></tr><tr><td>total_loss</td><td>5.89278</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_162621-tevqikjo<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_162621-tevqikjo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mind/vshevche/contrastive-learning/contrastive_phenotypes/src/ContModeling/viz_func.py:107: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  correlations[i // cols, i % cols] = spearmanr(flat_true[:, i], flat_recon[:, i])[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>▁</td></tr><tr><td>Test | Target Corr/val</td><td>▁</td></tr><tr><td>Test | Target MAPE/val</td><td>▁</td></tr><tr><td>Test | Train ratio</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Run</td><td>3</td></tr><tr><td>Test | Target Corr/val</td><td>0.22361</td></tr><tr><td>Test | Target MAPE/val</td><td>18.39191</td></tr><tr><td>Test | Train ratio</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_162934-ms2c7dcy<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data/parietal/store/work/vshevche/results/wandb/offline-run-20250108_162934-ms2c7dcy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda, ratio 1.0\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c69338beba3460c81802cb81a8fa30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 117\u001b[0m\n\u001b[1;32m    114\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/mape.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 63\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_runs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Run\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     62\u001b[0m         run_model \u001b[38;5;241m=\u001b[39m ModelRun()\n\u001b[0;32m---> 63\u001b[0m         job \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m         run_results\u001b[38;5;241m.\u001b[39mappend(job)\n\u001b[1;32m     66\u001b[0m losses, predictions, embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mrun_results)\n",
      "Cell \u001b[0;32mIn[5], line 98\u001b[0m, in \u001b[0;36mModelRun.__call__\u001b[0;34m(self, train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state, device, save_model, path)\u001b[0m\n\u001b[1;32m     95\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(train_features, torch\u001b[38;5;241m.\u001b[39mfrom_numpy(train_targets)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m     96\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(test_features)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(test_targets)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m---> 98\u001b[0m loss_terms, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB_init_fMRI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss_terms\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_ratio = @train_ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun = @run\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    101\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(mean)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m#do we need this?\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 103\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(run, train_ratio, train_dataset, test_dataset, mean, std, B_init_fMRI, cfg, model, device)\u001b[0m\n\u001b[1;32m    100\u001b[0m embedded_feat_vectorized \u001b[38;5;241m=\u001b[39m sym_matrix_to_vec(embedded_feat\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    101\u001b[0m embedded_feat_vectorized \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(embedded_feat_vectorized)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 103\u001b[0m features_vectorized \u001b[38;5;241m=\u001b[39m sym_matrix_to_vec(\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    104\u001b[0m features_vectorized \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(features_vectorized)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m## KERNLIZED LOSS: MAT embedding vs MAT\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# kernel_embedded_feature_loss, direction_reg_features = criterion_pft(embedded_feat_vectorized.unsqueeze(1), features_vectorized)\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# kernel_embedded_feature_loss = 100 * kernel_embedded_feature_loss\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# direction_reg_features = 100 * direction_reg_features\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m## TARGET DECODING FROM MAT EMBEDDING\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(cfg=cfg):\n",
    "\n",
    "    results_dir = os.path.join(cfg.output_dir, cfg.experiment_name)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    random_state = np.random.RandomState(seed=42)\n",
    "\n",
    "    dataset_path = cfg.dataset_path\n",
    "\n",
    "    if isinstance(cfg.targets, str):\n",
    "        \n",
    "        targets =[cfg.targets]\n",
    "    else:\n",
    "        targets = list(cfg.targets)\n",
    "        \n",
    "    test_ratio = cfg.test_ratio\n",
    "\n",
    "    dataset = MatData(dataset_path, targets, synth_exp = cfg.synth_exp, threshold=cfg.mat_threshold)\n",
    "    n_sub = len(dataset)\n",
    "    test_size = int(test_ratio * n_sub)\n",
    "    indices = np.arange(n_sub)\n",
    "    n_runs = cfg.n_runs\n",
    "    multi_gpu = cfg.multi_gpu\n",
    "    train_ratio = cfg.train_ratio\n",
    "    \n",
    "    multi_gpu = False\n",
    "    if multi_gpu:\n",
    "        print(\"Using multi-gpu\")\n",
    "        log_folder = Path(\"logs\")\n",
    "        executor = submitit.AutoExecutor(folder=str(log_folder / \"%j\"))\n",
    "        executor.update_parameters(\n",
    "            timeout_min=120,\n",
    "            slurm_partition=\"gpu_short\",\n",
    "            gpus_per_node=1,\n",
    "            tasks_per_node=1,\n",
    "            nodes=1\n",
    "            #slurm_constraint=\"v100-32g\",\n",
    "        )\n",
    "        run_jobs = []\n",
    "\n",
    "        with executor.batch():\n",
    "            train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "            run_size = test_size + train_size\n",
    "            for run in tqdm(range(n_runs)):\n",
    "                run_model = ModelRun()\n",
    "                job = executor.submit(run_model, train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state=random_state, device=None)\n",
    "                run_jobs.append(job)\n",
    "\n",
    "        async def get_result(run_jobs):\n",
    "            run_results = []\n",
    "            for aws in tqdm(asyncio.as_completed([j.awaitable().result() for j in run_jobs]), total=len(run_jobs)):\n",
    "                res = await aws\n",
    "                run_results.append(res)\n",
    "            return run_results\n",
    "        run_results = asyncio.run(get_result(run_jobs))\n",
    "\n",
    "    else:\n",
    "        run_results = []\n",
    "        train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "        run_size = test_size + train_size\n",
    "        for run in tqdm(range(n_runs), desc=\"Model Run\"):\n",
    "            run_model = ModelRun()\n",
    "            job = run_model(train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state=random_state, device=None)\n",
    "            run_results.append(job)\n",
    "\n",
    "    losses, predictions, embeddings = zip(*run_results)\n",
    "\n",
    "    prediction_metrics = predictions[0]\n",
    "    for prediction in predictions[1:]:\n",
    "        prediction_metrics.update(prediction)\n",
    "\n",
    "    pred_results = []\n",
    "    for k, v in prediction_metrics.items():\n",
    "        true_targets, predicted_targets, indices = v\n",
    "        \n",
    "        true_targets_dict = {\"train_ratio\": [k[0]] * len(true_targets),\n",
    "                             \"model_run\":[k[1]] * len(true_targets),\n",
    "                             \"dataset\":[k[2]] * len(true_targets)\n",
    "                            }\n",
    "        predicted_targets_dict = {\"indices\": indices}\n",
    "        \n",
    "        for i, target in enumerate(targets):\n",
    "            true_targets_dict[target] = true_targets[:, i]\n",
    "            predicted_targets_dict[f\"{target}_pred\"] = predicted_targets[:, i]\n",
    "            \n",
    "            \n",
    "        true_targets = pd.DataFrame(true_targets_dict)\n",
    "        predicted_targets = pd.DataFrame(predicted_targets_dict)\n",
    "        \n",
    "        pred_results.append(pd.concat([true_targets, predicted_targets], axis = 1))\n",
    "    pred_results = pd.concat(pred_results)\n",
    "    pred_results.to_csv(f\"{results_dir}/pred_results.csv\", index=False)\n",
    "\n",
    "    prediction_mape_by_element = []\n",
    "    for k, v in prediction_metrics.items():\n",
    "        true_targets, predicted_targets, indices = v\n",
    "        \n",
    "        mape_by_element = np.abs(true_targets - predicted_targets) / (np.abs(true_targets)+1e-10)\n",
    "        \n",
    "        for i, mape in enumerate(mape_by_element):\n",
    "            prediction_mape_by_element.append(\n",
    "                {\n",
    "                    'train_ratio': k[0],\n",
    "                    'model_run': k[1],\n",
    "                    'dataset': k[2],\n",
    "                    'mape': mape\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(prediction_mape_by_element)\n",
    "    df = pd.concat([df.drop('mape', axis=1), df['mape'].apply(pd.Series)], axis=1)\n",
    "    df.columns = ['train_ratio', 'model_run', 'dataset'] + targets\n",
    "    df= df.groupby(['train_ratio', 'model_run', 'dataset']).agg('mean').reset_index()\n",
    "    df.to_csv(f\"{results_dir}/mape.csv\", index = False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
