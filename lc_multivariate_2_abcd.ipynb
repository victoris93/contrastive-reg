{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs3/well/margulies/users/cpy397/python/neuro/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import yaml\n",
    "import wandb\n",
    "import xarray as xr\n",
    "import asyncio\n",
    "import submitit\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from nilearn.connectome import sym_matrix_to_vec, vec_to_sym_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "# from augmentations import augs, aug_args\n",
    "import glob, os, shutil\n",
    "from nilearn.datasets import fetch_atlas_schaefer_2018\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from ContModeling.utils import (\n",
    "    gaussian_kernel,\n",
    "    cauchy,\n",
    "    rbf,\n",
    "    standardize,\n",
    "    save_embeddings,\n",
    "    filter_nans\n",
    ")\n",
    "from ContModeling.losses import LogEuclideanLoss, NormLoss, KernelizedSupCon, OutlierRobustMSE\n",
    "from ContModeling.models import PhenoProj\n",
    "from ContModeling.helper_classes import MatData\n",
    "from ContModeling.viz_func import wandb_plot_acc_vs_baseline, wandb_plot_test_recon_corr, wandb_plot_individual_recon\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TASKS_DICT = {\n",
    "    \"PicVocab_AgeAdj\": \"Vocabulary (picture matching)\",\n",
    "    \"ReadEng_AgeAdj\": \"Reading (pronunciation)\",\n",
    "    \"WM_Task_2bk_Acc\": \"Working Memory (2-back)\",\n",
    "    \"Relational_Task_Acc\": \"Relational processing\",\n",
    "    \"Language_Task_Story_Acc\": \"Story comprehension\",\n",
    "    \"PMAT24_A_CR\": \"Fluid Intelligence (PMAT)\",\n",
    "    \"VSPLOT_TC\": \"Spatial orientation\",  #???\n",
    "    \"CardSort_AgeAdj\": \"Cognitive flexibility (DCCS)\",\n",
    "    \"ListSort_AgeAdj\": \"Working memory (list sorting)\",\n",
    "    \"Language_Task_Math_Acc\": \"Arithmetic\", # ???\n",
    "    \"ProcSpeed_AgeAdj\": \"Processing speed\",\n",
    "    \"PicSeq_AgeAdj\": \"Visual Episodic Memory\",\n",
    "    \"SCPT_SPEC\": \"Sustained attention (Spec.)\",\n",
    "    \"Flanker_AgeAdj\": \"Inhibition (Flanker Task)\",\n",
    "    \"Emotion_Task_Face_Acc\": \"Emotional Face Matching\",\n",
    "    \"IWRD_TOT\": \"Verbal Episodic Memory\",\n",
    "    \"Dexterity_AgeAdj\": \"Manual dexterity\",\n",
    "    \"ER40_CR\": \"Emotion recognition - Total\",\n",
    "    \"ER40SAD\": \"Emotion recognition - Sad\",\n",
    "    \"ER40ANG\": \"Emotion recognition - Angry\",\n",
    "    ### SOCIAL COGNITION - INTERACTION ??????\n",
    "    \"ER40NOE\": \"Emotion recognition - Neutral\",\n",
    "    \"MMSE_Score\": \"Cognitive status (MMSE)\",\n",
    "    \"ER40HAP\": \"Emotion recognition - Happy\",\n",
    "    \"SCPT_SEN\": \"Sustained attention (Sens.)\",\n",
    "    \"Social_Task_Perc_Random\": \"Social cognition (Random)\",\n",
    "    \"ER40FEAR\": \"Emotion recognition - Fear\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_LOSSES ={\n",
    "    'Norm': NormLoss(),\n",
    "    'LogEuclidean': LogEuclideanLoss(),\n",
    "    'MSE': nn.functional.mse_loss,\n",
    "    'MAE': nn.functional.l1_loss,\n",
    "    'MSERobust': OutlierRobustMSE(),\n",
    "    'Huber': nn.HuberLoss(),\n",
    "    'cosine': nn.functional.cosine_embedding_loss,\n",
    "}\n",
    "\n",
    "SUPCON_KERNELS = {\n",
    "    'cauchy': cauchy,\n",
    "    'gaussian_kernel': gaussian_kernel,\n",
    "    'rbf': rbf,\n",
    "    'None': None\n",
    "    }\n",
    "\n",
    "def train(run, train_ratio, train_dataset, test_dataset, mean, std, B_init_fMRI, cfg, model=None, device=device):\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    # MODEL DIMS\n",
    "    input_dim_feat = cfg.input_dim_feat\n",
    "    input_dim_target = cfg.input_dim_target\n",
    "    hidden_dim = cfg.hidden_dim\n",
    "    output_dim_target = cfg.output_dim_target\n",
    "    output_dim_feat = cfg.output_dim_feat\n",
    "    kernel = SUPCON_KERNELS[cfg.SupCon_kernel]\n",
    "    \n",
    "    # TRAINING PARAMS\n",
    "    lr = cfg.lr\n",
    "    batch_size = cfg.batch_size\n",
    "    dropout_rate = cfg.dropout_rate\n",
    "    weight_decay = cfg.weight_decay\n",
    "    num_epochs = cfg.num_epochs\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    mean= torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    if model is None:\n",
    "        model = PhenoProj(\n",
    "            input_dim_feat,\n",
    "            input_dim_target,\n",
    "            hidden_dim,\n",
    "            output_dim_target,\n",
    "            output_dim_feat,\n",
    "            dropout_rate,\n",
    "            cfg\n",
    "        ).to(device)\n",
    "\n",
    "    if cfg.full_model_pretrained:\n",
    "        print(f\"Loading pretrained FULL model, train ratio {train_ratio}...\")\n",
    "        state_dict = torch.load(f\"{cfg.output_dir}/{cfg.pretrained_full_model_exp}/saved_models/model_weights_train_ratio{train_ratio}_run0.pth\")\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    else:\n",
    "        if cfg.mat_ae_pretrained:\n",
    "            print(\"Loading pretrained MatrixAutoencoder...\")\n",
    "            state_dict = torch.load(f\"{cfg.output_dir}/{cfg.pretrained_mat_ae_exp}/saved_models/autoencoder_weights_fold{cfg.best_mat_ae_fold}.pth\")\n",
    "            model.matrix_ae.load_state_dict(state_dict)\n",
    "\n",
    "        if cfg.reduced_mat_ae_pretrained:\n",
    "            print(\"Loading pretrained ReducedMatrixAutoencoder...\")\n",
    "            state_dict = torch.load(f\"{cfg.output_dir}/{cfg.pretrained_reduced_mat_ae_exp}/saved_models/autoencoder_weights_fold{cfg.best_reduced_mat_ae_fold}.pth\")\n",
    "            model.reduced_matrix_ae.load_state_dict(state_dict)\n",
    "        \n",
    "    if cfg.mat_ae_enc_freeze:\n",
    "        print(\"Freezing weights for mat encoding...\")\n",
    "        for param in model.matrix_ae.enc_mat1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.matrix_ae.enc_mat2.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        model.matrix_ae.enc_mat1.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "        model.matrix_ae.enc_mat2.weight = torch.nn.Parameter(B_init_fMRI.transpose(0,1))\n",
    "\n",
    "    if cfg.mat_ae_dec_freeze:\n",
    "        print(\"Freezing weights for mat decoding...\")\n",
    "        for param in model.matrix_ae.dec_mat1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.matrix_ae.dec_mat2.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    if cfg.reduced_mat_ae_enc_freeze:\n",
    "        print(\"Freezing weights for reduced mat encoding...\")\n",
    "        for param in model.reduced_matrix_ae.reduced_mat_to_embed.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    if cfg.reduced_mat_ae_dec_freeze:\n",
    "        print(\"Freezing weights for reduced mat decoding...\")\n",
    "        for param in model.reduced_matrix_ae.embed_to_reduced_mat.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    if cfg.target_dec_freeze:\n",
    "        print(\"Freezing TargetDecoder...\")\n",
    "        for param in model.target_dec.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    criterion_pft = KernelizedSupCon(\n",
    "        method=\"yaware\",\n",
    "        temperature=cfg.pft_temperature,\n",
    "        base_temperature= cfg.pft_base_temperature,\n",
    "        reg_term = cfg.pft_reg_term,\n",
    "        kernel=kernel,\n",
    "        krnl_sigma=cfg.pft_sigma,\n",
    "    )\n",
    "\n",
    "    criterion_ptt = KernelizedSupCon(\n",
    "        method=\"yaware\",\n",
    "        temperature=cfg.ptt_temperature,\n",
    "        base_temperature= cfg.ptt_base_temperature,\n",
    "        reg_term = cfg.ptt_reg_term,\n",
    "        kernel=kernel,\n",
    "        krnl_sigma=cfg.ptt_sigma,\n",
    "    )\n",
    "    feature_autoencoder_crit = EMB_LOSSES[cfg.feature_autoencoder_crit]\n",
    "    target_decoding_crit = EMB_LOSSES[cfg.target_decoding_crit]\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=cfg.lr, weight_decay=weight_decay,\n",
    "    #                             momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1, patience = cfg.scheduler_patience)\n",
    "\n",
    "    loss_terms = []\n",
    "    validation = []\n",
    "    autoencoder_features = []\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    wandb.init(project=cfg.project,\n",
    "        mode = \"offline\",\n",
    "        name=f\"{cfg.experiment_name}_run{run}_train_ratio_{train_ratio}\",\n",
    "        dir = cfg.output_dir,\n",
    "        config = OmegaConf.to_container(cfg, resolve=True))\n",
    "    print(\"Wandb init\")\n",
    "    \n",
    "    with tqdm(range(num_epochs), desc=\"Epochs\", leave=False) as pbar:\n",
    "        for epoch in pbar:\n",
    "            model.train()\n",
    "\n",
    "            if cfg.reduced_mat_ae_pretrained:\n",
    "                model.reduced_matrix_ae.eval()\n",
    "            if cfg.reduced_mat_ae_enc_freeze:\n",
    "                model.reduced_matrix_ae.reduced_mat_to_embed.eval()\n",
    "            if cfg.reduced_mat_ae_dec_freeze:\n",
    "                model.reduced_matrix_ae.embed_to_reduced_mat.eval()\n",
    "            if cfg.target_dec_freeze:\n",
    "                model.target_dec.eval()\n",
    "                \n",
    "            loss_terms_batch = defaultdict(lambda:0)\n",
    "            for features, targets, inter_network_conn, _ in train_loader:\n",
    "                loss = 0\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                features, targets, _, inter_network_conn = filter_nans(features, targets, _z=inter_network_conn)\n",
    "\n",
    "                features = features.to(device)\n",
    "                targets = targets.to(device)\n",
    "                inter_network_conn = inter_network_conn.to(device)\n",
    "\n",
    "                ## FEATURE ENCODING == MATRIX REDUCTION\n",
    "                embedded_feat = model.encode_features(features)\n",
    "                \n",
    "                ## VECTORIZE REDUCED MATRIX\n",
    "                embedded_feat_vectorized = sym_matrix_to_vec(embedded_feat.detach().cpu().numpy())\n",
    "                embedded_feat_vectorized = torch.tensor(embedded_feat_vectorized).to(torch.float32).to(device)\n",
    "\n",
    "                ## EMBEDDING OF THE REDUCED MATRIX\n",
    "                reduced_mat_embedding, reduced_mat_embedding_norm = model.encode_reduced_mat(embedded_feat_vectorized)\n",
    "                out_target_decoded = model.decode_targets(reduced_mat_embedding_norm)\n",
    "\n",
    "                ## RECONSTRUCT REDUCED MATRIX FROM EMBEDDING AND THE FULL MATRIX FROM REDUCED\n",
    "                recon_reduced_mat = model.decode_reduced_mat(reduced_mat_embedding)\n",
    "\n",
    "                if not cfg.reduced_mat_ae_dec_freeze:\n",
    "                    reduced_mat_recon_loss = feature_autoencoder_crit(embedded_feat_vectorized, recon_reduced_mat) / 1000\n",
    "                    loss += reduced_mat_recon_loss\n",
    "\n",
    "                recon_reduced_mat = vec_to_sym_matrix(recon_reduced_mat.detach().cpu().numpy())\n",
    "                recon_reduced_mat = torch.tensor(recon_reduced_mat).to(torch.float32).to(device)\n",
    "\n",
    "                reconstructed_feat = model.decode_features(recon_reduced_mat)\n",
    "\n",
    "                ## LOSS: TARGET DECODING FROM TARGET EMBEDDING\n",
    "                if cfg.target_decoding_crit == 'Huber' and cfg.huber_delta != 'None':\n",
    "                    target_decoding_crit = nn.HuberLoss(delta = cfg.huber_delta)\n",
    "\n",
    "                if not cfg.reduced_mat_ae_enc_freeze:\n",
    "                    ## KERNLIZED LOSS: MAT embedding vs targets\n",
    "                    kernel_embedded_target_loss, _ = criterion_ptt(reduced_mat_embedding_norm.unsqueeze(1), targets)\n",
    "                    kernel_embedded_network_loss, _ = criterion_pft(reduced_mat_embedding_norm.unsqueeze(1), inter_network_conn)\n",
    "                    loss += (kernel_embedded_target_loss + kernel_embedded_network_loss)\n",
    "\n",
    "                if not cfg.mat_ae_enc_freeze or not cfg.mat_ae_dec_freeze:\n",
    "                    feature_autoencoder_loss = feature_autoencoder_crit(features, reconstructed_feat) / 1000\n",
    "                    loss += feature_autoencoder_loss\n",
    "\n",
    "                if not cfg.target_dec_freeze:\n",
    "                    target_decoding_from_reduced_emb_loss = target_decoding_crit(targets, out_target_decoded)\n",
    "                    loss += target_decoding_from_reduced_emb_loss\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                if cfg.clip_grad:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                if cfg.log_gradients:\n",
    "                    for name, param in model.named_parameters():\n",
    "                        if param.grad is not None:\n",
    "                            wandb.log({\n",
    "                                \"Epoch\": epoch,\n",
    "                                'Run': run,\n",
    "                                \"Train ratio\": train_ratio,\n",
    "                                f\"Gradient Norm/{name}\": param.grad.norm().item()\n",
    "                            })  \n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_terms_batch['loss'] = loss.item() / len(features)\n",
    "\n",
    "                if not cfg.reduced_mat_ae_enc_freeze:\n",
    "                    loss_terms_batch['kernel_embedded_target_loss'] = kernel_embedded_target_loss.item() / len(features)\n",
    "                    loss_terms_batch['kernel_embedded_network_loss'] = kernel_embedded_network_loss.item() / len(features)\n",
    "\n",
    "                    wandb.log({\n",
    "                        'Epoch': epoch,\n",
    "                        'Run': run,\n",
    "                        \"Train ratio\": train_ratio,\n",
    "                        'kernel_embedded_target_loss': loss_terms_batch['kernel_embedded_target_loss'],\n",
    "                        'kernel_embedded_network_loss': loss_terms_batch['kernel_embedded_network_loss'],\n",
    "                    })\n",
    "\n",
    "                if not cfg.reduced_mat_ae_dec_freeze:\n",
    "                    loss_terms_batch['reduced_mat_recon_loss'] = reduced_mat_recon_loss.item() / len(features)\n",
    "                    wandb.log({\n",
    "                        'Epoch': epoch,\n",
    "                        'Run': run,\n",
    "                        \"Train ratio\": train_ratio,\n",
    "                        'reduced_mat_recon_loss': loss_terms_batch['reduced_mat_recon_loss'],\n",
    "                    })\n",
    "                \n",
    "                if not cfg.target_dec_freeze:\n",
    "                    loss_terms_batch['target_decoding_loss'] = target_decoding_from_reduced_emb_loss.item() / len(features)\n",
    "                    wandb.log({\n",
    "                        'Epoch': epoch,\n",
    "                        'Run': run,\n",
    "                        \"Train ratio\": train_ratio,\n",
    "                        'target_decoding_loss': loss_terms_batch['target_decoding_loss'],\n",
    "                    })\n",
    "\n",
    "                # loss_terms_batch['direction_reg_target_loss'] = direction_reg_target.item() / len(features)\n",
    "                \n",
    "                if not cfg.mat_ae_enc_freeze or not cfg.mat_ae_dec_freeze:\n",
    "                    loss_terms_batch['feature_autoencoder_loss'] = feature_autoencoder_loss.item() / len(features)\n",
    "                    wandb.log({\n",
    "                        'Epoch': epoch,\n",
    "                        'Run': run,\n",
    "                        \"Train ratio\": train_ratio,\n",
    "                        'feature_autoencoder_loss': loss_terms_batch['feature_autoencoder_loss'],\n",
    "                    })\n",
    "                \n",
    "                wandb.log({\n",
    "                    'Epoch': epoch,\n",
    "                    'Run': run,\n",
    "                    \"Train ratio\": train_ratio,\n",
    "                    'total_loss': loss_terms_batch['loss'],\n",
    "                })\n",
    "\n",
    "            loss_terms_batch['epoch'] = epoch\n",
    "            loss_terms.append(loss_terms_batch)\n",
    "\n",
    "            model.eval()\n",
    "            mape_batch = 0\n",
    "            corr_batch = 0\n",
    "            with torch.no_grad():\n",
    "                for features, targets, _, _ in test_loader:\n",
    "\n",
    "                    features, targets, _, _ = filter_nans(features, targets)\n",
    "                    \n",
    "                    features, targets = features.to(device), targets.to(device)                    \n",
    "                    reduced_mat = model.encode_features(features)\n",
    "                    \n",
    "                    reduced_mat = torch.tensor(sym_matrix_to_vec(reduced_mat.detach().cpu().numpy())).to(torch.float32).to(device)\n",
    "                    embedding, embedding_norm = model.encode_reduced_mat(reduced_mat)\n",
    "                    out_target_decoded = model.decode_targets(embedding_norm)\n",
    "                    \n",
    "                    epsilon = 1e-8\n",
    "\n",
    "                    mape =  torch.mean(torch.abs((targets - out_target_decoded)) / torch.abs((targets + epsilon))) * 100\n",
    "                    if torch.isnan(mape):\n",
    "                        mape = torch.tensor(0.0)\n",
    "\n",
    "                    corr =  spearmanr(targets.cpu().numpy().flatten(), out_target_decoded.cpu().numpy().flatten())[0]\n",
    "                    if np.isnan(corr):\n",
    "                        corr = 0.0\n",
    "                        \n",
    "                    mape_batch+=mape.item()\n",
    "                    corr_batch += corr\n",
    "\n",
    "                mape_batch = mape_batch/len(test_loader)\n",
    "                corr_batch = corr_batch/len(test_loader)\n",
    "                validation.append(mape_batch)\n",
    "\n",
    "            wandb.log({\n",
    "                'Run': run,\n",
    "                \"Train ratio\": train_ratio,\n",
    "                'Target MAPE/val' : mape_batch,\n",
    "                'Target Corr/val': corr_batch,\n",
    "                })\n",
    "            \n",
    "            scheduler.step(mape_batch)\n",
    "            if np.log10(scheduler._last_lr[0]) < -5:\n",
    "                break\n",
    "\n",
    "            pbar.set_postfix_str(\n",
    "                f\"Epoch {epoch} \"\n",
    "                f\"| Loss {loss_terms[-1]['loss']:.02f} \"\n",
    "                f\"| val Target MAPE {mape_batch:.02f}\"\n",
    "                f\"| val Target Corr {corr_batch:.02f} \"\n",
    "                f\"| log10 lr {np.log10(scheduler._last_lr[0])}\"\n",
    "            )\n",
    "    wandb.finish()\n",
    "    loss_terms = pd.DataFrame(loss_terms)\n",
    "    return loss_terms, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRun(submitit.helpers.Checkpointable):\n",
    "    def __init__(self):\n",
    "        self.results = None\n",
    "        self.embeddings = None\n",
    "\n",
    "    def __call__(self, train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state=None, device=None, save_model = True, path: Path = None):\n",
    "        if self.results is None:\n",
    "            if device is None:\n",
    "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                print(f\"Device {device}, ratio {train_ratio}\", flush=True)\n",
    "            if not isinstance(random_state, np.random.RandomState):\n",
    "                random_state = np.random.RandomState(random_state)\n",
    "            \n",
    "            recon_mat_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.reconstructed_dir)\n",
    "            os.makedirs(recon_mat_dir, exist_ok=True)\n",
    "    \n",
    "            predictions = {}\n",
    "            autoencoder_features = {}\n",
    "            losses = []\n",
    "            self.embeddings = {'train': [], 'test': []}\n",
    "            self.run = run\n",
    "\n",
    "            if cfg.mat_ae_pretrained:\n",
    "                print(\"Loading test indices from the pretraining experiment...\")\n",
    "                test_indices = np.load(f\"{cfg.output_dir}/{cfg.pretrained_mat_ae_exp}/test_idx.npy\")\n",
    "                train_indices = np.setdiff1d(indices, test_indices)\n",
    "                if train_ratio < 1.0:\n",
    "                    train_size = int(len(train_indices) * train_ratio)\n",
    "                    train_indices = random_state.choice(train_indices, train_size, replace=False)\n",
    "\n",
    "            elif cfg.external_test_mode:\n",
    "                test_scanners = list(cfg.test_scanners)\n",
    "                xr_dataset = xr.open_dataset(cfg.dataset_path)\n",
    "                scanner_mask = np.sum([xr_dataset.isin(scanner).scanner.values for scanner in test_scanners],\n",
    "                                    axis = 0).astype(bool)\n",
    "                test_indices = indices[scanner_mask]\n",
    "                train_indices = indices[~scanner_mask]\n",
    "                if train_ratio < 1.0:\n",
    "                    train_size = int(len(train_indices) * train_ratio)\n",
    "                    train_indices = random_state.choice(train_indices, train_size, replace=False)\n",
    "                del xr_dataset\n",
    "\n",
    "            else:\n",
    "                run_indices = random_state.choice(indices, run_size, replace=False)\n",
    "                train_indices, test_indices = train_test_split(run_indices, test_size=test_size, random_state=random_state)\n",
    "                \n",
    "            train_dataset = Subset(dataset, train_indices)\n",
    "            test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "            train_features = train_dataset.dataset.matrices[train_dataset.indices]\n",
    "            train_targets = train_dataset.dataset.targets[train_dataset.indices].numpy()\n",
    "            train_inter_network_conn = train_dataset.dataset.inter_network_conn[train_dataset.indices]\n",
    "            train_intra_network_conn = train_dataset.dataset.intra_network_conn[train_dataset.indices]\n",
    "\n",
    "            std_train_targets, mean, std = standardize(train_targets)\n",
    "            # scaler = MinMaxScaler().fit(train_targets)\n",
    "            # train_targets = scaler.transform(train_targets)\n",
    "\n",
    "            input_dim_feat =cfg.input_dim_feat\n",
    "            output_dim_feat = cfg.output_dim_feat\n",
    "\n",
    "            ## Weight initialization for bilinear layer\n",
    "            mean_f = torch.mean(train_features, dim=0).to(device)\n",
    "            [D,V] = torch.linalg.eigh(mean_f,UPLO = \"U\")\n",
    "            B_init_fMRI = V[:,input_dim_feat-output_dim_feat:]\n",
    "\n",
    "            test_features= test_dataset.dataset.matrices[test_dataset.indices].numpy()\n",
    "            test_targets = test_dataset.dataset.targets[test_dataset.indices].numpy()\n",
    "            test_inter_network_conn = test_dataset.dataset.inter_network_conn[test_dataset.indices]\n",
    "            test_intra_network_conn = test_dataset.dataset.intra_network_conn[test_dataset.indices]\n",
    "\n",
    "            train_dataset = TensorDataset(train_features,\n",
    "                                          torch.from_numpy(train_targets).to(torch.float32),\n",
    "                                          train_inter_network_conn,\n",
    "                                          train_intra_network_conn)\n",
    "            \n",
    "            test_dataset = TensorDataset(torch.from_numpy(test_features).to(torch.float32),\n",
    "                                         torch.from_numpy(test_targets).to(torch.float32),\n",
    "                                         test_inter_network_conn,\n",
    "                                         test_intra_network_conn)\n",
    "\n",
    "            loss_terms, model = train(run, train_ratio, train_dataset, test_dataset, mean, std, B_init_fMRI, cfg, device=device)\n",
    "            losses.append(loss_terms.eval(\"train_ratio = @train_ratio\").eval(\"run = @run\"))\n",
    "\n",
    "            mean = torch.tensor(mean).to(device) #do we need this?\n",
    "            std  = torch.tensor(std).to(device)\n",
    "\n",
    "            wandb.init(project=cfg.project,\n",
    "                mode = \"offline\",\n",
    "                name=f\"TEST_{cfg.experiment_name}_run{run}_train_ratio_{train_ratio}\",\n",
    "                dir = cfg.output_dir,\n",
    "                config = OmegaConf.to_container(cfg, resolve=True))\n",
    "            \n",
    "            embedding_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.embedding_dir)\n",
    "            os.makedirs(embedding_dir, exist_ok=True)\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for label, d, d_indices in (('train', train_dataset, train_indices), ('test', test_dataset, test_indices)):\n",
    "\n",
    "                    is_test = True\n",
    "                    if label == 'train':\n",
    "                        is_test = False\n",
    "                    \n",
    "                    X, y, _, _ = zip(*d)\n",
    "                    X = torch.stack(X)\n",
    "                    y = torch.stack(y)\n",
    "                    X, y, d_indices, _ = filter_nans(X, y, d_indices)\n",
    "                    X = X.to(device)\n",
    "                    y = y.to(device)\n",
    "\n",
    "                    X_embedded = model.encode_features(X)\n",
    "                    X_embedded = X_embedded.cpu().numpy()\n",
    "                    X_embedded = torch.tensor(sym_matrix_to_vec(X_embedded)).to(torch.float32).to(device)\n",
    "                    X_emb_reduced, X_emb_reduced_norm = model.encode_reduced_mat(X_embedded)\n",
    "                    \n",
    "                    if label == 'test' and train_ratio == 1.0:\n",
    "                        np.save(f'{recon_mat_dir}/test_idx_run{run}',d_indices)\n",
    "                        inv_feat_embedding = model.decode_reduced_mat(X_emb_reduced).detach().cpu().numpy()\n",
    "                        inv_feat_embedding = vec_to_sym_matrix(inv_feat_embedding)\n",
    "                        inv_feat_embedding = torch.tensor(inv_feat_embedding).to(torch.float32).to(device)\n",
    "                        recon_mat = model.decode_features(inv_feat_embedding)\n",
    "                        mape_mat = torch.abs((X - recon_mat) / (X + 1e-10)) * 100\n",
    "                        \n",
    "                        wandb_plot_test_recon_corr(wandb, cfg.experiment_name, cfg.work_dir, recon_mat.cpu().numpy(), X.cpu().numpy(), mape_mat.cpu().numpy(), True, run)\n",
    "                        wandb_plot_individual_recon(wandb, cfg.experiment_name, cfg.work_dir, d_indices, recon_mat.cpu().numpy(), X.cpu().numpy(), mape_mat.cpu().numpy(), 0, True, run)\n",
    "\n",
    "                        np.save(f'{recon_mat_dir}/recon_mat_run{run}', recon_mat.cpu().numpy())\n",
    "                        np.save(f'{recon_mat_dir}/mape_mat_run{run}', mape_mat.cpu().numpy())\n",
    "                    y_pred = model.decode_targets(X_emb_reduced_norm)\n",
    "\n",
    "                    save_embeddings(X_embedded, \"mat\", cfg, is_test, run)\n",
    "                    save_embeddings(X_emb_reduced_norm, \"joint\", cfg, is_test, run)\n",
    "\n",
    "                    if label == 'test':\n",
    "                        epsilon = 1e-8\n",
    "                        mape =  100 * torch.mean(torch.abs((y - y_pred)) / torch.abs((y + epsilon))).item()\n",
    "                        corr =  spearmanr(y.cpu().numpy().flatten(), y_pred.cpu().numpy().flatten())[0]\n",
    "\n",
    "                        wandb.log({\n",
    "                            'Run': run,\n",
    "                            \"Train ratio\": train_ratio,\n",
    "                            'Test | Target MAPE/val' : mape,\n",
    "                            'Test | Target Corr/val': corr,\n",
    "                            'Test | Train ratio' : train_ratio\n",
    "                            })\n",
    "            \n",
    "                    predictions[(train_ratio, run, label)] = (y.cpu().numpy(), y_pred.cpu().numpy(), d_indices)\n",
    "                    for i, idx in enumerate(d_indices):\n",
    "                        self.embeddings[label].append({\n",
    "                            'index': idx,\n",
    "                            'joint_embedding': X_emb_reduced[i].cpu().numpy()\n",
    "                        })\n",
    "            wandb.finish()\n",
    "            \n",
    "            self.results = (losses, predictions, self.embeddings)\n",
    "\n",
    "        if save_model:\n",
    "            saved_models_dir = os.path.join(cfg.output_dir, cfg.experiment_name, cfg.model_weight_dir)\n",
    "            os.makedirs(saved_models_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"{saved_models_dir}/model_weights_train_ratio{train_ratio}_run{run}.pth\")\n",
    "\n",
    "        return self.results\n",
    "\n",
    "    def checkpoint(self, *args, **kwargs):\n",
    "        print(\"Checkpointing\", flush=True)\n",
    "        return super().checkpoint(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project: HCP_CL_REDMAT_ENC_MULTIVAR\n",
      "experiment_name: 1run_train_redmat_enc_hcp_sup_net_multivar\n",
      "hypothesis: '-'\n",
      "input_dim_feat: 400\n",
      "output_dim_feat: 100\n",
      "hidden_dim: 128\n",
      "input_dim_target: 1\n",
      "output_dim_target: 64\n",
      "seed: 42\n",
      "skip_conn: false\n",
      "skip_enc1: false\n",
      "ReEig: false\n",
      "full_model_pretrained: false\n",
      "mat_ae_pretrained: true\n",
      "reduced_mat_ae_pretrained: false\n",
      "pretrained_mat_ae_exp: pretrain_mat_ae_hcp\n",
      "pretrained_reduced_mat_ae_exp: ext_sup_reduced_mat_ae_abcd\n",
      "pretrained_full_model_exp: 1run_train_target_dec_hcp_sup_net_latest\n",
      "mat_ae_enc_freeze: true\n",
      "mat_ae_dec_freeze: true\n",
      "reduced_mat_ae_enc_freeze: false\n",
      "reduced_mat_ae_dec_freeze: true\n",
      "target_dec_freeze: true\n",
      "best_mat_ae_fold: 2\n",
      "best_reduced_mat_ae_fold: 4\n",
      "synth_exp: false\n",
      "multi_gpu: true\n",
      "num_epochs: 500\n",
      "batch_size: 256\n",
      "n_runs: 1\n",
      "lr: 0.001\n",
      "weight_decay: 0.0001\n",
      "dropout_rate: 0\n",
      "scheduler_patience: 20\n",
      "test_ratio: 0.3\n",
      "train_ratio:\n",
      "- 1.0\n",
      "log_gradients: true\n",
      "clip_grad: true\n",
      "external_test_mode: false\n",
      "test_scanners:\n",
      "- GE MEDICAL SYSTEMS_DISCOVERY MR750\n",
      "- Philips Medical Systems_Achieva dStream\n",
      "- Philips Medical Systems_Ingenia\n",
      "SupCon_kernel: rbf\n",
      "SupConLoss_on_mat: false\n",
      "pft_base_temperature: 0.07\n",
      "pft_temperature: 0.07\n",
      "pft_sigma: 0.2\n",
      "pft_reg_term: 0.01\n",
      "ptt_base_temperature: 0.07\n",
      "ptt_temperature: 0.07\n",
      "ptt_sigma: 5\n",
      "ptt_reg_term: 0.01\n",
      "feature_autoencoder_crit: Norm\n",
      "joint_embedding_crit: cosine\n",
      "target_decoding_crit: MSE\n",
      "huber_delta: 10\n",
      "augmentation: None\n",
      "mat_threshold: 0\n",
      "dataset_path: /well/margulies/users/cpy397/contrastive-learning/data/hcp_kong_400parcels.nc\n",
      "targets:\n",
      "- PicVocab_AgeAdj\n",
      "- ReadEng_AgeAdj\n",
      "- WM_Task_2bk_Acc\n",
      "- Relational_Task_Acc\n",
      "- Language_Task_Story_Acc\n",
      "- PMAT24_A_CR\n",
      "- VSPLOT_TC\n",
      "- CardSort_AgeAdj\n",
      "- ListSort_AgeAdj\n",
      "- Language_Task_Math_Acc\n",
      "- ProcSpeed_AgeAdj\n",
      "- PicSeq_AgeAdj\n",
      "- SCPT_SPEC\n",
      "- Flanker_AgeAdj\n",
      "- Emotion_Task_Face_Acc\n",
      "- IWRD_TOT\n",
      "- Dexterity_AgeAdj\n",
      "- ER40_CR\n",
      "- ER40SAD\n",
      "- ER40ANG\n",
      "- ER40NOE\n",
      "- MMSE_Score\n",
      "- ER40HAP\n",
      "- SCPT_SEN\n",
      "- Social_Task_Perc_Random\n",
      "- ER40FEAR\n",
      "standardize_target: true\n",
      "work_dir: /well/margulies/users/cpy397/contrastive-learning\n",
      "reconstructed_dir: recon_mat\n",
      "embedding_dir: embeddings\n",
      "model_weight_dir: saved_models\n",
      "output_dir: /well/margulies/users/cpy397/contrastive-learning/results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\".\"):\n",
    "    cfg = compose(config_name='jupyter_main_model_config.yaml')\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing target PicVocab_AgeAdj (min: 0.9583, max: 131.89) to [0, 1]\n",
      "Standardizing target ReadEng_AgeAdj (min: 0.9583, max: 112.36) to [0, 1]\n",
      "Standardizing target WM_Task_2bk_Acc (min: 0.8667, max: 132.63) to [0, 1]\n",
      "Standardizing target Relational_Task_Acc (min: 0.975, max: 146.5971) to [0, 1]\n",
      "Standardizing target Language_Task_Story_Acc (min: 0.975, max: 101.1697) to [0, 1]\n",
      "Standardizing target PMAT24_A_CR (min: 0.9167, max: 123.73) to [0, 1]\n",
      "Standardizing target VSPLOT_TC (min: 0.8917, max: 121.3679) to [0, 1]\n",
      "Standardizing target CardSort_AgeAdj (min: 0.8417, max: 111.31) to [0, 1]\n",
      "Standardizing target ListSort_AgeAdj (min: 0.9833, max: 113.58) to [0, 1]\n",
      "Standardizing target Language_Task_Math_Acc (min: 0.9667, max: 130.65) to [0, 1]\n",
      "Standardizing target ProcSpeed_AgeAdj (min: 0.0, max: 119.7597) to [0, 1]\n",
      "Standardizing target PicSeq_AgeAdj (min: 0.9333, max: 113.85) to [0, 1]\n",
      "Standardizing target SCPT_SPEC (min: 0.975, max: 118.5772) to [0, 1]\n",
      "Standardizing target Flanker_AgeAdj (min: 0.9667, max: 143.56) to [0, 1]\n",
      "Standardizing target Emotion_Task_Face_Acc (min: 0.9833, max: 123.2858) to [0, 1]\n",
      "Standardizing target IWRD_TOT (min: 0.9583, max: 112.66) to [0, 1]\n",
      "Standardizing target Dexterity_AgeAdj (min: nan, max: nan) to [0, 1]\n",
      "Standardizing target ER40_CR (min: 0.9667, max: 122.75) to [0, 1]\n",
      "Standardizing target ER40SAD (min: 0.9583, max: 127.41) to [0, 1]\n",
      "Standardizing target ER40ANG (min: 0.8333, max: 104.7) to [0, 1]\n",
      "Standardizing target ER40NOE (min: 0.8833, max: 100.0) to [0, 1]\n",
      "Standardizing target MMSE_Score (min: 0.975, max: 128.16) to [0, 1]\n",
      "Standardizing target ER40HAP (min: nan, max: nan) to [0, 1]\n",
      "Standardizing target SCPT_SEN (min: 0.9917, max: 134.81) to [0, 1]\n",
      "Standardizing target Social_Task_Perc_Random (min: 0.9917, max: 111.48) to [0, 1]\n",
      "Standardizing target ER40FEAR (min: 0.9833, max: 125.99) to [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Size:   0%|                                      | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[Ael Run:   0%|                                          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda, ratio 1.0\n",
      "Loading test indices from the pretraining experiment...\n",
      "Start training...\n",
      "Loading pretrained MatrixAutoencoder...\n",
      "Freezing weights for mat encoding...\n",
      "Freezing weights for mat decoding...\n",
      "Freezing weights for reduced mat decoding...\n",
      "Freezing TargetDecoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-30267538/ipykernel_1695927/3986217531.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"{cfg.output_dir}/{cfg.pretrained_mat_ae_exp}/saved_models/autoencoder_weights_fold{cfg.best_mat_ae_fold}.pth\")\n",
      "Model Run:   0%|                                          | 0/1 [00:58<?, ?it/s]\n",
      "Training Size:   0%|                                      | 0/1 [00:58<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 126\u001b[0m\n\u001b[1;32m    123\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/mape.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 72\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_runs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Run\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     71\u001b[0m             run_model \u001b[38;5;241m=\u001b[39m ModelRun()\n\u001b[0;32m---> 72\u001b[0m             job \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m             run_results\u001b[38;5;241m.\u001b[39mappend(job)\n\u001b[1;32m     75\u001b[0m losses, predictions, embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mrun_results)\n",
      "Cell \u001b[0;32mIn[5], line 82\u001b[0m, in \u001b[0;36mModelRun.__call__\u001b[0;34m(self, train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state, device, save_model, path)\u001b[0m\n\u001b[1;32m     72\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(train_features,\n\u001b[1;32m     73\u001b[0m                               torch\u001b[38;5;241m.\u001b[39mfrom_numpy(train_targets)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     74\u001b[0m                               train_inter_network_conn,\n\u001b[1;32m     75\u001b[0m                               train_intra_network_conn)\n\u001b[1;32m     77\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(test_features)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     78\u001b[0m                              torch\u001b[38;5;241m.\u001b[39mfrom_numpy(test_targets)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     79\u001b[0m                              test_inter_network_conn,\n\u001b[1;32m     80\u001b[0m                              test_intra_network_conn)\n\u001b[0;32m---> 82\u001b[0m loss_terms, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB_init_fMRI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss_terms\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_ratio = @train_ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun = @run\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     85\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(mean)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m#do we need this?\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 131\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(run, train_ratio, train_dataset, test_dataset, mean, std, B_init_fMRI, cfg, model, device)\u001b[0m\n\u001b[1;32m    127\u001b[0m autoencoder_features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    129\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m--> 131\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moffline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_run\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_train_ratio_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtrain_ratio\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mOmegaConf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_container\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWandb init\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1429\u001b[0m, in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1426\u001b[0m wl: wandb_setup\u001b[38;5;241m.\u001b[39m_WandbSetup \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1429\u001b[0m     wl \u001b[38;5;241m=\u001b[39m \u001b[43mwandb_setup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_service\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1431\u001b[0m     wi \u001b[38;5;241m=\u001b[39m _WandbInit(wl, init_telemetry)\n\u001b[1;32m   1433\u001b[0m     wi\u001b[38;5;241m.\u001b[39mmaybe_login(init_settings)\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:318\u001b[0m, in \u001b[0;36m_setup\u001b[0;34m(settings, start_service)\u001b[0m\n\u001b[1;32m    316\u001b[0m     _singleton\u001b[38;5;241m.\u001b[39m_update(settings\u001b[38;5;241m=\u001b[39msettings)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     _singleton \u001b[38;5;241m=\u001b[39m \u001b[43m_WandbSetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_service \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _singleton\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_noop:\n\u001b[1;32m    321\u001b[0m     _singleton\u001b[38;5;241m.\u001b[39mensure_service()\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:96\u001b[0m, in \u001b[0;36m_WandbSetup.__init__\u001b[0;34m(self, pid, settings, environ)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# TODO(jhr): defer strict checks until settings are fully initialized\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m#            and logging is ready\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger: Logger \u001b[38;5;241m=\u001b[39m _EarlyLogger()\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m wandb\u001b[38;5;241m.\u001b[39mtermsetup(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check()\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:130\u001b[0m, in \u001b[0;36m_WandbSetup._settings_setup\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    127\u001b[0m s\u001b[38;5;241m.\u001b[39mupdate_from_env_vars(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_environ)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# infer settings from the system environment\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_from_system_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# load SageMaker settings\u001b[39;00m\n\u001b[1;32m    133\u001b[0m check_sagemaker_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m s\u001b[38;5;241m.\u001b[39msagemaker_disable\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/wandb/sdk/wandb_settings.py:1339\u001b[0m, in \u001b[0;36mSettings.update_from_system_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;66;03m# Attempt to get notebook information if not already set by the user\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jupyter \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1339\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjupyter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotebook_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_jupyter_path \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_jupyter_name \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/wandb/jupyter.py:212\u001b[0m, in \u001b[0;36mnotebook_metadata\u001b[0;34m(silent)\u001b[0m\n\u001b[1;32m    207\u001b[0m error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to detect the name of this notebook, you can set it manually with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe WANDB_NOTEBOOK_NAME environment variable to enable code saving.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m     jupyter_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mnotebook_metadata_from_jupyter_servers_and_kernel_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# Colab:\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# request the most recent contents\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     ipynb \u001b[38;5;241m=\u001b[39m attempt_colab_load_ipynb()\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/wandb/jupyter.py:165\u001b[0m, in \u001b[0;36mnotebook_metadata_from_jupyter_servers_and_kernel_id\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt query password protected kernel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43murljoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapi/sessions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nn \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nn, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebook\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nn:\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/python/neuro/lib/python3.11/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/apps/eb/el8/2023a/skylake/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/apps/eb/el8/2023a/skylake/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/apps/eb/el8/2023a/skylake/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/apps/eb/el8/2023a/skylake/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(cfg=cfg):\n",
    "\n",
    "    results_dir = os.path.join(cfg.output_dir, cfg.experiment_name)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    random_state = np.random.RandomState(seed=42)\n",
    "\n",
    "    dataset_path = cfg.dataset_path\n",
    "\n",
    "    if isinstance(cfg.targets, str):\n",
    "        \n",
    "        targets =[cfg.targets]\n",
    "    else:\n",
    "        targets = list(cfg.targets)\n",
    "        \n",
    "    test_ratio = cfg.test_ratio\n",
    "\n",
    "    dataset = MatData(dataset_path, targets, synth_exp = cfg.synth_exp, standardize_target=cfg.standardize_target, threshold=cfg.mat_threshold)\n",
    "    n_sub = len(dataset)\n",
    "    test_size = int(test_ratio * n_sub)\n",
    "    indices = np.arange(n_sub)\n",
    "    n_runs = cfg.n_runs\n",
    "    multi_gpu = False\n",
    "    train_ratios = list(cfg.train_ratio)\n",
    "    \n",
    "    multi_gpu = False\n",
    "    if multi_gpu:\n",
    "        print(\"Using multi-gpu\")\n",
    "        log_folder = Path(\"logs\")\n",
    "        executor = submitit.AutoExecutor(folder=str(log_folder / \"%j\"))\n",
    "        executor.update_parameters(\n",
    "            timeout_min=120,\n",
    "            slurm_partition=\"gpu_short\",\n",
    "            gpus_per_node=1,\n",
    "            tasks_per_node=1,\n",
    "            nodes=1\n",
    "            #slurm_constraint=\"v100-32g\",\n",
    "        )\n",
    "        run_jobs = []\n",
    "\n",
    "        with executor.batch():\n",
    "            for train_ratio in tqdm(train_ratios, desc=\"Training Size\"):\n",
    "                train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "                run_size = test_size + train_size\n",
    "                for run in tqdm(range(n_runs)):\n",
    "                    run_model = ModelRun()\n",
    "                    job = executor.submit(run_model,\n",
    "                                          train, test_size,\n",
    "                                          indices,\n",
    "                                          train_ratio,\n",
    "                                          run_size, run,\n",
    "                                          dataset,\n",
    "                                          cfg,\n",
    "                                          random_state=random_state, device=None)\n",
    "                    run_jobs.append(job)\n",
    "\n",
    "        async def get_result(run_jobs):\n",
    "            run_results = []\n",
    "            for aws in tqdm(asyncio.as_completed([j.awaitable().result() for j in run_jobs]), total=len(run_jobs)):\n",
    "                res = await aws\n",
    "                run_results.append(res)\n",
    "            return run_results\n",
    "        run_results = asyncio.run(get_result(run_jobs))\n",
    "\n",
    "    else:\n",
    "        run_results = []\n",
    "        for train_ratio in tqdm(train_ratios, desc=\"Training Size\"):\n",
    "            train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "            run_size = test_size + train_size\n",
    "            for run in tqdm(range(n_runs), desc=\"Model Run\"):\n",
    "                run_model = ModelRun()\n",
    "                job = run_model(train, test_size, indices, train_ratio, run_size, run, dataset, cfg, random_state=random_state, device=None)\n",
    "                run_results.append(job)\n",
    "\n",
    "    losses, predictions, embeddings = zip(*run_results)\n",
    "\n",
    "    prediction_metrics = predictions[0]\n",
    "    for prediction in predictions[1:]:\n",
    "        prediction_metrics.update(prediction)\n",
    "\n",
    "    pred_results = []\n",
    "    for k, v in prediction_metrics.items():\n",
    "        true_targets, predicted_targets, indices = v\n",
    "        \n",
    "        true_targets_dict = {\"train_ratio\": [k[0]] * len(true_targets),\n",
    "                             \"model_run\":[k[1]] * len(true_targets),\n",
    "                             \"dataset\":[k[2]] * len(true_targets)\n",
    "                            }\n",
    "        predicted_targets_dict = {\"indices\": indices}\n",
    "        \n",
    "        for i, target in enumerate(targets):\n",
    "            true_targets_dict[target] = true_targets[:, i]\n",
    "            predicted_targets_dict[f\"{target}_pred\"] = predicted_targets[:, i]\n",
    "            \n",
    "            \n",
    "        true_targets = pd.DataFrame(true_targets_dict)\n",
    "        predicted_targets = pd.DataFrame(predicted_targets_dict)\n",
    "        \n",
    "        pred_results.append(pd.concat([true_targets, predicted_targets], axis = 1))\n",
    "    pred_results = pd.concat(pred_results)\n",
    "    pred_results.to_csv(f\"{results_dir}/pred_results.csv\", index=False)\n",
    "\n",
    "    prediction_mape_by_element = []\n",
    "    for k, v in prediction_metrics.items():\n",
    "        true_targets, predicted_targets, indices = v\n",
    "        \n",
    "        mape_by_element = np.abs(true_targets - predicted_targets) / (np.abs(true_targets)+1e-10)\n",
    "        \n",
    "        for i, mape in enumerate(mape_by_element):\n",
    "            prediction_mape_by_element.append(\n",
    "                {\n",
    "                    'train_ratio': k[0],\n",
    "                    'model_run': k[1],\n",
    "                    'dataset': k[2],\n",
    "                    'mape': mape\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(prediction_mape_by_element)\n",
    "    df = pd.concat([df.drop('mape', axis=1), df['mape'].apply(pd.Series)], axis=1)\n",
    "    df.columns = ['train_ratio', 'model_run', 'dataset'] + targets\n",
    "    df= df.groupby(['train_ratio', 'model_run', 'dataset']).agg('mean').reset_index()\n",
    "    df.to_csv(f\"{results_dir}/mape.csv\", index = False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
