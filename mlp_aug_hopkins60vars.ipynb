{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from cmath import isinf\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "# from torchvision import transforms\n",
    "# from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "from utils_v import compute_target_score, estimate_target, save_model, standardize_dataset\n",
    "from cmath import isinf\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split, KFold, LearningCurveDisplay, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "from helper_classes import MatData, MLP\n",
    "from dev_losses import cauchy, rbf, gaussian_kernel, CustomSupCon, CustomContrastiveLoss\n",
    "from losses import KernelizedSupCon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise: mean & std of nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "features  = np.load(\"vectorized_matrices_la5c.npy\")\n",
    "n_neighbors = 10\n",
    "nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1).fit(features)\n",
    "distances, indices = nbrs.kneighbors(features)\n",
    "\n",
    "# Calculate the std of the nearest neighbors for each sample, excluding the point itself\n",
    "std_neighbors = np.array([np.std(features[indices[i, 1:]], axis=0) for i in range(features.shape[0])]).mean(axis = 1)\n",
    "mean_neighbors = np.array([np.mean(features[indices[i, 1:]], axis=0) for i in range(features.shape[0])]).mean(axis = 1)\n",
    "\n",
    "\n",
    "# Calculate the mean std of neighbors as your Gaussian noise std\n",
    "mean_std = np.mean(std_neighbors)\n",
    "median_std = np.median(std_neighbors)\n",
    "\n",
    "mean_of_means = np.mean(mean_neighbors)\n",
    "median_of_means = np.median(mean_neighbors)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot for Standard Deviations\n",
    "axs[0].hist(std_neighbors, bins=30, alpha=0.75, color='blue')\n",
    "axs[0].axvline(mean_std, color='r', linestyle='dashed', linewidth=1, label=f'Mean: {mean_std:.2f}')\n",
    "axs[0].axvline(median_std, color='g', linestyle='dashed', linewidth=1, label=f'Median: {median_std:.2f}')\n",
    "axs[0].set_title(f'Distribution of Standard Deviations for {n_neighbors} neighbors')\n",
    "axs[0].set_xlabel('Standard Deviation')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for Means\n",
    "axs[1].hist(mean_neighbors, bins=30, alpha=0.75, color='orange')\n",
    "axs[1].axvline(mean_of_means, color='r', linestyle='dashed', linewidth=1, label=f'Mean: {mean_of_means:.2f}')\n",
    "axs[1].axvline(median_of_means, color='g', linestyle='dashed', linewidth=1, label=f'Median: {median_of_means:.2f}')\n",
    "axs[1].set_title(f'Distribution of Means for {n_neighbors} neighbors')\n",
    "axs[1].set_xlabel('Mean')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guassian Noise Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugGaussianNoise(object):\n",
    "    def __init__(self, mean=0.16, std=0.18):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatData(Dataset):\n",
    "    def __init__(self, path_feat, path_target, transform = None, train=True, train_size = 0.8, test_size=None, random_state=42):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with the capability to handle training and testing splits, \n",
    "        including multiple views for augmented data.\n",
    "        \n",
    "        Args:\n",
    "            path_feat (str): Path to the features file.\n",
    "            path_target (str): Path to the target file.\n",
    "            transform (callable): A transformation function to apply for augmentation.\n",
    "            train (bool): Whether the dataset is used for training. False will load the test set.\n",
    "            test_size (float): Proportion of the dataset to include in the test split.\n",
    "            random_state (int): Random state for reproducible train-test splits.\n",
    "        \"\"\"\n",
    "        # Load the entire dataset\n",
    "        features = np.load(path_feat)\n",
    "        targets = np.load(path_target)\n",
    "\n",
    "        # Split the dataset into training and test sets\n",
    "        train_indices, test_indices = train_test_split(np.arange(len(features)), \n",
    "                                                       train_size = train_size,\n",
    "                                                       test_size=test_size,                \n",
    "                                                       random_state=random_state)\n",
    "        \n",
    "        if train:\n",
    "            selected_indices = train_indices\n",
    "        else:\n",
    "            selected_indices = test_indices\n",
    "        \n",
    "        # Select the subset of data for the current mode (train/test)\n",
    "        features = features[selected_indices]\n",
    "        features = torch.from_numpy(features).float()\n",
    "        targets = targets[selected_indices]\n",
    "        targets = torch.from_numpy(targets).float()\n",
    "        \n",
    "\n",
    "        self.n_sub = len(features)\n",
    "        self.n_features = features.shape[-1]\n",
    "        self.n_views = 1\n",
    "        self.transform = transform\n",
    "        self.targets = targets\n",
    "        \n",
    "        if train:\n",
    "            # augmentation only in training mode\n",
    "            augmented_features = self.transform(features)\n",
    "\n",
    "            if len(augmented_features.shape) < 3:\n",
    "                self.n_views = self.n_views + 1\n",
    "                augmented_features = augmented_features.unsqueeze(1)\n",
    "            else:\n",
    "                self.n_views = self.n_views + augmented_feature[0]\n",
    "            self.features = np.zeros((self.n_sub, self.n_views, self.n_features))\n",
    "            self.features[:, 0, :] = features\n",
    "            self.features[:, 1:, :] = augmented_features\n",
    "            self.features = torch.from_numpy(self.features).float()\n",
    "        else:\n",
    "            self.features = features\n",
    "                \n",
    "    def __len__(self):\n",
    "        return self.n_sub\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features[idx]\n",
    "        targets = self.targets[idx]\n",
    "        return features, targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise: Rank of covar matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_rank_of_covariance(X, n_neighbors=5):\n",
    "#     \"\"\"\n",
    "#     Compute the rank of the covariance matrix of nearest neighbors for each sample in X.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - X: numpy array of shape (n_samples, n_features), the dataset.\n",
    "#     - n_neighbors: int, the number of nearest neighbors to consider.\n",
    "    \n",
    "#     Returns:\n",
    "#     - ranks: numpy array of shape (n_samples,), the rank of the covariance matrix for each sample.\n",
    "#     \"\"\"\n",
    "#     nbrs = NearestNeighbors(n_neighbors=n_neighbors+1, algorithm='auto').fit(X)\n",
    "#     _, indices = nbrs.kneighbors(X)\n",
    "    \n",
    "#     ranks = np.zeros(X.shape[0])\n",
    "    \n",
    "#     for i in range(X.shape[0]):\n",
    "#         # Extract the nearest neighbors for the current sample, excluding the sample itself\n",
    "#         neighbors = X[indices[i, 1:]]  # Skip the first neighbor (the point itself)\n",
    "        \n",
    "#         # Compute the covariance matrix of the neighbors\n",
    "#         cov_matrix = np.cov(neighbors, rowvar=False)\n",
    "        \n",
    "#         # Compute the rank of the covariance matrix\n",
    "#         ranks[i] = np.linalg.matrix_rank(cov_matrix)\n",
    "    \n",
    "#     return ranks\n",
    "\n",
    "\n",
    "# ranks = compute_rank_of_covariance(features, n_neighbors=5)\n",
    "# plt.hist(ranks, bins=np.arange(ranks.min(), ranks.max()+1), alpha=0.75, color='green')\n",
    "# plt.title('Distribution of Covariance Matrix Ranks Among Nearest Neighbors')\n",
    "# plt.xlabel('Rank')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = AugGaussianNoise(mean=0.16, std=0.15)\n",
    "# test_dataset = MatData(\"vectorized_matrices_la5c.npy\", \"hopkins_age.npy\", train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelizedSupCon(nn.Module):\n",
    "    \"\"\"Supervised contrastive loss: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\n",
    "    Based on: https://github.com/HobbitLong/SupContrast\"\"\"\n",
    "    def __init__(self, method: str, krnl_sigma = None, temperature: float=0.07, contrast_mode: str='all',\n",
    "                 base_temperature: float=0.07, kernel: callable=None, delta_reduction: str='sum'):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "        self.method = method\n",
    "        self.kernel = kernel\n",
    "        self.delta_reduction = delta_reduction\n",
    "        self.krnl_sigma = krnl_sigma\n",
    "\n",
    "        if kernel is not None and method == 'supcon':\n",
    "            raise ValueError('Kernel must be none if method=supcon')\n",
    "        \n",
    "        if kernel is None and method != 'supcon':\n",
    "            raise ValueError('Kernel must not be none if method != supcon')\n",
    "\n",
    "        if delta_reduction not in ['mean', 'sum']:\n",
    "            raise ValueError(f\"Invalid reduction {delta_reduction}\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__} ' \\\n",
    "               f'(t={self.temperature}, ' \\\n",
    "               f'method={self.method}, ' \\\n",
    "               f'kernel={self.kernel is not None}, ' \\\n",
    "               f'delta_reduction={self.delta_reduction}, ' \\\n",
    "               f'krnl_sigma={self.krnl_sigma}'\n",
    "                \n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        \"\"\"Compute loss for model. If `labels` is None, \n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, n_features]. \n",
    "                input has to be rearranged to [bsz, n_views, n_features] and labels [bsz],\n",
    "            labels: ground truth of shape [bsz].\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "\n",
    "        if len(features.shape) != 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, n_feats],'\n",
    "                             '3 dimensions are required')\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        n_views = features.shape[1]\n",
    "\n",
    "        if labels is None:\n",
    "            mask = torch.eye(batch_size, device=device)\n",
    "        \n",
    "        else:\n",
    "            # labels = labels.view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError(f'Num of labels does not match num of features: {labels.shape[0]} vs. {batch_size}')\n",
    "            \n",
    "            if self.kernel is None:\n",
    "                mask = torch.eq(labels, labels.T)\n",
    "            else:\n",
    "                mask = self.kernel(labels, self.krnl_sigma)\n",
    "            \n",
    "        view_count = features.shape[1]\n",
    "        features = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            features = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            features = features\n",
    "            anchor_count = view_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # Tile mask\n",
    "        mask = mask.repeat(anchor_count, view_count)\n",
    "\n",
    "        # Inverse of torch-eye to remove self-contrast (diagonal)\n",
    "        inv_diagonal = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size*n_views, device=device).view(-1, 1),\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # compute similarity\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(features, features.T),\n",
    "            self.temperature\n",
    "        )\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "        alignment = logits \n",
    "\n",
    "        # base case is:\n",
    "        # - supcon if kernel = none \n",
    "        # - y-aware is kernel != none\n",
    "        uniformity = torch.exp(logits) * inv_diagonal\n",
    "\n",
    "        if self.method == 'threshold':\n",
    "            repeated = mask.unsqueeze(-1).repeat(1, 1, mask.shape[0]) # repeat kernel mask\n",
    "\n",
    "            delta = (mask[:, None].T - repeated.T).transpose(1, 2) # compute the difference w_k - w_j for every k,j\n",
    "            delta = (delta > 0.).float()\n",
    "\n",
    "            # for each z_i, repel only samples j s.t. K(z_i, z_j) < K(z_i, z_k)\n",
    "            uniformity = uniformity.unsqueeze(-1).repeat(1, 1, mask.shape[0])\n",
    "            \n",
    "            \n",
    "            if self.delta_reduction == 'mean':\n",
    "                uniformity = (uniformity * delta).mean(-1)\n",
    "            else:\n",
    "                uniformity = (uniformity * delta).sum(-1)\n",
    "                \n",
    "        elif self.method == 'expw':\n",
    "            # exp weight e^(s_j(1-w_j))\n",
    "            uniformity = torch.exp(logits * (1 - mask)) * inv_diagonal\n",
    "\n",
    "        uniformity = torch.log(uniformity.sum(1, keepdim=True))\n",
    "        # positive mask contains the anchor-positive pairs\n",
    "        # excluding <self,self> on the diagonal\n",
    "        positive_mask = mask * inv_diagonal\n",
    "\n",
    "        log_prob = alignment - uniformity # log(alignment/uniformity) = log(alignment) - log(uniformity)\n",
    "        log_prob = (positive_mask * log_prob).sum(1) / positive_mask.sum(1) # compute mean of log-likelihood over positive\n",
    " \n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * log_prob\n",
    "        return loss.mean()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim_feat = 499500 # vectorized mat, diagonal discarded\n",
    "# input_dim_target = 59\n",
    "# # the rest is arbitrary\n",
    "# hidden_dim_feat_1 = 1024\n",
    "# hidden_dim_feat_2 = 512\n",
    "# hidden_dim_target_1 = 24\n",
    "# hidden_dim_target_2 = 8\n",
    "# output_dim = 2\n",
    "# num_epochs = 1000\n",
    "\n",
    "input_dim_feat = 499500 # vectorized mat, diagonal discarded\n",
    "input_dim_target = 60\n",
    "# the rest is arbitrary\n",
    "hidden_dim_feat = 1000\n",
    "hidden_dim_target = 30\n",
    "output_dim = 2\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "lr = 0.001 # too low values return nan loss\n",
    "kernel = gaussian_kernel\n",
    "batch_size = 5 # too low values return nan loss\n",
    "dropout_rate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, krnl_sigma):\n",
    "    kernelized = []\n",
    "    for var in x.T:\n",
    "        krnl_var = var.unsqueeze(-1).T - var.unsqueeze(-1)\n",
    "        kernelized.append(krnl_var)\n",
    "    kernelized = sum([krnl_var**2 for krnl_var in kernelized])\n",
    "    return torch.exp(-kernelized / (2*(krnl_sigma**2))) / (math.sqrt(krnl_sigma*torch.pi)*krnl_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dataset(dataset):\n",
    "    # Flatten the dataset across subjects and views to simplify standardization across features\n",
    "    all_features_flat = torch.cat([dataset[i][0].view(-1, dataset[i][0].shape[-1]) for i in range(len(dataset))], dim=0)\n",
    "    all_targets = torch.cat([dataset[i][1].unsqueeze(0) for i in range(len(dataset))], dim=0)\n",
    "    \n",
    "    # Calculate mean and std dev for each feature across all subjects and views\n",
    "    features_mean = all_features_flat.mean(dim=0)\n",
    "    features_std = all_features_flat.std(dim=0)\n",
    "    \n",
    "    # Ensure no division by zero\n",
    "    features_std[features_std == 0] = 1\n",
    "    \n",
    "    # Initialize containers for standardized features\n",
    "    standardized_features_list = []\n",
    "    \n",
    "    # Apply standardization to each sample\n",
    "    for i in range(len(dataset)):\n",
    "        features = dataset[i][0].view(-1, dataset[i][0].shape[-1])  # Flatten views for standardization\n",
    "        # Standardize\n",
    "        standardized_features = (features - features_mean) / features_std\n",
    "        # Reshape back to original [n_views, n_feat] and store\n",
    "        standardized_features_list.append(standardized_features.view(dataset[i][0].shape))\n",
    "    \n",
    "    # Stack standardized features to match original dataset structure [n_sub, n_views, n_feat]\n",
    "    standardized_features = torch.stack(standardized_features_list)\n",
    "    \n",
    "    # Targets don't change structure, so we just use the original targets here\n",
    "    standardized_dataset = TensorDataset(standardized_features, all_targets)\n",
    "    \n",
    "    return standardized_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MatData(\"vectorized_matrices_la5c.npy\", \"hopkins_covars.npy\", train=True, train_size = 15,transform=aug)\n",
    "test_dataset = MatData(\"vectorized_matrices_la5c.npy\", \"hopkins_covars.npy\",test_size = 5, train=False)\n",
    "\n",
    "standardized_train_dataset = standardize_dataset(train_dataset)\n",
    "std_train_loader = DataLoader(standardized_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "standardized_test_dataset = standardize_dataset(test_dataset)\n",
    "std_test_loader = DataLoader(standardized_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Mean Loss 144.02464040120444\n",
      "Epoch 1 | Mean Loss 141.02452596028647\n",
      "Epoch 2 | Mean Loss 111.45223744710286\n",
      "Epoch 3 | Mean Loss 123.26609802246094\n",
      "Epoch 4 | Mean Loss 103.52383931477864\n",
      "Epoch 5 | Mean Loss 47.42347208658854\n",
      "Epoch 6 | Mean Loss 39.88684972127279\n",
      "Epoch 7 | Mean Loss 31.696186701456707\n",
      "Epoch 8 | Mean Loss 25.059825897216797\n",
      "Epoch 9 | Mean Loss 27.2372891108195\n",
      "Epoch 10 | Mean Loss 16.101516723632812\n",
      "Epoch 11 | Mean Loss 14.147429784138998\n",
      "Epoch 12 | Mean Loss 19.786001205444336\n",
      "Epoch 13 | Mean Loss 13.221532503763834\n",
      "Epoch 14 | Mean Loss 7.995614687601726\n",
      "Epoch 15 | Mean Loss 9.749869664510092\n",
      "Epoch 16 | Mean Loss 13.29816977183024\n",
      "Epoch 17 | Mean Loss 7.502921899159749\n",
      "Epoch 18 | Mean Loss 7.798559029897054\n",
      "Epoch 19 | Mean Loss 8.063296635945639\n",
      "Epoch 20 | Mean Loss 8.533267339070639\n",
      "Epoch 21 | Mean Loss 7.735104878743489\n",
      "Epoch 22 | Mean Loss 7.008580048878987\n",
      "Epoch 23 | Mean Loss 5.54757301012675\n",
      "Epoch 24 | Mean Loss 5.3606077035268145\n",
      "Epoch 25 | Mean Loss 5.555595397949219\n",
      "Epoch 26 | Mean Loss 5.640610535939534\n",
      "Epoch 27 | Mean Loss 6.867994944254558\n",
      "Epoch 28 | Mean Loss 8.476945559183756\n",
      "Epoch 29 | Mean Loss 6.265928904215495\n",
      "Epoch 30 | Mean Loss 4.788191715876262\n",
      "Epoch 31 | Mean Loss 5.345766385396321\n",
      "Epoch 32 | Mean Loss 4.157696882883708\n",
      "Epoch 33 | Mean Loss 4.986058870951335\n",
      "Epoch 34 | Mean Loss 5.0175074736277265\n",
      "Epoch 35 | Mean Loss 6.17580000559489\n",
      "Epoch 36 | Mean Loss 4.017263889312744\n",
      "Epoch 37 | Mean Loss 4.886558771133423\n",
      "Epoch 38 | Mean Loss 4.30262811978658\n",
      "Epoch 39 | Mean Loss 4.007925669352214\n",
      "Epoch 40 | Mean Loss 4.097587585449219\n",
      "Epoch 41 | Mean Loss 3.883141279220581\n",
      "Epoch 42 | Mean Loss 4.228406508763631\n",
      "Epoch 43 | Mean Loss 4.003991365432739\n",
      "Epoch 44 | Mean Loss 3.8574001789093018\n",
      "Epoch 45 | Mean Loss 4.28735629717509\n",
      "Epoch 46 | Mean Loss 4.148826440175374\n",
      "Epoch 47 | Mean Loss 4.48740800221761\n",
      "Epoch 48 | Mean Loss 3.728292147318522\n",
      "Epoch 49 | Mean Loss 4.103092034657796\n",
      "Epoch 50 | Mean Loss 4.190144697825114\n",
      "Epoch 51 | Mean Loss 4.028828144073486\n",
      "Epoch 52 | Mean Loss 4.290896892547607\n",
      "Epoch 53 | Mean Loss 4.143089771270752\n",
      "Epoch 54 | Mean Loss 4.108186403910319\n",
      "Epoch 55 | Mean Loss 4.252799431482951\n",
      "Epoch 56 | Mean Loss 4.043404817581177\n",
      "Epoch 57 | Mean Loss 3.8627373377482095\n",
      "Epoch 58 | Mean Loss 4.124408006668091\n",
      "Epoch 59 | Mean Loss 4.811049620310466\n",
      "Epoch 60 | Mean Loss 3.7578066190083823\n",
      "Epoch 61 | Mean Loss 4.910266399383545\n",
      "Epoch 62 | Mean Loss 4.278809150060018\n",
      "Epoch 63 | Mean Loss 3.8180293242136636\n",
      "Epoch 64 | Mean Loss 8.623040596644083\n",
      "Epoch 65 | Mean Loss 3.864931583404541\n",
      "Epoch 66 | Mean Loss 3.9826658566792807\n",
      "Epoch 67 | Mean Loss 4.116428057352702\n",
      "Epoch 68 | Mean Loss 4.232818524042766\n",
      "Epoch 69 | Mean Loss 3.7396369775136313\n",
      "Epoch 70 | Mean Loss 4.212220589319865\n",
      "Epoch 71 | Mean Loss 3.534106890360514\n",
      "Epoch 72 | Mean Loss 4.058208703994751\n",
      "Epoch 73 | Mean Loss 3.5020251274108887\n",
      "Epoch 74 | Mean Loss 4.270001252492269\n",
      "Epoch 75 | Mean Loss 5.077180862426758\n",
      "Epoch 76 | Mean Loss 4.291413466135661\n",
      "Epoch 77 | Mean Loss 3.7023606300354004\n",
      "Epoch 78 | Mean Loss 5.170149803161621\n",
      "Epoch 79 | Mean Loss 4.206456979115804\n",
      "Epoch 80 | Mean Loss 5.625066916147868\n",
      "Epoch 81 | Mean Loss 4.514498869578044\n",
      "Epoch 82 | Mean Loss 6.27179217338562\n",
      "Epoch 83 | Mean Loss 3.7716643810272217\n",
      "Epoch 84 | Mean Loss 4.833138783772786\n",
      "Epoch 85 | Mean Loss 3.822839339574178\n",
      "Epoch 86 | Mean Loss 4.217154026031494\n",
      "Epoch 87 | Mean Loss 3.8711841901143393\n",
      "Epoch 88 | Mean Loss 3.98553737004598\n",
      "Epoch 89 | Mean Loss 3.6916948159535727\n",
      "Epoch 90 | Mean Loss 3.9822888374328613\n",
      "Epoch 91 | Mean Loss 3.890583038330078\n",
      "Epoch 92 | Mean Loss 3.90466316541036\n",
      "Epoch 93 | Mean Loss 4.031428496042888\n",
      "Epoch 94 | Mean Loss 3.8827709356943765\n",
      "Epoch 95 | Mean Loss 4.698242823282878\n",
      "Epoch 96 | Mean Loss 3.677041530609131\n",
      "Epoch 97 | Mean Loss 4.897054036458333\n",
      "Epoch 98 | Mean Loss 4.1067062218983965\n",
      "Epoch 99 | Mean Loss 3.7632691065470376\n",
      "Training target estimator\n",
      "Training target estimator\n",
      "6.922076 1.5902571418036082e-06\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "model = MLP(input_dim_feat, input_dim_target, hidden_dim_feat, hidden_dim_target, output_dim, dropout_rate = 0).to(device)\n",
    "criterion_pft = KernelizedSupCon(method='expw', temperature=0.01, base_temperature=0.01, kernel=kernel, krnl_sigma = 1)\n",
    "criterion_ptt = KernelizedSupCon(method='expw', temperature=0.01, base_temperature=0.01, kernel=kernel, krnl_sigma = 1)\n",
    "\n",
    "# criterion = CustomKernelizedSupCon(temperature = temperature, base_temperature = base_temperature, kernel = kernel)\n",
    "# criterion = CustomSupCon('exp',temperature = temperature, base_temperature = base_temperature, kernel = kernel)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batch_losses = []\n",
    "    for batch_num, (features, targets) in enumerate(std_train_loader):\n",
    "        bsz = targets.shape[0]\n",
    "        n_views = features.shape[1]\n",
    "        n_feat = features.shape[-1]\n",
    "        \n",
    "        features = features.view(bsz * n_views, n_feat) # [bsz*2, 499500]\n",
    "        features, targets = features.to(device), targets.to(device) # [bsz, 2, 499500], [bsz, 60]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out_feat, out_target = model(features, torch.cat([targets, targets], dim=0)) # ([bsz*2, 2], [bsz*2, 60])\n",
    "        \n",
    "        out_feat = torch.split(out_feat, [bsz]*n_views, dim=0)\n",
    "        out_feat = torch.cat([f.unsqueeze(1) for f in out_feat], dim=1) # [bsz, 2, 2]\n",
    "        \n",
    "        loss = criterion_pft(out_feat, targets) # ([bsz, 2, 2], [bsz, 60])\n",
    "        \n",
    "        out_target = torch.split(out_target, [bsz]*n_views, dim=0)\n",
    "        out_target = torch.cat([f.unsqueeze(1) for f in out_target], dim=1) # [bsz, 2, 2]\n",
    "        \n",
    "        loss += criterion_ptt(out_target, targets) # ([bsz, 2, 2], [bsz, 60])\n",
    "        loss += torch.nn.functional.mse_loss(out_feat.view(bsz * n_views, 2), out_target.view(bsz * n_views, 2)) # mse_loss([bsz*2, 2], [bsz*2, 2])\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        batch_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch} | Mean Loss {sum(batch_losses)/len(batch_losses)}')\n",
    "\n",
    "\n",
    "mape_train, _ = compute_target_score(model, std_train_loader, std_test_loader, device, 'mape')\n",
    "r2_train, _ = compute_target_score(model, std_train_loader, std_test_loader, device, 'r2')\n",
    "# results_cv.append(['Overall', mape_train, r2_train, mape_val, r2_val])\n",
    "print(mape_train, r2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(results_cv, columns=['Fold', 'Train_MAPE', 'Train_R2', 'Val_MAPE', 'Val_R2'])\n",
    "# results_df.to_csv('cv_results_hopkins.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "# features = torch.vstack([test_dataset[i][0] for i in range(len(test_loader))])\n",
    "# targets = torch.vstack([test_dataset[i][1] for i in range(len(test_loader))])\n",
    "# features_mean, features_std, targets_mean, targets_std = compute_global_stats(test_dataset)\n",
    "# standardized_features = (features - features_mean) / features_std\n",
    "# standardized_targets = (targets - targets_mean) / targets_std\n",
    "# standardized_test_dataset = TensorDataset(standardized_features, standardized_targets)\n",
    "# test_loader = DataLoader(standardized_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 2]) torch.Size([5, 2, 2])\n",
      "torch.Size([5, 2, 2]) torch.Size([5, 2, 2])\n",
      "torch.Size([5, 2, 2]) torch.Size([5, 2, 2])\n",
      "Mean Test Loss:   3.66\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_losses = []\n",
    "emb_features = [] # saving the embedded features for each batch\n",
    "emb_targets = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    for batch_num, (features, targets) in enumerate(std_train_loader):\n",
    "        \n",
    "        if len(features.shape) > 2:\n",
    "            bsz = features.shape[0]\n",
    "            n_views =  features.shape[1]\n",
    "            n_feat =  features.shape[-1]\n",
    "            features = features.view(bsz * n_views, n_feat)\n",
    "            in_targets = torch.cat([targets, targets], dim=0)\n",
    "        else:\n",
    "            in_targets = targets\n",
    "        features = features.to(device).float()\n",
    "        in_targets = in_targets.to(device)\n",
    "\n",
    "        out_feat, out_target = model(features,in_targets)\n",
    "        \n",
    "        if out_feat.shape[0] > batch_size: \n",
    "            out_feat = torch.split(out_feat, [bsz]*n_views, dim=0)\n",
    "            out_feat = torch.cat([f.unsqueeze(1) for f in out_feat], dim=1)\n",
    "            \n",
    "            out_target = torch.split(out_target, [bsz]*n_views, dim=0)\n",
    "            out_target = torch.cat([f.unsqueeze(1) for f in out_target], dim=1)\n",
    "            print(out_feat.shape, out_target.shape)\n",
    "        else:\n",
    "            out_feat = out_feat.unsqueeze(1)\n",
    "            out_target = out_target.unsqueeze(1)\n",
    "        \n",
    "        loss = criterion_pft(out_feat, targets)\n",
    "        loss += criterion_ptt(out_target, targets)\n",
    "        loss += torch.nn.functional.mse_loss(out_feat[:, 0, :], out_target[:, 0, :])\n",
    "        \n",
    "        emb_features.append(out_feat[:, 0, :])\n",
    "        emb_targets.append(out_target[:, 0, :])\n",
    "        \n",
    "        test_losses.append(loss.item())\n",
    "        total_loss += loss.item() * features.size(0)\n",
    "        total_samples += features.size(0)\n",
    "        \n",
    "    test_losses =np.array(test_losses)\n",
    "    average_loss = total_loss / total_samples\n",
    "    print('Mean Test Loss: %6.2f' % (average_loss))\n",
    "    #np.save(f\"losses/test_losses_batch{batch_num}.npy\", test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_features = torch.row_stack(emb_features).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_targets = torch.row_stack(emb_targets).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_features = pd.DataFrame(emb_features,columns = [\"Dim_1\", \"Dim_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_targets = pd.DataFrame(emb_targets,columns = [\"Dim_1\", \"Dim_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_features[\"sub\"] = np.arange(1, len(emb_features) +1)\n",
    "emb_targets[\"sub\"] = np.arange(1, len(emb_targets) +1)\n",
    "emb_features[\"Type\"] = 'Features'\n",
    "emb_targets[\"Type\"] = 'Targets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f721c1c2520>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# time to cry\n",
    "# I probably messed up the original loss. Went over it multiple times\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "sns.scatterplot(emb_features, x = 'Dim_1', y = 'Dim_2', s = 100, alpha = 0.8, hue = 'sub', palette = 'nipy_spectral', label='Features')\n",
    "sns.scatterplot(emb_targets, x = 'Dim_1', marker = 'v', y = 'Dim_2', s = 100, alpha = 0.8, hue = 'sub', palette = 'nipy_spectral', label='Targets')\n",
    "plt.xlim(-1.2, 1.2)\n",
    "plt.ylim(-1.2, 1.2)\n",
    "\n",
    "feature_handle = mlines.Line2D([], [], color='black', marker='o', linestyle='None', markersize=10, label='Features')\n",
    "target_handle = mlines.Line2D([], [], color='black', marker='v', linestyle='None', markersize=10, label='Targets')\n",
    "\n",
    "plt.legend(handles=[feature_handle, target_handle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
