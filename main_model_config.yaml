project: "PhenProjCBCL | AEs Pretrained"
experiment_name: "main_model_train_ratio1.0"
hypothesis: "-"

# Model dimensions
input_dim_feat: 400
output_dim_feat: 50
hidden_dim: 1000
input_dim_target: 1
output_dim_target: 2

# MatAutoencoder options
skip_enc1: True
ReEig: False

# Pretrained models options
mat_ae_pretrained: True
target_ae_pretrained: True
pretrained_mat_ae_exp: "mat_ae_abcd"
pretrained_target_ae_exp: "out2_target_ae"
best_mat_ae_fold: 3
best_target_ae_fold: 1

# Training parameters
multi_gpu: True
num_epochs: 100
batch_size: 32
n_runs: 1 # set 1 if some part of the model is pretrained (the test set should be the same)
lr: 0.01
weight_decay: 0
dropout_rate: 0
scheduler_patience: 10
test_ratio: 0.2 # makes no difference if some part of the model is pretrained
train_ratio: 1.0

# Contrastive loss parameters
SupCon_kernel: cauchy

## feature proj vs. targets
pft_base_temperature: 10
pft_temperature: 10
pft_sigma: 50

## target proj vs. targets
ptt_base_temperature: 0.07
ptt_temperature: 0.07
ptt_sigma: 1

# Other losses
feature_autoencoder_crit: Norm  # Options: Norm, MSE, LogEuclidean
joint_embedding_crit: cosine  # Options: Norm, MSE, cosine
target_decoding_crit: MSE  # Options: Norm, MSE
target_decoding_from_reduced_emb_crit: MSE # Options: Norm, MSE

augmentation: None
mat_threshold: 0
# Paths for data
dataset_path: "/gpfs3/well/margulies/users/cpy397/contrastive-learning/ABCD/abcd_dataset_400parcels.nc"
targets:
    - cbcl_scr_syn_totprob_r

# Directory for saving results
work_dir: "/gpfs3/well/margulies/users/cpy397/contrastive-learning"
reconstructed_dir : recon_mat
model_weight_dir : saved_models
output_dir: "/gpfs3/well/margulies/users/cpy397/contrastive-learning/results"