{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "from scipy.stats import pearsonr\n",
    "from cmath import isinf\n",
    "import torch.nn.functional as F\n",
    "#import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "from cmath import isinf\n",
    "from utils_v import compute_target_score\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split, KFold, LearningCurveDisplay, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "from helper_classes import MatData, MLP\n",
    "#from dev_losses import cauchy, rbf, gaussian_kernel, CustomSupCon, CustomContrastiveLoss\n",
    "#from losses import KernelizedSupCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_kernel(d, sigma : float,):\n",
    "    \n",
    "    exponent = -0.5 *(d/sigma)  \n",
    "    exp = torch.exp(exponent)\n",
    "    \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(features, threshold, regions=None):\n",
    "    threshold = np.quantile(features, threshold)\n",
    "    features_thresholded = np.where(np.abs(features) > threshold, 0, features)\n",
    "    norm = np.linalg.norm(features_thresholded)\n",
    "    normalized_features = features_thresholded / norm if norm != 0 else features_thresholded\n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_matrix = \"/data/parietal/store/work/dwassermann/data/victoria_mat_age/matrices.npy\"\n",
    "matrix = np.load(path_matrix)\n",
    "vec_m = sym_matrix_to_vec(matrix, discard_diagonal=True)\n",
    "vec_m_thresholded = threshold(vec_m ,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_augmentation_wrt_original(matrix, augmented_matrix, sigma=100000):\n",
    "    \n",
    "    matrix = torch.tensor(matrix)\n",
    "    augmented_matrix = torch.tensor(augmented_matrix)\n",
    "    \n",
    "    #compute the average value of the kernel of original samples and their augmented counterpart\n",
    "    augmented_dist = torch.cdist(augmented_matrix, matrix,p=2)**2\n",
    "    augmented_kernel = multivariate_kernel(augmented_dist, sigma)\n",
    "    avg_kernel_values_diag = torch.mean(torch.diag(augmented_kernel))\n",
    "    \n",
    "    #compute average value of original samples with respect to all other original samples \n",
    "    original_dist = torch.cdist(matrix, matrix, p=2)**2\n",
    "    original_kernel = multivariate_kernel(original_dist, sigma)\n",
    "    original_kernel = original_kernel.numpy()\n",
    "    avg_kernel_non_diag_values = np.mean(sym_matrix_to_vec(original_kernel, discard_diagonal=True))\n",
    "    \n",
    "    return avg_kernel_values_diag > avg_kernel_non_diag_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_augmentation_wrt_original(vec_m, vec_m_thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_augmentation_wrt_augmented(matrix, augmented_matrix, sigma=100000):\n",
    "    \n",
    "    matrix = torch.tensor(matrix)\n",
    "    augmented_matrix = torch.tensor(augmented_matrix)\n",
    "    \n",
    "    #compute the average value of the kernel of original samples and their augmented counterpart\n",
    "    augmented_dist = torch.cdist(augmented_matrix, matrix,p=2)**2\n",
    "    augmented_kernel = multivariate_kernel(augmented_dist, sigma)\n",
    "    avg_kernel_values_diag = torch.mean(torch.diag(augmented_kernel))\n",
    "    \n",
    "    #compute average kernel value of augmentations with respect to the other augmentations \n",
    "    augmented_kernel_eval = augmented_kernel.numpy()\n",
    "    avg_kernel_non_diag_values = np.mean(sym_matrix_to_vec(augmented_kernel_eval, discard_diagonal=True))\n",
    "    \n",
    "    return avg_kernel_values_diag > avg_kernel_non_diag_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_augmentation_wrt_augmented(vec_m, vec_m_thresholded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
