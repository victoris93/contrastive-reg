{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mind/mrenaudi/.local/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import asyncio\n",
    "import submitit\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "from augmentations import augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "torch.cuda.empty_cache()\n",
    "multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0\n",
    "AUGMENTATION = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_feat = \"/data/parietal/store/work/dwassermann/data/victoria_mat_age/matrices.npy\"\n",
    "path_target = \"/data/parietal/store/work/dwassermann/data/victoria_mat_age/data_mat_age_demian/participants.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim_feat, input_dim_target, hidden_dim_feats, output_dim, dropout_rate, lr, weight_decay):\n",
    "        \n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        self.feat_gcn = Seq_g('x, edge_index', [\n",
    "            (GCNConv(input_dim_feat, hidden_dim_feats), 'x, edge_index -> x'),\n",
    "            nn.ReLU(),\n",
    "            (GCNConv(hidden_dim_feats, hidden_dim_feats), 'x, edge_index -> x'),\n",
    "            nn.ReLU(),\n",
    "            (GCNConv(hidden_dim_feats, output_dim), 'x, edge_index -> x')\n",
    "        ])\n",
    "        #self.init_weights(self.feat_gcn)\n",
    "        \n",
    "        self.target_mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim_target),\n",
    "            nn.Linear(input_dim_target, hidden_dim_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(hidden_dim_feats, output_dim)\n",
    "        )\n",
    "        #self.init_weights(self.target_mlp)\n",
    "        \n",
    "        self.decode_target = nn.Sequential(\n",
    "            nn.Linear(output_dim, hidden_dim_feats),\n",
    "            nn.BatchNorm1d(hidden_dim_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim_feats, input_dim_target)\n",
    "        )\n",
    "        #self.init_weights(self.decode_target)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, GCNConv):\n",
    "            # GCNConv initializes its weights during initialization\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "                    \n",
    "\n",
    "    \n",
    "    def transform_feat(self, x, edge_index):\n",
    "        features = self.feat_gcn(x, edge_index)\n",
    "        pooling = global_mean_pool(features, batch=None)\n",
    "        pooling = nn.functional.normalize(features, p=2, dim=1)\n",
    "        return pooling\n",
    "    \n",
    "    def transform_targets(self, y):\n",
    "        targets = self.target_mlp(y)\n",
    "        targets = nn.functional.normalize(targets, p=2, dim=1)\n",
    "        return targets\n",
    " \n",
    "    def decode_targets(self, embedding):\n",
    "        return self.decode_target(embedding)\n",
    "\n",
    "        \n",
    "    def forward(self, x, y, edge_index):\n",
    "        x_embedding = self.transform_feat(x, edge_index)\n",
    "        y_embedding = self.transform_targets(y)\n",
    "        return x_embedding, y_embedding\n",
    "    \n",
    "    def initialize_optimizer(self, lr, weight_decay):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.dataset import Dataset as graph_dataset\n",
    "\n",
    "class GraphData(graph_dataset):\n",
    "    def __init__(self, matrices, target, target_name):\n",
    "        self.matrices = np.load(path_feat).astype(np.float32)[:15]\n",
    "        self.target = torch.tensor(\n",
    "            np.expand_dims(\n",
    "                pd.read_csv(path_target)[target_name].values, axis=1\n",
    "            )[:15],\n",
    "            dtype=torch.float32\n",
    "        )        \n",
    "        #self.edge_indices = edge_indices\n",
    "        self.indices = range(len(self.matrices))\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.matrices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features = self.matrices[idx]\n",
    "        targets = self.target[idx]   \n",
    "        edge_indices = torch.tensor(np.argwhere(matrix != 0).T, dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        return features, targets, edge_indices\n",
    "    \n",
    "        def index_select(self, idx):\n",
    "        # Convert idx to a list if it's not already one\n",
    "        if not isinstance(idx, list):\n",
    "            idx = list(idx)\n",
    "        \n",
    "        # Select the data corresponding to the specified indices\n",
    "        selected_matrices = self.matrices[idx]\n",
    "        selected_target = self.target[idx]\n",
    "        selected_indices = [self.indices[i] for i in idx]\n",
    "\n",
    "        # Create a new instance of the dataset with the selected data\n",
    "        selected_dataset = GraphData(selected_matrices, selected_target, self.target_name)\n",
    "        selected_dataset.indices = selected_indices\n",
    "\n",
    "        return selected_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelizedSupCon(nn.Module):\n",
    "    \"\"\"Supervised contrastive loss: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\n",
    "    Based on: https://github.com/HobbitLong/SupContrast\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        method: str,\n",
    "        temperature: float = 0.07,\n",
    "        contrast_mode: str = \"all\",\n",
    "        base_temperature: float = 0.07,\n",
    "        krnl_sigma: float = 1.0,\n",
    "        kernel: callable = None,\n",
    "        delta_reduction: str = \"sum\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "        self.method = method\n",
    "        self.kernel = kernel\n",
    "        self.krnl_sigma = krnl_sigma\n",
    "        self.delta_reduction = delta_reduction\n",
    "\n",
    "        if kernel is not None and method == \"supcon\":\n",
    "            raise ValueError(\"Kernel must be none if method=supcon\")\n",
    "\n",
    "        if kernel is None and method != \"supcon\":\n",
    "            raise ValueError(\"Kernel must not be none if method != supcon\")\n",
    "\n",
    "        if delta_reduction not in [\"mean\", \"sum\"]:\n",
    "            raise ValueError(f\"Invalid reduction {delta_reduction}\")\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"{self.__class__.__name__} \"\n",
    "            f\"(t={self.temperature}, \"\n",
    "            f\"method={self.method}, \"\n",
    "            f\"kernel={self.kernel is not None}, \"\n",
    "            f\"delta_reduction={self.delta_reduction})\"\n",
    "        )\n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        \"\"\"Compute loss for model. If `labels` is None,\n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, n_features].\n",
    "                input has to be rearranged to [bsz, n_views, n_features] and labels [bsz],\n",
    "            labels: ground truth of shape [bsz].\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "\n",
    "        if len(features.shape) != 3:\n",
    "            raise ValueError(\n",
    "                \"`features` needs to be [bsz, n_views, n_feats],\"\n",
    "                \"3 dimensions are required\"\n",
    "            )\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        n_views = features.shape[1]\n",
    "        if labels is None:\n",
    "            mask = torch.eye(batch_size, device=device)\n",
    "\n",
    "        else:\n",
    "            labels = labels.view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError(\"Num of labels does not match num of features\")\n",
    "\n",
    "            if self.kernel is None:\n",
    "                mask = torch.eq(labels, labels.T)\n",
    "            else:\n",
    "                mask = self.kernel(labels, krnl_sigma=self.krnl_sigma)\n",
    "\n",
    "        view_count = features.shape[1]\n",
    "        features = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == \"one\":\n",
    "            features = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == \"all\":\n",
    "            features = features\n",
    "            anchor_count = view_count\n",
    "        else:\n",
    "            raise ValueError(\"Unknown mode: {}\".format(self.contrast_mode))\n",
    "\n",
    "        # Tile mask\n",
    "        mask = mask.repeat(anchor_count, view_count)\n",
    "        # Inverse of torch-eye to remove self-contrast (diagonal)\n",
    "        inv_diagonal = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * n_views, device=device).view(-1, 1),\n",
    "            0,\n",
    "        )\n",
    "\n",
    "        # compute similarity\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(features, features.T), self.temperature\n",
    "        )\n",
    "\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        alignment = logits\n",
    "\n",
    "        # base case is:\n",
    "        # - supcon if kernel = none\n",
    "        # - y-aware is kernel != none\n",
    "        uniformity = torch.exp(logits) * inv_diagonal\n",
    "\n",
    "        if self.method == \"threshold\":\n",
    "            repeated = mask.unsqueeze(-1).repeat(\n",
    "                1, 1, mask.shape[0]\n",
    "            )  # repeat kernel mask\n",
    "\n",
    "            delta = (mask[:, None].T - repeated.T).transpose(\n",
    "                1, 2\n",
    "            )  # compute the difference w_k - w_j for every k,j\n",
    "            delta = (delta > 0.0).float()\n",
    "\n",
    "            # for each z_i, repel only samples j s.t. K(z_i, z_j) < K(z_i, z_k)\n",
    "            uniformity = uniformity.unsqueeze(-1).repeat(1, 1, mask.shape[0])\n",
    "\n",
    "            if self.delta_reduction == \"mean\":\n",
    "                uniformity = (uniformity * delta).mean(-1)\n",
    "            else:\n",
    "                uniformity = (uniformity * delta).sum(-1)\n",
    "\n",
    "        elif self.method == \"expw\":\n",
    "            # exp weight e^(s_j(1-w_j))\n",
    "            uniformity = torch.exp(logits * (1 - mask)) * inv_diagonal\n",
    "\n",
    "        uniformity = torch.log(uniformity.sum(1, keepdim=True))\n",
    "\n",
    "        # positive mask contains the anchor-positive pairs\n",
    "        # excluding <self,self> on the diagonal\n",
    "        positive_mask = mask * inv_diagonal\n",
    "\n",
    "        log_prob = (\n",
    "            alignment - uniformity\n",
    "        )  # log(alignment/uniformity) = log(alignment) - log(uniformity)\n",
    "        log_prob = (positive_mask * log_prob).sum(1) / positive_mask.sum(\n",
    "            1\n",
    "        )  # compute mean of log-likelihood over positive\n",
    "\n",
    "        # loss\n",
    "        loss = -(self.temperature / self.base_temperature) * log_prob\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, krnl_sigma):\n",
    "    x = x - x.T\n",
    "    return torch.exp(-(x**2) / (2 * (krnl_sigma**2))) / (math.sqrt(2 * torch.pi))\n",
    "\n",
    "def gaussian_kernel_on_similarity_matrix(x, krnl_sigma):\n",
    "    return torch.exp(-(x**2) / (2 * (krnl_sigma**2))) / (math.sqrt(2 * torch.pi))\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_kernel_original(x, krnl_sigma):\n",
    "    x = x - x.T\n",
    "    return torch.exp(-(x**2) / (2 * (krnl_sigma**2))) / (\n",
    "        math.sqrt(2 * torch.pi) * krnl_sigma\n",
    "    )\n",
    "\n",
    "\n",
    "def cauchy(x, krnl_sigma):\n",
    "    x = x - x.T\n",
    "    return 1.0 / (krnl_sigma * (x**2) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader as graph_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, test_dataset, model=None, device=device, kernel=cauchy, num_epochs=100, batch_size=32):\n",
    "    input_dim_feat = 499500\n",
    "    # the rest is arbitrary\n",
    "    hidden_dim_feat = 1000\n",
    "    input_dim_target = 1\n",
    "    output_dim = 2\n",
    "\n",
    "    num_epochs = 100\n",
    "\n",
    "    lr = 0.1  # too low values return nan loss\n",
    "    kernel = cauchy\n",
    "    batch_size = 32  # too low values return nan loss\n",
    "    dropout_rate = 0\n",
    "    weight_decay = 0\n",
    "\n",
    "    train_loader = graph_dataloader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = graph_dataloader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    if model is None:\n",
    "        model = GCN(\n",
    "            input_dim_feat,\n",
    "            input_dim_target,\n",
    "            hidden_dim_feat,\n",
    "            output_dim,\n",
    "            dropout_rate=dropout_rate,\n",
    "            lr = lr,\n",
    "            weight_decay = weight_decay\n",
    "        ).to(device)\n",
    "    \n",
    "    model.init_weights()   \n",
    "    criterion_pft = KernelizedSupCon(\n",
    "    method=\"expw\", temperature=0.03, base_temperature=0.03, kernel=kernel, krnl_sigma=1\n",
    "    )\n",
    "    \n",
    "    criterion_ptt = KernelizedSupCon(\n",
    "        method=\"expw\", temperature=0.03, base_temperature=0.03, kernel=kernel, krnl_sigma=1\n",
    "    )\n",
    "    \n",
    "    optimizer = model.initialize_optimizer(lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1)\n",
    "\n",
    "    loss_terms = []\n",
    "    validation = []\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    with tqdm(range(num_epochs), desc=\"Epochs\", leave=False) as pbar:\n",
    "        for epoch in pbar:\n",
    "            model.train()\n",
    "            loss_terms_batch = defaultdict(lambda:0)\n",
    "            for features, targets, edge_indices in train_loader:\n",
    "                \n",
    "                bsz = targets.shape[0]\n",
    "                n_views = features.shape[1]\n",
    "                n_feat = features.shape[-1]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                features = features.view(bsz * n_views, n_feat)\n",
    "                features = features.to(device)              \n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                out_feat, out_target = model(features, torch.cat(n_views*[targets], dim=0), edge_indices)\n",
    "                \n",
    "                joint_embedding = nn.functional.mse_loss(out_feat, out_target)\n",
    "                \n",
    "                out_feat = torch.split(out_feat, [bsz]*n_views, dim=0)\n",
    "                out_feat = torch.cat([f.unsqueeze(1) for f in out_feat], dim=1)\n",
    "                kernel_feature = criterion_pft(out_feat, targets)\n",
    "\n",
    "                out_target_decoded = model.decode_target(out_target)\n",
    "                #cosine_target = torch.ones(len(out_target), device=device)                \n",
    "                out_target = torch.split(out_target, [bsz]*n_views, dim=0)\n",
    "                out_target = torch.cat([f.unsqueeze(1) for f in out_target], dim=1)\n",
    "        \n",
    "                kernel_target = criterion_ptt(out_target, targets)\n",
    "                #joint_embedding = 1000 * nn.functional.cosine_embedding_loss(out_feat, out_target, cosine_target)\n",
    "                target_decoding = .1 * nn.functional.mse_loss(torch.cat(n_views*[targets], dim=0), out_target_decoded)\n",
    "\n",
    "                loss = kernel_feature + kernel_target + joint_embedding + target_decoding\n",
    "                loss.backward()\n",
    "                                # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_terms_batch['loss'] += loss.item() / len(train_loader)\n",
    "                loss_terms_batch['kernel_feature'] += kernel_feature.item() / len(train_loader)\n",
    "                loss_terms_batch['kernel_target'] += kernel_target.item() / len(train_loader)\n",
    "                loss_terms_batch['joint_embedding'] += joint_embedding.item() / len(train_loader)\n",
    "                loss_terms_batch['target_decoding'] += target_decoding.item() / len(train_loader)\n",
    "            loss_terms_batch['epoch'] = epoch\n",
    "            loss_terms.append(loss_terms_batch)\n",
    "\n",
    "            model.eval()\n",
    "            mae_batch = 0\n",
    "            with torch.no_grad():\n",
    "                for (features, targets) in test_loader:\n",
    "                    bsz = targets.shape[0]\n",
    "                    n_views = 1\n",
    "                    n_feat = features.shape[-1]\n",
    "                    \n",
    "                    if len(features.shape) > 2:\n",
    "                        n_views = features.shape[1]\n",
    "                        features = features.view(bsz * n_views, n_feat)\n",
    "                        \n",
    "                    features, targets = features.to(device), targets.to(device)\n",
    "                    \n",
    "                    out_feat = model.transform_feat(features)\n",
    "                    out_target_decoded = model.decode_target(out_feat)\n",
    "                    \n",
    "                    mae_batch += (targets - out_target_decoded).abs().mean() / len(test_loader)\n",
    "                validation.append(mae_batch.item())\n",
    "            scheduler.step(mae_batch)\n",
    "            if np.log10(scheduler._last_lr[0]) < -4:\n",
    "                break\n",
    "            \n",
    "            pbar.set_postfix_str(\n",
    "                f\"Epoch {epoch} \"\n",
    "                f\"| Loss {loss_terms[-1]['loss']:.02f} \"\n",
    "                f\"| val MAE {validation[-1]:.02f}\"\n",
    "                f\"| log10 lr {np.log10(scheduler._last_lr[0])}\"\n",
    "            )\n",
    "            \n",
    "    loss_terms = pd.DataFrame(loss_terms)\n",
    "    return loss_terms, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(submitit.helpers.Checkpointable):\n",
    "    def __init__(self):\n",
    "        self.results = None\n",
    "\n",
    "    def __call__(self, train, test_size, indices, train_ratio, experiment_size, experiment, dataset, random_state=None, device=None, path: Path = None):\n",
    "        if self.results is None:\n",
    "            if device is None:\n",
    "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                print(f\"Device {device}, ratio {train_ratio}\", flush=True)\n",
    "            if not isinstance(random_state, np.random.RandomState):\n",
    "                random_state = np.random.RandomState(random_state)\n",
    "\n",
    "            # if dataset is None:\n",
    "            #     print(\"Loading data\", flush=True)\n",
    "            #     dataset = MatData(\n",
    "            #         data_path / \"vectorized_matrices.npy\",\n",
    "            #         data_path / \"participants.csv\",\n",
    "            #         \"age\",\n",
    "            #         threshold=threshold\n",
    "            #     )\n",
    "\n",
    "            # print(\"Data loaded\", flush=True)\n",
    "            predictions = {}\n",
    "            losses = []\n",
    "            experiment_indices = random_state.choice(indices, experiment_size, replace=False)\n",
    "            train_indices, test_indices = train_test_split(experiment_indices, test_size=test_size, random_state=random_state)\n",
    "            #train_dataset = Subset(dataset, train_indices)\n",
    "            train_dataset = dataset.index_select(train_indices)\n",
    "            \n",
    "            #test_dataset = Subset(dataset, test_indices)\n",
    "            test_dataset = dataset.index_select(test_indices)\n",
    "            ### Augmentation\n",
    "            n_views = 1\n",
    "            \n",
    "            train_features = train_dataset.features.numpy()\n",
    "            #train_features = train_dataset.matrices.numpy()\n",
    "            #train_features = np.array([data.x for data in train_dataset])\n",
    "           \n",
    "\n",
    "            train_targets = train_dataset.target.numpy()\n",
    "            #train_targets = [data.y.numpy() for data in train_dataset]\n",
    "\n",
    "            #train_edge_indices = [data.edge_index for data in train_dataset]\n",
    "            train_edge_indices = train_dataset.edge_indices.numpy()\n",
    "\n",
    "            #test_features= train_dataset.dataset.matrices[test_dataset.indices]#.numpy()\n",
    "            test_features= test_dataset.features.numpy()\n",
    "\n",
    "            #test_targets = train_dataset.dataset.target[test_dataset.indices].numpy()\n",
    "            #test_targets = [data.y.numpy() for data in test_dataset]#.numpy()\n",
    "            test_target = test_dataset.target.numpy()\n",
    "\n",
    "            test_edge_indices = test_dataset.edge_indices.numpy()\n",
    "\n",
    "            if AUGMENTATION is not None:\n",
    "                transform = augs[AUGMENTATION]\n",
    "                aug_features = np.array([transform(sample) for sample in train_features])\n",
    "\n",
    "                train_features = sym_matrix_to_vec(train_features, discard_diagonal=True)\n",
    "                aug_features = sym_matrix_to_vec(train_features, discard_diagonal=True)\n",
    "\n",
    "                n_views = n_views + aug_features.shape[1]\n",
    "                n_features = train_features.shape[-1]\n",
    "                n_samples = len(train_dataset)\n",
    "\n",
    "                new_train_features = np.zeros((n_samples, n_views, n_features))\n",
    "                new_train_features[:, 0, :] = train_features\n",
    "                new_train_features[:, 1:, :] = aug_features\n",
    "            else:\n",
    "                train_features = sym_matrix_to_vec(train_features, discard_diagonal=True)\n",
    "                train_features = np.expand_dims(train_features, axis = 1)\n",
    "                #train_features = train_features\n",
    "            \n",
    "            train_dataset = TensorDataset(torch.from_numpy(train_features).to(torch.float32), torch.from_numpy(train_targets).to(torch.float32))\n",
    "            #train_dataset = TensorDataset(train_features.to(torch.float32), train_targets.to(torch.float32))\n",
    "            test_features = sym_matrix_to_vec(test_features, discard_diagonal=True)\n",
    "            #test_features = test_features\n",
    "            test_dataset = TensorDataset(torch.from_numpy(test_features).to(torch.float32), torch.from_numpy(test_targets).to(torch.float32))\n",
    "            #test_dataset = TensorDataset(test_features.to(torch.float32), test_targets.to(torch.float32))\n",
    "            loss_terms, model = train(train_dataset, test_dataset, model = None, device=device)\n",
    "            losses.append(loss_terms.eval(\"train_ratio = @train_ratio\").eval(\"experiment = @experiment\"))\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                #train_dataset = Subset(dataset, train_indices)\n",
    "                train_dataset = dataset.index_select(train_indices)\n",
    "\n",
    "                #train_features = train_dataset.dataset.matrices[train_dataset.indices].numpy()\n",
    "                train_features = train_dataset.features.numpy()\n",
    "                #train_targets = train_dataset.dataset.target[train_dataset.indices].numpy()\n",
    "                train_targets = train_dataset.target.numpy()\n",
    "                #train_features = np.array([sym_matrix_to_vec(i, discard_diagonal=True) for i in train_features])\n",
    "                train_edge_indices = train_dataset.edge_indices.numpy()\n",
    "\n",
    "                #train_features = preprocess_features(train_features)\n",
    "                train_dataset = TensorDataset(torch.from_numpy(train_features).to(torch.float32), torch.from_numpy(train_targets).to(torch.float32))\n",
    "                for label, d, d_indices in (('train', train_dataset, train_indices), ('test', test_dataset, test_indices)):\n",
    "                    X, y = zip(*d)\n",
    "                    X = torch.stack(X).to(device)\n",
    "                    y = torch.stack(y).to(device)\n",
    "                    y_pred = model.decode_target(model.transform_feat(X))\n",
    "                    predictions[(train_ratio, experiment, label)] = (y.cpu().numpy(), y_pred.cpu().numpy(), d_indices)\n",
    "\n",
    "            self.results = (losses, predictions)\n",
    "\n",
    "        if path:\n",
    "            self.save(path)\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "    def checkpoint(self, *args, **kwargs):\n",
    "        print(\"Checkpointing\", flush=True)\n",
    "        return super().checkpoint(*args, **kwargs)\n",
    "\n",
    "    def save(self, path: Path):\n",
    "        with open(path, \"wb\") as o:\n",
    "            pickle.dump(self.results, o, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(seed=42)\n",
    "dataset = GraphData(path_feat, path_target, \"age\")\n",
    "n_sub = len(dataset)\n",
    "test_ratio = .2\n",
    "test_size = int(test_ratio * n_sub)\n",
    "indices = np.arange(n_sub)\n",
    "experiments = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Size:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu, ratio 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Training Size:   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'range' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/parietal/store2/work/mrenaudi/contrastive-reg-2/graph_rep_2.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-2/graph_rep_2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mfor\u001b[39;00m experiment \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(experiments), desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExperiment\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-2/graph_rep_2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     run_experiment \u001b[39m=\u001b[39m Experiment()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-2/graph_rep_2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     job \u001b[39m=\u001b[39m run_experiment(train,  test_size, indices, train_ratio, experiment_size, experiment, dataset, random_state\u001b[39m=\u001b[39;49mrandom_state, device\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-2/graph_rep_2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     experiment_results\u001b[39m.\u001b[39mappend(job)\n",
      "\u001b[1;32m/data/parietal/store2/work/mrenaudi/contrastive-reg-2/graph_rep_2.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-2/graph_rep_2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m train_indices, test_indices \u001b[39m=\u001b[39m train_test_split(experiment_indices, test_size\u001b[39m=\u001b[39mtest_size, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-2/graph_rep_2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#train_dataset = Subset(dataset, train_indices)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-2/graph_rep_2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mindex_select(train_indices)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-2/graph_rep_2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#test_dataset = Subset(dataset, test_indices)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-2/graph_rep_2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mindex_select(test_indices)\n",
      "File \u001b[0;32m~/.local/miniconda3/lib/python3.12/site-packages/torch_geometric/data/dataset.py:306\u001b[0m, in \u001b[0;36mDataset.index_select\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mindex_select\u001b[39m(\u001b[39mself\u001b[39m, idx: IndexType) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    301\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Creates a subset of the dataset from specified indices :obj:`idx`.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[39m    Indices :obj:`idx` can be a slicing object, *e.g.*, :obj:`[2:5]`, a\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m    list, a tuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39m    long or bool.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices()\n\u001b[1;32m    308\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mslice\u001b[39m):\n\u001b[1;32m    309\u001b[0m         start, stop, step \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mstart, idx\u001b[39m.\u001b[39mstop, idx\u001b[39m.\u001b[39mstep\n",
      "\u001b[0;31mTypeError\u001b[0m: 'range' object is not callable"
     ]
    }
   ],
   "source": [
    "# %% ## Training\n",
    "if multi_gpu:\n",
    "    log_folder = Path(\"log_folder\")\n",
    "    executor = submitit.AutoExecutor(folder=str(log_folder / \"%j\"))\n",
    "    executor.update_parameters(\n",
    "        #timeout_min=120,\n",
    "        slurm_partition=\"gpu-best\",\n",
    "        gpus_per_node=1,\n",
    "        tasks_per_node=1,\n",
    "        nodes=1,\n",
    "        cpus_per_task=8\n",
    "        #slurm_qos=\"qos_gpu-t3\",\n",
    "        #slurm_constraint=\"v100-32g\",\n",
    "        #slurm_mem=\"10G\",\n",
    "        #slurm_additional_parameters={\"requeue\": True}\n",
    "    )\n",
    "    # srun -n 1  --verbose -A hjt@v100 -c 10 -C v100-32g   --gres=gpu:1 --time 5  python\n",
    "    experiment_jobs = []\n",
    "    # module_purge = submitit.helpers.CommandFunction(\"module purge\".split())\n",
    "    # module_load = submitit.helpers.CommandFunction(\"module load pytorch-gpu/py3/2.0.1\".split())\n",
    "    with executor.batch():\n",
    "        for train_ratio in tqdm(np.linspace(.1, 1., 5)):\n",
    "            train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "            experiment_size = test_size + train_size\n",
    "            for experiment in tqdm(range(experiments)):\n",
    "                run_experiment = Experiment()\n",
    "                job = executor.submit(run_experiment, train, test_size, indices, train_ratio, experiment_size, experiment, dataset, random_state=random_state, device=None)\n",
    "                experiment_jobs.append(job)\n",
    "\n",
    "    async def get_result(experiment_jobs):\n",
    "        experiment_results = []\n",
    "        for aws in tqdm(asyncio.as_completed([j.awaitable().result() for j in experiment_jobs]), total=len(experiment_jobs)):\n",
    "            res = await aws\n",
    "            experiment_results.append(res)\n",
    "        return experiment_results\n",
    "    experiment_results = asyncio.run(get_result(experiment_jobs))\n",
    "\n",
    "else:\n",
    "    experiment_results = []\n",
    "    for train_ratio in tqdm(np.linspace(.1, 1., 5), desc=\"Training Size\"):\n",
    "        train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "        experiment_size = test_size + train_size\n",
    "        for experiment in tqdm(range(experiments), desc=\"Experiment\"):\n",
    "            run_experiment = Experiment()\n",
    "            job = run_experiment(train,  test_size, indices, train_ratio, experiment_size, experiment, dataset, random_state=random_state, device=None)\n",
    "            experiment_results.append(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
