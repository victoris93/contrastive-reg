{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import asyncio\n",
    "import submitit\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "from augmentations import augs, aug_args\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "torch.cuda.empty_cache()\n",
    "multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0\n",
    "AUGMENTATION = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_feat = \"./matrices\"\n",
    "path_target = \"participants.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.nn import Sequential as graph_sequential\n",
    "from torch_geometric.loader import DataLoader as graph_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim_feat, input_dim_target, hidden_dim_feats, output_dim, dropout_rate, lr, weight_decay):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.feat_gcn = graph_sequential('x, edge_index', [\n",
    "            (GCNConv(input_dim_feat, hidden_dim_feats), 'x, edge_index -> x'),\n",
    "            nn.ReLU(),\n",
    "            (GCNConv(hidden_dim_feats, hidden_dim_feats), 'x, edge_index -> x'),\n",
    "            nn.ReLU(),\n",
    "            (GCNConv(hidden_dim_feats, output_dim), 'x, edge_index -> x')\n",
    "        ])\n",
    "        #self.init_weights(self.feat_gcn)\n",
    "        \n",
    "        self.target_mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim_target),\n",
    "            nn.Linear(input_dim_target, hidden_dim_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(hidden_dim_feats, output_dim)\n",
    "        )\n",
    "        #self.init_weights(self.target_mlp)\n",
    "        \n",
    "        self.decode_target = nn.Sequential(\n",
    "            nn.Linear(output_dim, hidden_dim_feats),\n",
    "            nn.BatchNorm1d(hidden_dim_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim_feats, input_dim_target)\n",
    "        )\n",
    "        #self.init_weights(self.decode_target)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, GCNConv):\n",
    "            # GCNConv initializes its weights during initialization\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "                    \n",
    "\n",
    "    \n",
    "    def transform_feat(self, x, edge_index):\n",
    "        features = self.feat_gcn(x, edge_index)\n",
    "        pooling = global_mean_pool(features, batch=None)\n",
    "        pooling = nn.functional.normalize(features, p=2, dim=1)\n",
    "        return pooling\n",
    "    \n",
    "    def transform_targets(self, y):\n",
    "        targets = self.target_mlp(y)\n",
    "        targets = nn.functional.normalize(targets, p=2, dim=1)\n",
    "        return targets\n",
    " \n",
    "    def decode_targets(self, embedding):\n",
    "        return self.decode_target(embedding)\n",
    "    \n",
    "    def initialize_optimizer(self, lr, weight_decay):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x, y, edge_index):\n",
    "        x_embedding = self.transform_feat(x, edge_index)\n",
    "        y_embedding = self.transform_targets(y)\n",
    "        return x_embedding, y_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphData Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.data import Data as graph_data\n",
    "from torch_geometric.data import Dataset as graph_dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "class GraphData(graph_dataset):\n",
    "    def __init__(self, path_feat, path_target, target_name, indices, augmentations = None):\n",
    "        \n",
    "        self.path_feat = path_feat\n",
    "        self.path_target = path_target\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "        self.features = np.array([np.load(i) for i in self.raw_file_names[indices]])\n",
    "        self.targets = np.expand_dims(\n",
    "                pd.read_csv(path_target)[target_name].values[indices], axis=1\n",
    "            )\n",
    "        self.features, self.graphs, self.targets = self.process(self.features, self.targets)\n",
    "        self.features = sym_matrix_to_vec(self.features, discard_diagonal = True)\n",
    "            \n",
    "        self.targets = torch.FloatTensor(self.targets)\n",
    "        self.features = torch.FloatTensor(self.features)\n",
    "        gc.collect()\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        raw_file_names = [join(self.path_feat, f) for f in listdir(self.path_feat) if isfile(join(self.path_feat, f))]\n",
    "        raw_file_names = sorted(raw_file_names, key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "        raw_file_names = np.array(raw_file_names)\n",
    "        return raw_file_names\n",
    "\n",
    "    @property\n",
    "    def show_indices(self):\n",
    "        return self.indices\n",
    "    \n",
    "    def process(self, features, targets):\n",
    "        ### AUGMENTATIONS\n",
    "        n_augs = 0\n",
    "        if self.augmentations is not None:\n",
    "            aug_samples = []\n",
    "            if not isinstance(self.augmentations, list):\n",
    "                self.augmentations = [self.augmentations]\n",
    "                \n",
    "            n_augs = len(self.augmentations)\n",
    "            for func in self.augmentations:\n",
    "                transform = augs[func]\n",
    "                transform_args = aug_args[func]\n",
    "                for sample in features:\n",
    "                    aug_features = transform(sample, **transform_args)\n",
    "                    aug_samples.append(aug_features)\n",
    "                        \n",
    "            aug_samples = np.array(aug_samples)\n",
    "            features = np.concatenate([features, aug_samples], axis=0)\n",
    "        targets = np.concatenate([targets]*(n_augs + 1), axis=0)\n",
    "        targets = np.array(targets)\n",
    "#         targets = torch.FloatTensor(targets)\n",
    "        ### GRAPH CONSTRUCTION\n",
    "        graphs = []\n",
    "        for sample in tqdm(features, desc=\"Processing samples\"):\n",
    "            graph = self.make_graph(sample)\n",
    "            graphs.append(graph)\n",
    "        return features, graphs, targets\n",
    "    \n",
    "    def get_edge_indices(self, feat_sample):\n",
    "#         idx_upper_tri = np.triu_indices_from(feat_sample, k=1)  # k=1 excludes the diagonal\n",
    "#         source_nodes = idx_upper_tri[0]\n",
    "#         target_nodes = idx_upper_tri[1]\n",
    "        \n",
    "        source_nodes, target_nodes = np.nonzero(feat_sample)\n",
    "        edge_indices = np.vstack((source_nodes, target_nodes))\n",
    "        return edge_indices\n",
    "\n",
    "    def make_graph(self, feat_sample):\n",
    "        edge_index = self.get_edge_indices(feat_sample)\n",
    "        graph = graph_data(x=torch.FloatTensor(feat_sample), edge_index=torch.LongTensor(edge_index).contiguous())\n",
    "        return graph\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.features[idx], self.targets[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelizedSupCon(nn.Module):\n",
    "    \"\"\"Supervised contrastive loss: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\n",
    "    Based on: https://github.com/HobbitLong/SupContrast\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        method: str,\n",
    "        temperature: float = 0.07,\n",
    "        contrast_mode: str = \"all\",\n",
    "        base_temperature: float = 0.07,\n",
    "        krnl_sigma: float = 1.0,\n",
    "        kernel: callable = None,\n",
    "        delta_reduction: str = \"sum\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "        self.method = method\n",
    "        self.kernel = kernel\n",
    "        self.krnl_sigma = krnl_sigma\n",
    "        self.delta_reduction = delta_reduction\n",
    "\n",
    "        if kernel is not None and method == \"supcon\":\n",
    "            raise ValueError(\"Kernel must be none if method=supcon\")\n",
    "\n",
    "        if kernel is None and method != \"supcon\":\n",
    "            raise ValueError(\"Kernel must not be none if method != supcon\")\n",
    "\n",
    "        if delta_reduction not in [\"mean\", \"sum\"]:\n",
    "            raise ValueError(f\"Invalid reduction {delta_reduction}\")\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"{self.__class__.__name__} \"\n",
    "            f\"(t={self.temperature}, \"\n",
    "            f\"method={self.method}, \"\n",
    "            f\"kernel={self.kernel is not None}, \"\n",
    "            f\"delta_reduction={self.delta_reduction})\"\n",
    "        )\n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        \"\"\"Compute loss for model. If `labels` is None,\n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, n_features].\n",
    "                input has to be rearranged to [bsz, n_views, n_features] and labels [bsz],\n",
    "            labels: ground truth of shape [bsz].\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "\n",
    "        if len(features.shape) != 3:\n",
    "            raise ValueError(\n",
    "                \"`features` needs to be [bsz, n_views, n_feats],\"\n",
    "                \"3 dimensions are required\"\n",
    "            )\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        n_views = features.shape[1]\n",
    "        if labels is None:\n",
    "            mask = torch.eye(batch_size, device=device)\n",
    "\n",
    "        else:\n",
    "            labels = labels.view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError(\"Num of labels does not match num of features\")\n",
    "\n",
    "            if self.kernel is None:\n",
    "                mask = torch.eq(labels, labels.T)\n",
    "            else:\n",
    "                mask = self.kernel(labels, krnl_sigma=self.krnl_sigma)\n",
    "\n",
    "        view_count = features.shape[1]\n",
    "        features = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == \"one\":\n",
    "            features = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == \"all\":\n",
    "            features = features\n",
    "            anchor_count = view_count\n",
    "        else:\n",
    "            raise ValueError(\"Unknown mode: {}\".format(self.contrast_mode))\n",
    "\n",
    "        # Tile mask\n",
    "        mask = mask.repeat(anchor_count, view_count)\n",
    "        # Inverse of torch-eye to remove self-contrast (diagonal)\n",
    "        inv_diagonal = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * n_views, device=device).view(-1, 1),\n",
    "            0,\n",
    "        )\n",
    "\n",
    "        # compute similarity\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(features, features.T), self.temperature\n",
    "        )\n",
    "\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        alignment = logits\n",
    "\n",
    "        # base case is:\n",
    "        # - supcon if kernel = none\n",
    "        # - y-aware is kernel != none\n",
    "        uniformity = torch.exp(logits) * inv_diagonal\n",
    "\n",
    "        if self.method == \"threshold\":\n",
    "            repeated = mask.unsqueeze(-1).repeat(\n",
    "                1, 1, mask.shape[0]\n",
    "            )  # repeat kernel mask\n",
    "\n",
    "            delta = (mask[:, None].T - repeated.T).transpose(\n",
    "                1, 2\n",
    "            )  # compute the difference w_k - w_j for every k,j\n",
    "            delta = (delta > 0.0).float()\n",
    "\n",
    "            # for each z_i, repel only samples j s.t. K(z_i, z_j) < K(z_i, z_k)\n",
    "            uniformity = uniformity.unsqueeze(-1).repeat(1, 1, mask.shape[0])\n",
    "\n",
    "            if self.delta_reduction == \"mean\":\n",
    "                uniformity = (uniformity * delta).mean(-1)\n",
    "            else:\n",
    "                uniformity = (uniformity * delta).sum(-1)\n",
    "\n",
    "        elif self.method == \"expw\":\n",
    "            # exp weight e^(s_j(1-w_j))\n",
    "            uniformity = torch.exp(logits * (1 - mask)) * inv_diagonal\n",
    "\n",
    "        uniformity = torch.log(uniformity.sum(1, keepdim=True))\n",
    "\n",
    "        # positive mask contains the anchor-positive pairs\n",
    "        # excluding <self,self> on the diagonal\n",
    "        positive_mask = mask * inv_diagonal\n",
    "\n",
    "        log_prob = (\n",
    "            alignment - uniformity\n",
    "        )  # log(alignment/uniformity) = log(alignment) - log(uniformity)\n",
    "        log_prob = (positive_mask * log_prob).sum(1) / positive_mask.sum(\n",
    "            1\n",
    "        )  # compute mean of log-likelihood over positive\n",
    "\n",
    "        # loss\n",
    "        loss = -(self.temperature / self.base_temperature) * log_prob\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, krnl_sigma):\n",
    "    x = x - x.T\n",
    "    return torch.exp(-(x**2) / (2 * (krnl_sigma**2))) / (math.sqrt(2 * torch.pi))\n",
    "\n",
    "def gaussian_kernel_on_similarity_matrix(x, krnl_sigma):\n",
    "    return torch.exp(-(x**2) / (2 * (krnl_sigma**2))) / (math.sqrt(2 * torch.pi))\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_kernel_original(x, krnl_sigma):\n",
    "    x = x - x.T\n",
    "    return torch.exp(-(x**2) / (2 * (krnl_sigma**2))) / (\n",
    "        math.sqrt(2 * torch.pi) * krnl_sigma\n",
    "    )\n",
    "\n",
    "\n",
    "def cauchy(x, krnl_sigma):\n",
    "    x = x - x.T\n",
    "    return 1.0 / (krnl_sigma * (x**2) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, test_dataset, model=None, device=device, kernel=cauchy, num_epochs=100, batch_size=32):\n",
    "    input_dim_feat = 1000\n",
    "    # the rest is arbitrary\n",
    "    hidden_dim_feat = 500\n",
    "    input_dim_target = 1\n",
    "    output_dim = 2\n",
    "    lr = 0.1  # too low values return nan loss\n",
    "    dropout_rate = 0\n",
    "    weight_decay = 0\n",
    "\n",
    "    train_loader = graph_dataloader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # first_batch = next(iter(train_loader))\n",
    "    # first_sample = first_batch[0]\n",
    "    # print(\"Shape of the first sample:\", first_sample.shape)\n",
    "    \n",
    "    test_loader = graph_dataloader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    if model is None:\n",
    "        model = GCN(\n",
    "            input_dim_feat,\n",
    "            input_dim_target,\n",
    "            hidden_dim_feat,\n",
    "            output_dim,\n",
    "            dropout_rate=dropout_rate,\n",
    "            lr = lr,\n",
    "            weight_decay = weight_decay\n",
    "        ).to(device)\n",
    "    \n",
    "    model.init_weights()   \n",
    "    criterion_pft = KernelizedSupCon(\n",
    "    method=\"expw\", temperature=0.03, base_temperature=0.03, kernel=kernel, krnl_sigma=1\n",
    "    )\n",
    "    \n",
    "    criterion_ptt = KernelizedSupCon(\n",
    "        method=\"expw\", temperature=0.03, base_temperature=0.03, kernel=kernel, krnl_sigma=1\n",
    "    )\n",
    "    \n",
    "    optimizer = model.initialize_optimizer(lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1)\n",
    "\n",
    "    loss_terms = []\n",
    "    validation = []\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    with tqdm(range(num_epochs), desc=\"Epochs\", leave=False) as pbar:\n",
    "        for epoch in pbar:\n",
    "            model.train()\n",
    "            loss_terms_batch = defaultdict(lambda:0)\n",
    "            for graphs, features, targets in train_loader:\n",
    "                \n",
    "                print(type(graphs), features.shape, targets.shape)\n",
    "                graphs = graphs.to(device)\n",
    "                nodes = graphs.x\n",
    "                edge_index = graphs.edge_index\n",
    "                \n",
    "#                 bsz = targets.shape[0]\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                features = features.to(device)              \n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                out_feat, out_target = model(nodes, targets, edge_index)\n",
    "                \n",
    "                joint_embedding = nn.functional.mse_loss(out_feat, out_target)\n",
    "                kernel_feature = criterion_pft(out_feat.unsqueeze(1), targets)\n",
    "\n",
    "                out_target_decoded = model.decode_target(out_target)\n",
    "#                 cosine_target = torch.ones(len(out_target), device=device)                \n",
    "        \n",
    "                kernel_target = criterion_ptt(out_target.unsqueeze(1), targets)\n",
    "#                 joint_embedding = 1000 * nn.functional.cosine_embedding_loss(out_feat, out_target, cosine_target)\n",
    "                target_decoding = .1 * nn.functional.mse_loss(targets, out_target_decoded)\n",
    "\n",
    "                loss = kernel_feature + kernel_target + joint_embedding + target_decoding\n",
    "                loss.backward()\n",
    "                                # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_terms_batch['loss'] += loss.item() / len(train_loader)\n",
    "                loss_terms_batch['kernel_feature'] += kernel_feature.item() / len(train_loader)\n",
    "                loss_terms_batch['kernel_target'] += kernel_target.item() / len(train_loader)\n",
    "                loss_terms_batch['joint_embedding'] += joint_embedding.item() / len(train_loader)\n",
    "                loss_terms_batch['target_decoding'] += target_decoding.item() / len(train_loader)\n",
    "            loss_terms_batch['epoch'] = epoch\n",
    "            loss_terms.append(loss_terms_batch)\n",
    "\n",
    "            model.eval()\n",
    "            mae_batch = 0\n",
    "            with torch.no_grad():\n",
    "                for (features, targets) in test_loader:\n",
    "                    bsz = targets.shape[0]\n",
    "                    n_views = 1\n",
    "                    n_feat = features.shape[-1]\n",
    "                    \n",
    "                    if len(features.shape) > 2:\n",
    "                        n_views = features.shape[1]\n",
    "                        features = features.view(bsz * n_views, n_feat)\n",
    "                        \n",
    "                    features, targets = features.to(device), targets.to(device)\n",
    "                    \n",
    "                    out_feat = model.transform_feat(features)\n",
    "                    out_target_decoded = model.decode_target(out_feat)\n",
    "                    \n",
    "                    mae_batch += (targets - out_target_decoded).abs().mean() / len(test_loader)\n",
    "                validation.append(mae_batch.item())\n",
    "            scheduler.step(mae_batch)\n",
    "            if np.log10(scheduler._last_lr[0]) < -4:\n",
    "                break\n",
    "            \n",
    "            pbar.set_postfix_str(\n",
    "                f\"Epoch {epoch} \"\n",
    "                f\"| Loss {loss_terms[-1]['loss']:.02f} \"\n",
    "                f\"| val MAE {validation[-1]:.02f}\"\n",
    "                f\"| log10 lr {np.log10(scheduler._last_lr[0])}\"\n",
    "            )\n",
    "            \n",
    "    loss_terms = pd.DataFrame(loss_terms)\n",
    "    return loss_terms, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(submitit.helpers.Checkpointable):\n",
    "    def __init__(self):\n",
    "        self.results = None\n",
    "\n",
    "    def __call__(self, train, test_size, indices, train_ratio, experiment_size, experiment, feat_path, target_path, target_name, random_state, device = None, augmentations = AUGMENTATION, save_path: Path = None):\n",
    "        if self.results is None:\n",
    "            if device is None:\n",
    "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                print(f\"Device {device}, ratio {train_ratio}\", flush=True)\n",
    "            if not isinstance(random_state, np.random.RandomState):\n",
    "                random_state = np.random.RandomState(random_state)\n",
    "                \n",
    "            predictions = {}\n",
    "            losses = []\n",
    "            experiment_indices = random_state.choice(indices, experiment_size, replace=False)\n",
    "            train_indices, test_indices = train_test_split(experiment_indices, test_size=test_size, random_state=random_state)\n",
    "            \n",
    "            ## Create train & test datasets\n",
    "            train_dataset = GraphData(feat_path, target_path, target_name, train_indices, augmentations = augmentations)\n",
    "            test_dataset = GraphData(feat_path, target_path, target_name, test_indices, augmentations = None)\n",
    "            \n",
    "            loss_terms, model = train(train_dataset, test_dataset, model = None, device=device)\n",
    "            losses.append(loss_terms.eval(\"train_ratio = @train_ratio\").eval(\"experiment = @experiment\"))\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                train_dataset = GraphData(feat_path, target_path, train_indices, augmentations = None)\n",
    "                for label, d, d_indices in (('train', train_dataset, train_indices), ('test', test_dataset, test_indices)):\n",
    "                    X, y = zip(*d)\n",
    "                    X = torch.stack(X).to(device)\n",
    "                    y = torch.stack(y).to(device)\n",
    "                    y_pred = model.decode_target(model.transform_feat(X))\n",
    "                    predictions[(train_ratio, experiment, label)] = (y.cpu().numpy(), y_pred.cpu().numpy(), d_indices)\n",
    "\n",
    "            self.results = (losses, predictions)\n",
    "\n",
    "        if save_path:\n",
    "            self.save(save_path)\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "    def checkpoint(self, *args, **kwargs):\n",
    "        print(\"Checkpointing\", flush=True)\n",
    "        return super().checkpoint(*args, **kwargs)\n",
    "    \n",
    "    def save(self, path: Path):\n",
    "        with open(path, \"wb\") as o:\n",
    "            pickle.dump(self.results, o, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(seed=42)\n",
    "#dataset = GraphData(path_feat, path_target, \"age\")\n",
    "n_sub = 936\n",
    "test_ratio = .2\n",
    "test_size = int(test_ratio * n_sub)\n",
    "indices = np.arange(n_sub)\n",
    "experiments = 1\n",
    "feat_path = './matrices'\n",
    "target_path = 'participants.csv'\n",
    "target_name = 'age'\n",
    "# folder_path = \"./matrices\"\n",
    "# file_names = os.listdir(folder_path)\n",
    "# target_name = \"age\"\n",
    "# targets = np.expand_dims(\n",
    "#                 pd.read_csv(path_target)[target_name].values, axis=1\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f3ea5f26164f65907f620eab8e757f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Size:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d873403e1e3542c0906226458b40c82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiment:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee72c8c3df34faa88dd0315934ca79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing samples:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef63e3a4f7041a5ace4433cd85ed793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing samples:   0%|          | 0/187 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9951aea36123453f8ceeea1f82591a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.data.batch.DataBatch'> torch.Size([32, 499500]) torch.Size([32, 1])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 59.61 GiB. GPU 0 has a total capacty of 15.89 GiB of which 13.59 GiB is free. Including non-PyTorch memory, this process has 2.30 GiB memory in use. Of the allocated memory 1.32 GiB is allocated by PyTorch, and 322.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m experiment \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(experiments), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     44\u001b[0m     run_experiment \u001b[38;5;241m=\u001b[39m Experiment()\n\u001b[0;32m---> 45\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     experiment_results\u001b[38;5;241m.\u001b[39mappend(job)\n",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m, in \u001b[0;36mExperiment.__call__\u001b[0;34m(self, train, test_size, indices, train_ratio, experiment_size, experiment, feat_path, target_path, target_name, random_state, device, augmentations, save_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m GraphData(feat_path, target_path, target_name, train_indices, augmentations \u001b[38;5;241m=\u001b[39m augmentations)\n\u001b[1;32m     20\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m GraphData(feat_path, target_path, target_name, test_indices, augmentations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 22\u001b[0m loss_terms, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss_terms\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_ratio = @train_ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment = @experiment\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[11], line 65\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_dataset, test_dataset, model, device, kernel, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     62\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mto(device)              \n\u001b[1;32m     63\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 65\u001b[0m out_feat, out_target \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m joint_embedding \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmse_loss(out_feat, out_target)\n\u001b[1;32m     68\u001b[0m kernel_feature \u001b[38;5;241m=\u001b[39m criterion_pft(out_feat\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), targets)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 66\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, y, edge_index)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, edge_index):\n\u001b[0;32m---> 66\u001b[0m     x_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     y_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_targets(y)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_embedding, y_embedding\n",
      "Cell \u001b[0;32mIn[7], line 48\u001b[0m, in \u001b[0;36mGCN.transform_feat\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_feat\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[0;32m---> 48\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeat_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     pooling \u001b[38;5;241m=\u001b[39m global_mean_pool(features, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m     pooling \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(features, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/slurm-58084845/torch_geometric.nn.sequential_7c456c_3tg1_l5f.py:25\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_1(x)\n\u001b[1;32m     27\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_2(x, edge_index)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py:263\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    260\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m/tmp/slurm-58084845/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_bkz2vlb3.py:168\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_weight, size)\u001b[0m\n\u001b[1;32m    162\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    163\u001b[0m         out,\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m/tmp/slurm-58084845/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_bkz2vlb3.py:89\u001b[0m, in \u001b[0;36mcollect\u001b[0;34m(self, edge_index, x, edge_weight, size)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Tensor):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, j, x)\n\u001b[0;32m---> 89\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:313\u001b[0m, in \u001b[0;36mMessagePassing._index_select\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:336\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)):\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m that are larger \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:317\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_index_select_safe\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: Tensor, index: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 59.61 GiB. GPU 0 has a total capacty of 15.89 GiB of which 13.59 GiB is free. Including non-PyTorch memory, this process has 2.30 GiB memory in use. Of the allocated memory 1.32 GiB is allocated by PyTorch, and 322.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# %% ## Training\n",
    "if multi_gpu:\n",
    "    log_folder = Path(\"log_folder\")\n",
    "    executor = submitit.AutoExecutor(folder=str(log_folder / \"%j\"))\n",
    "    executor.update_parameters(\n",
    "        #timeout_min=120,\n",
    "        slurm_partition=\"gpu-best\",\n",
    "        gpus_per_node=1,\n",
    "        tasks_per_node=1,\n",
    "        nodes=1,\n",
    "        cpus_per_task=8\n",
    "        #slurm_qos=\"qos_gpu-t3\",\n",
    "        #slurm_constraint=\"v100-32g\",\n",
    "        #slurm_mem=\"10G\",\n",
    "        #slurm_additional_parameters={\"requeue\": True}\n",
    "    )\n",
    "    # srun -n 1  --verbose -A hjt@v100 -c 10 -C v100-32g   --gres=gpu:1 --time 5  python\n",
    "    experiment_jobs = []\n",
    "    # module_purge = submitit.helpers.CommandFunction(\"module purge\".split())\n",
    "    # module_load = submitit.helpers.CommandFunction(\"module load pytorch-gpu/py3/2.0.1\".split())\n",
    "    with executor.batch():\n",
    "        for train_ratio in tqdm(np.linspace(.1, 1., 5)):\n",
    "            train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "            experiment_size = test_size + train_size\n",
    "            for experiment in tqdm(range(experiments)):\n",
    "                run_experiment = Experiment()\n",
    "                job = executor.submit(run_experiment, train, test_size, indices, train_ratio, experiment_size, experiment, feat_path, target_path, target_name, random_state, device)\n",
    "                experiment_jobs.append(job)\n",
    "\n",
    "    async def get_result(experiment_jobs):\n",
    "        experiment_results = []\n",
    "        for aws in tqdm(asyncio.as_completed([j.awaitable().result() for j in experiment_jobs]), total=len(experiment_jobs)):\n",
    "            res = await aws\n",
    "            experiment_results.append(res)\n",
    "        return experiment_results\n",
    "    experiment_results = asyncio.run(get_result(experiment_jobs))\n",
    "\n",
    "else:\n",
    "    experiment_results = []\n",
    "    for train_ratio in tqdm(np.linspace(.1, 1., 5), desc=\"Training Size\"):\n",
    "        train_size = int(n_sub * (1 - test_ratio) * train_ratio)\n",
    "        experiment_size = test_size + train_size\n",
    "        for experiment in tqdm(range(experiments), desc=\"Experiment\"):\n",
    "            run_experiment = Experiment()\n",
    "            job = run_experiment(train,  test_size, indices, train_ratio, experiment_size, experiment, feat_path, target_path, target_name, random_state, device)\n",
    "            experiment_results.append(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_indices = random_state.choice(indices, experiment_size, replace=False)\n",
    "\n",
    "train_indices, test_indices = train_test_split(experiment_indices, test_size=test_size, random_state=random_state)\n",
    "            \n",
    "## Creation of the train dataset\n",
    "train_features = [np.load(os.path.join(folder_path, file_names[i])) for i in train_indices]\n",
    "train_targets = targets[train_indices]\n",
    "train_dataset = GraphDataBatch(train_features, train_targets, augmentations = AUGMENTATION)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.35451447,  0.4236528 , ...,  0.2614414 ,\n",
       "         0.05499221,  0.42104756],\n",
       "       [ 0.35451447,  1.        ,  0.91314694, ..., -0.43924817,\n",
       "         0.0834473 ,  0.08932603],\n",
       "       [ 0.4236528 ,  0.91314694,  1.        , ..., -0.41183948,\n",
       "         0.04010099,  0.30829757],\n",
       "       ...,\n",
       "       [ 0.2614414 , -0.43924817, -0.41183948, ..., 18.36840028,\n",
       "         0.33187268,  0.42616195],\n",
       "       [ 0.05499221,  0.0834473 ,  0.04010099, ...,  0.33187268,\n",
       "         1.        ,  0.67589603],\n",
       "       [ 0.42104756,  0.08932603,  0.30829757, ...,  0.42616195,\n",
       "         0.67589603,  1.        ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(train_features[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = nx.from_numpy_array(train_features[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_indices = np.array(graph.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [  0,   1],\n",
       "       [  0,   2],\n",
       "       ...,\n",
       "       [998, 998],\n",
       "       [998, 999],\n",
       "       [999, 999]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0],\n",
       "        [  0,   1],\n",
       "        [  0,   2],\n",
       "        ...,\n",
       "        [998, 998],\n",
       "        [998, 999],\n",
       "        [999, 999]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(edge_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/parietal/store2/work/mrenaudi/contrastive-reg-3/graph_rep_2.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-3/graph_rep_2.ipynb#Y106sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39mfeatures_list[idx]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-3/graph_rep_2.ipynb#Y106sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[idx]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmargaret/data/parietal/store2/work/mrenaudi/contrastive-reg-3/graph_rep_2.ipynb#Y106sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m data_list \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "features = self.features_list[idx]\n",
    "target = self.targets[idx]\n",
    "data_list = []\n",
    "\n",
    "for anchor in features:\n",
    "            edge_index_anchor = get_edge_indices(anchor)\n",
    "            data = graph_data(x=torch.FloatTensor(anchor), y=torch.FloatTensor(target), edge_index=torch.LongTensor(edge_index_anchor))\n",
    "            print(\"x\", data.x.shape)\n",
    "            print(\"y\", data.y.shape)\n",
    "            print(\"edge_index\", data.edge_index.shape)\n",
    "\n",
    "            data_list.append(data)\n",
    "\n",
    "if self.augmentations is not None:\n",
    "                        transform = augs[augmentations]\n",
    "                        aug_sample = np.array(transform(anchor))\n",
    "                        edge_index_aug = get_edge_indices(aug_sample)\n",
    "                        data_aug = graph_data(x=torch.FloatTensor(aug_sample), y=torch.FloatTensor(target), edge_index=torch.LongTensor(edge_index_aug))\n",
    "                        data_list.append(data_aug)\n",
    "\n",
    "return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
