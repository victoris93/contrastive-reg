{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nilearn as nl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from nilearn.connectome import vec_to_sym_matrix, sym_matrix_to_vec\n",
    "from nilearn import plotting\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import xarray as xr\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset\n",
    "from PIL import Image\n",
    "from scipy.linalg import issymmetric\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = {\n",
    "#     \"Interview Age\": \"interview_age\",\n",
    "    \"CBCL Internalizing\": \"cbcl_scr_syn_internal_r\",\n",
    "    \"CBCL Externalizing\": \"cbcl_scr_syn_external_r\",\n",
    "    \"CBCL Thought Problems\": \"cbcl_scr_syn_thought_r\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_network(label, network_labels):\n",
    "    for network in network_labels:\n",
    "        if network in label:\n",
    "            return network\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_cog(csv, cog_score):\n",
    "    file = pd.read_csv(csv)\n",
    "    file = file[[\"train_ratio\", \"experiment\", \"dataset\", cog_score]]\n",
    "    file[cog_score]= file[cog_score]#*100\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cog(data, cog_score, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.violinplot(data=data, x=\"train_ratio\", y=cog_score, hue=\"dataset\", hue_order=['train', 'test'], width = 0.8, scale = 'count', split = True) #, width = 2, gap = 0.01\n",
    "\n",
    "    for patch in ax.collections:\n",
    "        patch.set_alpha(0.4)\n",
    "\n",
    "    sns.pointplot(x='train_ratio', y=cog_score, hue='dataset', data=data.groupby(['train_ratio', 'dataset'], as_index=False)[cog_score].median(), ax=ax, hue_order=['train', 'test'], markers=\"_\")\n",
    "    # ax.set_yticks(np.arange(0, 50, 5))\n",
    "    #set x axis limit to 100\n",
    "    # ax.set_ylim(-5, 50)\n",
    "    #plt.axhline(10, c='r')\n",
    "    #plt.axhline(5, c='g', linestyle='--')\n",
    "    plt.ylabel(\"MAPE\")\n",
    "    # plt.axhline(0, c='k')\n",
    "    # plt.suptitle(f\"Training set ratio 20%, 20 experiments per size, thresh =  {threshold}%, FlippedEdge Aug\")\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(csv, title):\n",
    "    loss_j = pd.read_csv(csv)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.pointplot(x='train_ratio', y='loss', data=loss_j.groupby(['train_ratio'], as_index=False)['loss'].median(), markers=\"_\", label = \"loss\")\n",
    "    sns.pointplot(x='train_ratio', y='target_decoding', data=loss_j.groupby(['train_ratio'], as_index=False)['target_decoding'].median(), markers=\"_\", label='target decoding')\n",
    "    sns.pointplot(x='train_ratio', y='kernel_feature', data=loss_j.groupby(['train_ratio'], as_index=False)['kernel_feature'].median(), markers=\"_\", label = \"kernel_feature\")\n",
    "    sns.pointplot(x='train_ratio', y='kernel_target', data=loss_j.groupby(['train_ratio'], as_index=False)['kernel_target'].median(), markers=\"_\", label = \"kernel_target\")\n",
    "    sns.pointplot(x='train_ratio', y='joint_embedding', data=loss_j.groupby(['train_ratio'], as_index=False)['joint_embedding'].median(), markers=\"_\", label = \"joint_embedding\")\n",
    "    #sns.pointplot(x='train_ratio', y='feature_decoding', data=loss_j.groupby(['train_ratio'], as_index=False)['feature_decoding'].median(), markers=\"_\", label = \"feature_decoding\")\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend(title=title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(image_paths, save_to):\n",
    "\n",
    "    images = [Image.open(image_path) for image_path in image_paths]\n",
    "\n",
    "    total_width = sum(image.width for image in images)\n",
    "    max_height = max(image.height for image in images)\n",
    "\n",
    "    combined_image = Image.new(\"RGB\", (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for image in images:\n",
    "        combined_image.paste(image, (x_offset, 0))\n",
    "        x_offset += image.width\n",
    "\n",
    "    combined_image.save(save_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_correlations(true, recon):\n",
    "    batch_size, rows, cols = true.shape\n",
    "    correlations = np.zeros((batch_size, rows, cols))\n",
    "    flat_true = true.reshape(batch_size, rows * cols)\n",
    "    flat_recon = recon.reshape(batch_size, rows * cols)\n",
    "    \n",
    "    with tqdm(total=rows * cols, desc='Computing correlations') as pbar:\n",
    "        for i in range(rows * cols):\n",
    "            for b in range(batch_size):\n",
    "                correlations[b, i // cols, i % cols] = pearsonr(flat_true[:, i], flat_recon[:, i])[0]\n",
    "\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_elementwise_correlation(true, recon):\n",
    "    batch_size, rows, cols = true.shape\n",
    "    correlations = np.zeros((rows, cols))\n",
    "\n",
    "    flat_true = true.reshape(batch_size, -1)\n",
    "    flat_recon = recon.reshape(batch_size, -1)\n",
    "    \n",
    "    for i in range(rows * cols):\n",
    "        correlations[i // cols, i % cols] = spearmanr(flat_true[:, i], flat_recon[:, i])[0]\n",
    "\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_labels = nl.datasets.fetch_atlas_schaefer_2018()['labels']\n",
    "atlas_labels = [label.decode('utf-8') for label in atlas_labels]\n",
    "network_labels = ['Vis', 'SomMot', 'DorsAttn', 'SalVentAttn', 'Limbic', 'Cont', 'Default']\n",
    "network_labels = [replace_with_network(label, network_labels) for label in atlas_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"ae_loss_norm\"\n",
    "root = \"/gpfs3/well/margulies/users/cpy397/contrastive-learning\"\n",
    "exp_dir = f\"{root}/results/{exp}\"\n",
    "recon_mat_dir = f\"{exp_dir}/recon_mat\"\n",
    "recon_mat_files = sorted([i for i in os.listdir(recon_mat_dir) if \"recon_mat\" in i])\n",
    "mape_mat_files = sorted([i for i in os.listdir(recon_mat_dir) if \"mape_mat\" in i])\n",
    "recon_paths = [os.path.join(recon_mat_dir, i) for i in recon_mat_files]\n",
    "mape_paths = [os.path.join(recon_mat_dir, i) for i in mape_mat_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = np.load(f\"{exp_dir}/test_idx.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"{root}/ABCD/abcd_dataset_400parcels.nc\"\n",
    "dataset = xr.open_dataset(dataset_path)\n",
    "true_mat = dataset.isel(subject = test_idx).to_array().squeeze().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_mat = np.concatenate([np.load(i) for i in recon_paths])\n",
    "mape_mat = np.concatenate([np.load(i) for i in mape_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(recon_mat.shape[0]):\n",
    "    np.fill_diagonal(recon_mat[i], 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_mat_flat = sym_matrix_to_vec(recon_mat, discard_diagonal = True)\n",
    "mape_mat_flat = sym_matrix_to_vec(mape_mat, discard_diagonal = True)\n",
    "true_mat_flat = sym_matrix_to_vec(true_mat, discard_diagonal = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"{root}/ABCD/abcd_dataset_400parcels.nc\"\n",
    "dataset = xr.open_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('true_mat_flat.npy', true_mat_flat)\n",
    "np.save('recon_mat_flat.npy', recon_mat_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sub, p_value = spearmanr(true_mat_flat.flatten(), recon_mat_flat.flatten())\n",
    "corr_sub, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat_pred = compute_batch_elementwise_correlation(true_mat, recon_mat)\n",
    "np.fill_diagonal(corr_mat_pred, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data_ae = {\n",
    "    'correlation': [],\n",
    "    'network': [],\n",
    "    'model': 'AE Only'\n",
    "}\n",
    "for i, network in enumerate(network_labels):\n",
    "    corr_data_ae['correlation'].extend(corr_mat_pred[i])\n",
    "    corr_data_ae['network'].extend([network]*corr_mat_pred.shape[1])\n",
    "    \n",
    "corr_data_ae = pd.DataFrame(corr_data_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_matrix(corr_mat_pred,\n",
    "    title=f\"Corr(True, Recon) | Exp {exp} | AE Only\",\n",
    "                     grid = False,\n",
    "                     vmax = 1.,\n",
    "                     vmin = -1.\n",
    "    )\n",
    "# Calculate the mean correlation value\n",
    "mean_corr = corr_mat_pred.mean()\n",
    "mean_mape = mape_mat.mean()\n",
    "# Add text annotation for the mean correlation value\n",
    "plt.text(-12, 0.02, f'mean_corr = {mean_corr:.2f}', color='black', ha='right', va='bottom', fontsize=12, transform=plt.gca().transAxes,\n",
    "        bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
    "plt.text(-10.5, 0.09, f'mean_mape = {mean_mape:.2f}', color='black', ha='right', va='bottom', fontsize=12, transform=plt.gca().transAxes,\n",
    "        bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mat_idx in enumerate(test_idx[0:5]):\n",
    "    recon = recon_mat[i]\n",
    "    mape = np.abs(mape_mat[i])\n",
    "    true = dataset.isel(subject = mat_idx).to_array().squeeze()\n",
    "\n",
    "    # min_val = recon.min()\n",
    "    # max_val = recon.max()\n",
    "    # recon = (recon - min_val) / (max_val - min_val)\n",
    "\n",
    "    residual = true - recon\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(36, 7))\n",
    "\n",
    "    plotting.plot_matrix(true,\n",
    "    axes = axes[0],\n",
    "    title=f\"True Mat | Exp {exp} idx{mat_idx}\",\n",
    "    )\n",
    "\n",
    "    plotting.plot_matrix(recon,\n",
    "    axes = axes[1],\n",
    "    title=f\"Recon Mat | Exp {exp} idx{mat_idx}\",\n",
    "    )\n",
    "\n",
    "    plotting.plot_matrix(residual,\n",
    "    axes = axes[2],\n",
    "    title=f\"Risiduals | Exp {exp} idx{mat_idx}\",\n",
    "    )\n",
    "\n",
    "    plotting.plot_matrix(mape,\n",
    "    axes = axes[3],\n",
    "    title=f\"MAPE | Exp {exp} idx{mat_idx}\",\n",
    "    vmax = 100, vmin=0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"main_model_loss_norm\"\n",
    "root = \"/gpfs3/well/margulies/users/cpy397/contrastive-learning\"\n",
    "exp_dir = f\"{root}/results/{exp}\"\n",
    "recon_mat_dir = f\"{exp_dir}/recon_mat\"\n",
    "predictions=pd.read_csv(f\"{exp_dir}/pred_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"ABCD/abcd_dataset_400parcels.nc\"\n",
    "dataset = xr.open_dataset(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 15\n",
    "true_mat_idx = predictions[(predictions[\"dataset\"] == \"test\") & (predictions[\"train_ratio\"] == 1) & (predictions[\"experiment\"] == exp)]['indices'].values\n",
    "true_mat = dataset.isel(subject = true_mat_idx).to_array().squeeze().values\n",
    "recon_paths = sorted([i for i in os.listdir(recon_mat_dir) if \"recon_mat\" in i and f\"exp{exp}\" in i])\n",
    "mape_paths = sorted([i for i in os.listdir(recon_mat_dir) if \"mape_mat\" in i and f\"exp{exp}\" in i])\n",
    "\n",
    "recon_mat = np.concatenate([np.load(f\"{recon_mat_dir}/{i}\") for i in recon_paths])\n",
    "mape_mat = np.concatenate([np.load(f\"{recon_mat_dir}/{i}\") for i in mape_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_mat_flat = sym_matrix_to_vec(recon_mat, discard_diagonal = True)\n",
    "mape_mat_flat = sym_matrix_to_vec(mape_mat, discard_diagonal = True)\n",
    "true_mat_flat = sym_matrix_to_vec(true_mat, discard_diagonal = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sub, p_value = spearmanr(true_mat_flat.flatten(), recon_mat_flat.flatten())\n",
    "corr_sub, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation: True Mat vs. Recon Across Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat_pred = compute_batch_elementwise_correlation(true_mat, recon_mat)\n",
    "np.fill_diagonal(corr_mat_pred, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_matrix(corr_mat_pred,\n",
    "    title=f\"Corr(True, Recon) | Exp {exp}\",\n",
    "                     grid = False,\n",
    "                     vmax = 1.,\n",
    "                     vmin = -1.\n",
    "    )\n",
    "\n",
    "mean_corr = corr_mat_pred.mean()\n",
    "mean_mape = mape_mat.mean()\n",
    "plt.text(-12, 0.02, f'mean_corr = {mean_corr:.2f}', color='black', ha='right', va='bottom', fontsize=12, transform=plt.gca().transAxes,\n",
    "        bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
    "plt.text(-10.5, 0.09, f'mean_mape = {mean_mape:.2f}', color='black', ha='right', va='bottom', fontsize=12, transform=plt.gca().transAxes,\n",
    "        bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation: True Mat vs. Recon Across Subjects Per Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data_main = {\n",
    "    'correlation': [],\n",
    "    'network': [],\n",
    "    'model': 'Main'\n",
    "}\n",
    "for i, network in enumerate(network_labels):\n",
    "    corr_data_main['correlation'].extend(corr_mat_pred[i])\n",
    "    corr_data_main['network'].extend([network]*corr_mat_pred.shape[1])\n",
    "    \n",
    "corr_data_main = pd.DataFrame(corr_data_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data_ae[corr_data_ae[\"network\"] == ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = pd.concat([corr_data_ae, corr_data_main])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.violinplot(data=corr_data, x=\"network\", y=\"correlation\", hue=\"model\", split=True, inner=\"quart\", width = 1., dodge = True, palette = 'hls')\n",
    "plt.ylim(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "def add_mean_line(x, **kwargs):\n",
    "    plt.axvline(x.mean(), color='#7b2cbf', linestyle='--', lw=2)\n",
    "\n",
    "g = sns.FacetGrid(corr_data, row=\"network\", col = 'model', hue=\"network\", aspect=10, height=1, palette=\"Spectral_r\", xlim = (0, 1.))\n",
    "\n",
    "g.map(sns.kdeplot, \"correlation\", clip_on=False, shade=True, alpha=1, lw=1.5, bw=.5)\n",
    "g.map(sns.kdeplot, \"correlation\", clip_on=False, color=\"black\", lw=1.5, bw=.5)\n",
    "\n",
    "g.map(plt.axhline, y=0, lw=2, clip_on=False)\n",
    "g.map(add_mean_line, \"correlation\")\n",
    "\n",
    "g.fig.subplots_adjust(hspace=0.25)\n",
    "\n",
    "for ax, label in zip(g.axes.flat, g.row_names):\n",
    "    ax.text(0, 0.2, label, fontsize=20, ha='left', va='center', transform=ax.transAxes)\n",
    "\n",
    "g.set_titles(\"\")\n",
    "g.despine(bottom=True, left=True)\n",
    "g.set(yticks=[], xlim=(0.1, 1.0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Individual Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mat_idx in enumerate(true_mat_idx[0:5]):\n",
    "    recon = recon_mat[i]\n",
    "    mape = np.abs(mape_mat[i])\n",
    "    true = dataset.isel(subject = mat_idx).to_array().squeeze()\n",
    "\n",
    "    # min_val = recon.min()\n",
    "    # max_val = recon.max()\n",
    "    # recon = (recon - min_val) / (max_val - min_val)\n",
    "\n",
    "    residual = true - recon\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(36, 7))\n",
    "\n",
    "    plotting.plot_matrix(true,\n",
    "    axes = axes[0],\n",
    "    title=f\"True Mat | Exp {exp} idx{mat_idx}\",\n",
    "    )\n",
    "\n",
    "    plotting.plot_matrix(recon,\n",
    "    axes = axes[1],\n",
    "    title=f\"Recon Mat | Exp {exp} idx{mat_idx}\",\n",
    "    )\n",
    "\n",
    "    plotting.plot_matrix(residual,\n",
    "    axes = axes[2],\n",
    "    title=f\"Risiduals | Exp {exp} idx{mat_idx}\",\n",
    "    )\n",
    "\n",
    "    plotting.plot_matrix(mape,\n",
    "    axes = axes[3],\n",
    "    title=f\"MAPE | Exp {exp} idx{mat_idx}\",\n",
    "    vmax = 100, vmin=0\n",
    "\n",
    ")\n",
    "#     save_plot_path = f\"results/multivariate/abcd/recon_mat/plots/mat_{exp}_idx{mat_idx}.png\"\n",
    "#     plt.savefig(save_plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets: Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
