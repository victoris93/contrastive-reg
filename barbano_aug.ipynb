{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "from cmath import isinf\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "from utils_v import compute_target_score, estimate_target, save_model, standardize_dataset\n",
    "from cmath import isinf\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split, KFold, LearningCurveDisplay, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "from helper_classes import MatData, MLP\n",
    "from dev_losses import cauchy, rbf, gaussian_kernel, CustomSupCon, CustomContrastiveLoss\n",
    "from losses import KernelizedSupCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim_feat, input_dim_target, hidden_dim_feat, output_dim, dropout_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Xavier initialization for feature MLP\n",
    "        self.feat_mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim_feat, hidden_dim_feat),\n",
    "            nn.BatchNorm1d(hidden_dim_feat),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(hidden_dim_feat, output_dim)\n",
    "        )\n",
    "        self.init_weights(self.feat_mlp)\n",
    "\n",
    "        # Xavier initialization for target MLP\n",
    "        self.target_mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim_target, output_dim)\n",
    "        )\n",
    "        self.init_weights(self.target_mlp)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        features = self.feat_mlp(x)\n",
    "        targets = self.target_mlp(y)\n",
    "        features = nn.functional.normalize(features, p=2, dim=1)\n",
    "        targets = nn.functional.normalize(targets, p=2, dim=1)\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_conn(matrix, region_indices, vecrorize_mat = True):\n",
    "    \"\"\"\n",
    "    Flips the connectivity of specified regions within their hemispheres. Handles both single indices and lists of indices.\n",
    "    \n",
    "    :param matrix: The connectivity matrix.\n",
    "    :param region_indices: A single index or a list of indices for the regions.\n",
    "    :return: A 3D array of modified connectivity matrices. Each \"slice\" corresponds to the matrix after flipping each specified region.\n",
    "    \"\"\"\n",
    "    if not isinstance(region_indices, list):\n",
    "        region_indices = [region_indices]\n",
    "    flipped_matrices = []\n",
    "    \n",
    "    for index in region_indices:\n",
    "        new_matrix = matrix.copy()\n",
    "        print(matrix[index])\n",
    "        hemisphere_size = matrix.shape[0] // 2\n",
    "        is_left_hemisphere = index < hemisphere_size\n",
    "        opposite_index = index + (-1 if is_left_hemisphere else 1) * hemisphere_size\n",
    "        \n",
    "        # Flip connectivity for the specified region within its hemisphere\n",
    "        if is_left_hemisphere:\n",
    "            new_matrix[index, :hemisphere_size], new_matrix[opposite_index, :hemisphere_size] = \\\n",
    "                new_matrix[opposite_index, :hemisphere_size].copy(), new_matrix[index, :hemisphere_size].copy()\n",
    "            print(new_matrix[index])\n",
    "            print(new_matrix[opposite_index])\n",
    "            \n",
    "        else:\n",
    "            new_matrix[index, hemisphere_size:], new_matrix[opposite_index, hemisphere_size:] = \\\n",
    "                new_matrix[opposite_index, hemisphere_size:].copy(), new_matrix[index, hemisphere_size:].copy()\n",
    "            \n",
    "        if vecrorize_mat:\n",
    "            new_matrix = sym_matrix_to_vec(new_matrix, discard_diagonal = True)\n",
    "        flipped_matrices.append(new_matrix)\n",
    "        \n",
    "    return np.array(flipped_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_edge_between_regions(matrix, region_pairs, vectorize_mat=True):\n",
    "    \"\"\"\n",
    "    Flips the connectivity edge between two specified regions across hemispheres.\n",
    "    Handles pairs of regions or lists of pairs of regions.\n",
    "    \n",
    "    :param matrix: The connectivity matrix.\n",
    "    :param region_pairs: A pair of indices or a list of pairs of indices for the regions.\n",
    "    :param vectorize_mat: Whether to vectorize the output matrices.\n",
    "    :return: A 3D array of modified connectivity matrices. Each \"slice\" corresponds to the matrix after flipping the edge for each specified pair.\n",
    "    \"\"\"\n",
    "    if not isinstance(region_pairs[0], list):\n",
    "        region_pairs = [region_pairs]\n",
    "    flipped_matrices = []\n",
    "    \n",
    "    for pair in region_pairs:\n",
    "        new_matrix = matrix.copy()\n",
    "        hemisphere_size = matrix.shape[0] // 2\n",
    "        \n",
    "        # Determine the indices for flipping\n",
    "        for index1, index2 in [pair]:\n",
    "            is_left_hemisphere1 = index1 < hemisphere_size\n",
    "            is_left_hemisphere2 = index2 < hemisphere_size\n",
    "            \n",
    "            # Calculate the opposite indices in the other hemisphere\n",
    "            opposite_index1 = index1 + (-1 if is_left_hemisphere1 else 1) * hemisphere_size\n",
    "            opposite_index2 = index2 + (-1 if is_left_hemisphere2 else 1) * hemisphere_size\n",
    "            \n",
    "            # Flip the connectivity edge between the specified pairs across hemispheres\n",
    "            new_matrix[index1, opposite_index2], new_matrix[index2, opposite_index1] = \\\n",
    "                new_matrix[index2, opposite_index1], new_matrix[index1, opposite_index2]\n",
    "            new_matrix[opposite_index2, index1], new_matrix[opposite_index1, index2] = \\\n",
    "                new_matrix[opposite_index1, index2], new_matrix[opposite_index2, index1]\n",
    "        \n",
    "        if vectorize_mat:\n",
    "            # Assuming 'sym_matrix_to_vec' is a function you have that vectorizes a symmetric matrix\n",
    "            new_matrix = sym_matrix_to_vec(new_matrix, discard_diagonal=True)\n",
    "        \n",
    "        flipped_matrices.append(new_matrix)\n",
    "        \n",
    "    return np.array(flipped_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.load(\"matrices.npy\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatData(Dataset):\n",
    "    def __init__(self, path_feat, path_target, target_name, transform = None, train=True, train_size = 0.8, test_size=None, region_pairs = None, random_state=42):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with the capability to handle training and testing splits, \n",
    "        including multiple views for augmented data.\n",
    "        \n",
    "        Args:\n",
    "            path_feat (str): Path to the features file.\n",
    "            path_target (str): Path to the target file.\n",
    "            transform (callable): A transformation function to apply for augmentation.\n",
    "            train (bool): Whether the dataset is used for training. False will load the test set.\n",
    "            test_size (float): Proportion of the dataset to include in the test split.\n",
    "            random_state (int): Random state for reproducible train-test splits.\n",
    "        \"\"\"\n",
    "        # Load the entire dataset\n",
    "        features = np.load(path_feat)\n",
    "        targets = np.expand_dims(pd.read_csv(path_target)[target_name].values, axis = 1)        \n",
    "\n",
    "        # Split the dataset into training and test sets\n",
    "        train_indices, test_indices = train_test_split(np.arange(len(features)), \n",
    "                                                       train_size = train_size,\n",
    "                                                       test_size=test_size,                \n",
    "                                                       random_state=random_state)\n",
    "        if train:\n",
    "            selected_indices = train_indices\n",
    "        else:\n",
    "            selected_indices = test_indices\n",
    "        \n",
    "        # Select the subset of data for the current mode (train/test)\n",
    "        features = features[selected_indices]\n",
    "        targets = targets[selected_indices]\n",
    "        \n",
    "\n",
    "        self.n_sub = len(features)\n",
    "        self.n_views = 1\n",
    "        self.transform = transform\n",
    "        self.targets = targets\n",
    "        \n",
    "        vectorized_feat = np.array([sym_matrix_to_vec(mat, discard_diagonal=True) for mat in features])\n",
    "        self.n_features = vectorized_feat.shape[-1]\n",
    "        \n",
    "        if (train and transform is not None):\n",
    "            # augmentation only in training mode\n",
    "            augmented_features = np.array([self.transform(sample, region_pairs = region_pairs) for sample in features])\n",
    "\n",
    "            self.n_views = self.n_views + augmented_features.shape[1]\n",
    "            self.features = np.zeros((self.n_sub, self.n_views, self.n_features))\n",
    "            for sub in range(self.n_sub):\n",
    "                self.features[sub, 0, :] = vectorized_feat[sub]\n",
    "                self.features[sub, 1:, :] = augmented_features[sub]\n",
    "        else:\n",
    "            self.features = np.expand_dims(vectorized_feat, axis = 1)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.n_sub\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features[idx]\n",
    "        targets = self.targets[idx]\n",
    "        features = torch.from_numpy(features).float()\n",
    "        targets = torch.from_numpy(targets).float()\n",
    "        \n",
    "        return features, targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dataset(dataset):\n",
    "    all_features_flat = torch.cat([dataset[i][0].view(-1, dataset[i][0].shape[-1]) for i in range(len(dataset))], dim=0)\n",
    "    all_targets = torch.cat([dataset[i][1].unsqueeze(0) for i in range(len(dataset))], dim=0)\n",
    "    \n",
    "    features_mean = all_features_flat.mean(dim=0)\n",
    "    features_std = all_features_flat.std(dim=0)\n",
    "    \n",
    "    features_std[features_std == 0] = 1\n",
    "    standardized_features_list = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        features = dataset[i][0].view(-1, dataset[i][0].shape[-1])\n",
    "        standardized_features = (features - features_mean) / features_std\n",
    "        standardized_features_list.append(standardized_features.view(dataset[i][0].shape))\n",
    "    \n",
    "    standardized_features = torch.stack(standardized_features_list)\n",
    "    \n",
    "    standardized_dataset = TensorDataset(standardized_features, all_targets)\n",
    "    \n",
    "    return standardized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, krnl_sigma):\n",
    "    x = x - x.T\n",
    "    return torch.exp(-(x**2) / (2*(krnl_sigma**2))) / (math.sqrt(2*torch.pi)*krnl_sigma)\n",
    "\n",
    "def cauchy(x, krnl_sigma):\n",
    "        x = x - x.T\n",
    "        return  1. / (krnl_sigma*(x**2) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs3/well/margulies/users/cpy397/contrastive-learning\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss from: https://github.com/EIDOSLAB/contrastive-brain-age-prediction/blob/master/src/losses.py\n",
    "# modified to accept input shape [bsz, n_feats]. In the age paper: [bsz, n_views, n_feats].\n",
    "class KernelizedSupCon(nn.Module):\n",
    "    \"\"\"Supervised contrastive loss: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\n",
    "    Based on: https://github.com/HobbitLong/SupContrast\"\"\"\n",
    "    def __init__(self, method: str, temperature: float=0.07, contrast_mode: str='all',\n",
    "                 base_temperature: float=0.07, krnl_sigma: float = 1., kernel: callable=None, delta_reduction: str='sum'):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "        self.method = method\n",
    "        self.kernel = kernel\n",
    "        self.krnl_sigma = krnl_sigma\n",
    "        self.delta_reduction = delta_reduction\n",
    "\n",
    "        if kernel is not None and method == 'supcon':\n",
    "            raise ValueError('Kernel must be none if method=supcon')\n",
    "        \n",
    "        if kernel is None and method != 'supcon':\n",
    "            raise ValueError('Kernel must not be none if method != supcon')\n",
    "\n",
    "        if delta_reduction not in ['mean', 'sum']:\n",
    "            raise ValueError(f\"Invalid reduction {delta_reduction}\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__} ' \\\n",
    "               f'(t={self.temperature}, ' \\\n",
    "               f'method={self.method}, ' \\\n",
    "               f'kernel={self.kernel is not None}, ' \\\n",
    "               f'delta_reduction={self.delta_reduction})'\n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        \"\"\"Compute loss for model. If `labels` is None, \n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, n_features]. \n",
    "                input has to be rearranged to [bsz, n_views, n_features] and labels [bsz],\n",
    "            labels: ground truth of shape [bsz].\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "\n",
    "        if len(features.shape) != 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, n_feats],'\n",
    "                             '3 dimensions are required')\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        n_views = features.shape[1]\n",
    "\n",
    "        if labels is None:\n",
    "            mask = torch.eye(batch_size, device=device)\n",
    "        \n",
    "        else:\n",
    "            labels = labels.view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            \n",
    "            if self.kernel is None:\n",
    "                mask = torch.eq(labels, labels.T)\n",
    "            else:\n",
    "                mask = self.kernel(labels, krnl_sigma = self.krnl_sigma)\n",
    "            \n",
    "        view_count = features.shape[1]\n",
    "        features = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            features = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            features = features\n",
    "            anchor_count = view_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # Tile mask\n",
    "        mask = mask.repeat(anchor_count, view_count)\n",
    "\n",
    "        # Inverse of torch-eye to remove self-contrast (diagonal)\n",
    "        inv_diagonal = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size*n_views, device=device).view(-1, 1),\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # compute similarity\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(features, features.T),\n",
    "            self.temperature\n",
    "        )\n",
    "\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        alignment = logits \n",
    "\n",
    "        # base case is:\n",
    "        # - supcon if kernel = none \n",
    "        # - y-aware is kernel != none\n",
    "        uniformity = torch.exp(logits) * inv_diagonal \n",
    "\n",
    "        if self.method == 'threshold':\n",
    "            repeated = mask.unsqueeze(-1).repeat(1, 1, mask.shape[0]) # repeat kernel mask\n",
    "\n",
    "            delta = (mask[:, None].T - repeated.T).transpose(1, 2) # compute the difference w_k - w_j for every k,j\n",
    "            delta = (delta > 0.).float()\n",
    "\n",
    "            # for each z_i, repel only samples j s.t. K(z_i, z_j) < K(z_i, z_k)\n",
    "            uniformity = uniformity.unsqueeze(-1).repeat(1, 1, mask.shape[0])\n",
    "\n",
    "            if self.delta_reduction == 'mean':\n",
    "                uniformity = (uniformity * delta).mean(-1)\n",
    "            else:\n",
    "                uniformity = (uniformity * delta).sum(-1)\n",
    "    \n",
    "        elif self.method == 'expw':\n",
    "            # exp weight e^(s_j(1-w_j))\n",
    "            uniformity = torch.exp(logits * (1 - mask)) * inv_diagonal\n",
    "\n",
    "        uniformity = torch.log(uniformity.sum(1, keepdim=True))\n",
    "\n",
    "\n",
    "        # positive mask contains the anchor-positive pairs\n",
    "        # excluding <self,self> on the diagonal\n",
    "        positive_mask = mask * inv_diagonal\n",
    "\n",
    "        log_prob = alignment - uniformity # log(alignment/uniformity) = log(alignment) - log(uniformity)\n",
    "        log_prob = (positive_mask * log_prob).sum(1) / positive_mask.sum(1) # compute mean of log-likelihood over positive\n",
    " \n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * log_prob\n",
    "        return loss.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim_feat = 499500 # vectorized mat, diagonal discarded\n",
    "# input_dim_target = 59\n",
    "# # the rest is arbitrary\n",
    "# hidden_dim_feat_1 = 1024\n",
    "# hidden_dim_feat_2 = 512\n",
    "# hidden_dim_target_1 = 24\n",
    "# hidden_dim_target_2 = 8\n",
    "# output_dim = 2\n",
    "# num_epochs = 1000\n",
    "\n",
    "input_dim_feat = 499500 # vectorized mat, diagonal discarded\n",
    "# the rest is arbitrary\n",
    "hidden_dim_feat = 1000\n",
    "input_dim_target = 1\n",
    "output_dim = 2\n",
    "num_epochs = 100\n",
    "\n",
    "lr = 0.001 # too low values return nan loss\n",
    "kernel = cauchy\n",
    "batch_size = 60 # too low values return nan loss\n",
    "dropout_rate = 0\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MatData(\"matrices.npy\", \"participants.csv\", \"age\", transform = flip_edge_between_regions, region_pairs = [374, 375],train_size = 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MatData(\"matrices.npy\", \"participants.csv\", \"age\", train=False, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_train_dataset = standardize_dataset(train_dataset)\n",
    "std_train_loader = DataLoader(standardized_train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_test_dataset = standardize_dataset(test_dataset)\n",
    "std_test_loader = DataLoader(standardized_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Mean Loss 10.268819662240835\n",
      "Epoch 1 | Mean Loss 9.72146254319411\n",
      "Epoch 2 | Mean Loss 9.510937177217924\n",
      "Epoch 3 | Mean Loss 9.469245323768028\n",
      "Epoch 4 | Mean Loss 9.454100095308744\n",
      "Epoch 5 | Mean Loss 9.448433362520658\n",
      "Epoch 6 | Mean Loss 9.446660335247334\n",
      "Epoch 7 | Mean Loss 9.444597537700947\n",
      "Epoch 8 | Mean Loss 9.443568082956167\n",
      "Epoch 9 | Mean Loss 9.442188336299015\n",
      "Epoch 10 | Mean Loss 9.441386589637169\n",
      "Epoch 11 | Mean Loss 9.440813798170824\n",
      "Epoch 12 | Mean Loss 9.440363737253042\n",
      "Epoch 13 | Mean Loss 9.439884112431454\n",
      "Epoch 14 | Mean Loss 9.43957967024583\n",
      "Epoch 15 | Mean Loss 9.439313961909367\n",
      "Epoch 16 | Mean Loss 9.43902008350079\n",
      "Epoch 17 | Mean Loss 9.438963890075684\n",
      "Epoch 18 | Mean Loss 9.438713660606972\n",
      "Epoch 19 | Mean Loss 9.438535396869366\n",
      "Epoch 20 | Mean Loss 9.43841552734375\n",
      "Epoch 21 | Mean Loss 9.438241665179913\n",
      "Epoch 22 | Mean Loss 9.438078880310059\n",
      "Epoch 23 | Mean Loss 9.43799040867732\n",
      "Epoch 24 | Mean Loss 9.437775905315693\n",
      "Epoch 25 | Mean Loss 9.437577394338755\n",
      "Epoch 26 | Mean Loss 9.437458551847017\n",
      "Epoch 27 | Mean Loss 9.437297600966234\n",
      "Epoch 28 | Mean Loss 9.437102757967436\n",
      "Epoch 29 | Mean Loss 9.436914664048414\n",
      "Epoch 30 | Mean Loss 9.436750118549053\n",
      "Epoch 31 | Mean Loss 9.436546178964468\n",
      "Epoch 32 | Mean Loss 9.436369015620304\n",
      "Epoch 33 | Mean Loss 9.43612920320951\n",
      "Epoch 34 | Mean Loss 9.435997889592098\n",
      "Epoch 35 | Mean Loss 9.435580620398888\n",
      "Epoch 36 | Mean Loss 9.435380642230694\n",
      "Epoch 37 | Mean Loss 9.434993817256046\n",
      "Epoch 38 | Mean Loss 9.434731483459473\n",
      "Epoch 39 | Mean Loss 9.43439190204327\n",
      "Epoch 40 | Mean Loss 9.434101691612831\n",
      "Epoch 41 | Mean Loss 9.433715086716871\n",
      "Epoch 42 | Mean Loss 9.433208538935734\n",
      "Epoch 43 | Mean Loss 9.432584909292368\n",
      "Epoch 44 | Mean Loss 9.432109319246733\n",
      "Epoch 45 | Mean Loss 9.43145619905912\n",
      "Epoch 46 | Mean Loss 9.430799264174242\n",
      "Epoch 47 | Mean Loss 9.429944771986742\n",
      "Epoch 48 | Mean Loss 9.429186160747822\n",
      "Epoch 49 | Mean Loss 9.427923055795523\n",
      "Epoch 50 | Mean Loss 9.426541255070614\n",
      "Epoch 51 | Mean Loss 9.424903796269344\n",
      "Epoch 52 | Mean Loss 9.422603680537296\n",
      "Epoch 53 | Mean Loss 9.419952172499437\n",
      "Epoch 54 | Mean Loss 9.415223891918476\n",
      "Epoch 55 | Mean Loss 9.409385937910814\n",
      "Epoch 56 | Mean Loss 9.397842480586124\n",
      "Epoch 57 | Mean Loss 9.372695519373966\n",
      "Epoch 58 | Mean Loss 9.292978653540978\n",
      "Epoch 59 | Mean Loss 8.923424207247221\n",
      "Epoch 60 | Mean Loss 8.616068069751446\n",
      "Epoch 61 | Mean Loss 8.568806281456581\n",
      "Epoch 62 | Mean Loss 8.541476359734169\n",
      "Epoch 63 | Mean Loss 8.550643517420841\n",
      "Epoch 64 | Mean Loss 8.561836095956656\n",
      "Epoch 65 | Mean Loss 8.547941464644213\n",
      "Epoch 66 | Mean Loss 8.553188910851112\n",
      "Epoch 67 | Mean Loss 8.559954129732573\n",
      "Epoch 68 | Mean Loss 8.555519580841064\n",
      "Epoch 69 | Mean Loss 8.561817792745737\n",
      "Epoch 70 | Mean Loss 8.553708296555738\n",
      "Epoch 71 | Mean Loss 8.552600420438326\n",
      "Epoch 72 | Mean Loss 8.541434434744028\n",
      "Epoch 73 | Mean Loss 8.56035404938918\n",
      "Epoch 74 | Mean Loss 8.545314495380108\n",
      "Epoch 75 | Mean Loss 8.546032208662767\n",
      "Epoch 76 | Mean Loss 8.553771385779747\n",
      "Epoch 77 | Mean Loss 8.568172051356388\n",
      "Epoch 78 | Mean Loss 8.54226383796105\n",
      "Epoch 79 | Mean Loss 8.557742192195011\n",
      "Epoch 80 | Mean Loss 8.552181830772987\n",
      "Epoch 81 | Mean Loss 8.545340281266432\n",
      "Epoch 82 | Mean Loss 8.55311606480525\n",
      "Epoch 83 | Mean Loss 8.549706018888033\n",
      "Epoch 84 | Mean Loss 8.545547852149376\n",
      "Epoch 85 | Mean Loss 8.54237413406372\n",
      "Epoch 86 | Mean Loss 8.553285892193134\n",
      "Epoch 87 | Mean Loss 8.53979781957773\n",
      "Epoch 88 | Mean Loss 8.5629180761484\n",
      "Epoch 89 | Mean Loss 8.550679060129019\n",
      "Epoch 90 | Mean Loss 8.558837487147404\n",
      "Epoch 91 | Mean Loss 8.552017175234282\n",
      "Epoch 92 | Mean Loss 8.55487640087421\n",
      "Epoch 93 | Mean Loss 8.547949350797213\n",
      "Epoch 94 | Mean Loss 8.552634532635029\n",
      "Epoch 95 | Mean Loss 8.548380888425386\n",
      "Epoch 96 | Mean Loss 8.545765766730675\n",
      "Epoch 97 | Mean Loss 8.550986950214092\n",
      "Epoch 98 | Mean Loss 8.551322863652157\n",
      "Epoch 99 | Mean Loss 8.553771275740404\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "model = MLP(input_dim_feat, input_dim_target, hidden_dim_feat, output_dim, dropout_rate).to(device)\n",
    "criterion_pft = KernelizedSupCon(method='expw', temperature=1, base_temperature=1, kernel=kernel, krnl_sigma = 3)\n",
    "criterion_ptt = KernelizedSupCon(method='expw', temperature=0.07, base_temperature=0.07, kernel=kernel, krnl_sigma = 3)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batch_losses = []\n",
    "    for batch_num, (features, targets) in enumerate(std_train_loader):\n",
    "        bsz = targets.shape[0]\n",
    "        n_views = features.shape[1]\n",
    "        n_feat = features.shape[-1]\n",
    "        \n",
    "        features = features.view(bsz * n_views, n_feat) # [bsz*2, 499500]\n",
    "        features, targets = features.to(device), targets.to(device) # [bsz, 2, 499500], [bsz, 1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out_feat, out_target = model(features, torch.cat(n_views*[targets], dim=0)) # ([bsz*5, 1], [bsz*5, 1])\n",
    "        \n",
    "        out_feat = torch.split(out_feat, [bsz]*n_views, dim=0)\n",
    "        out_feat = torch.cat([f.unsqueeze(1) for f in out_feat], dim=1) # [bsz, 5, 2]\n",
    "        \n",
    "        loss = criterion_pft(out_feat, targets) # ([bsz, 5, 2], [bsz, 1])\n",
    "        \n",
    "        out_target = torch.split(out_target, [bsz]*n_views, dim=0)\n",
    "        out_target = torch.cat([f.unsqueeze(1) for f in out_target], dim=1) # [bsz, 2, 2]\n",
    "        loss += criterion_ptt(out_target, targets) # ([bsz, 5, 2], [bsz, 1])\n",
    "        loss += torch.nn.functional.mse_loss(out_feat.view(bsz * n_views, 2), out_target.view(bsz * n_views, 2)) # mse_loss([bsz*2, 2], [bsz*2, 2])\n",
    "    \n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        batch_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch} | Mean Loss {sum(batch_losses)/len(batch_losses)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target estimator\n",
      "Training target estimator\n",
      "1.3085256 6.821486429831047e-06\n"
     ]
    }
   ],
   "source": [
    "mape_train, _ = compute_target_score(model, std_train_loader, std_test_loader, device, 'mape')\n",
    "r2_train, _ = compute_target_score(model, std_train_loader, std_test_loader, device, 'r2')\n",
    "# results_cv.append(['Overall', mape_train, r2_train, mape_val, r2_val])\n",
    "print(mape_train, r2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(results_cv, columns=['Fold', 'Train_MAPE', 'Train_R2', 'Val_MAPE', 'Val_R2'])\n",
    "# results_df.to_csv('cv_results_hopkins.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "# features = torch.vstack([test_dataset[i][0] for i in range(len(test_loader))])\n",
    "# targets = torch.vstack([test_dataset[i][1] for i in range(len(test_loader))])\n",
    "# features_mean, features_std, targets_mean, targets_std = compute_global_stats(test_dataset)\n",
    "# standardized_features = (features - features_mean) / features_std\n",
    "# standardized_targets = (targets - targets_mean) / targets_std\n",
    "# standardized_test_dataset = TensorDataset(standardized_features, standardized_targets)\n",
    "# test_loader = DataLoader(standardized_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Loss:   7.21\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_losses = []\n",
    "emb_features = [] # saving the embedded features for each batch\n",
    "emb_targets = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    for batch_num, (features, targets) in enumerate(std_test_loader):\n",
    "        bsz = targets.shape[0]\n",
    "        n_views = 1\n",
    "        n_feat = features.shape[-1]\n",
    "        \n",
    "        if len(features.shape) > 2:\n",
    "            n_views = features.shape[1]\n",
    "            features = features.view(bsz * n_views, n_feat) # [bsz*2, 499500]\n",
    "        features, targets = features.to(device), targets.to(device) # [bsz, 2, 499500], [bsz, 1]\n",
    "\n",
    "        out_feat, out_target = model(features, torch.cat(n_views*[targets], dim=0))   \n",
    "        \n",
    "        out_feat = torch.split(out_feat, [bsz]*n_views, dim=0)\n",
    "        out_feat = torch.cat([f.unsqueeze(1) for f in out_feat], dim=1) # [bsz, 5, 2]\n",
    "        \n",
    "        loss = criterion_pft(out_feat, targets) # ([bsz, 5, 2], [bsz, 1])\n",
    "        \n",
    "        out_target = torch.split(out_target, [bsz]*n_views, dim=0)\n",
    "        out_target = torch.cat([f.unsqueeze(1) for f in out_target], dim=1) # [bsz, 2, 2]\n",
    "        \n",
    "        loss += criterion_ptt(out_target, targets) # ([bsz, 5, 2], [bsz, 1])\n",
    "        loss += torch.nn.functional.mse_loss(out_feat.view(bsz * n_views, 2), out_target.view(bsz * n_views, 2)) # mse_loss([bsz*2, 2], [bsz*2, 2])\n",
    "        \n",
    "        emb_features.append(out_feat[:, 0, :])\n",
    "        emb_targets.append(out_target[:, 0, :])\n",
    "        \n",
    "        test_losses.append(loss.item())\n",
    "        total_loss += loss.item() * features.size(0)\n",
    "        total_samples += features.size(0)\n",
    "        \n",
    "    test_losses =np.array(test_losses)\n",
    "    average_loss = total_loss / total_samples\n",
    "    print('Mean Test Loss: %6.2f' % (average_loss))\n",
    "    #np.save(f\"losses/test_losses_batch{batch_num}.npy\", test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_features = torch.row_stack(emb_features).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_targets = torch.row_stack(emb_targets).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_features = pd.DataFrame(emb_features,columns = [\"Dim_1\", \"Dim_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_targets = pd.DataFrame(emb_targets,columns = [\"Dim_1\", \"Dim_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_features[\"sub\"] = np.arange(1, len(emb_features) +1)\n",
    "emb_targets[\"sub\"] = np.arange(1, len(emb_targets) +1)\n",
    "emb_features[\"Type\"] = 'Features'\n",
    "emb_targets[\"Type\"] = 'Targets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc7a07dd520>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# time to cry\n",
    "# I probably messed up the original loss. Went over it multiple times\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "sns.scatterplot(emb_features, x = 'Dim_1', y = 'Dim_2', s = 100, alpha = 0.8, hue = 'sub', palette = 'nipy_spectral', label='Features')\n",
    "sns.scatterplot(emb_targets, x = 'Dim_1', marker = 'v', y = 'Dim_2', s = 100, alpha = 0.8, hue = 'sub', palette = 'nipy_spectral', label='Targets')\n",
    "plt.xlim(-1.2, 1.2)\n",
    "plt.ylim(-1.2, 1.2)\n",
    "\n",
    "feature_handle = mlines.Line2D([], [], color='black', marker='o', linestyle='None', markersize=10, label='Features')\n",
    "target_handle = mlines.Line2D([], [], color='black', marker='v', linestyle='None', markersize=10, label='Targets')\n",
    "\n",
    "plt.legend(handles=[feature_handle, target_handle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
