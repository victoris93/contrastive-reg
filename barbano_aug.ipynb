{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nilearn.connectome import sym_matrix_to_vec\n",
    "from cmath import isinf\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "from utils_v import compute_target_score, estimate_target, save_model, standardize_dataset\n",
    "from cmath import isinf\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split, KFold, LearningCurveDisplay, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "from helper_classes import MatData, MLP\n",
    "from dev_losses import cauchy, rbf, gaussian_kernel, CustomSupCon, CustomContrastiveLoss\n",
    "from losses import KernelizedSupCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_conn(matrix, region_indices, vecrorize_mat = True):\n",
    "    \"\"\"\n",
    "    Flips the connectivity of specified regions within their hemispheres. Handles both single indices and lists of indices.\n",
    "    \n",
    "    :param matrix: The connectivity matrix.\n",
    "    :param region_indices: A single index or a list of indices for the regions.\n",
    "    :return: A 3D array of modified connectivity matrices. Each \"slice\" corresponds to the matrix after flipping each specified region.\n",
    "    \"\"\"\n",
    "    # Ensure region_indices is a list to simplify processing\n",
    "    if not isinstance(region_indices, list):\n",
    "        region_indices = [region_indices]\n",
    "    \n",
    "    flipped_matrices = []\n",
    "    \n",
    "    for index in region_indices:\n",
    "        new_matrix = matrix.copy()\n",
    "        hemisphere_size = matrix.shape[0] // 2\n",
    "        is_left_hemisphere = index < hemisphere_size\n",
    "        opposite_index = index + (-1 if is_left_hemisphere else 1) * hemisphere_size\n",
    "\n",
    "        # Flip connectivity for the specified region within its hemisphere\n",
    "        if is_left_hemisphere:\n",
    "            new_matrix[index, :hemisphere_size], new_matrix[opposite_index, :hemisphere_size] = \\\n",
    "                new_matrix[opposite_index, :hemisphere_size].copy(), new_matrix[index, :hemisphere_size].copy()\n",
    "        else:\n",
    "            new_matrix[index, hemisphere_size:], new_matrix[opposite_index, hemisphere_size:] = \\\n",
    "                new_matrix[opposite_index, hemisphere_size:].copy(), new_matrix[index, hemisphere_size:].copy()\n",
    "            \n",
    "        if vecrorize_mat:\n",
    "            new_matrix = sym_matrix_to_vec(new_matrix, discard_diagonal = True)\n",
    "        flipped_matrices.append(new_matrix)\n",
    "        \n",
    "    return np.array(flipped_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatData(Dataset):\n",
    "    def __init__(self, path_feat, path_target, target_name, transform = None, train=True, train_size = 0.8, test_size=None, region_indices = None, random_state=42):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with the capability to handle training and testing splits, \n",
    "        including multiple views for augmented data.\n",
    "        \n",
    "        Args:\n",
    "            path_feat (str): Path to the features file.\n",
    "            path_target (str): Path to the target file.\n",
    "            transform (callable): A transformation function to apply for augmentation.\n",
    "            train (bool): Whether the dataset is used for training. False will load the test set.\n",
    "            test_size (float): Proportion of the dataset to include in the test split.\n",
    "            random_state (int): Random state for reproducible train-test splits.\n",
    "        \"\"\"\n",
    "        # Load the entire dataset\n",
    "        features = np.load(path_feat)\n",
    "        targets = pd.read_csv(path_target)[target_name].values\n",
    "        \n",
    "\n",
    "        # Split the dataset into training and test sets\n",
    "        train_indices, test_indices = train_test_split(np.arange(len(features)), \n",
    "                                                       train_size = train_size,\n",
    "                                                       test_size=test_size,                \n",
    "                                                       random_state=random_state)\n",
    "        \n",
    "        if train:\n",
    "            selected_indices = train_indices\n",
    "        else:\n",
    "            selected_indices = test_indices\n",
    "        \n",
    "        # Select the subset of data for the current mode (train/test)\n",
    "        features = features[selected_indices]\n",
    "        targets = targets[selected_indices]\n",
    "        \n",
    "\n",
    "        self.n_sub = len(features)\n",
    "        self.n_views = 1\n",
    "        self.transform = transform\n",
    "        self.targets = targets\n",
    "        \n",
    "        vectorized_feat = np.array([sym_matrix_to_vec(mat, discard_diagonal=True) for mat in features])\n",
    "        self.n_features = vectorized_feat.shape[-1]\n",
    "        \n",
    "        if train:\n",
    "            # augmentation only in training mode\n",
    "            augmented_features = np.array([self.transform(sample, region_indices = region_indices) for sample in features])\n",
    "            print(augmented_features.shape)\n",
    "\n",
    "            self.n_views = self.n_views + augmented_features.shape[1]\n",
    "            print(augmented_features.shape[0] == self.n_sub)\n",
    "            self.features = np.zeros((self.n_sub, self.n_views, self.n_features))\n",
    "            print(self.features.shape)\n",
    "            for sub in range(self.n_sub):\n",
    "                self.features[sub, 0, :] = vectorized_feat[sub]\n",
    "                self.features[sub, 1:, :] = augmented_features[sub]\n",
    "        else:\n",
    "            self.features = vectorized_feat\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.n_sub\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features[idx]\n",
    "        targets = self.targets[idx]\n",
    "        features = torch.from_numpy(features).float()\n",
    "        targets = torch.from_numpy(targets).float()\n",
    "        \n",
    "        return features, targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, krnl_sigma):\n",
    "    x = x - x.T\n",
    "    return torch.exp(-(x**2) / (2*(krnl_sigma**2))) / (math.sqrt(2*torch.pi)*krnl_sigma)\n",
    "\n",
    "def cauchy(x, krnl_sigma):\n",
    "        x = x - x.T\n",
    "        return  1. / (krnl_sigma*(x**2) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs3/well/margulies/users/cpy397/contrastive-learning\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748, 4, 499500)\n",
      "True\n",
      "(748, 5, 499500)\n"
     ]
    }
   ],
   "source": [
    "dataset = MatData(\"matrices.npy\", \"participants.csv\", 'age', transform = mirror_conn, region_indices = [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split(np.arange(len(dataset)), test_size = 0.2, random_state=42) #train_size = 5\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 499500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelizedSupCon(nn.Module):\n",
    "    \"\"\"Supervised contrastive loss: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\n",
    "    Based on: https://github.com/HobbitLong/SupContrast\"\"\"\n",
    "    def __init__(self, method: str, krnl_sigma = None, temperature: float=0.07, contrast_mode: str='all',\n",
    "                 base_temperature: float=0.07, kernel: callable=None, delta_reduction: str='sum'):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "        self.method = method\n",
    "        self.kernel = kernel\n",
    "        self.delta_reduction = delta_reduction\n",
    "        self.krnl_sigma = krnl_sigma\n",
    "\n",
    "        if kernel is not None and method == 'supcon':\n",
    "            raise ValueError('Kernel must be none if method=supcon')\n",
    "        \n",
    "        if kernel is None and method != 'supcon':\n",
    "            raise ValueError('Kernel must not be none if method != supcon')\n",
    "\n",
    "        if delta_reduction not in ['mean', 'sum']:\n",
    "            raise ValueError(f\"Invalid reduction {delta_reduction}\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__} ' \\\n",
    "               f'(t={self.temperature}, ' \\\n",
    "               f'method={self.method}, ' \\\n",
    "               f'kernel={self.kernel is not None}, ' \\\n",
    "               f'delta_reduction={self.delta_reduction}, ' \\\n",
    "               f'krnl_sigma={self.krnl_sigma}'\n",
    "                \n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        \"\"\"Compute loss for model. If `labels` is None, \n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, n_features]. \n",
    "                input has to be rearranged to [bsz, n_views, n_features] and labels [bsz],\n",
    "            labels: ground truth of shape [bsz].\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "\n",
    "        if len(features.shape) != 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, n_feats],'\n",
    "                             '3 dimensions are required')\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        n_views = features.shape[1]\n",
    "\n",
    "        if labels is None:\n",
    "            mask = torch.eye(batch_size, device=device)\n",
    "        \n",
    "        else:\n",
    "            # labels = labels.view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError(f'Num of labels does not match num of features: {labels.shape[0]} vs. {batch_size}')\n",
    "            \n",
    "            if self.kernel is None:\n",
    "                mask = torch.eq(labels, labels.T)\n",
    "            else:\n",
    "                mask = self.kernel(labels, self.krnl_sigma)\n",
    "            \n",
    "        view_count = features.shape[1]\n",
    "        features = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            features = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            features = features\n",
    "            anchor_count = view_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # Tile mask\n",
    "        mask = mask.repeat(anchor_count, view_count)\n",
    "\n",
    "        # Inverse of torch-eye to remove self-contrast (diagonal)\n",
    "        inv_diagonal = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size*n_views, device=device).view(-1, 1),\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # compute similarity\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(features, features.T),\n",
    "            self.temperature\n",
    "        )\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "        alignment = logits \n",
    "\n",
    "        # base case is:\n",
    "        # - supcon if kernel = none \n",
    "        # - y-aware is kernel != none\n",
    "        uniformity = torch.exp(logits) * inv_diagonal \n",
    "\n",
    "        if self.method == 'threshold':\n",
    "            repeated = mask.unsqueeze(-1).repeat(1, 1, mask.shape[0]) # repeat kernel mask\n",
    "\n",
    "            delta = (mask[:, None].T - repeated.T).transpose(1, 2) # compute the difference w_k - w_j for every k,j\n",
    "            delta = (delta > 0.).float()\n",
    "\n",
    "            # for each z_i, repel only samples j s.t. K(z_i, z_j) < K(z_i, z_k)\n",
    "            uniformity = uniformity.unsqueeze(-1).repeat(1, 1, mask.shape[0])\n",
    "\n",
    "            if self.delta_reduction == 'mean':\n",
    "                uniformity = (uniformity * delta).mean(-1)\n",
    "            else:\n",
    "                uniformity = (uniformity * delta).sum(-1)\n",
    "    \n",
    "        elif self.method == 'expw':\n",
    "            # exp weight e^(s_j(1-w_j))\n",
    "            uniformity = torch.exp(logits * (1 - mask)) * inv_diagonal\n",
    "\n",
    "        uniformity = torch.log(uniformity.sum(1, keepdim=True))\n",
    "        # positive mask contains the anchor-positive pairs\n",
    "        # excluding <self,self> on the diagonal\n",
    "        positive_mask = mask * inv_diagonal\n",
    "\n",
    "        log_prob = alignment - uniformity # log(alignment/uniformity) = log(alignment) - log(uniformity)\n",
    "        log_prob = (positive_mask * log_prob).sum(1) / positive_mask.sum(1) # compute mean of log-likelihood over positive\n",
    " \n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * log_prob\n",
    "        return loss.mean()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim_feat = 499500 # vectorized mat, diagonal discarded\n",
    "# input_dim_target = 59\n",
    "# # the rest is arbitrary\n",
    "# hidden_dim_feat_1 = 1024\n",
    "# hidden_dim_feat_2 = 512\n",
    "# hidden_dim_target_1 = 24\n",
    "# hidden_dim_target_2 = 8\n",
    "# output_dim = 2\n",
    "# num_epochs = 1000\n",
    "\n",
    "input_dim_feat = 499500 # vectorized mat, diagonal discarded\n",
    "input_dim_target = 60\n",
    "# the rest is arbitrary\n",
    "hidden_dim_feat = 100\n",
    "hidden_dim_target = 30\n",
    "output_dim = 2\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "temperature = 0.07\n",
    "base_temperature = 0.07 # too low values return nan loss\n",
    "\n",
    "lr = 0.04280208745038064 # too low values return nan loss\n",
    "kernel = gaussian_kernel\n",
    "batch_size = 10 # too low values return nan loss\n",
    "dropout_rate = 0\n",
    "weight_decay = 0.00798804871363378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_train_dataset = standardize_dataset(train_dataset)\n",
    "std_train_loader = DataLoader(standardized_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "standardized_test_dataset = standardize_dataset(test_dataset)\n",
    "std_test_loader = DataLoader(standardized_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Mean Loss 11.688053369522095\n",
      "Epoch 1 | Mean Loss 5.749300996462504\n",
      "Epoch 2 | Mean Loss 5.354528506596883\n",
      "Epoch 3 | Mean Loss 5.226688106854756\n",
      "Epoch 4 | Mean Loss 5.292391101519267\n",
      "Epoch 5 | Mean Loss 5.220405101776123\n",
      "Epoch 6 | Mean Loss 5.220960060755412\n",
      "Epoch 7 | Mean Loss 5.2125939925511675\n",
      "Epoch 8 | Mean Loss 5.2051611344019575\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     batch_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 25\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Mean Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(batch_losses)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch_losses)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/adam.py:385\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    384\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 385\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    388\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = MLP(input_dim_feat, input_dim_target, hidden_dim_feat, hidden_dim_target, output_dim, dropout_rate = dropout_rate).to(device)\n",
    "criterion_pft = KernelizedSupCon(method='expw', temperature=0.01, base_temperature=0.01, kernel=kernel, krnl_sigma = 3)\n",
    "criterion_ptt = KernelizedSupCon(method='expw', temperature=0.04, base_temperature=0.04, kernel=kernel, krnl_sigma = 3)\n",
    "\n",
    "# criterion = CustomKernelizedSupCon(temperature = temperature, base_temperature = base_temperature, kernel = kernel)\n",
    "# criterion = CustomSupCon('exp',temperature = temperature, base_temperature = base_temperature, kernel = kernel)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batch_losses = []\n",
    "    for batch_num, (features, targets) in enumerate(std_train_loader):\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out_feat, out_target = model(features, targets)\n",
    "        loss = criterion_pft(out_feat.unsqueeze(1), targets)\n",
    "        loss += criterion_ptt(out_target.unsqueeze(1), targets)\n",
    "        # loss += torch.nn.functional.hinge_embedding_loss(out_feat, out_target)\n",
    "        loss += torch.nn.functional.mse_loss(out_feat, out_target)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        batch_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch} | Mean Loss {sum(batch_losses)/len(batch_losses)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target estimator\n",
      "Training target estimator\n",
      "1.4873439 1.1315570863534852e-05\n"
     ]
    }
   ],
   "source": [
    "mape_train, _ = compute_target_score(model, std_train_loader, std_test_loader, device, 'mape')\n",
    "r2_train, _ = compute_target_score(model, std_train_loader, std_test_loader, device, 'r2')\n",
    "# results_cv.append(['Overall', mape_train, r2_train, mape_val, r2_val])\n",
    "print(mape_train, r2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(results_cv, columns=['Fold', 'Train_MAPE', 'Train_R2', 'Val_MAPE', 'Val_R2'])\n",
    "# results_df.to_csv('cv_results_hopkins.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "# features = torch.vstack([test_dataset[i][0] for i in range(len(test_loader))])\n",
    "# targets = torch.vstack([test_dataset[i][1] for i in range(len(test_loader))])\n",
    "# features_mean, features_std, targets_mean, targets_std = compute_global_stats(test_dataset)\n",
    "# standardized_features = (features - features_mean) / features_std\n",
    "# standardized_targets = (targets - targets_mean) / targets_std\n",
    "# standardized_test_dataset = TensorDataset(standardized_features, standardized_targets)\n",
    "# test_loader = DataLoader(standardized_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Loss:   2.20\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_losses = []\n",
    "emb_features = [] # saving the embedded features for each batch\n",
    "emb_targets = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    for batch_num, (features, targets) in enumerate(std_train_loader):\n",
    "        features = features.to(device).float()\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        out_feat, out_target = model(features, targets)\n",
    "        emb_features.append(out_feat.cpu())\n",
    "        emb_targets.append(out_target.cpu())\n",
    "        loss = criterion_pft(out_feat.unsqueeze(1), out_target)\n",
    "        test_losses.append(loss.item())\n",
    "        total_loss += loss.item() * features.size(0)\n",
    "        total_samples += features.size(0)\n",
    "        \n",
    "    test_losses =np.array(test_losses)\n",
    "    average_loss = total_loss / total_samples\n",
    "    print('Mean Test Loss: %6.2f' % (average_loss))\n",
    "    #np.save(f\"losses/test_losses_batch{batch_num}.npy\", test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_features = torch.row_stack(emb_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_targets = torch.row_stack(emb_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_features = pd.DataFrame(emb_features,columns = [\"Dim_1\", \"Dim_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_targets = pd.DataFrame(emb_targets,columns = [\"Dim_1\", \"Dim_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_features[\"sub\"] = np.arange(1, len(emb_features) +1)\n",
    "emb_targets[\"sub\"] = np.arange(1, len(emb_targets) +1)\n",
    "emb_features[\"Type\"] = 'Features'\n",
    "emb_targets[\"Type\"] = 'Targets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/gpfs3/well/margulies/users/cpy397/.local/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0444f01280>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAGxCAYAAABhi7IUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2hUlEQVR4nO3de3RU9b3//9eeSTK5MQmXkEkkXCIIihjuGKpFNBoQrXhopciSwOJyaKtyUSl4LBRvWCsUsXjw1CWprVbxfEH9IWI1SuV2EJEAAlLuIJCEWzK5kcvM/v1BmRIhIQmZTCb7+Vhrr5W95/OZee9s4rz87M/e2zBN0xQAAIBF2QJdAAAAQCARhgAAgKURhgAAgKURhgAAgKURhgAAgKURhgAAgKURhgAAgKURhgAAgKWFBLqAps7r9er48eNq0aKFDMMIdDkAAKAWTNNUYWGhEhMTZbPVPPZDGLqC48ePKykpKdBlAACAejh69KjatWtXYxvC0BW0aNFC0vlfptPpDHA1AACgNtxut5KSknzf4zUhDF3BhVNjTqeTMAQAQJCpzRQXJlADAABLIwwBAABLIwwBAABLY84QAAAX8Xg8qqioCHQZuILQ0FDZ7fYGeS/CEAAAOn9fmpycHOXn5we6FNRSbGysXC7XVd8HkDAEAIDkC0Jt27ZVZGQkN9ptwkzTVElJifLy8iRJCQkJV/V+hCEAgOV5PB5fEGrdunWgy0EtRERESJLy8vLUtm3bqzplxgRqAIDlXZgjFBkZGeBKUBcXjtfVzvFiZAgAgH9piFNjpmnq9OnTKioqUnR0tFq3bs0pNz9pqN8rI0MAADSA/Px8vfzyy+rSpYvi4uLUqVMnxcXFqUuXLnr55ZeZmN2EEYYAALhKn3zyidq1a6dp06bpwIEDVV47cOCApk2bpnbt2umTTz4JUIWoCWEIAICr8Mknn2jYsGEqLS2VaZoyTbPK6xe2lZaWatiwYQ0eiMaOHSvDMC5Z9u3bd9XvnZmZqdjY2KsvsokjDAEAUE/5+fkaMWKETNOU1+utsa3X65VpmhoxYkSDnzIbMmSITpw4UWXp1KlTg37G1WrKN7IkDAEAUE9//vOfVVJScsUgdIHX61VJSYnefPPNBq3D4XDI5XJVWex2uz744AP17t1b4eHhSk5O1ty5c1VZWenrt2DBAvXo0UNRUVFKSkrSL3/5SxUVFUmS1qxZo3HjxqmgoMA32vTb3/5W0vmJy++//36VGmJjY5WZmSlJOnTokAzD0LvvvqtBgwYpPDxcb731liTp9ddf1/XXX6/w8HB169ZNr776qu89ysvL9fDDDyshIUHh4eHq0KGD5s2b16C/q8vhajIAAOrBNE298sor9eq7aNEiPfLII369ymzt2rUaM2aMFi1apFtvvVX79+/XpEmTJElz5syRJNlsNi1atEidOnXSgQMH9Mtf/lIzZszQq6++qoEDB2rhwoWaPXu29uzZI0mKjo6uUw0zZ87U/Pnz1atXL18gmj17tv74xz+qV69e2rp1qyZOnKioqChlZGRo0aJF+vDDD7Vs2TK1b99eR48e1dGjRxv2F3MZhCEAAOrh9OnT2r9/f537maap/fv368yZMw12g8eVK1dWCSpDhw7V2bNnNXPmTGVkZEiSkpOT9cwzz2jGjBm+MDR16lRfn44dO+rZZ5/V5MmT9eqrryosLEwxMTEyDEMul6tedU2dOlX/8R//4VufM2eO5s+f79vWqVMn7dq1S6+99poyMjJ05MgRdenSRbfccosMw1CHDh3q9bl1RRgCAKAeLpxOqq/CwsIGC0ODBw/Wf//3f/vWo6KidNNNN2n9+vV67rnnfNs9Ho/OnTunkpISRUZG6rPPPtO8efP03Xffye12q7KyssrrV6tv376+n4uLi7V//36NHz9eEydO9G2vrKxUTEyMpPOTwe+880517dpVQ4YM0T333KO77rrrquu4EsIQAAD1UNdTRj/UokWLBqrkfPjp3LlzlW1FRUWaO3dulZGZC8LDw3Xo0CHdc889+sUvfqHnnntOrVq10rp16zR+/HiVl5fXGIYMw7jkqrnLTZCOioqqUo8k/elPf9KAAQOqtLvwKI3evXvr4MGD+vjjj/XZZ5/pgQceUFpamv73f//3Cr+Bq0MYAgCgHlq3bq1rr71WBw4cuCQY1MQwDCUnJ6tVq1Z+rO58sNizZ88lIemCLVu2yOv1av78+bLZzl9PtWzZsiptwsLC5PF4LukbFxenEydO+Nb37t2rkpKSGuuJj49XYmKiDhw4oNGjR1fbzul0auTIkRo5cqR++tOfasiQITpz5oxff1+EIQAA6sEwDD3yyCOaNm1anfs++uijfn9Ex+zZs3XPPfeoffv2+ulPfyqbzaZt27bp22+/1bPPPqvOnTuroqJCr7zyiu69916tX79eS5YsqfIeHTt2VFFRkbKyspSSkqLIyEhFRkbq9ttv1x//+EelpqbK4/Ho17/+tUJDQ69Y09y5c/Xoo48qJiZGQ4YMUVlZmb7++mudPXtW06dP14IFC5SQkKBevXrJZrPpvffek8vl8vu9jri0HgCAesrIyFBkZKRvZOVKbDabIiMjNWbMGD9XJqWnp2vlypX6+9//rn79+unmm2/WH/7wB9+k5JSUFC1YsEC/+93vdOONN+qtt9665DL2gQMHavLkyRo5cqTi4uL04osvSpLmz5+vpKQk3XrrrXrwwQf1+OOP12qO0YQJE/T6669r6dKl6tGjhwYNGqTMzEzfPZFatGihF198UX379lW/fv106NAhrVq1qta/3/oyzLqM7VmQ2+1WTEyMCgoK5HQ6A10OAMAPzp07p4MHD6pTp04KDw+vU98Ld6C+0o0XbTabDMPQqlWrGmVSsBXUdNzq8v3NyBAAAFchPT1dH330kSIiInw3J7zYhW0REREEoSYqqMLQl19+qXvvvVeJiYmXvfvl5axZs0a9e/eWw+FQ586dfXfHBACgoaSnp+v777/XwoULlZycXOW15ORkLVy4UMeOHSMINVFBFYaKi4uVkpKixYsX16r9wYMHNWzYMA0ePFjZ2dmaOnWqJkyYwFODAQANLjY2Vo8++qj27t2rU6dO6eDBgzp16pT27t3rmzSMpimoriYbOnSohg4dWuv2S5YsUadOnTR//nxJ0vXXX69169bpD3/4g9LT0/1VJgDAwgzDUOvWrRvshorwv6AaGaqrjRs3Ki0trcq29PR0bdy4MUAVAQCApiaoRobqKicnR/Hx8VW2xcfHy+12q7S0VBEREZf0KSsrU1lZmW/d7Xb7vU4AABA4zXpkqD7mzZunmJgY35KUlBTokgAAgB8165Ehl8ul3NzcKttyc3PldDovOyokSbNmzdL06dN96263m0AEALiso0eP6uTJk3Xu17ZtW7Vr184PFaE+mnUYSk1N1apVq6ps+/TTT5WamlptH4fDIYfD4e/SAABBrqysTP369bvkf7prw+Vy6dChQ3zfNBFBdZqsqKhI2dnZys7OlnT+0vns7GwdOXJE0vlRnYtvcT558mQdOHBAM2bM0HfffadXX31Vy5Ytq9dzZAAAuFhYWJjat29f50dF2Gw2JSUlKSws7KpruHBDx+qW3/72t1f9GVdTW23uB9gUBNXI0Ndff63Bgwf71i+czsrIyFBmZqZOnDjhC0aS1KlTJ3300UeaNm2aXn75ZbVr106vv/46l9UDAK6aYRh65plnNGTIkDr183q9euaZZxrkQa0XPzn+3Xff1ezZs7Vnzx7ftujo6Dq9X3l5eYOEtGATVCNDt912m0zTvGS5cFfpzMxMrVmz5pI+W7duVVlZmfbv36+xY8c2et0AgObprrvuUr9+/WS322vV3m63q1+/fg12J2qXy+VbYmJiZBiGb724uFijR49WfHy8oqOj1a9fP3322WdV+nfs2FHPPPOMxowZI6fTqUmTJkmS/vSnPykpKUmRkZG6//77tWDBgkueHP/BBx+od+/eCg8PV3JysubOnavKykrf+0rS/fffL8MwfOvbtm3T4MGD1aJFCzmdTvXp00dff/11g/wurkZQhSEAAJqSC6NDHo+nVu09Hk+DjQpdSVFRke6++25lZWVp69atGjJkiO69994qZ1Ak6aWXXlJKSoq2bt2q3/zmN1q/fr0mT56sKVOmKDs7W3feeaeee+65Kn3Wrl2rMWPGaMqUKdq1a5dee+01ZWZm+tpt3rxZkrR06VKdOHHCtz569Gi1a9dOmzdv1pYtWzRz5kyFhob6/XdxRSZqVFBQYEoyCwoKAl0KAMBPSktLzV27dpmlpaV17uv1es1+/fqZdrvdlFTtYrfbzX79+pler9cPe2CaS5cuNWNiYmps0717d/OVV17xrXfo0MEcPnx4lTYjR440hw0bVmXb6NGjq7z3HXfcYT7//PNV2vzlL38xExISfOuSzBUrVlRp06JFCzMzM7MWe1M7NR23unx/MzIEAMBVqO3oUGOOCknnR4Yef/xxXX/99YqNjVV0dLR27959ychQ3759q6zv2bNH/fv3r7Lth+vbtm3T008/rejoaN8yceJEnThxQiUlJdXWNH36dE2YMEFpaWl64YUXtH///qvcy4ZBGAIA4Cpdae5QQ88Vqo3HH39cK1as0PPPP6+1a9cqOztbPXr0UHl5eZV2UVFRdX7voqIizZ0713eFd3Z2tnbs2KG9e/cqPDy82n6//e1vtXPnTg0bNkyff/65brjhBq1YsaLOn9/QgupqMgAAmqIrXVnW2KNCkrR+/XqNHTtW999/v6TzAebQoUNX7Ne1a1ffHJ8Lfrjeu3dv7dmzR507d672fUJDQy87Wnbdddfpuuuu07Rp0zRq1CgtXbrUV2OgMDIEAEADqG50KBCjQpLUpUsXLV++XNnZ2dq2bZsefPBBeb3eK/Z75JFHtGrVKi1YsEB79+7Va6+9po8//rhKkJs9e7befPNNzZ07Vzt37tTu3bv1zjvv6KmnnvK16dixo7KyspSTk6OzZ8+qtLRUDz/8sNasWaPDhw9r/fr12rx5s66//nq/7H9dEIYAAGgA1c0dCsSokCQtWLBALVu21MCBA3XvvfcqPT1dvXv3vmK/H/3oR1qyZIkWLFiglJQUrV69WtOmTaty+is9PV0rV67U3//+d/Xr108333yz/vCHP6hDhw6+NvPnz9enn36qpKQk9erVS3a7XadPn9aYMWN03XXX6YEHHtDQoUM1d+5cv+x/XRimaZqBLqIpc7vdiomJUUFBgZxOZ6DLAQD4wblz53Tw4EF16tSpxjkvV2KapgYMGKBvvvlGHo9HdrtdvXv31qZNmxo9DDWkiRMn6rvvvtPatWsDXUoVNR23unx/MzIEAEAD+eHoUKBGha7WSy+9pG3btmnfvn165ZVX9Oc//1kZGRmBLstvCEMAADSgC3OHJAVkrlBD+Oqrr3TnnXeqR48eWrJkiRYtWqQJEyYEuiy/4WoyAAAakGEYev755/Xoo4/q+eefD7pRIUlatmxZoEtoVIQhAAAaWFpamnbt2hXoMlBLnCYDAACWRhgCAOBfuMA6uDTU8SIMAQAs78KT02t6rhaangvH68Lxqy/mDAEALM9utys2NlZ5eXmSpMjIyKCc+GwVpmmqpKREeXl5io2NrfaZcLVFGAIAQJLL5ZIkXyBC0xcbG+s7bleDMAQAgM5fEp+QkKC2bduqoqIi0OXgCkJDQ696ROgCwhAAABex2+0N9iWL4MAEagAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGmEIQAAYGlBF4YWL16sjh07Kjw8XAMGDNBXX31VbdvMzEwZhlFlCQ8Pb8RqAQBAUxdUYejdd9/V9OnTNWfOHH3zzTdKSUlRenq68vLyqu3jdDp14sQJ33L48OFGrBgAADR1QRWGFixYoIkTJ2rcuHG64YYbtGTJEkVGRuqNN96oto9hGHK5XL4lPj6+ESsGAABNXdCEofLycm3ZskVpaWm+bTabTWlpadq4cWO1/YqKitShQwclJSXpvvvu086dOxujXAAAECSCJgydOnVKHo/nkpGd+Ph45eTkXLZP165d9cYbb+iDDz7QX//6V3m9Xg0cOFDff/99tZ9TVlYmt9tdZQEAAM1X0ISh+khNTdWYMWPUs2dPDRo0SMuXL1dcXJxee+21avvMmzdPMTExviUpKakRKwYAAI0taMJQmzZtZLfblZubW2V7bm6uXC5Xrd4jNDRUvXr10r59+6ptM2vWLBUUFPiWo0ePXlXdAACgaQuaMBQWFqY+ffooKyvLt83r9SorK0upqam1eg+Px6MdO3YoISGh2jYOh0NOp7PKAgAAmq+QQBdQF9OnT1dGRob69u2r/v37a+HChSouLta4ceMkSWPGjNE111yjefPmSZKefvpp3XzzzercubPy8/P1+9//XocPH9aECRMCuRsAAKAJCaowNHLkSJ08eVKzZ89WTk6OevbsqdWrV/smVR85ckQ2278Hu86ePauJEycqJydHLVu2VJ8+fbRhwwbdcMMNgdoFAADQxBimaZqBLqIpc7vdiomJUUFBAafMAAAIEnX5/g6aOUMAAAD+QBgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWRhgCAACWVq8wdOLECf31r3/VqlWrVF5eXuW14uJiPf300w1SHAAAgL8ZpmmademwefNm3XXXXfJ6vaqoqNA111yj999/X927d5ck5ebmKjExUR6Pxy8FNza3262YmBgVFBTI6XQGuhwAAFALdfn+rvPI0JNPPqn7779fZ8+eVW5uru68804NGjRIW7durXfBAAAAgRJS1w5btmzR4sWLZbPZ1KJFC7366qtq37697rjjDn3yySdq3769P+oEAADwizqHIUk6d+5clfWZM2cqJCREd911l954440GKQwAAKAx1DkM3XjjjdqwYYNuuummKtsff/xxeb1ejRo1qsGKAwAA8Lc6zxkaM2aM1q9ff9nXZsyYoblz53KqDAAABI06X01WV+vXr1ffvn3lcDj8+TF+w9VkAAAEH79eTVZXQ4cO1bFjx/z9MQAAAPXi9zDk54EnAACAq8LjOAAAgKURhgAAgKURhgAAgKX5PQwZhtGg77d48WJ17NhR4eHhGjBggL766qsa27/33nvq1q2bwsPD1aNHD61atapB6wEAAMEtqCZQv/vuu5o+fbrmzJmjb775RikpKUpPT1deXt5l22/YsEGjRo3S+PHjtXXrVg0fPlzDhw/Xt99+22A1AQCA4Ob3+ww1pAEDBqhfv3764x//KEnyer1KSkrSI488opkzZ17SfuTIkSouLtbKlSt9226++Wb17NlTS5YsqdVncp8hAACCT6PcZ+j06dP61a9+pRtuuEFt2rRRq1atqiwNrby8XFu2bFFaWppvm81mU1pamjZu3HjZPhs3bqzSXpLS09OrbQ8AAKynXg9qlaSHHnpI+/bt0/jx4xUfH9/gc4N+6NSpU/J4PIqPj6+yPT4+Xt99991l++Tk5Fy2fU5OTrWfU1ZWprKyMt+62+2+iqoBAEBTV+8wtHbtWq1bt04pKSkNWU/AzZs3T3Pnzg10GQAAoJHU+zRZt27dVFpa2pC11KhNmzay2+3Kzc2tsj03N1cul+uyfVwuV53aS9KsWbNUUFDgW44ePXr1xQMAgCar3mHo1Vdf1X/913/pH//4h06fPi23211laWhhYWHq06ePsrKyfNu8Xq+ysrKUmpp62T6pqalV2kvSp59+Wm17SXI4HHI6nVUWAADQfNX7NFlsbKzcbrduv/32KttN05RhGPJ4PFdd3A9Nnz5dGRkZ6tu3r/r376+FCxequLhY48aNkySNGTNG11xzjebNmydJmjJligYNGqT58+dr2LBheuedd/T111/rf/7nfxq8NgAAEJzqHYZGjx6t0NBQvf32240ygVo6f6n8yZMnNXv2bOXk5Khnz55avXq1b5L0kSNHZLP9e7Br4MCBevvtt/XUU0/pySefVJcuXfT+++/rxhtv9HutAAAgONT7PkORkZHaunWrunbt2tA1NSncZwgAgODTKPcZ6tu3L5OLAQBA0Kv3abJHHnlEU6ZM0RNPPKEePXooNDS0yus33XTTVRcHAADgb/U+TXbx3BzfmxmGXydQBwKnyQAACD51+f6u98jQwYMH69sVAACgyah3GOrQoUND1gEAABAQdQpDH374oYYOHarQ0FB9+OGHNbb9yU9+clWFAQAANIY6zRmy2WzKyclR27ZtLztnyPemzBkCAAAB5Lc5Q16v97I/AwAABKt6zRnyer3KzMzU8uXLdejQIRmGoeTkZI0YMUIPPfRQo9yNGgAAoCHU+aaLpmnqJz/5iSZMmKBjx46pR48e6t69uw4dOqSxY8fq/vvv90edAAAAflHnkaHMzEx9+eWXysrK0uDBg6u89vnnn2v48OF68803NWbMmAYrEgAAwF/qPDL0t7/9TU8++eQlQUiSbr/9ds2cOVNvvfVWgxQHAADgb3UOQ9u3b9eQIUOqfX3o0KHatm3bVRUFAADQWOochs6cOaP4+PhqX4+Pj9fZs2evqigAAIDGUucw5PF4FBJS/VQju92uysrKqyoKAACgsdR5ArVpmho7dqwcDsdlXy8rK7vqogAAABpLncNQRkbGFdtwJRkAAAgWdQ5DS5cu9UcdAAAAAVHnOUMAAADNCWEIAABYGmEIAABYGmEIAABYGmEIAABYGmEIAABYGmEIAABYWp3vMwQAAJo3T0GBzIoKSZIREiJ7bGxgC/IzwhAAAJBpmvKeOaPyvXtVuGKFKo4ckUxTIYmJanHffQrr3l32Vq1k2JrfSSXCEAAAFmd6vao4dEinn31WZdu3V3mtYt8+lX75pUK7dFGbOXMU1rmzjBoe2B6Mml+8AwAAdVJ57JhOPvHEJUHoYhV79yrvscdUcfhwI1bWOAhDAABYmLe4WO6//KVWIceTm6v8P/1JnoKCRqis8RCGAACwMG9hoYo//7zW7UvXrZPX7fZjRY2PMAQAgIWVffutvPn5tW5vnjun0g0b/FdQABCGAACwsLoEoQs8Z840fCEBRBgCAMDCjKioOvexRUf7oZLAIQwBAGBhjhtvlBERUfsOISGKGDDAfwUFAGEIAAALs8XEKOKWW2rdPrxvX9nj4vxYUeMjDAEAYGF2p1MxGRmytWx5xbZGVJRix42TvRZtgwlhCAAAiwtNTlbbF16QPT6+2ja22FjFPfuswrp3b8TKGkfzup82AACoM1tYmMJSUpTw+usq+eILFX30kSq+//78s8kSEhSVnq6o9HTZ27SRzeEIdLkNjjAEAIAFeTym8vMrVVFhqrLSVFiYoYjoOLV44AFFDRki0+ORJBk2mwynU7bQ0ABX7D+EIQAALMQ0TZ08WaHs7CIdPVqms2crVVrq1eHD59SmTah++tM4deniVEwr60QE6+wpAAAWZ5qmcnPL9c/vzyiqQ6mKW+xWaUWhHIZDY9umqCjXoXffzdM11ziUkRGvli2b72jQxQzTNM1AF9GUud1uxcTEqKCgQE6nM9DlAABQb2fc5/R94Uk5oyWXzSGbx5TXMFUYaipz2zrtOvW9Hrx2iPatj5LdDNGDD8YrOtoe6LLrpS7f34wMAQBgAWWVFYoMO6fuMU6ZXsnrlSRTdq9XsafOaFq3H6k8zK7nN6/Wzak9deAfLeV2VwZtGKoLLq0HAMAC7JXlsnvDVOGRTp08pWOHDurYoYM6mXdSFVEt5TEdCi04p9m907Wz4J+6JT1U69YVqLLSG+jS/Y6RIQAAmjlP+Tl5TZtyjh5Rfl6uvJ6LAs6ZMzr5/VHFtG0rV7sk2UtLNLXHIL23f49CdZ2KiryKjW3eYyeEIQAAmiFPRblM779Dj81mKLFjByV27FBzx6hI2YoK1KlNjMIc5yddN3eEIQAAmhlPZaW8pnSuuETeiopa93NERys0LEym3aHerRJ01G7Ibjf8WGnTQBgCAKC5qayQDJvyCwuVn5dXqy5h4eFKjo1VhccjGYbCzDC1iDTldDb/qNC8TwICAGAx3spKmaZ0Li9PrWJjz2/zeq+4tHa5ZNhs2rV+vYoLCiTDLkdY87+STGJkCACAZsXr8aispETekBCF2GyKiYtTwdmzNfZxREQoJiZGlR6P5PWqorJSMgw5wyIbqerAIgwBANBMVBYVyfR6VVZSopzvvlOYw6G47t116vjxKpOpqzAMJbRrJ5thaHtWloyQEBl2u2QYCgmxxgkka+wlAABW4PWodMcOhZWUyFZaqtL8fHlKShTbunW1XSJatFBMTMz5uUKSJFPRMTEymuHT6atDGAIAoBnwFBfLLC2Vo0MHFW/YoJYulwzD0Ol9+9S6TRsZtst85RuG2iYkyGazade6dZKk6DZxCgsPl81mjflCEmEIAIBmwXA4VLxhozz5+XIkJioqKkr2ykqdc7urHR3yjQpVVko2m4yQELXt2FG2EOsEIYkwBABAs2ALCVHUj34k9+qPFd71OhVv3KhWiYkybLbLjw5dNCq084svZAsJUfuUFEVHRclut9aUYsIQAADNhBEVpbCOneQtKpYjKUlR0dHVjg5dPCoUd9116tyrl2JjYmQLCwvgHgQGYQgAgGbAW1kp02ZT1MCBcq9eVfPo0EWjQmZFheKcToWWlMgwvLJdbm5RM2e9PQYAoBmqPHdOx7/9ViePHVNIu/Y1jg5dPCqUm5Wl0n37ZAsLkz08KtC7ERCEIQAAglxFcbG+37BBhbm5OrV/v8L795f74+pHh+ITE8/PFXr+eVWWlMjRtq1skeGB3o2AIQwBABDEvJWVKj5zRsX5+bKFhcm02ZSfn6+QpMuPDtlMU06n8/wVZKap8LZtFda2reyOiEDvSsAQhgAACFKmacpTVqazR47IU1goT36+bDabTu3de9nRIVtIiELCwmQzDOV9/rlCnE616dVL9khrPHajOta6dg4AgGakMv+sPBWVOrNpk1RZKbOsTKFJSSo7e1ZnT55UxEWjQyHR0ZLTqZCwMJ05fVrR114rIyJCIeHhstmtdV+hH2JkCACAIFRZUKD8Ze/JU1go/eu5Y96iInmLixXmdOr0wYMK79fPNzp07ttv1bJ9e9lCQ3V21y6FRkerba9eComy5qTpixGGAAAIQpU5x3Vm+TIZdvv5B6v+S8X3R2WWlckeGXl+7lC7JHmLihXdv79sNpu2vf22QhwOOWJjFWLx02MXEIYAAAgynoJc5S97Q56cQ6o8flwtOnT494teUxWHD8uTlyd3To4iUlN17p97FBoXp8IzZ+Ro2VKxCQmy2+2yW/AGi5cTNGHozJkzGj16tJxOp2JjYzV+/HgVFRXV2Oe2226TYRhVlsmTJzdSxQAA+EH5aXkLvlfxV2tklp9W4cr/Ty07dpQMo0ozz5kzKt25U2ePHFFEj5tUXFCg49nZ8ubkKLptW9nDrXsp/Q8FTRgaPXq0du7cqU8//VQrV67Ul19+qUmTJl2x38SJE3XixAnf8uKLLzZCtQAA+IFpSmc3y5BX3pJieb2lKvzHZwoPDVVst26XBCJJOpWdrbO5udr3v/8reb1KvO022exB8/XfKILit7F7926tXr1ar7/+ugYMGKBbbrlFr7zyit555x0dP368xr6RkZFyuVy+xel0NlLVAAA0sIqzUs77kqdUtugYGTLkOXtAeS88L9d1XdTyhhukH1wZ5jl3Tic2bJDN4VDCTTcpJjFRIRHMFbpYUIShjRs3KjY2Vn379vVtS0tLk81m06ZNm2rs+9Zbb6lNmza68cYbNWvWLJWUlPi7XAAA/MP0SIW7Zavcoxa3DpZNNnk9RSrJ/kI5s2crLj5enYcOVeuUFIXHxSmsZUtFXnONXKmpuu4nP5GzbVsmTV9GUNxnKCcnR23btq2yLSQkRK1atVJOTk61/R588EF16NBBiYmJ2r59u379619rz549Wr58ebV9ysrKVFZW5lt3u91XvwMAADQIU/JWyFaQpZh7HtXpN1+TUVYss/KsSndk6eh/7lJU34Fy3n232vTrJyMsTN7iYpVu2iRbYoLkanvlj7CggIahmTNn6ne/+12NbXbv3l3v9794TlGPHj2UkJCgO+64Q/v379e111572T7z5s3T3Llz6/2ZAAD4jWGXQmOl4n0KaZWnuMnTlPfy8/LKK6+nUCoqVtGX36to498lI/R8F0mtxk6WvU0bhdiCYgyk0QX0t/LYY49p7NixNbZJTk6Wy+VSXl5ele2VlZU6c+aMXC5XrT9vwIABkqR9+/ZVG4ZmzZql6dOn+9bdbreSkpJq/RkAAPiNLVxqfYt0YrnsOYsVO+y/JD2pU68tlPdciUyZ8npLpbJSGTJkC4tQmwmz1OqhcQqJiQ109U1WQMNQXFyc4uLirtguNTVV+fn52rJli/r06SNJ+vzzz+X1en0Bpzays7MlSQkJCdW2cTgccjgctX5PAAAaTUiUlPAfUs4HUsVZhRx7Ti2H/EIt0laqYOVKFa9fI29RoYzIaEWl3qrYe4crJOFa2WNbBbryJs0wTdMMdBG1MXToUOXm5mrJkiWqqKjQuHHj1LdvX7399tuSpGPHjumOO+7Qm2++qf79+2v//v16++23dffdd6t169bavn27pk2bpnbt2ukf//hHrT/X7XYrJiZGBQUFXIkGAAi8ykLp+P+TDi6W9K+v8MhkeWPvkNd+nUx7hOQ5J7v3kGytb5CcN0l2691TqC7f30Fz8vCtt97Sww8/rDvuuEM2m00jRozQokWLfK9XVFRoz549vqvFwsLC9Nlnn2nhwoUqLi5WUlKSRowYoaeeeipQuwAAwNULaSEl3H8+4BxeKlWclkoOyFZy4N+XiEckSclTpRbdLRmE6ipoRoYChZEhAECTVFkieQql0+ukMxsl77nzQSnuzvOjQSFOyW7dx200y5EhAABwkZDI80vC/VJcmmR6JSNECm0R6MqCDmEIAIBgZtik0JhAVxHUguIO1AAAAP5CGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJYWNGHoueee08CBAxUZGanY2Nha9TFNU7Nnz1ZCQoIiIiKUlpamvXv3+rdQAAAQVIImDJWXl+tnP/uZfvGLX9S6z4svvqhFixZpyZIl2rRpk6KiopSenq5z5875sVIAABBMDNM0zUAXUReZmZmaOnWq8vPza2xnmqYSExP12GOP6fHHH5ckFRQUKD4+XpmZmfr5z39eq89zu92KiYlRQUGBnE7n1ZYPAAAaQV2+v4NmZKiuDh48qJycHKWlpfm2xcTEaMCAAdq4cWMAKwMAAE1JSKAL8JecnBxJUnx8fJXt8fHxvtcup6ysTGVlZb51t9vtnwIBAECTENCRoZkzZ8owjBqX7777rlFrmjdvnmJiYnxLUlJSo34+AABoXAEdGXrsscc0duzYGtskJyfX671dLpckKTc3VwkJCb7tubm56tmzZ7X9Zs2apenTp/vW3W43gQgAgGYsoGEoLi5OcXFxfnnvTp06yeVyKSsryxd+3G63Nm3aVOMVaQ6HQw6Hwy81AQCApidoJlAfOXJE2dnZOnLkiDwej7Kzs5Wdna2ioiJfm27dumnFihWSJMMwNHXqVD377LP68MMPtWPHDo0ZM0aJiYkaPnx4gPYCAAA0NUEzgXr27Nn685//7Fvv1auXJOmLL77QbbfdJknas2ePCgoKfG1mzJih4uJiTZo0Sfn5+brlllu0evVqhYeHN2rtAACg6Qq6+ww1Nu4zBABA8OE+QwAAALVEGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJZGGAIAAJYWEugCmjrTNCVJbrc7wJUAAIDauvC9feF7vCaEoSsoLCyUJCUlJQW4EgAAUFeFhYWKiYmpsY1h1iYyWZjX69Xx48fVokULGYYR6HIuy+12KykpSUePHpXT6Qx0OfgBjk/TxbFpujg2TVswHB/TNFVYWKjExETZbDXPCmJk6ApsNpvatWsX6DJqxel0Ntl/lOD4NGUcm6aLY9O0NfXjc6URoQuYQA0AACyNMAQAACyNMNQMOBwOzZkzRw6HI9Cl4DI4Pk0Xx6bp4tg0bc3t+DCBGgAAWBojQwAAwNIIQwAAwNIIQwAAwNIIQ0Hqueee08CBAxUZGanY2Nha9TFNU7Nnz1ZCQoIiIiKUlpamvXv3+rdQCzpz5oxGjx4tp9Op2NhYjR8/XkVFRTX2ue2222QYRpVl8uTJjVRx87Z48WJ17NhR4eHhGjBggL766qsa27/33nvq1q2bwsPD1aNHD61ataqRKrWeuhybzMzMS/5GwsPDG7Fa6/jyyy917733KjExUYZh6P33379inzVr1qh3795yOBzq3LmzMjMz/V5nQyIMBany8nL97Gc/0y9+8Yta93nxxRe1aNEiLVmyRJs2bVJUVJTS09N17tw5P1ZqPaNHj9bOnTv16aefauXKlfryyy81adKkK/abOHGiTpw44VtefPHFRqi2eXv33Xc1ffp0zZkzR998841SUlKUnp6uvLy8y7bfsGGDRo0apfHjx2vr1q0aPny4hg8frm+//baRK2/+6npspPM3+Lv4b+Tw4cONWLF1FBcXKyUlRYsXL65V+4MHD2rYsGEaPHiwsrOzNXXqVE2YMEGffPKJnyttQCaC2tKlS82YmJgrtvN6vabL5TJ///vf+7bl5+ebDofD/Nvf/ubHCq1l165dpiRz8+bNvm0ff/yxaRiGeezYsWr7DRo0yJwyZUojVGgt/fv3N3/1q1/51j0ej5mYmGjOmzfvsu0feOABc9iwYVW2DRgwwPzP//xPv9ZpRXU9NrX9bx0aliRzxYoVNbaZMWOG2b179yrbRo4caaanp/uxsobFyJBFHDx4UDk5OUpLS/Nti4mJ0YABA7Rx48YAVta8bNy4UbGxserbt69vW1pammw2mzZt2lRj37feektt2rTRjTfeqFmzZqmkpMTf5TZr5eXl2rJlS5V/8zabTWlpadX+m9+4cWOV9pKUnp7O30gDq8+xkaSioiJ16NBBSUlJuu+++7Rz587GKBdX0Bz+bng2mUXk5ORIkuLj46tsj4+P972Gq5eTk6O2bdtW2RYSEqJWrVrV+Ht+8MEH1aFDByUmJmr79u369a9/rT179mj58uX+LrnZOnXqlDwez2X/zX/33XeX7ZOTk8PfSCOoz7Hp2rWr3njjDd10000qKCjQSy+9pIEDB2rnzp1B8/zI5qq6vxu3263S0lJFREQEqLLaY2SoCZk5c+YlEwR/uFT3Hwr4l7+PzaRJk5Senq4ePXpo9OjRevPNN7VixQrt37+/AfcCCF6pqakaM2aMevbsqUGDBmn58uWKi4vTa6+9FujS0AwwMtSEPPbYYxo7dmyNbZKTk+v13i6XS5KUm5urhIQE3/bc3Fz17NmzXu9pJbU9Ni6X65IJoJWVlTpz5ozvGNTGgAEDJEn79u3TtddeW+d6IbVp00Z2u125ublVtufm5lZ7LFwuV53ao37qc2x+KDQ0VL169dK+ffv8USLqoLq/G6fTGRSjQhJhqEmJi4tTXFycX967U6dOcrlcysrK8oUft9utTZs21emKNKuq7bFJTU1Vfn6+tmzZoj59+kiSPv/8c3m9Xl/AqY3s7GxJqhJcUTdhYWHq06ePsrKyNHz4cEmS1+tVVlaWHn744cv2SU1NVVZWlqZOnerb9umnnyo1NbURKraO+hybH/J4PNqxY4fuvvtuP1aK2khNTb3kFhRB93cT6BncqJ/Dhw+bW7duNefOnWtGR0ebW7duNbdu3WoWFhb62nTt2tVcvny5b/2FF14wY2NjzQ8++MDcvn27ed9995mdOnUyS0tLA7ELzdaQIUPMXr16mZs2bTLXrVtndunSxRw1apTv9e+//97s2rWruWnTJtM0TXPfvn3m008/bX799dfmwYMHzQ8++MBMTk42f/zjHwdqF5qNd955x3Q4HGZmZqa5a9cuc9KkSWZsbKyZk5NjmqZpPvTQQ+bMmTN97devX2+GhISYL730krl7925zzpw5ZmhoqLljx45A7UKzVddjM3fuXPOTTz4x9+/fb27ZssX8+c9/boaHh5s7d+4M1C40W4WFhb7vFEnmggULzK1bt5qHDx82TdM0Z86caT700EO+9gcOHDAjIyPNJ554wty9e7e5ePFi0263m6tXrw7ULtQZYShIZWRkmJIuWb744gtfG0nm0qVLfeter9f8zW9+Y8bHx5sOh8O84447zD179jR+8c3c6dOnzVGjRpnR0dGm0+k0x40bVyWkHjx4sMqxOnLkiPnjH//YbNWqlelwOMzOnTubTzzxhFlQUBCgPWheXnnlFbN9+/ZmWFiY2b9/f/P//u//fK8NGjTIzMjIqNJ+2bJl5nXXXWeGhYWZ3bt3Nz/66KNGrtg66nJspk6d6msbHx9v3n333eY333wTgKqbvy+++OKy3y8XjkdGRoY5aNCgS/r07NnTDAsLM5OTk6t89wQDnloPAAAsjavJAACApRGGAACApRGGAACApRGGAACApRGGAACApRGGAACApRGGAACApRGGAACApRGGADQ7hmHo/fffD3QZAIIEYQhA0Bg7dqwMw5BhGAoNDVV8fLzuvPNOvfHGG/J6vb52J06c0NChQ/1Wx86dOzVixAh17NhRhmFo4cKFfvssAP5HGAIQVIYMGaITJ07o0KFD+vjjjzV48GBNmTJF99xzjyorKyVJLpdLDofDbzWUlJQoOTlZL7zwglwul98+B0DjIAwBCCoOh0Mul0vXXHONevfurSeffFIffPCBPv74Y2VmZkqqeprs0KFDMgxDy5Yt06233qqIiAj169dP//znP7V582b17dtX0dHRGjp0qE6ePFmrGvr166ff//73+vnPf+7X0AWgcRCGAAS922+/XSkpKVq+fHm1bebMmaOnnnpK33zzjUJCQvTggw9qxowZevnll7V27Vrt27dPs2fPbsSqATQVIYEuAAAaQrdu3bR9+/ZqX3/88ceVnp4uSZoyZYpGjRqlrKws/ehHP5IkjR8/3jeyBMBaGBkC0CyYpinDMKp9/aabbvL9HB8fL0nq0aNHlW15eXn+KxBAk0UYAtAs7N69W506dar29dDQUN/PF0LTD7ddfEUaAOsgDAEIep9//rl27NihESNGBLoUAEGIOUMAgkpZWZlycnLk8XiUm5ur1atXa968ebrnnns0ZsyYRqmhvLxcu3bt8v187NgxZWdnKzo6Wp07d26UGgA0HMIQgKCyevVqJSQkKCQkRC1btlRKSooWLVqkjIwM2WyNM9h9/Phx9erVy7f+0ksv6aWXXtKgQYO0Zs2aRqkBQMMxTNM0A10EAABAoDBnCAAAWBphCAB+IDo6utpl7dq1gS4PQAPjNBkA/MC+ffuqfe2aa65RREREI1YDwN8IQwAAwNI4TQYAACyNMAQAACyNMAQAACyNMAQAACyNMAQAACyNMAQAACyNMAQAACyNMAQAACzt/wf0YmY3TYgSUgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# time to cry\n",
    "# I probably messed up the original loss. Went over it multiple times\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "sns.scatterplot(emb_features, x = 'Dim_1', y = 'Dim_2', s = 100, alpha = 0.8, hue = 'sub', palette = 'nipy_spectral', label='Features')\n",
    "sns.scatterplot(emb_targets, x = 'Dim_1', marker = 'v', y = 'Dim_2', s = 100, alpha = 0.8, hue = 'sub', palette = 'nipy_spectral', label='Targets')\n",
    "plt.xlim(-1.2, 1.2)\n",
    "plt.ylim(-1.2, 1.2)\n",
    "\n",
    "feature_handle = mlines.Line2D([], [], color='black', marker='o', linestyle='None', markersize=10, label='Features')\n",
    "target_handle = mlines.Line2D([], [], color='black', marker='v', linestyle='None', markersize=10, label='Targets')\n",
    "\n",
    "plt.legend(handles=[feature_handle, target_handle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
